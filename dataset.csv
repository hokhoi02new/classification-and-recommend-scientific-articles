"In order to test this hypothesis , our source and target texts were POS - tagged using Freeling 3 . 0 suite of language analyzers ( Padr ´ o and Stanilovsky , 2012 ). Freeling gives comparatively good results in English and Russian POS - tagging , using Markov trigram scheme trained on large disambiguated corpus . Freeling tag set for English follows that of Penn TreeBank , while Russian tag set , according to Freeling manual , corresponds to EAGLES recommendations for morphosyntactic annotation of corpora described on ( Monachini and Calzolari , 1996 ). It is not trivial to project one scheme onto another completely , except for the main content words – nouns , verbs and adjectives . Moreover , these three parts of speech are the ones used in the paper by Chen and Chen ( 1994 ), mentioned above .",Material,Data,Introduce,Vocabulary Choice as an Indicator of Perspective,https://www.dialog-21.ru/digests/dialog2013/materials/pdf/KutuzovAB.pdf
"Large scale annotated corpora , e . g ., the Penn TreeBank ( PTB ) project ( Marcus et al . 1993 ), have played an important role in text - mining . The Penn Discourse Treebank ( PDTB ) ( ) ( Prasad et al . 2008a ) annotates the argument structure , semantics , and attribution of discourse connectives and their arguments . The current release of PDTB2 . 0 contains the annotations of 1 , 808 Wall Street Journal articles (~ 1 million words ) from the Penn TreeBank ( Marcus et al .",Material,Data,Introduce,A Pilot Annotation to Investigate Discourse Connectivity in Biomedical Text,https://dl.acm.org/doi/pdf/10.5555/1572306.1572325
"The corpora are detailed in Table 1 . Links to descriptions of the corpora can be found at bakeoff_instr . html ; publications on specific corpora are ( Huang et al ., 1997 ) ( Academia Sinica ), ( Xia , 1999 ) ( Chinese Treebank ); the Beijing University standard is very similar to that outlined in ( GB / T 13715 – 92 , 1993 ). Table 1 lists the abbreviations for the four corpora that will be used throughout this paper . The suffixes “ o ” and “ c ” will be used to denote open and closed tracks , respectively : Thus “ ASo , c ” denotes the Academia Sinica corpus , both open and closed tracks ; and “ PKc ” denotes the Beijing University corpus , closed track .",Material,Data,Introduce,The First International Chinese Word Segmentation Bakeoff,https://aclanthology.org/W03-1719.pdf
"Training of a classifier (’ language annotator ’) in a supervised framework , requires a set of annotated entries with a distribution similar to the set of entries to be annotated . We know of only two such databases which can be freely accessed6 ; WALS and the library catalogue of MPI / EVA in Leipzig . WALS : The bibliography for the World Atlas of Language Structures book can now be accessed online ( ). This database contains 5633 entries annotated to 2053 different languages . MPI / EVA : The library catalogue for the library of the Max Planck Institute for Evolution Anthropology ( http :// biblio . eva . mpg . de /) is queryable online .",Material,Data,Introduce,Automatic Annotation of Bibliographical References with Target Language,https://aclanthology.org/W08-1409.pdf
"http :// www . hf . uio . no / tekstlab / for an overview ). To our knowledge , the largest existing written corpus of Norwegian is the Norsk Aviskorpus ( Hofland 2000 , cf . ), an expanding newspaper - based corpus currently containing 700 million words . However , the Norsk Aviskorpus is only available though a dedicated web interface for non commercial use , and advanced research tasks cannot be freely carried out on its contents . Even though we have only worked on building a web corpus for Bokmål Norwegian , we intend to apply the same procedures to create web - corpora also for Nynorsk and North Sami , thus covering the whole spectrum of written languages in Norway .",Material,Data,Introduce,NoWaC: a large web-based corpus for Norwegian,https://aclanthology.org/W10-1501.pdf
"in data recording , storage , and coding methods in recent decades . Thanks to corpora and tools such as those developed in the context of the CHILDES project ( ), researchers in areas such as morphology and syntax have enjoyed a convenient and powerful method to analyze the morphosyntactic properties of adult languages and their acquisition by first and second language learners . In the area of phonetics , the Praat system ( http :// www . fon . hum . uva . nl / praat /) has expanded our abilities to conduct phonological modeling , computational simulations based on a variety of theoretical approaches , and articulatory synthesis . In this rapidly - expanding software universe , phonologists interested in the organization of sound systems ( e . g .",Material,Data,Introduce,Phon 1.2: A Computational Basis for Phonological Database Elaboration and Model Testing,https://aclanthology.org/W07-0603.pdf
"The whole evaluation Wolf Moon T - shirt is the clearest example . This item corpus is integrated with 8 , 861 documents . It is became one of the most popular products , both in available at Amazon as well as in social networks , due to the 4 Model ironic reviews posted by people1 . We define a model with six categories which atOur positive data are thus integrated with reviews tempts to represent irony from different linguistic of five different products published by Amazon .",Material,Data,Introduce,Mining Subjective Knowledge from Customer Reviews: A Specific Case of Irony Detection,https://aclanthology.org/W11-1715.pdf
"Automatic evaluation of the results was performed against a gold standard lexicon of health - related terms that was obtained from the top - ranking nouns in the English health domain model of the initial corpus and that at the same time appeared in the comprehensive dictionary of medical terms mediLexicon2 and were missing from the general bilingual seed dictionary . The gold standard 2 [ 1 . 4 . 2010 ] contains 360 English single - word terms with their translations into Slovene . If more than one translation variant is possible for a single English term , all variants appear in the gold standard and any of these translations suggested by the algorithm is considered as correct . Below we present the results of three experiments that best demonstrate the performance and impact of the key parameters for bilingual lexicon extraction from comparable corpora that we were testing in this research .",Material,Data,Introduce,Building and using comparable corpora for domain-specific bilingual lexicon extraction,https://aclanthology.org/W11-1204.pdf
"Both annotators disagreed in only 2 % of the cases . The numbers of annotations , including their distribution over positive and negative instances , are summarized in Table 3 . The corpus is made publicly available at_CITE_ 2673424 ( Hartung and Zwick , 2014 ). In order to alleviate the imbalance of positive and negative examples in the data , additional positive examples have been gathered by manually searching PubMed7 . At this point , special attention has been paid to extract only instances denoting the correct gene / protein corresponding to the full long name , as we are interested in assessing the impact of examples of a particularly high quality .",Material,Data,Introduce,Towards Gene Recognition from Rare and Ambiguous Abbreviations using a Filtering Approach,https://aclanthology.org/W14-3418.pdf
"In fact , the adherence to one model rather than another has an impact on who should be performing the evaluation . Senseval - 2 was in line with Putnam ’ s view of ‘ division of linguistic labour ’ by relying on lexicographers ’ judgments to build a gold standard ( Kilgarrif , 1998 ). On the other hand , Senseval - 3 collected data via Open - Mind Initiative , which was much more in line with Fodor ’ s view that any common people can use their own similarity metric to disambiguate polysemous terms . Interestingly , a recent empirical study ( Murray and Green 2004 ) showed how judgments by ordinary people were consistent among themselves but different from the one of lexicographers . It is important to decide who the best judges are ; a decision which can certainly be based on the foreseen application , but also , as we suggest here , on some theoretical grounds .",Material,Data,Introduce,"Similarity judgments: philosophical, psychological and mathematical investigations",https://aclanthology.org/W06-1103.pdf
"Speakerindependent triphones are used as acoustic models . The Finnish , Estonian , and Turkish data sets contain planned speech , i . e ., written text read aloud . By contrast , the Arabic data consists of transcribed spontaneous telephone conversations , which are characterized by disfluencies and by the presence of “ non - speech ”, such as laugh and cough sounds . There are multiple speakers in the Arabic data , and online speaker adaptation has been performed . The n - gram language models are trained using the SRILM toolkit ( Stolcke , 2002 ) ( Fin1 , Fin2 , Tur1 , Tur2 , ECA ) or similar software developed at HUT ( Siivola and Pellom , 2005 ) ( Fin3 , Fin4 , Est ).",Material,Data,Introduce,Analysis of Morph-Based Speech Recognition and the Modeling of Out-of-Vocabulary Words Across Languages,https://aclanthology.org/N07-1048/
"For example , the CUI for “ Original ,” another term mapped from the caption shown in Figure 1 , is “ C0205313 .” Our results indicate that “ C0205313 ,” which occurs 19 times in our evaluation data , never identifies a useful indexing term . F . 2 Semantic Type ( nominal ): The concept ’ s semantic categorization . There are currently 132 different semantic types in the UMLS Metathesaurus . For example , The semantic type of “ Original ” is “ Idea or Concept .” F . 3 Presence in Caption ( nominal ): true if the phrase that generated the concept is located in the image caption ; false if the phrase is located in the image mention . F . 4 MeSH Ratio ( real ): The ratio of words ci in the concept c that are also contained in the Medical Subject Headings ( MeSH terms ) M assigned to the document to the total number of words in the concept .",Material,Data,Introduce,Using Non-lexical Features to Identify Effective Indexing Terms for Biomedical Illustrations,https://aclanthology.org/E09-1084.pdf
"This often involves user interaction to support the system ’ s interpretation , as in ( Damljanovic et al ., 2010b ). A crucial question is to figure out whether open domain QA techniques , which leverage statistical methods and require minimal ( if any ) intervention at design stage , can be successfully combined with semantic search techniques , in order to leverage the benefits of both . In this perspective , the development and widespread usage of vast knowledge bases such as DBPedia , GeoNames and YAGO ( Suchanek et al ., 2007 ) demonstrates that semantics can encompass universal vocabularies and domains , opening the way to open - domain search . Recent initiatives such as the W3C Linked Open Data community project are fostering the adoption of Linked Data ( LD ) as a best practice . Clearly , the widespread presence of data services makes them a valuable resource for IR ; however , the problems typically addressed in this field concern service discovery ( Carenini et al ., 2008 ), automatic composition ( Martin et al ., 2007 ; Fensel et al ., 2011 ) and mediation ( Manolescu et al ., 2005 ) rather than the issue of interfacing to data services .",Material,Data,Introduce,"Question Answering, Semantic Search and Data Service Querying",https://aclanthology.org/W11-3102.pdf
"Efforts in building large Chinese corpora started in the 90s , for example , the Sinica corpus ( CKIP , 1995 ) and the Chinese Penn Tree Bank ( Xia et al ., 2000 ). However , these two corpora concentrate on the tagging of parts - of - speech and syntactic structures , while little work has been done on semantic annotation . Of the few efforts that were carried out , Lua annotated 340 , 000 words with semantic classes defined in a thesaurus ( Mei , 1983 ). This resource , however , was not publicly accessible . With the release of HowNet ( Dong , 1999 ; Dong , 2000 ) in YANG Yongsheng Department of Computer Science , HKUST , Clear Water Bay , Hong Kong .",Material,Data,Introduce,Annotating information structures in Chinese texts using HowNet,https://aclanthology.org/W00-1213.pdf
"( Roche et al ., 2009 ) The aim of checking a report for its completeness of content includes the need to determine what content is required . The CAP ( College of American Pathologists ) offers some cancer protocols , which specify the content of pathology reports for different cancer types . Moreover , the ICCR group ( International Collaboration on Cancer Reporting ) has published five datasets for reporting different types of cancer . These determine which information is required in a report and which information is just considered to be recommended . Daniel and Macary ( 2011 ) created a terminology called PathLex , which covers the scope of anatomic pathology observations and speci men collection procedures .",Material,Data,Introduce,Checking a structured pathology report for completeness of content using terminological knowledge,https://aclanthology.org/W15-2613.pdf
"These relations form a hierarchical structure with the most general relation at the root . There are various argument relations like subject , object , objects of prepositions , and clausal complements , modifier relations like adjectival , adverbial , participial , and infinitival modifiers , and other relations like coordination , conjunct , expletive , and punctuation . UNL : The 44 UNL relations include relations such as agent , object , co - agent , and partner , temporal relations , locative relations , conjunctive and disjunctive relations , comparative relations and also hierarchical relationships like part - of and aninstance - of . Comparison : Unlike the Stanford parser which expresses the semantic relationships through grammatical relations , UNL uses attributes and universal words , in addition to the semantic roles , to express the same . Universal words are used to disambiguate words , while attributes are used to express the speaker ’ s point of view in the sentence .",Material,Data,Introduce,Case markers and Morphology: Addressing the crux of the fluency problem in English-Hindi SMT,https://aclanthology.org/P09-1090.pdf
"The respective dependency parse tree is included through following the shortest dependency path hypothesis ( Bunescu and Mooney , 2005 ), by using the syntactical and dependency information of edges ( e ) and vertices ( v ). So - called v - walks and e - walks of length 3 are created as well as n grams along the shortest path ( Miwa et al ., 2010 ). One of the most important source of publications in the biomedical domain is MEDLINE , currently containing more than 21 million citations . The initial step is annotation of named entities – in our case performed by ProMiner ( Hanisch et al ., 2005 ), a tool proving state - of - the - art results in e . g . the BioCreative competition ( Fluck et al ., 2007 ). Based on the named entity recognition , only sentences containing co - occurrences are further processed .",Material,Data,Introduce,Improving Distantly Supervised Extraction of Drug-Drug and Protein-Protein Interactions,https://aclanthology.org/W12-0705.pdf
"The opinion score is calculated using the number of opinion words normalized by the total number of words in candidate sentence . For lexicon - based opinion analysis , the selection of opinion thesaurus plays an important role in the final performance . HowNet is a knowledge database of the Chinese language , and provides an online word list with tags of positive and negative polarity . We use the English translation of those sentiment words as the sentimental lexicon . SentiWordNet ( Esuli and Sebastiani , 2006 ) is another popular lexical resource for opinion mining .",Material,Data,Introduce,Answering Opinion Questions with Random Walks on Graphs,https://aclanthology.org/P09-1083.pdf
YourDictionary . com lists about five such dictionaries . Most of them are narrowdomain dictionaries . The Google directory lists seven dictionaries . Rjecnik . com is the oldest one in these language pairs and is still active and expanding . Tkusmic . com was created in 2003 and has a very similar interface .,Material,Data,Introduce,R{j}ecnik.com: English—Serbo-Croatian Electronic Dictionary,https://aclanthology.org/W04-2112.pdf
"We modeled our approach based on the features motivated by the morphological complexity of Estonian . To our knowledge , this is the first work that studies the role of morphology based features for proficiency classification in general and in Estonian in particular . The Estonian Interlanguage Corpus ( EIC ) was created by the Talinn University . It is a collection of written texts produced by learners of Estonian as a second language . Most of the learners were native speakers of Russian .",Material,Data,Introduce,Role of Morpho-Syntactic Features in Estonian Proficiency Classification,https://aclanthology.org/W13-1708.pdf
"Ai are the parameters need to be estimated which reflects the importance of fi ( c , d ) in prediction . Li and Roth ( 2002 ) have developed a machine learning approach which uses the SNoW learning architecture . They have compiled the UIUC question classification dataset which consists of 5500 training and 500 test questions . All questions in the dataset have been manually labeled according to the coarse and fine grained categories as shown in Table 1 , with coarse classes ( in bold ) followed by their fine classes . The UIUC dataset has laid a platform for the follow - up research including ( Hacioglu and Ward , 2003 ; Zhang and Lee , 2003 ; Li and Roth , 2006 ; Krishnan et al ., 2005 ; Moschitti et al ., 2007 ).",Material,Data,Introduce,Investigation of Question Classifier in Question Answering,https://aclanthology.org/D09-1057.pdf
"It was created by manually identifying the emotions of a few seed words and then marking all their WordNet synonyms as having the same emotion . The General Inquirer ( Stone et al ., 1966 ) has 11 , 788 words labeled with 182 categories of word tags , including positive and negative semantic orientation . It also has certain other affect categories , such as pleasure , arousal , feeling , and pain but these have not been exploited to a significant degree by the natural language processing community . Work in emotion detection can be roughly classified into that which looks for specific emotion denoting words ( Elliott , 1992 ), that which determines tendency of terms to co - occur with seed words whose emotions are known ( Read , 2004 ), that which uses hand - coded rules ( Neviarouskaya et al ., 2009 ), and that which uses machine learning and a number of emotion features , including emotion denoting words ( Alm et al ., 2005 ). Much of this recent work focuses on six emotions studied by Ekman ( 1992 ).",Material,Data,Introduce,Aligning an Italian WordNet with a lexicographic dictionary: Coping with limited data,https://hal.science/hal-01140354/
"Each synset is accompanied by a gloss describing its meaning and , when present , one or more examples of use . Only 3 , 177 glosses ( 8 , 21 %) are in Italian and , in particular , 402 for verbs and 2 , 481 for nouns . The SCDM lexicon is part of a larger research initiative , Senso Comune ( Oltramari et al . ( 2013 )). Senso Comune aims at building an open knowledge base for the Italian language , designed as a crowd - sourced initiative that stands on the solid ground of an ontological formalization and wellestablished lexical resources .",Material,Data,Introduce,Senso Comune: A Collaborative Knowledge Resource for Italian,https://www.researchgate.net/publication/236585168_Senso_Comune_A_Collaborative_Knowledge_Resource_for_Italian
"Thanks to the fact that it is translated into English , it is open to international audiences . To the best of our knowledge , most correspondence seminars are organised in the area of former Czechoslovakia . The Slovak seminars include KMS ( mathematics ), FKS ( physics ), and STROM ( mathematics ). The last mentioned one claims to have the longest tradition in the area of former Czechoslovakia , having been established in 1976 . Correspondence seminars organised in the Czech Republic include MKS ( mathematics ; founded 1981 ), FYKOS ( physics ; 1986 ), and KSICHT ( chemistry ; 2002 ; cf .",Material,Data,Introduce,Correspondence Seminar: Bringing Linguistics to High Schools,https://aclanthology.org/W13-3407.pdf
"In order to perform the task , participants are required to resolve entity coreference , as timelines should contain events involving all coreferring textual mentions of the target entities ( including pronominal mentions ). For example , in Figure 1 , the event fighting involving the target entity Steve Jobs mentioned as he is included in the timeline together with other events also referring to Steve Jobs . The dataset released for this task is composed of 120 Wikinews articles and 44 target entities . 30 documents and 6 target entities ( each associated to a timeline ) are provided as trial data , while the evaluation dataset consist of 90 documents and 38 target entities ( each associated to a timeline ). We manually selected a set of target entities that appeared in at least two different documents and were involved in more than two events .",Material,Data,Introduce,SemEval-2015 Task 4: TimeLine: Cross-Document Event Ordering,https://aclanthology.org/S15-2132.pdf
"While Romanian normally has diacritical markings , this particular newspaper does not include those in their online edition , so the alphabet used was the same as English . The Bulgarian data is from the Sega 2002 news corpus , which was originally prepared for the CLEF competition . This is a corpus of news articles from the Newspaper Sega , which is based in Sofia , Bulgaria . The Bulgarian text was transliterated ( phonetically ) from Cyrillic to the Roman alphabet . Thus , the alphabet used was the same as English , although the phonetic transliteration leads to fewer cognates and borrowed English words that are spelled exactly the same as in English text .",Material,Data,Introduce,Improving Name Discrimination: A Language Salad Approach,https://aclanthology.org/W06-2004.pdf
"While some progress has been made toward enabling syntactic interoperability via the development of standard representation formats ( e . g ., ISO LAF / GrAF ( Ide and Suderman , 2014 ; ISO - 24612 , 2012 ), NLP Interchange Format ( NIF ) ( Hellmann et al ., 2013 ), UIMA Common Analysis System ( CAS )) which , if not identical , can be trivially mapped to one another , semantic interoperability among NLP tools remains problematic ( Ide and Pustejovsky , 2010 ). A few efforts to create repositories , type systems , and ontologies of linguistic terms ( e . g ., ISOCat , OLiA , various repositories for UIMA type systems , GOLD , NIF Core Ontology ) have been undertaken to enable ( or provide ) a mapping among linguistic terms , but none has yet proven to include all requisite terms and relations or be easy to use and reference . General repositories such as Dublin Core , schema . org , and the Friend of a Friend This work is licensed under a Creative Commons Attribution 4 . 0 International License . Page numbers and proceedings footer are added by the organizers . License details : http :// creativecommons . org / licenses / by / 4 . 0 / See , for example , proceedings of the recent LREC workshop on “ Language Technology Service Platforms : Synergies , Standards , Sharing ” ( http :// www . ilc . cnr . it / ltsp2014 /).",Material,Data,Introduce,The Language Application Grid Web Service Exchange Vocabulary,https://aclanthology.org/W14-5204.pdf
The third stage puts together all possible tags for a sequence of tokens and chooses the best one according to the probability which was computed from the output of the classifiers ( before thresholding ) via a Sigmoid function . The paper reports evaluation results on three corpora covering different IE tasks – named entity recognition ( CoNLL - 2003 ) and template filling or scenario templates in different domains ( Jobs and CFP ). The CoNLL - 2003 provides the most recent evaluation results of many learning algorithms on named entity recognition . The Jobs corpus has also been used recently by several learning systems . The CFP corpus was created as part of the recent Pascal Challenge for evaluation of machine learning methods for IE .,Material,Data,Introduce,Using Uneven Margins SVM and Perceptron for Information Extraction,https://aclanthology.org/W05-0610.pdf
"KB BIO 101 is organized into a set of concept maps , where each concept map corresponds to a biological entity or process . It was encoded by biology teachers and contains around 5 , 000 concept maps . KB BIO 101 is available for download for academic purposes in various formats including OWL . To test and evaluate our approach , we focus on the subpart of KB BIO 101 isolated for the KBGEN surface realisation shared task by ( Banik et al ., 2013 ). In this dataset , content units were semiautomatically selected from KB BIO 101 in such a way that ( i ) the set of relations in each content unit forms a connected graph ; ( ii ) each content unit can be verbalised by a single , possibly complex sentence which is grammatical and meaningful and ( iii ) the set of content units contain as many different relations and concepts of different semantic types ( events , entities , properties , etc ) as possible .",Material,Data,Introduce,A Domain Agnostic Approach to Verbalizing n-ary Events without Parallel Corpora,https://hal.inria.fr/hal-01207155/
"Articles might be deleted only by Wikipedia administrators if they are subject to copyright violations , vandalism , spam or other conditions that violate Wikipedia policies . As a consequence , they are removed from the public view along with all their revision information , which makes it impossible to recover them from any future publicly available dump . Even though about five thousand pages are deleted every day , only a small percentage of those pages actually corresponds to meaningful articles . Most of the affected pages are newly created duplicates of already existing articles or spam articles . Even though article revisions are available from the official Wikipedia revision dumps , accessing this information on a large scale is still a difficult task .",Material,Data,Introduce,Modern Information Technologies and Innovation Methodologies of Education in Professional Training Methodology Theory Experience Problems,https://vspu.net/sit/index.php/sit/article/view/3783
"The system is best on Greek and worst on Upper Midwest corpus , and its overall performance for place names is higher than the most of other applications . The KIM Platform provides a novel Knowledge and Information Management ( KIM ) infrastructure and services for automatic semantic annotation , indexing and retrieval of unstructured and semi - structured content . The ontologies and knowledge bases are kept in Semantic repositories based on cutting edge Semantic Web technology and standards , including RDF ( S ) repositories , ontology middleware ( Kiryakov et al , 2002 ) and reasoning . It provides a mature infrastructure for scalable and customizable information extraction as well as annotation and document management , based on GATE ( Cunningham et al ., 2002 ). GATE , a General Architecture for Text Engineering , is developed by the Sheffield NLP group and has been used in many language processing projects ; in particular for Information Extraction in a variety of languages ( Maynard and Cunningham , 2003 ).",Material,Data,Introduce,Experiments with geographic knowledge for information extraction,https://aclanthology.org/W03-0101.pdf
"Finally , the corpus is applied in several tasks , such as generation of emotion object ontology or retrieval of emotional and moral consequences of actions . There is a lack of large corpora for Japanese applicable in sentiment and affect analysis . Although there are large corpora of newspaper articles , like Mainichi Shinbun Corpus , or corpora of classic literature , like Aozora Bunko , they are usually unsuitable for research on emotions since spontaneous emotive expressions either appear rarely in these kinds of texts ( newspapers ), or the vocabulary is not up to date ( classic literature ). Although there exist speech corpora , such as Corpus of Spontaneous Japanese , which could become suitable for this kind of research , due to the difficulties with compilation of such corpora they are relatively small . In research such as the one by Abbasi and Chen ( 2007 ) it was proved that public Internet services , such as forums or blogs , are a good material for affect analysis because of their richness in evaluative and emotive information .",Material,Data,Introduce,Automatically Annotating A Five-Billion-Word Corpus of Japanese Blogs for Affect and Sentiment Analysis,https://aclanthology.org/W12-3714.pdf
"Organizing bioscience images is not a new task . Related work includes the building of domainspecific image databases . For example , the Protein Data Bank ( PDB ) ( Sussman et al ., 1998 ) stores 3 - D images of macromolecular structure data . WebPath is a medical web - based resource that has been created by physicians to include over 4 , 700 gross and microscopic medical images . Textbased image search systems like Google ignore image content .",Material,Data,Introduce,Exploring Text and Image Features to Classify Images in Bioscience Literature,https://aclanthology.org/W06-3310.pdf
or word vectors trained by the model of Collobert and Weston ( 2008 ) and provided by Turian et al . ( 2010 ). These vectors were trained on an unlabeled corpus of the English Wikipedia . Note that alternatives such as Brown clusters are not suitable since they do not capture sentiment information ( good and bad are usually in the same cluster ) and cannot be modified via backpropagation . The confessions section of the experience project website lets people anonymously write short personal stories or “ confessions ”.,Material,Data,Introduce,Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions,https://aclanthology.org/D11-1014.pdf
"There are four types of slots for morphemes : ( 1 ) derivational prefixes ( four slots ), ( 2 ) the lexical part ( three slots – in the majority of cases only one is filled , the three slots are provided for verbal compounds of two roots and an interfix ), ( 3 ) derivational and conjugational suffixes ( three slots ), and ( 4 ) infinitive ending ( one slot ). The metadata in lexical entries indicate verbal aspect and types of reflexivity . The database enables queries across the full derivational span of a particular base form and provides extensive data about the distribution and frequency of affixes in the derivation of Croatian verbs . In the following section , the underlying analysis of affixal meanings is described . The majority of verbal prefixes in Croatian developed from prepositions , and the original locative component pervades in their meaning .",Material,Data,Introduce,Morphosemantic relations between verbs in Croatian WordNet,https://aclanthology.org/W14-0136.pdf
"We chose GermanEnglish translation for the experiments in this paper . The following details the resources used . The LEO bilingual German - English dictionary is an ongoing volunteer effort . While it is still not finished , it already provides an outstanding resource with over 230 , 000 entries . Bilingual dictionaries may not be easily available for other language pairs , especially for lowdensity languages .",Material,Data,Introduce,Knowledge sources for word-level translation models,https://aclanthology.org/www.mt-archive.info/EMNLP-2001-Koehn.pdf
"Nevertheless , most of the work has focused on the task of factoid QA , where questions match short answers , usually in the form of named or numerical entities . Thanks to international evaluations organized by conferences such as the Text REtrieval Conference ( TREC ) and the Cross Language Evaluation Forum ( CLEF ) Workshop , annotated corpora of questions and answers have become available for several languages , which has facilitated the development of robust machine learning models for the task . The situation is different once one moves beyond the task of factoid QA . Comparatively little research has focused on QA models for non - factoid questions such as causation , manner , or reason questions . Because virtually no training data is available for this problem , most automated systems train either on small hand - annotated corpora built in - house ( Higashinaka and Isozaki 2008 ) or on question – answer pairs harvested from Frequently Asked Questions ( FAQ ) lists or similar resources ( Soricut and Brill 2006 ; Riezler et al .",Material,Data,Introduce,Learning to Rank Answers on Large Online QA Collections,https://aclanthology.org/P08-1082.pdf
"However , this library pursues a slightly different strategy by providing Ruby accessor methods to a data collection internally represented in RDF . In contrary , POSEIdON provides a simple way of getting an additional representation ( in RDF ) from an already existing library or data source in a read - only fashion , without modifying the source code of existing classes . Such data interfaces are typically based on XML documents or relational databases which are accessed with standard libraries ( e . g ., Nokogiri for XML or ActiveRecord for SQL databases ). A modifi markup URIs ( line 3 ) or to express rules for the export of instance properties ( lines 4 - 8 ). — ( b ) The RDF resulting from these POSEIdON instructions .",Material,Data,Introduce,Releasing multimodal data as Linguistic Linked Open Data: An experience report,https://aclanthology.org/W13-5507.pdf
"Banko and Brill ( 2001a , 2001b ) experiment with context - sensitive spelling correction , a task for which large amounts of data can be obtained straightforwardly , as no manual annotation is required . They demonstrate that the learning algorithms typically used for spelling correction benefit significantly from larger training sets , and that their performance shows no sign of reaching an asymptote as the size of the training set increases . Arguably , the largest data set that is available for NLP is the Web , which currently consists of at least 3 , 033 million pages . Data retrieved from the Web therefore provide enormous potential for training NLP algorithms , if Banko and Brill ’ s ( 2001a , 2001b ) findings for spelling corrections generalize ; potential applications include tasks that involve word n - grams and simple surface syntax . There is a small body of existing research that tries to harness the potential of the Web for NLP .",Material,Data,Introduce,Using the Web to Obtain Frequencies for Unseen Bigrams,https://aclanthology.org/J03-3005.pdf
"ROUGE scores , based on n - gram overlap between human abstracts and automatic extracts , were also calculated for comparison [ 5 ]. ROUGE2 , based on bigram overlap , is considered the most stable as far as correlating with human judgments , and this was therefore our ROUGE metric of interest . ROUGE - SU4 , which evaluates bigrams with intervening material between the two elements of the bigram , has recently been shown in the context of the Document Understanding Conference ( DUC ) to bring no significant additional information as compared with ROUGE - 2 . Results from [ 4 ] and from DUC 2005 also show that ROUGE does not always correlate well with human judgments . It is therefore included in this research in the hope of further determining how reliable the ROUGE metric is for our domain of meeting summarization .",Material,Data,Introduce,Incorporating Speaker and Discourse Features into Speech Summarization,https://aclanthology.org/N06-1047.pdf
"However , Hussain ( 2008 ) has done a good job in assimilating most of the resources available on the internet . The lexicon provided as a part of the EMILLE ( 2003 ) data set for Urdu has about 200 , 000 words . CRL has released a lexicon of 8000 words as a part of their Urdu data collection . They also provide an NE tagged data set mostly used for morphological analysis . The lexicon includes POS information as well .",Material,Data,Introduce,NE Tagging for Urdu based on Bootstrap POS Learning,https://aclanthology.org/W09-1609.pdf
"Beside the common task of identifying POS and of reducing this set to NEs , they provide more and more disambiguation facility with URIs that describe web resources , leveraging on the web of real world objects . Moreover , these services classify such information using common ontologies ( e . g . DBpedia ontology or YAGO ) exploiting the large amount of knowledge available from the web of data . Tools such as AlchemyAPI , DBpedia Spotlight , Evri , Extractiv , Lupedia , OpenCalais , Saplo , Wikimeta10 , Yahoo ! Content Extraction11 and Zemanta12 represent a clear opportunity for the web community to increase the volume of interconnected data .",Material,Data,Introduce,NERD: A Framework for Unifying Named Entity Recognition and Disambiguation Extraction Tools,https://aclanthology.org/E12-2015.pdf
"Different automatic rule translation strategies are evaluated and discussed , providing a comprehensive overview of the challenge . In recent years , inspired by the success of MUC evaluations , a growing number of initiatives ( e . g . TREC , CLEF , CoNLL , Senseval ) have been developed to boost research towards the automatic understanding of textual data . Since 1999 , the Automatic Content Extraction ( ACE ) program has been contributing to broaden the varied scenario of evaluation campaigns by proposing three main tasks , namely the recognition of entities , relations , and events . In 2004 , the Timex2 Detection and Recognition task ( also known as TERN , for Time Expression Recognition and Normalization ) has been added to the ACE program , making the whole evaluation exercise more complete .",Material,Data,Introduce,Evaluating knowledge-based approaches to the multilingual extension of a temporal expression normalizer,https://rua.ua.es/dspace/handle/10045/22492
"Graphs have long been used to describe linguistic annotations , most familiarly in the form of trees ( a graph in which each node has a single parent ) for syntactic annotation . Annotation Graphs ( Bird and Liberman , 2001 ) have been widely used to represent layers of annotation , each associated with primary data , although the concept was not extended to allow for annotations linked to other annotations and thus to consider multiple annotations as a single graph . More recently , the Penn Discourse TreeBank released its annotations of the Penn TreeBank as a graph , accompanied by an API that provides a set of standard graphhandling functions for query and access . The graph model therefore seems to be gaining ground as a natural and flexible model for linguistic annotations which , as we demonstrate below , can repre LAF provides a general framework for representing annotations that has been described elsewhere in detail ( Ide and Romary , 2004 , 2006 ). Its development has built on common practice and convergence of approach in linguistic annotation over the past 15 - 20 years .",Material,Data,Introduce,GrAF: A Graph-based Format for Linguistic Annotations,https://dl.acm.org/doi/pdf/10.5555/1642059.1642060
"Depending on the generality of the knowledge domains they cover , several types of ontologies are distinguished . These are upper - level ontologies , domain ontologies and application ontologies . Upper - level ontologies , or foundational ontologies , describe very general concepts that can be used across multiple domains ; examples include DOLCE , SUMO , and PROTON . Domain ontologies cover the conceptualization of given subject domains . They describe concepts and relationships representative for the subject domain like biology , vehicle sales , product types , etc .",Material,Data,Introduce,Accessing Linked Open Data via A Common Ontology,https://aclanthology.org/W15-5506.pdf
"dry - PRF - PL DEF - cloth - PL - SUBJ - NOM ‘ The colthes dried .’ In example ( 1 ) the causative / incoative alternation is realized through an overt morphological change on the head of the sentence ( reduplication of the second root consonant in ( 1a )), in such a way that the verb changes to a new entry , which according to the hierarchical organisation of the class and especially to the inheritance relation between its subparts , cannot longer be kept into the original class . Transporting the new verb entry into a new class risks to loose its connection to the original class , which is an undesired effect , since it does not necessarily reflect the natural organisation of the lexicon of Arabic . Arabic VerbNet is a large coverage verb lexicon exploiting Levin ’ s classes ( Levin , 1993 ) and the basic development procedure of Kipper Schuler ( 2005 ). The current version has 202 classes populating 4707 verbs and 834 frames . Every class is a hierarchical structure providing syntactic and semantic information about verbs and percolating them to subclasses .",Material,Data,Introduce,Classifying Arabic Verbs Using Sibling Classes,https://aclanthology.org/W11-0142.pdf
"Thus , physicians practicing EBM should be constantly aware of the new ideas and the best methodologies available based on the most recent literature . But the amount of clinical documents available is increasing everyday . For example , Pubmed , a service of the US National Library of Medicine contains more than 29 million citations for biomedical literature from MEDLINE , life science journals , and online books ( last updated on December 7 , 2011 ) . The abundance of digital information makes difficult the task of evaluating the quality of results presented and the significance of the conclusions drawn . Thus , it has become an important task to grade the quality of evidence so that the most significant evidence is incorporated into the clinical practices .",Material,Data,Introduce,"Opioid Epidemic in the United States: Empirical Trends, and A Literature Review of Social Determinants and Epidemiological, Pain Management, and Treatment Patterns",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6804319/
"Given such a hypergraph , we use the Algorithm 3 described in ( Huang and Chiang , 2005 ) to extract its k - best ( k = 500 in our experiments ) derivations . Since different derivations may lead to the same target language string , we further adopt Algorithm 3 ’ s modification , i . e ., keep a hash - table to maintain the unique target sentences ( Huang et al ., 2006 ), to efficiently generate the unique k - best translations . The JST Japanese - English paper abstract corpus , which consists of one million parallel sentences , was used for training and testing . This corpus was constructed from a Japanese - English paper abstract corpus by using the method of Utiyama and Isahara ( 2007 ). Table 3 shows the statistics of this corpus .",Material,Data,Introduce,Fine-grained Tree-to-String Translation Rule Extraction,https://aclanthology.org/P10-1034.pdf
"The DFKI Citation Corpus has been used for classifying citation function ( Dong and Sch ¨ afer , 2011 ), but the dataset also includes polarity annotation . The dataset has 1768 citation sentences with polarity annotation : 190 are labeled as positive , 57 as negative , and the vast majority , 1521 , are left neutral . The second citation corpus , the IMS Citation Corpus contains 2008 annotated citations : 1836 are labeled positive and 172 are labeled negative . Jochim and Sch ¨ utze ( 2012 ) use annotation labels from Moravcsik and Murugesan ( 1975 ) where positive instances are labeled confirmative , negative instances are labeled negational , and there is no neutral class . Because each of the citation corpora is of modest size we combine them to form one citation dataset , which we will refer to as CITD .",Material,Data,Introduce,Improving Citation Polarity Classification with Product Reviews,https://aclanthology.org/P14-2008.pdf
"In ( Passonneau et al ., 2008 ), a similar lack of correlation between interannotator agreement and machine learning performance is found in an empirical investigation . The Manually Annotated Sub - Corpus ( MASC ) project ( Ide et al ., 2010 ) is creating a small , representative corpus of American English written and spoken texts drawn from the Open American National Corpus ( OANC ). The MASC corpus includes hand - validated or manual annotations for a variety of linguistic phenomena . The first MASC release , available as of May 2010 , consists of 82K words . One of the goals of MASC is to support efforts to harmonize WordNet ( Miller et al ., 1993 ) and FrameNet ( Ruppenhofer et al ., 2006 ), in order to bring the sense distinctions each makes into better alignment .",Material,Data,Introduce,Anveshan: A Framework for Analysis of Multiple Annotators’ Labeling Behavior,https://aclanthology.org/W10-1806.pdf
"Sentences have been manually aligned during the human translation process , and words have been then aligned automatically using GIZA ++ ( Och and Ney , 2003 ). We have used valency frame annotation ( and other features ) of the PCEDT 2 . 0 in our previous work ; however , billingual alignment information has not been used before . PDT - Vallex ( Hajiˇc et al ., 2003 ; Urešová , 2011 ) is a valency lexicon of Czech verbs ( and nouns ), manually created during the annotation of the PDT / PCEDT 2 . 0 . Each entry in the lexicon contains a headword ( lemma ), according to which the valency frames ( i . e ., senses ) are grouped . Each valency frame includes the valency frame members and the following information for each of them ( see Fig .",Material,Data,Introduce,Using Parallel Texts and Lexicons for Verbal Word Sense Disambiguation,https://aclanthology.org/W15-2111.pdf
"This is an extension of the similarity task for compositional models developed by Mitchell and Lapata ( 2008 ), and constructed according to the same guidelines . The dataset contains 2500 similarity judgements , provided by 25 participants , and is publicly available . The data consists of transitive verbs , each paired with both a subject and an object noun – thus forming a small transitive sentence . Additionally , a ‘ landmark ’ verb is provided . The idea is to compose both the target verb and the landmark verb with subject and noun , in order to form two small compositional phrases .",Material,Data,Introduce,A Tensor-based Factorization Model of Semantic Compositionality,https://aclanthology.org/N13-1134.pdf
"To give their network a better initialization , they learn word embeddings using a nonprobabilistic language model , which was trained on English Wikipedia for about 2 months . They released their 50 - dimensional word embeddings ( vocabulary size 130K ) under the name SENNA . Mikolov et al . ( 2013a ) propose two log - linear models for computing word embeddings from large corpora efficiently : ( i ) a bag - of - words model CBOW that predicts the current word based on the context words , and ( ii ) a skip - gram model that predicts surrounding words given the current word . They released their pre - trained 300 - dimensional word embeddings ( vocabulary size 3M ) trained by the skip - gram model on part of Google news dataset containing about 100 billion words .",Material,Data,Introduce,Fine-grained Opinion Mining with Recurrent Neural Networks and Word Embeddings,https://aclanthology.org/D15-1168.pdf
"The version of TectoMT submitted to WMT12 builds upon the WMT11 version . Several rule - based components were slightly refined . However , most of the effort was devoted to creating a better and bigger parallel treebank — CzEng 1 . 0 ( Bojar et al ., 2012b ), and re - training the statistical components on this resource . Apart from bigger size and improved filtering , one of the main differences between CzEng 0 . 9 ( Bojar and Žabokrtský , 2009 ) ( used in WMT11 ) and CzEng 1 . 0 ( used in WMT12 ) is the revised annotation of formemes . There are two distinct structural layers used in the TectoMT system : The analytical layer can be obtained using different dependency parsers ( Popel et al ., 2011 ); the tectogrammatical representation is then created by rulebased modules from the analytical trees .",Material,Data,Introduce,Formemes in English-Czech Deep Syntactic MT,https://aclanthology.org/W12-3132.pdf
"It is apparent from the comparison of the “ Total ” rows in this table and Table 3 that the first five argument labels cover more that their syntactic counterparts . For example , the arguments A0 - A4 account for all but 3 % of all arguments labels , whereas Spanish and Catalan have much more rich set of argument labels , with a high entropy of the most - frequent - label distribution . The Catalan and Spanish datasets ( Taul ´ e et al ., 2008 ) were generated from the AnCora corpora through an automatic conversion process from a constituentbased formalism to dependencies ( Civit et al ., 2006 ). AnCora corpora contain about half million words for Catalan and Spanish annotated with syntactic and semantic information . Text sources for the Catalan corpus are EFE news agency (- 75Kw ), ACN Catalan news agency (- 225Kw ), and ‘ El Peri ´ odico ’ newspaper (- 200Kw ).",Material,Data,Introduce,The CoNLL-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages,https://aclanthology.org/W09-1201.pdf
"Each extracted rule is assigned a count fC . In this section we will explore variations of this rule extraction procedure involving alternative definitions of the ranking and counting functions , fR and fC , based on probabilities over alignment models . Common practice ( Koehn et al ., 2003 ) takes a set of word alignment links L and defines the alignment constraints CA so that there is a consistency between the links in the ( fj as the set of alignment links is generally obtained after applying a symmetrization heuristic to sourceto - target and target - to - source Viterbi alignments . In the following section we depart from this approach and apply novel functions to rank and count target - side translations according to their quality in the context of each parallel sentence , as defined by the word alignment models . We also depart from common practice in that we do not use a set of links as alignment constraints .",Material,Data,Introduce,Hierarchical Phrase-based Translation Grammars Extracted from Alignment Posterior Probabilities,https://dl.acm.org/doi/pdf/10.5555/1870658.1870711
"One of the advantages of corpusbased approaches is that the techniques used are less language specific than classical rulebased approaches where a human analyses the behaviour of target languages and constructs rules manually . This naturally led the way for international resource standardisation , and indeed there is a long standing precedent in the West for it . The Human Language Technology ( HLT ) society in Europe has been particularly zealous in this regard , propelling the creation of resource interoperability through a series of initiatives , namely EAGLES ( Sanfilippo et al ., 1999 ), PAROLE / SIMPLE ( Lenci et al ., 2000 ), ISLE / MILE ( Ide et al ., 2003 ), and LIRICS . These continuous efforts have matured into activities in ISO - TC37 / SC4 , which aims at making an international standard for language resources . However , due to the great diversity of languages themselves and the differing degree of technological development for each , Asian languages , have received less attention for creating resources than their Western counterparts .",Material,Data,Introduce,Query Expansion using LMF-Compliant Lexical Resources,https://aclanthology.org/W09-3421.pdf
"lexicons from the given training data respectively ( e ., laptop and restaurant ). Given a term w , this PMI - based score is calculated from labeled reviews as below : where PMI stands for pointwise mutual information . - Bing Liu opinion lexicon : This sentiment lexicon contains two annotated words lists : positive ( about 2 , 000 ) and negative ( about 4 , 800 ). - General Inquirer lexicon : The General Inquirer lexicon tries to classify English words along several dimensions , including sentiment polarity and we selected about 1 , 500 positive words and 2 , 000 negative words . - IMDB : This lexicon is generated from a large data set from IMDB which contains 25 , 000 positive and 25 , 000 negative movie reviews and the PMI - based sentiment score of each word is calculated as above .",Material,Data,Introduce,ECNU: Extracting Effective Features from Multiple Sequential Sentences for Target-dependent Sentiment Analysis in Reviews,https://aclanthology.org/S15-2125.pdf
"A lexical resource is usually based on semantic judgements about lexical elements ( a human judgement performed by a lexicographer , or a machine - based judgement in the case of automatically built resources ). Often , two independently built resources that describe the same linguistic reality only show a weak agreement even when based on human judgements under the same protocol ( Murray and Green , 2004 ). Many of such resources , such as WordNet ( Fellbaum , 1998 ) or Wiktionary ( Zesch et al ., 2008 ; Sajous et al ., 2010 ) can be modelled as graphs . A graph encodes a binary relation on a set V of vertices . A graph G = ( V , E ) is therefore defined by a finite , non empty set of n = JV J vertices and by a set E C_ V x V of m = JEJ couples of vertices ( edges ).",Material,Data,Introduce,Invariants and Variability of Synonymy Networks: Self Mediated Agreement by Confluence,https://aclanthology.org/W11-1103.pdf
"Discussion Forum Treebank The treebank is an extension of that described in Foster ( 2010 ). It contains 481 sentences taken from two threads on the BBC Sport 606 discussion forum in November 2009 . The discussion forum posts were split into sentences by hand . The sentences were first parsed automatically using an implementation of the Collins Model 2 generative statistical parser ( Bikel , 2004 ). They were then corrected by hand using as a reference the Penn Treebank ( PTB ) bracketing guidelines ( Bies et al ., 1995 ) and the PTB trees themselves ( Marcus et al ., 1994 ).",Material,Data,Introduce,Comparing the Use of Edited and Unedited Text in Parser Self-Training,https://aclanthology.org/W11-2925.pdf
"The number of documents in the collection is n . Similarly to the first criterion , we consider only patterns positively correlated with the corresponding category : The x statistic was previously reported to be the best feature selection strategy for text categorization ( Yang and Pedersen , 1997 ). Criterion 4 : Mutual Information ( MI ) Mutual information is a well known information theory criterion that measures the independence of two variables , in our case a pattern p and a category y ( Yang and Pedersen , 1997 ). Using the same contingency table introduced above , the MI criterion is estimated as : For all experiments reported in this paper we used the following three document collections : ( a ) the AP collection is the Associated Press ( year 1999 ) subset of the AQUAINT collection ( LDC catalog number LDC2002T31 ); ( b ) the LATIMES collection is the Los Angeles Times subset of the TREC5 collection ; and ( c ) the REUTERS collection is the by now classic Reuters - 21578 text categorization collection . Similarly to previous work , for the REUTERS collection we used the ModApte split and selected the ten most frequent categories ( Nigam et al ., 2000 ). Due to memory limitations on our test machines , we reduced the size of the AP and LATIMES collections to their first 5 , 000 documents ( the complete collections contain over 100 , 000 documents ).",Material,Data,Introduce,A review of feature selection methods based on mutual information,https://link.springer.com/article/10.1007/s00521-013-1368-0
"2 . The Nematode Biology data set contains 2500 ( randomly sampled ) research abstracts ( ). It has 2944 unique terms , around 179K observed words and an average of 52 unique terms per document . 3 .",Material,Data,Introduce,Decoupling Sparsity and Smoothness in theDiscrete Hierarchical Dirichlet Process,https://www.researchgate.net/publication/221619716_Decoupling_Sparsity_and_Smoothness_in_the_Discrete_Hierarchical_Dirichlet_Process
"We conclude with a brief experiment exemplifying some of the ideas discussed so far . The statistics division of the United Nations makes available extensive data sets detailing the amounts of trade between major sovereign nations ( see ). We used a data set indicating , for each pair of nations , the total amount of trade in U . S . dollars between that pair in the year 2002 . For our purposes , we would like to extract a discrete network structure from this numerical data .",Material,Data,Introduce,Economic Properties of Social Networks,https://proceedings.neurips.cc/paper/2004/hash/50abc3e730e36b387ca8e02c26dc0a22-Abstract.html
"Proof of concept : Key Influencers in Theoretical Physics : Drawn from a KDD Cup 2003 task , this datasetis publically available at : http :// www . cs . cornell . edu / projects / kddcup / datasets . html . It consists of the latex sources of all papers in the hep - th portion of the arXiv ( ) In consultation with a theoretical physicist we did our analysis at a time granularity of 1 month . In total , the data spans 137 months . We created document term matrices using standard text processing techniques , over a vocabulary of 463 words chosen by running an unsupervised topic model .",Material,Data,Introduce,Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference,https://proceedings.neurips.cc/paper/2010/hash/bcc0d400288793e8bdcd7c19a8ac0c2b-Abstract.html
"It has 2944 unique terms , around 179K observed words and an average of 52 unique terms per document . 3 . The NIPS data set contains the NIPS articles published between 1988 - 1999 ( ). It has 5005 unique terms and around 403K observed words . We randomly sample 20 % of the words for each paper and this leads to an average of 150 unique terms per document .",Material,Data,Introduce,Decoupling Sparsity and Smoothness in the Discrete Hierarchical Dirichlet Process,https://proceedings.neurips.cc/paper/2009/hash/3b8a614226a953a8cd9526fca6fe9ba5-Abstract.html
"4 . The Conf . abstracts set data contains abstracts ( including papers and posters ) from six international conferences : CIKM , ICML , KDD , NIPS , SIGIR and WWW ( ). It has 3733 unique terms , around 173K observed words and an average of 46 unique terms per document . The data are from 2005 - 2008 .",Material,Data,Introduce,Decoupling Sparsity and Smoothness in the Discrete Hierarchical Dirichlet Process,https://proceedings.neurips.cc/paper/2009/hash/3b8a614226a953a8cd9526fca6fe9ba5-Abstract.html
"Thus , the total database consists of 96 digit utterances . The specifics of this database are explained in ( Movellan , 1995 ). The database is available at Visual processing We have tried a wide variety of visual processing approaches on this database , including decomposition with local Gaussian templates ( Movellan , 1995 ), PCA - based templates ( Gray , Movellan & Sejnowski , 1997 ), and Gabor energy templates ( Movellan & Prayaga , 1996 ). To date , best performance was achieved with the local Gaussian approach .",Material,Data,Introduce,Bayesian Robustification for Audio Visual Fusion,https://proceedings.neurips.cc/paper/1997/hash/b7087c1f4f89e63af8d46f3b20271153-Abstract.html
"CDM was learnt for a Japanese OCR environment . Specifically , there were 3018 functions f in the environment F , each one a classifier for a different Kanji character . A database containing 90 , 918 segmented , machine - printed Kanji characters scanned from various sources was purchased from the CEDAR group at the State University of New York , Buffalo The quality of the images ranged from clean to very degraded ( see The main reason for choosing Japanese OCR rather than English OCR as a test - bed was the large number of distinct characters in Japanese . Recall from Theorem 2 that to get good generalisation from a learnt CDM , sufficiently many functions must be sampled from the environment . If the environment just consisted of English characters then it is likely that & quot ; sufficiently many & quot ; characters would mean all characters , and so it would be impossible to test the learnt CDM on novel characters not seen in training .",Material,Data,Introduce,The Canonical Distortion Measure in Feature Space and 1-NN Classification,https://proceedings.neurips.cc/paper/1997/hash/c26820b8a4c1b3c2aa868d6d57e14a79-Abstract.html
"While the latter is a strongly performing method , it also suffers from scalability problems . Learning a model of term correlations over a large vocabulary is a considerable challenge that requires a large amount of training data . Standard retrieval datasets like TREC or LETOR [ 22 ] contain only a few hundred training queries , and are hence too small for that purpose . Moreover , some datasets only provide pre - processed features like tf , idf or BM25 , and not the actual words . Click - through from web search engines could provide valuable supervision .",Material,Data,Introduce,Polynomial Semantic Indexing,https://proceedings.neurips.cc/paper/2009/hash/7504adad8bb96320eb3afdd4df6e1f60-Abstract.html
"The Office part consists of 4 , 652 images in 31 categories collected from three distinct domains ( tasks ): Amazon ( A ), which contains images downloaded from amazon . com , Webcam ( W ) and DSLR ( D ), which are images taken by Web camera and digital SLR camera under different environmental variations . This dataset is organized by selecting the 10 common categories shared by the Office dataset and the Caltech - 256 ( C ) dataset [ 12 ], hence it yields four multi - class learning tasks . Office - Home [ 26 ] This dataset is to evaluate transfer learning algorithms using deep learning . It consists of images from 4 different domains : Artistic images ( A ), Clip Art ( C ), Product images ( P ) and Real - World images ( R ). For each domain , the dataset contains images of 65 object categories collected in office and home settings .",Material,Data,Introduce,Learning Multiple Tasks with Multilinear Relationship Networks,https://proceedings.neurips.cc/paper/2017/hash/03e0704b5690a2dee1861dc3ad3316c9-Abstract.html
"The vocabulary size is 13 , 649 , and there are 2 . 3 million tokens in total . We randomly divide the corpus into a 1 , 392 - document training set and a 348 - document test set . New York Times The New York Times Annotated Corpus consists of over 1 . 8 million articles appearing in the New York Times between 1987 and 2007 . The vocabulary is pruned to 8 , 000 words . We hold out a randomly selected subset of 5 , 000 test documents , and use the remainder for training .",Material,Data,Introduce,Truly Nonparametric Online Variational Inference for Hierarchical Dirichlet Processes,https://proceedings.neurips.cc/paper_files/paper/2012/file/838e8afb1ca34354ac209f53d90c3a43-Paper.pdf
"‘ Books ’ concerns data collected from the Book - Crossing community about users providing ratings on books where we extracted the bipartite network from the ratings . ‘ Citations ’ is the co - authorship network based on preprints posted to Condensed Matter section of ArXiv between 1995 and 1999 [ 15 ]. ‘ Movielens100k ’ contains information about users rating particular movies from which we extracted the bipartite network . Finally , ‘ IMDB ’ contains information about actors co - starring a movie . The sizes of the different networks are given in We evaluate the fit of four different models on these datasets .",Material,Data,Introduce,Bayesian nonparametric models for bipartite graphs,https://proceedings.neurips.cc/paper/2012/hash/0768281a05da9f27df178b5c39a51263-Abstract.html
"An efficient C - code implementation for Matlab of the proposed table completion tool is also released on the authors website . In recent years , probabilistic modeling has become an attractive option for building database management systems since it allows estimating missing values , detecting errors , visualizing the data , and providing probabilistic answers to queries [ 19 ]. BayesDB , for instance , is a database management system that resorts to Crosscat [ 18 ], which originally appeared as a Bayesian approach to model human categorization of objects . BayesDB provides missing data estimates and probabilistic answer to queries , but it only considers Gaussian and multinomial likelihood functions . In the literature , probabilistic low - rank matrix factorization approaches have been broadly applied to table completion ( see , e . g ., [ 14 , 15 , 21 ])",Material,Data,Introduce,General Table Completion using a Bayesian Nonparametric Model,https://proceedings.neurips.cc/paper/2014/hash/d86ea612dec96096c5e0fcc8dd42ab6d-Abstract.html
"Besides , unless specified otherwise , we fix the training set size to 2 , 000 and the code length K to 24 . The Wiki data set , generated from Wikipedia featured articles , consists of 2 , 866 image - text pairs . In each pair , the text is an article describing some events or people and the image is closely related to the content of the article . The images are represented by 128 - dimensional SIFT [ 28 ] feature vectors , while the text articles are represented by the probability distributions over 10 topics learned by a latent Dirichlet allocation ( LDA ) model [ 29 ]. Each pair is labeled with one of 10 semantic classes .",Material,Data,Introduce,Co-Regularized Hashing for Multimodal Data,https://proceedings.neurips.cc/paper/2012/hash/5c04925674920eb58467fb52ce4ef728-Abstract.html
"It consists of images from 4 different domains : Artistic images ( A ), Clip Art ( C ), Product images ( P ) and Real - World images ( R ). For each domain , the dataset contains images of 65 object categories collected in office and home settings . Real World Product Clipart Art ImageCLEF - DA This dataset is the benchmark for ImageCLEF domain adaptation challenge , organized by selecting the 12 common categories shared by the following four public datasets ( tasks ): Caltech - 256 ( C ), ImageNet ILSVRC 2012 ( I ), Pascal VOC 2012 ( P ), and Bing ( B ). All three datasets are evaluated using DeCAF7 [ 9 ] features for shallow methods and original images for deep methods . We compare MRN with standard and state - of - the - art methods : Single - Task Learning ( STL ), MultiTask Feature Learning ( MTFL ) [ 2 ], Multi - Task Relationship Learning ( MTRL ) [ 31 ], Robust MultiTask Learning ( RMTL ) [ 5 ], and Deep Multi - Task Learning with Tensor Factorization ( DMTL - TF ) [ 27 ].",Material,Data,Introduce,Aligning Domain-Specific Distribution and Classifier for Cross-Domain Classification from Multiple Sources,https://ojs.aaai.org/index.php/AAAI/article/view/4551
"Additionally , in initial user studies we observed that data programming may be an easier way for non - experts to create machine learning models when training data is limited or unavailable . Many of the major machine learning breakthroughs of the last decade have been catalyzed by the release of a new labeled training dataset . Supervised learning approaches that use such datasets have increasingly become key building blocks of applications throughout science and industry . This trend has also been fueled by the recent empirical success of automated feature generation approaches , notably deep learning methods such as long short term memory ( LSTM ) networks [ 14 ], which ameliorate the burden of feature engineering given large enough labeled training sets . For many real - world applications , however , large hand - labeled training sets do not exist , and are prohibitively expensive to create due to requirements that labelers be experts in the application domain .",Material,Data,Introduce,"Data Programming: Creating Large Training Sets, Quickly",https://arxiv.org/abs/1605.07723
"The SDPP samples , however , are more diverse , tending to cover more of the space while still respecting the quality scores — they are still smooth , and still tend to start near the middle position . To demonstrate that SDPPs effectively model characteristics of real - world data , we apply them to a multiple - person pose estimation task . Our dataset consists of 73 still frames taken from various TV shows , each approximately 720 by 540 pixels in size . As much as possible , the selected frames contain three or more people at similar scale , all facing the camera and without serious occlusions . Sample images from the dataset are shown in Figure 4 .",Material,Data,Introduce,Structured Determinantal Point Processes,https://repository.upenn.edu/cgi/viewcontent.cgi?article=1545&context=cis_papers
"This confidently beats the “ magic barrier ” of 0 . 73 reported in the collaborative filtering literature [ 11 ]. The root mean squared error ( RMSE ) measured for the same clustering with a mean of z values within each section c , d taken for prediction yields 0 . 96 ( with a deviation below 0 . 01 ). This is much better than 1 . 165 RMSE reported for a dataset 20 times larger [ 20 ] and quite close to 0 . 9525 RMSE reported by Netflix for a dataset 1000 times larger of a similar nature . A new model independent approach to the analysis of data given in the form of samples of a function Z ( X , Y ) rather than samples of co - occurrence statistics of X and Y is introduced . From a theoretical viewpoint the approach is a much required extension of the Information Bottleneck method that allows for its application to entirely new domains .",Material,Data,Introduce,Information Bottleneck for Non Co-Occurrence Data,https://proceedings.neurips.cc/paper/2006/hash/494ba9ff03bdad881378a6fd4092a6c7-Abstract.html
"‘ Citations ’ is the co - authorship network based on preprints posted to Condensed Matter section of ArXiv between 1995 and 1999 [ 15 ]. ‘ Movielens100k ’ contains information about users rating particular movies from which we extracted the bipartite network . Finally , ‘ IMDB ’ contains information about actors co - starring a movie . The sizes of the different networks are given in We evaluate the fit of four different models on these datasets . First , the stable IBP [ 18 ] with parameters ( αIBP , τIBP , σIBP ) ( S - IBP ).",Material,Data,Introduce,Bayesian nonparametric models for bipartite graphs,https://proceedings.neurips.cc/paper/2012/hash/0768281a05da9f27df178b5c39a51263-Abstract.html
"We set each training sequence to have the length of 50 . Quality of fit is evaluated by the bits - per - character ( BPC ) metric , which is loge of perplexity . text8 dataset : Another dataset used for character level language modelling is the text8 dataset , which contains 100M characters from Wikipedia with an alphabet size of 27 . We follow the setting from [ 23 ] and each training sequence has length of 180 . adding problem : The adding problem ( and the following copying memory problem ) was introduced in [ 10 ]. For the adding problem , each input has two sequences with length of T where the first sequence are numbers sampled from uniform [ 0 , 1 ] and the second sequence are all zeros except two elements which indicates the position of the two elements in the first sequence that should be summed together .",Material,Data,Introduce,Architectural Complexity Measures of Recurrent Neural Networks,https://arxiv.org/pdf/1602.08210.pdf
"2 and 3 on four data sets . In the ABALONE data set [ 1 ] with 4177 examples , the goal is to predict the age of Abalones based on 8 inputs . The KIN8NM data set represents the forward dynamics of an 8 link all - revolute robot arm , based on 8192 examples . The goal is to predict the distance of the end - effector from a target , given the twist angles of the 8 links as features . KIN40K represents the same task , yet has a lower noise level than KIN8NM and contains 40000 examples .",Material,Data,Introduce,Transductive and Inductive Methods for Approximate Gaussian Process Regression,https://proceedings.neurips.cc/paper/2002/hash/329e6581efbc90bd92a1f22c4ba2103d-Abstract.html
"Also , we believe that simpler , heuristic approaches could be used to identify such sentences . We use “ GUG ” (“ Grammatical ” versus “ UnGrammatical ”) to refer to this dataset . The dataset is available for research at gug - data .",Material,Data,Produce,Predicting Grammaticality on an Ordinal Scale,https://aclanthology.org/P14-2029.pdf
"Overall and pairwise agreement lied within the range set by current related literature . From the four sets of annotations , we built a gold standard , where paragraphs were classified according to the opinion of the majority of annotators . This gold standard and annotated corpus , by all four annotators , are available to the community under a Creative Commons licence at We hope our efforts to be useful to other researchers in a number of ways , from deeper studies related to news texts to the application of machine learning techniques , also serving as a common ground for comparison amongst research that build on our corpus and gold standard . As for future work , we intend to use this corpus as one of the variables necessary to identify bias in newswire outlets , thereby determining not only if news from some outlet is biased , but also allowing for the identification of the way this bias is introduced in texts .",Material,Data,Produce,An Annotated Corpus for Sentiment Analysis in Political News,https://sol.sbc.org.br/index.php/stil/article/view/3970
"We hope our work will pave the way for new research on the generation and exploitation of large - scale sense - annotated corpora . Furthermore , our new type of pseudoword might also be used for a realistic , wide - coverage evaluation of other difficult tasks such as Word Sense Induction ( Bordag 2006 ; Di Marco and Navigli 2013 ; Navigli and Vannella 2013 ), Entity Linking ( Moro , Raganato , and Navigli 2014 ) and selectional preference acquisition ( Chambers and Jurafsky 2010 ; Erk , Pad ´ o , and Pad ´ o 2010 ), among others . We are releasing to the research community the entire set of 15 , 935 pseudowords of WordNet 3 . 0 polysemous nouns , including those selected for our WSD experiments ( ). Together with the pseudosense - annotated corpus , this will allow for future experimental comparisons and studies with other WSD systems , also in other languages . In fact , our pseudowords and our WSD framework are not language - dependent and can readily be applied to other languages with the help of multilingual semantic networks such as BabelNet ( Navigli and Ponzetto 2012a ) and the use of multilingual WSD algorithms ( Moro , Raganato , and Navigli 2014 ).",Material,Data,Produce,A Large-Scale Pseudoword-Based Evaluation Framework for State-of-the-Art Word Sense Disambiguation,https://direct.mit.edu/coli/article/40/4/837/1488/A-Large-Scale-Pseudoword-Based-Evaluation
"We test its reliability on the WordNet sense inventory . Overall , the experimental results show high agreement , confirming our hypothesis that agreement at sense level might be higher than at the word level . The annotated sense inventory will be made publically available to other researchers at The remainder of this paper is organized as follows . Section 2 discusses previous related work .",Material,Data,Produce,CSI: A Coarse Sense Inventory for 85% Word Sense Disambiguation,https://ojs.aaai.org/index.php/AAAI/article/view/6324
"The SIGHAN 2013 Chinese Spelling Check Bakeoff was the first campaign to provide data sets as benchmarks for the objective performance evaluation of Chinese spelling checkers ( Wu et al . 2013 ). The collected data set is publicly available at The competition resulted in the integration of effective NLP techniques in the development of Chinese spelling checkers . Language modeling was used to glean extra semantic clues and collect web resources together to identify and correct spelling errors ( Chen et al ., 2013 ).",Material,Data,Produce,Overview of SIGHAN 2014 Bake-off for Chinese Spelling Check,https://aclanthology.org/W14-6820.pdf
"We collected pairs of articles spanning from 1 / 1 / 2001 through 10 / 05 / 2005 . The corpus consists of 2 , 327 documents , with 0 - 8 documents per day . The corpus is available on our web page at cogcomp /. The English side was tagged with a publicly available NER system based on the SNoW learning architecture ( Roth , 1998 ), that is available on the same site . This set of English NEs was hand - pruned to remove incorrectly classified words to obtain 978 single word NEs .",Material,Data,Produce,A Corpus of Turkish Offensive Language on Social Media,https://aclanthology.org/2020.lrec-1.758/
"Analysis scripts and primary data and results files are available for download from When no target segment is found by the algorithm for the speech of one caregiver , this results in missing data , as no recall , purity , or collocation can be calculated in these conditions . Therefore , we excluded from inspection all settings of the similarity threshold that resulted in missing data prior to carrying out statistical analyses .",Material,Data,Produce,"Fog Computing in Medical Internet-of-Things: Architecture, Implementation, and Applications",https://link.springer.com/chapter/10.1007/978-3-319-58280-1_11
tem . The dataset and code can be downloaded from _CITE_,Material,Data,Produce,FMA: A Dataset For Music Analysis,https://arxiv.org/abs/1612.01840
"We are able to extract high - quality information about temporal durations and to effectively classify tweets as to their habituality . It is clear that Twitter tweets contain a lot of unique data about different kinds of events and habits , and mining this data for temporal duration information has turned out to be a fruitful avenue for collecting the kind of worldknowledge that we need for robust temporal language processing . Our verb lexicon is available at : _CITE_",Material,Data,Produce,Extracting and modeling durations for habits and events from Twitter,https://aclanthology.org/P12-2044.pdf
author refers both to a book but also to his DNA ; this paradox is a good illustration of the difficulty translating a literary work ! The data in this article are available at There one can find :,Material,Data,Produce,Automated translation of a literary work: a pilot study,https://hal.science/hal-01147903/
"Because LDA - SP generates a complete probabilistic model for our relation data , its results are easily applicable to many other tasks such as identifying similar relations , ranking inference rules , etc . In the future , we wish to apply our model to automatically discover new inference rules and paraphrases . Finally , our repository of selectional preferences for 10 , 000 relations is available at _CITE_",Material,Data,Produce,A Latent Dirichlet Allocation method for Selectional Preferences,https://aclanthology.org/P10-1044.pdf
"It is often believed of natural language and speech applications that deployed commercial systems are about a generation behind the systems being developed in research laboratories . It would be interesting to know if this is true in the domain of Chinese word segmentation , which should be possible to find out if we get a good balance of both . For the present , we will make the training and test data for the bakeoff available via ( subject to the restrictions of the content providers ), so that others can better study the results of this contest .",Material,Data,Produce,Commercial applications of natural language processing,https://dl.acm.org/doi/abs/10.1145/219717.219778
"Reddit comprises ‘ sub - reddits ’, which focus on specific topics . For example , http :// reddit . com / r / politics features articles ( and hence comments ) centered around political news . The current version of the corpus is available at : ACL - 2014 - irony . Data collection and annotation is ongoing , so we will continue to release new ( larger ) versions of the corpus in the future . The present version comprises 3 , 020 annotated comments scraped from the six subreddits enumerated in Table 1 .",Material,Data,Produce,Analyzing the Traits and Anomalies of Political Discussions on Reddit,https://ojs.aaai.org/index.php/ICWSM/article/view/3222
"Regardless of actual performance , all submissions contribute to the common effort to produce an effective Chinese spell checker , and the individual reports in the Bake - off proceedings provide useful insight into Chinese language processing . We hope the data sets collected for this Bakeoff can facilitate and expedite the development of effective Chinese spelling checkers . All data sets with gold standards and evaluation tool are publicly available for research purposes at Based on the results of this Bake - off , we plan to build new language resources to improve existing and develop new techniques for computer",Material,Data,Produce,Overview of SIGHAN 2014 Bake-off for Chinese Spelling Check,https://aclanthology.org/W14-6820.pdf
"This approach is denoted as PRvis + Per ( PMI ). This section discusses the experimental design for evaluating the proposed approaches to labelling topics with images . To our knowledge no data set for evaluating these approaches is currently available and consequently we developed one for this study . Human judgements about the suitability of images are obtained through crowdsourcing . We created a data set of topics from two collections which cover a broad thematic range : police , officer , crime , street , man , city , gang , suspect , arrested , violence game , season , team , patriot , bowl , nfl , quarterback , week , play , jet military , afghanistan , force , official , afghan , defense , pentagon , american , war , gates categories ( e . g .",Material,Data,Produce,Representing Topics Using Images,https://aclanthology.org/N13-1016.pdf
"However , the task is slightly more difficult than simply mining for a “ similar_to ” relation , which is addressed by our approach in section 5 . As the goal of this paper is to supply the tools for creating a large corpus of analogies from the Web , we require a reliable mechanism for automatically classifying if a text snippet contains an analogy or not . Such classification requires a Gold dataset which we construct in this section and which we make available to the community for download . As we expect the number of analogies in a completely random collection of web documents to be extremely low , we first start by collecting a set of web documents that are likely to contain an analogy by applying some easy - to - implement but rather coarse techniques as follows : In order to obtain a varied set of text snippets ( i . e . short excerpts from larger Web documents ), we first used a Web search engine ( Google Search API ) with simple Hearst - like patterns for crawling potentially relevant websites .",Material,Data,Produce,A holistic lexicon-based approach to opinion mining,https://dl.acm.org/doi/abs/10.1145/1341531.1341561
"We also combine this system with a baseline system consisting of effective surface features . A second contribution of the paper is the release of a new data set for QE . This data set comprises a set of 4 . 5K sentences chosen from customer support forum text . The machine translation of the sentences are not only evaluated in terms of adequacy and fluency , but also manually post - edited allowing various metrics of interest to be applied to measure different aspects of quality . All experiments are carried out on this data set .",Material,Data,Produce,Syntax and Semantics in Quality Estimation of Machine Translation,https://aclanthology.org/W14-4008.pdf
"The two computational semantics annotators had to tag each English constituent noun with its corresponding WordNet sense and each instance with the corresponding semantic category . If the word was not found in WordNet the instance was not considered . Whenever the annotators found an example encoding a semantic category other than those provided or they didn ’ t know what interpretation to give , they had to tag it as “ OTHER - SR ”, and respectively “ OTHER - PP ” . The details of the annotation task and the observations drawn from there are presented in a companion paper ( Girju , 2007 ). The corpus instances used in the corpus analysis phase have the following format : < NPEn ; NPEs ; NPIt ; NPFr ; NPPort ; NPRo ; target >.",Material,Data,Produce,On the semantics of noun compounds,https://www.sciencedirect.com/science/article/abs/pii/S0885230805000094
"Here , we consider an important dimension of style , namely , simplicity . Systems that can rewrite text into simpler versions promise to make information available to a broader audience , such as non - native speakers , children , laypeople , and so on . One major effort to produce such text is the Simple English Wikipedia ( henceforth SimpleEW ) , a sort of spin - off of the well - known English Wikipedia ( henceforth ComplexEW ) where human editors enforce simplicity of language through rewriting . The crux of our proposal is to learn lexical simplifications from SimpleEW edit histories , thus leveraging the efforts of the 18K pseudonymous individuals who work on SimpleEW . Importantly , not all the changes on SimpleEW are simplifications ; we thus also make use of ComplexEW edits to filter out non - simplifications .",Material,Data,Produce,For the sake of simplicity: Unsupervised extraction of lexical simplifications from Wikipedia,https://arxiv.org/abs/1008.1986
"By providing scalar factuality judgments for events , our models enable more fine - grained reasoning than previously considered . The corpus and learned models are available online . While event definitions have been proposed in several prior studies , existing approaches vary in how they model various linguistic forms such as nominal events , stative events , generic events , and light verbs ( Pustejovsky et al ., 2003 ; Palmer et al ., 2005 ; Meyers et al ., 2004 ; Kim et al ., 2009 ; Song et al ., 2015 ). Even with a formal and precise account of events , training annotators to learn all such linguistic intricacies remains a practical challenge . Instead of definition - driven instructions , we propose example - driven instructions and show their effectiveness .",Material,Data,Produce,Event Detection and Factuality Assessment with Non-Expert Supervision,https://aclanthology.org/D15-1189.pdf
"We give a full spectrum evaluation of all three stages of IR + QA : document retrieval , passage retrieval and answer extraction , to examine thoroughly the effectiveness of the method . All of our code and datasets are publicly available . Besides Predictive Annotation , our work is closest to structured retrieval , which covers techniques of dependency path mapping ( Lin and Pantel , 2001 ; Cui et al ., 2005 ; Kaisser , 2012 ), graph matching with Semantic Role Labeling ( Shen and Lapata , 2007 ) and answer type checking ( Pinchak et al ., 2009 ), etc . Specifically , Bilotti et al . ( 2007 ) proposed indexing text with their semantic roles and named entities .",Material,Data,Produce,"Frontiers, challenges, and opportunities for information retrieval: Report from SWIRL 2012 the second strategic workshop on information retrieval in Lorne",https://dl.acm.org/doi/abs/10.1145/2215676.2215678
"Extract entities from collection of documents We started with one corpus of documents ( the test documents in the online approach or a pre – compiled set in the offline version ): the seed documents ( SD ). Then we applied the statistical implementation of DBPedia Spotlight ( Daiber et al ., 2013 ) in order to obtain entities and their corresponding links to DBPedia . With this we compile the EA corpus , which contains all the Wikipedia texts associated to the DBpedia links extracted . We experimented with some filtering techniques on the list of DBPedia links in order to keep just domain specific ones , such as considering only those DBPedia links tagged with an ontological concept which is a leaf of the ontology tree . Nevertheless , we found a better performance when using all the DBpedia links without any filtering .",Material,Data,Produce,VUA-background : When to Use Background Information to Perform Word Sense Disambiguation,https://aclanthology.org/S15-2058.pdf
"We detected emotions using four feature types : 1 ) interjections , 2 ) profanity , 3 ) emoticons and 4 ) overall sentiment of the tweet . Interjections , profanity , and emoticons are widely used by individuals to convey emotion , such as anger , surprise , happiness , etc . To identify these three feature types , we used a combination of POS tags in the English tagger ( which contains tags for interjections , emoticons , etc ), compiled lists of interjections and profanity from the web for both English and Spanish and regular expression patterns for emoticons . We also included sentiment features using the sentiment140 API ( Go et al ., 2009 ). This API provides a sentiment label ( positive , negative or neutral ) for a tweet corresponding to its overall sentiment .",Material,Data,Produce,User Type Classification of Tweets with Implications for Event Recognition,https://aclanthology.org/W14-2714.pdf
"The inter - tagger agreement rate was 0 . 80 , with a Kappa score of 0 . 77 . This annotation was used to group the pairs in three categories : similar pairs ( those classified as synonyms , antonyms , identical , or hyponym - hyperonym ), related pairs ( those classified as meronym - holonym , and pairs classified as none - of - the - above , with a human average similarity greater than 5 ), and unrelated pairs ( those classified as none - of - the - above that had average similarity less than or equal to 5 ). We then created two new gold - standard datasets : similarity ( the union of similar and unrelated pairs ), and relatedness ( the union of related and unrelated ) . Table 5 shows the results on the relatedness and similarity subsets of WordSim353 for the different methods . Regarding WordNet methods , both WN30 and WN30g perform similarly on the similarity subset , but WN30g obtains the best results by far on the relatedness data .",Material,Data,Produce,"A comprehensive survey on sentiment analysis: Approaches, challenges and trends",https://www.sciencedirect.com/science/article/abs/pii/S095070512100397X
"In releasing this data we hope to equip researchers with the data to support numerous research directions going forward . The JCLC is freely available to the research community and accessible via our website . It can be used via a web - based interface for querying the data . Alternatively , the original texts can be downloaded in text format for more advanced tasks . Interest in learning Chinese is rapidly growing , leading to increased research in Teaching Chinese as a Foreign Language ( TCFL ) and the development of related resources such as learner corpora ( Chen et al ., 2010 ).",Material,Data,Produce,The Jinan Chinese Learner Corpus,https://aclanthology.org/W15-0614.pdf
"We evaluate our mixture model on four different test sets . On the three most AAC - like test sets , we found substantial reductions in not only perplexity but also in potential keystroke savings when used in a predictive keyboard interface . Finally , to aid other AAC researchers , we have publicly released our crowdsourced AAC collection , word lists and best - performing language models . As we mentioned in the introduction , there are unfortunately no publicly available sources of genuine conversational AAC messages . We conjectured we could create surrogate data by asking workers on Amazon Mechanical Turk to imagine they were a user of an AAC device and having them invent things they might want to say .",Material,Data,Produce,Intelligent Techniques to Accelerate Everyday Text Communication,https://www.proquest.com/openview/81410a369f59b49ae223ea63ad9b6fc0/1?pq-origsite=gscholar&cbl=18750&
"The final filtered version of hrWaC contains 51M sentences and 1 . 2B tokens . The corpus is freely available for download , along with a more detailed description of the preprocessing steps . Tagging , lemmatization , and parsing . For morphosyntactic ( MSD ) tagging , lemmatization , and dependency parsing of hrWaC , we use freely available tools with models trained on the new SETimes Corpus of Croatian ( SETIMES . HR ), based on the Croatian part of the SETimes parallel corpus . SETIMES . HR and the derived tools are prototypes racy that are about to be released as parts of another work .",Material,Data,Produce,Building and Evaluating a Distributional Memory for Croatian,https://aclanthology.org/P13-2137.pdf
"First , our results may be idiosyncratic to the specifics of the particular domain of our experiment . We would point out , however , that the domain is more complex , and arguably more realistic , than the much - simplified experimental contexts that have served as intuitions for earlier work in the field ; we have in mind here in particular the experiments discussed in ( Ford and Olson , 1975 ), ( Sonnenschein , 1985 ) and ( Pechmann , 1989 ). In the belief that the data provides a good test set for the generation of referring expressions , we are making the data set publicly available , so others may try to develop algorithms covering the data . A second concern is that we have only explored the extent to which three specific algorithms are able to cover the human data . Many of the other algorithms in the literature take these as a base , and so are unlikely to deliver significantly different results .",Material,Data,Produce,The Influence of Social Interaction on Intuitions of Objectivity and Subjectivity,https://onlinelibrary.wiley.com/doi/full/10.1111/cogs.12380
"This is lower than Bergsma ’ s top score of 92 . 2 % ( Figure 3 ), but again , Bergsma ’ s top system relies on Google search queries for each new word , while ours are all pre - stored in a table for fast access . We are pleased to be able to share our gender and number data with the NLP community . In Section 6 , we show the benefit of this data as a probabilistic feature in our pronoun resolution system . Probabilistic data is useful because it allows us to rapidly prototype resolution systems without incurring the overhead of large - scale lexical databases such as WordNet ( Miller et al ., 1990 ). Researchers since Dagan and Itai ( 1990 ) have variously argued for and against the utility of collocation statistics between nouns and parents for improving the performance of pronoun resolution .",Material,Data,Produce,Community-level Research on Suicidality Prediction in a Secure Environment: Overview of the CLPsych 2021 Shared Task,https://aclanthology.org/2021.clpsych-1.7/
"This corpus contains English transcriptions and multilingual , sentencealigned translations of talks from the TED conference . While the corpus is aimed at machine translation tasks , we use the keywords associated with each talk to build a subsidiary corpus for multilingual document classification as follows . The development sections provided with the IWSLT 2013 corpus were again reserved for development . We removed approximately 10 percent of the training data in each language to create a test corpus ( all talks with id ≥ 1 , 400 ). The new training corpus consists of a total of 12 , 078 parallel documents distributed across 12 language pairs .",Material,Data,Produce,The Multilingual TEDx Corpus for Speech Recognition and Translation,https://arxiv.org/abs/2102.01757
An implementation of the proposed multi - sentence compression approach is available for download . We constructed an evaluation dataset made of 40 sets of related sentences along with reference compressions composed by humans . This dataset is freely available for download . We performed both manual and automatic evaluations and showed that our method significantly improves the informativity of the generated compressions . We also investigated the correlation between manual and automatic evaluation metrics and found that ROUGE and BLEU have a medium correlation with manual ratings .,Material,Data,Produce,Overcoming the Lack of Parallel Data in Sentence Compression,https://storage.googleapis.com/pub-tools-public-publication-data/pdf/41393.pdf
"The human - labelled dataset was used as a sanity check to make sure the dataset labelled using the emoticons classifier was not too noisy and that the human and emoticon labels matched for a majority of tweets . We collected a total of 18 million , geo - tagged , English - language tweets over three years , from January 1st , 2012 to January 1st , 2015 , evenly divided across all 36 months , using Historical PowerTrack for Twitter provided by GNIP . We created geolocation bounding boxes for each of the 50 states which were used to collect our dataset . All 18 million tweets originated from one of the 50 states and are tagged as such . Moreover , all tweets contained one of the six emoticons in Table 1 and were labelled as either positive or negative based on the emoticon .",Material,Data,Produce,Enhanced Twitter Sentiment Classification Using Contextual Information,https://arxiv.org/abs/1605.05195
"Its place is Aberdeen ’). Such ‘ utility ’ classes are used across domains . In PolicyGrid we have created a utility ontology that contains classes such as ‘ Person ’, ‘ Address ’ and ‘ Date ’ . Instances of these classes are generated to a special surface form . In order to get the best realisation from the WYSIWYM tool , domain ontologies should use the classes from this utility ontology .",Material,Data,Produce,Evaluating an Ontology-Driven WYSIWYM Interface,https://aclanthology.org/W08-1118.pdf
"for and against , policies ultimately adopted by the government , and the impact of those policies . The set of datasets made available is listed in Table 1 . Several additional datasets were suggested on the website , but were not part of the official data . Forty teams initially registered to participate in the unshared task ; ten submitted papers . The teams came from a variety of institutions spread across six countries .",Material,Data,Produce,"ICLabel: An automated electroencephalographic independent component classifier, dataset, and website",https://www.sciencedirect.com/science/article/abs/pii/S1053811919304185
"This quantity is an estimate of type - I error under H0 , and corresponds to test power when H1 is true . We set α = 0 . 01 in all the experiments . All the code and preprocessed data are available at Optimization The parameter tuning objective ˆλtrn / 2 ( θ ) is a function of θ consisting of one real - valued σ and J test locations each of d dimensions . The parameters θ can thus be regarded as a Jd + 1 Euclidean vector .",Material,Data,Produce,Interpretable Distribution Features with Maximum Testing Power,https://proceedings.neurips.cc/paper_files/paper/2016/file/0a09c8844ba8f0936c20bd791130d6b6-Paper.pdf
Experimental evaluation of the new algorithm was performed on the modified KDD Cup 1998 data set . The original data set is available under The following modifications were made to obtain a pure regression problem :,Material,Data,Produce,KDD Cup 99 Data Sets: A Perspective on the Role of Data Sets in Network Intrusion Detection Research,https://ieeexplore.ieee.org/abstract/document/8672520
"Our goal was to segment the scenes into two classespuppet and background . We use five of the scenes for our training data , three for validation and three for testing . Sample scans from the training and test set can be seen at We computed spin images of size 10 x 5 bins at two different resolutions , then scaled the values and performed PCA to obtain 45 principal components , which comprised our node features . We used the surface links output by the scanner as edges between points and for each edge only used a",Material,Data,Produce,Discriminative learning of Markov random fields for segmentation of 3D scan data,https://ieeexplore.ieee.org/abstract/document/1467438
"Our approach provides a first step towards surpassing this limitation , by not just anticipating but certifying the reliability of a defender , thus implicitly considering an infinite number of attacks before they occur . Reproducibility . The code and data for replicating our experiments is available on GitHub ( ) and Codalab Worksheets ( http :// bit . ly / cl - datapois ). Acknowledgments . JS was supported by a Fannie & John Hertz Foundation Fellowship and an NSF Graduate Research Fellowship .",Material,Data,Produce,Certified Defenses for Data Poisoning Attacks,https://proceedings.neurips.cc/paper_files/paper/2017/file/9d7311ba459f9e45ed746755a32dcd11-Paper.pdf
"Note that , while a naive implementation of the arg max in Algorithm 3 requires evaluating the objective for each item in U , here we can exploit the fact that DPPs are closed under conditioning to compute all necessary values with only two matrix inversions [ 5 ]. We report baseline runtimes using this optimized greedy algorithm , which is about 10 times faster than the naive version at N = 200 . The code and data for all experiments can be downloaded from _CITE_",Material,Data,Produce,Near-Optimal MAP Inference for Determinantal Point Processes,https://proceedings.neurips.cc/paper/2012/hash/6c8dba7d0df1c4a79dd07646be9a26c8-Abstract.html
"We presume no more objectivity in answering this question than we would have in judging the merits of our other children . However , we believe that the level of musicality attained by our system is truly surprising , while the reliability is sufficient for live demonstration . We hope that the interested reader will form an independent opinion , even if different from ours , and to this end we have made musical examples demonstrating our progress available on the web page : _CITE_",Material,Data,Produce,"General Intelligence"" Objectively Determined and Measured.",https://psycnet.apa.org/record/2006-10257-006
"The images are rather inhomogeneous , since they show different persons with different facial expressions . Some sample images are depicted in figure 6 . For a complete overview over the whole image set , we refer the reader to our supplementary web page , where all images can be viewed in higher quality .",Material,Data,Produce,Feature Selection in Clustering Problems,https://proceedings.neurips.cc/paper/2003/hash/bb03e43ffe34eeb242a2ee4a4f125e56-Abstract.html
"The retraction mechanism is implemented by 3 resonators ( , Hz ) which connect the collision sensors ( CS ) to the neurons ( speed ) and ( steering angle ) with fixed weights ( reflex ). Each range finder ( RF ) is fed into a filter bank of 10 resonators with Hz where its output converges with variable weights on both the and - neuron . A more detailed technical description together with a set of movies can be found at : – movie 1 . ( b , d ) Parts of the motion trajectory for one trial in an arena of with three obstacles ( shaded ). Circles denote collisions .",Material,Data,Produce,Isotropic sequence order learning using a novel linear algorithm in a closed loop behavioural system,https://www.sciencedirect.com/science/article/abs/pii/S0303264702000771
"The FLIC - full dataset contains 20928 training images , however many of these training set images contain samples from the 1016 test set scenes and so would allow unfair overtraining on the FLIC test set . Therefore , we propose a new dataset - called FLIC - plus ( plus . htm ) - which is a 17380 image subset from the FLIC - plus dataset . To create this dataset , we produced unique scene labels for both the FLIC test set and FLICplus training sets using Amazon Mechanical Turk . We then removed all images from the FLIC - plus training set that shared a scene with the test set .",Material,Data,Produce,Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation,https://proceedings.neurips.cc/paper/2014/hash/e744f91c29ec99f0e662c9177946c627-Abstract.html
"Leave - one - out ( LOO ) is a standard procedure in predicting the generalization power of a trained classifier , both from a theoretical and empirical perspective [ 12 ], It is naturally implemented by decremental unlearning , adiabatic reversal of incremental learning , on each of the training data from the full trained solution . Similar ( but different ) bookkeeping of elements migrating across 5 , E and R applies as in the incremental case . & apos ; Matlab code and data are available at _CITE_",Material,Data,Produce,Incremental and Decremental Support Vector Machine Learning,https://proceedings.neurips.cc/paper/2000/hash/155fa09596c7e18e50b58eb7e0c6ccb4-Abstract.html
"We now empirically explore our method ’ s behavior . All of our code , data , and experiments may be found on the CodaLab worksheet for this paper at , which also contains more detailed plots beyond those shown here . We would like to answer the following questions :",Material,Data,Produce,Out-of-the-Box Reproducibility: A Survey of Machine Learning Platforms,https://ieeexplore.ieee.org/abstract/document/9041744
"In particular , we achieve a 25 % higher recall for 2K proposals than the state - of - the - art RGB - D method MCG - D [ 14 ]. Combined with CNN scoring , our method outperforms all published results on object detection for Car , Cyclist and Pedestrian on KITTI [ 11 ]. Our code and data are online : _CITE_",Material,Data,Produce,3D Object Proposals for Accurate Object Class Detection,https://proceedings.neurips.cc/paper/2015/hash/6da37dd3139aa4d9aa55b8d237ec5d4a-Abstract.html
"It is also worth studying how different kernel functions affect the performance of NPE . These are matters of our future inquiry . To facilitate such exploration , we make our Mturk dataset public at _CITE_",Material,Data,Produce,Overview and comparative study of dimensionality reduction techniques for high dimensional data,https://www.sciencedirect.com/science/article/abs/pii/S156625351930377X
"1 . We show how to incorporate this information in Policy Gradient RL [ 30 ], and show that we can improve over RL that has access to the same amount of ground - truth captions . Our code and data will be released ( ) to facilitate more human - like training of captioning models .",Material,Data,Produce,Teaching Machines to Describe Images with Natural Language Feedback,https://proceedings.neurips.cc/paper/2017/hash/8e68c3c7bf14ad0bcaba52babfa470bd-Abstract.html
"Through evolution , structure is more conserved than sequence , so that detecting even very subtle sequence similarities , or remote homology , is important for predicting function . The major methods for homology detection can be split into three basic groups : pairwise sequence comparison algorithms [ 1 , 2 ], generative models for protein families [ 3 , 4 ], and discriminative classifiers [ 5 , 6 , 7 ]. Popular sequence comparison methods such as BLAST * Supplemental information for the paper , including the data sets and Matlab source code can be found on this author ’ s web page at and Smith - Waterman are based on unsupervised alignment scores . Generative models such as profile hidden Markov models ( HMMs ) model positive examples of a protein family , but they can be trained iteratively using both positively labeled and unlabeled examples by pulling in close homologs and adding them to the positive set . A compromise between these methods is PSI - BLAST [ 8 ], which uses BLAST to iteratively build a probabilistic profile of a query sequence and obtain a more sensitive sequence comparison score .",Material,Data,Produce,Protein homology detection by HMM–HMM comparison,https://academic.oup.com/bioinformatics/article/21/7/951/268976
"The PROP - diff , PROP - WL and the WL kernel were each run with 10 iterations . In the CSM kernel , the clique size parameter was set to k = 5 . Our kernel implementations and datasets ( with the exception of AIRWAYS ) can be found at Classification experiments were made on four datasets : ENZYMES , PROTEINS , AIRWAYS and SYNTHETIC . ENZYMES and PROTEINS are sets of proteins from the BRENDA database [ 22 ] and the dataset of Dobson and Doig [ 23 ], respectively .",Material,Data,Produce,Scalable kernels for graphs with continuous attributes,https://proceedings.neurips.cc/paper/2013/hash/a2557a7b2e94197ff767970b67041697-Abstract.html
"We trained the networks using an implementation based on Caffe [ 25 ]. Details on the training , the hyperparameter settings , and an analysis of the performance depending on the network architecture is provided in the supplementary material . Our code and training data are available at . We applied the feature representation to images of arbitrary size by convolutionally computing the responses of all the network layers except the top softmax . To each feature map , we applied the pooling method that is commonly used for the respective dataset : 1 ) 4 - quadrant max - pooling , resulting in 4 values per feature map , which is the standard procedure for STL - 10 and CIFAR - 10 [ 26 , 10 , 27 , 12 ]; 2 ) 3 - layer spatial pyramid , i . e .",Material,Data,Produce,Convolutional neural network architectures for predicting DNA–protein binding,https://academic.oup.com/bioinformatics/article/32/12/i121/2240609
"We also find that a low rank version is able to achieve approximately 23 × compression of the original data , with the optimal solution very close to the full rank optimum . Our method is a superior predictor to the existing regional model for visual system data , and the success of the low rank version suggests that this approach will be able to reveal whole - brain structural connectivity at unprecedented scale . All of our supplemental material and data processing and optimization code is available for download from : _CITE_",Material,Data,Produce,High resolution neural connectivity from incomplete tracing data using nonnegative spline regression,https://proceedings.neurips.cc/paper/2016/hash/f337d999d9ad116a7b4f3d409fcc6480-Abstract.html
"However , COCO - QA questions are actually easier to answer than DAQUAR from a human point of view . This encourages the model to exploit salient object relations instead of exhaustively searching all possible relations . COCO - QA dataset can be downloaded at _CITE_",Material,Data,Produce,Exploring Models and Data for Image Question Answering,https://proceedings.neurips.cc/paper/2015/hash/831c2f88a604a07ca94314b56a4921b8-Abstract.html
"The features of each book are given by the words in the Amazon . com front page for that particular book . The choice of books , labels , and relationships are given in the data collected by Valdis Krebs and available at http :// www - personal . umich . edu / mejn / netdata . The data containing book features can be found at There are 105 books , 43 of which are labeled as liberal books . The relationships are pairs of books which are frequently purchased together by a same customer .",Material,Data,Produce,Hidden Common Cause Relations in Relational Learning,https://proceedings.neurips.cc/paper/2007/hash/912d2b1c7b2826caf99687388d2e8f7c-Abstract.html
"This output distribution can be seen as a saliency map from the point of view of the person inside the picture . To train and evaluate our model , we also introduce GazeFollow , a large - scale benchmark dataset for gaze - following . Our model , code and dataset are available for download at Related Work ( Saliency ): Although strongly related , there are a number of important distinctions between gaze - following [ 3 ] and saliency models of attention [ 8 ]. In traditional models of visual attention , the goal is to predict the eye fixations of an observer looking at a picture , while in gazefollowing the goal is to estimate what is being looked at by a person inside a picture .",Material,Data,Produce,Where are they looking?,https://proceedings.neurips.cc/paper/2015/hash/ec8956637a99787bd197eacd77acce5e-Abstract.html
"We used a soft - max operation with an increasing temperature parameter to model the non - differentiable color channel selection at each point , which allowed us to train the pattern effectively . Finally , we demonstrated that our learned pattern enabled better reconstructions than past designs . An implementation of our method , along with trained models , data , and results , is available at our project page at Our results suggest that learning measurement strategies jointly with computational inference is both useful and possible . In particular , our approach can be used directly to learn other forms of optimized multiplexing patterns — e . g ., spatio - temporal multiplexing for video , viewpoint multiplexing in lightfield cameras , etc .",Material,Data,Produce,FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search,http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_FBNet_Hardware-Aware_Efficient_ConvNet_Design_via_Differentiable_Neural_Architecture_Search_CVPR_2019_paper.html
We perform a systematic evaluation of these variants by using humans to judge photorealism and a perceptual distance metric [ 52 ] to assess output diversity . Code and data are available at _CITE_,Material,Data,Produce,Toward Multimodal Image-to-Image Translation,https://proceedings.neurips.cc/paper_files/paper/2017/hash/819f46e52c25763a55cc642422644317-Abstract.html
"There are 22 , 894 atom symmetry classes , which when paired with reaction condition yields 29 , 104 ( a , c ) tuples . Of these 29 , 104 ( a , c ) tuples , 1 , 262 have label srcreact = 1 , and 1 , 786 have label sinkreact = 1 . Atom and MO interaction data is available at our chemoinformatics portal ( ) under Supplements .",Material,Data,Produce,Accurate Molecular Van Der Waals Interactions from Ground-State Electron Density and Free-Atom Reference Data,https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.102.073005
"This dataset is important to us , because we are interested in conducting neuroscience research concerning this brain region . Even to those with no interest in piriform cortex , the dataset could be useful for research on image segmentation algorithms . Therefore we make the annotated dataset publicly available ( ).",Material,Data,Produce,Recursive Training of 2D-3D Convolutional Networks for Neuronal Boundary Prediction,https://proceedings.neurips.cc/paper/2015/hash/39dcaf7a053dc372fbc391d4e6b5d693-Abstract.html
"Co - authored papers gave fractional counts evenly to all authors . All words occurring in six or more documents were included , except for stopwords giving a vocabulary size of 13649 . The NIPS text data is available at . in terms of , the probability that version of picks versionof :",Material,Data,Produce,Stochastic Neighbor Embedding,https://proceedings.neurips.cc/paper/2002/hash/6150ccc6069bea6b5716254057a194ef-Abstract.html
"5 and 6 and we provide results on smaller corrupted datasets ( to show the performance of IWS - LS ) as well as non - corrupted data simulated according to [ 13 ] in § SI . 7 . Airline delay dataset The dataset consists of details of all commercial flights in the USA over 20 years . Dataset along with visualisations available from Selecting the first ntrain = 13 , 000 US Airways flights from January 2000 ( corresponding to approximately 1 . 5 weeks ) our goal is to predict the delay time of the next ntest = 5 , 000 US Airways flights . The features in this dataset consist of a binary vector representing origin - destination pairs and a real value representing distance ( p = 170 ).",Material,Data,Produce,Nanocubes for Real-Time Exploration of Spatiotemporal Datasets,https://ieeexplore.ieee.org/abstract/document/6634137
More experiments and results on real data sets can be found on our web - page _CITE_,Material,Data,Produce,The MovieLens Datasets: History and Context,https://dl.acm.org/doi/abs/10.1145/2827872
"Of course , our model is a general statistical model and given an expressive feature map , it can learn any ground truth . In this view the experiments suggest the relative performance of the compared models . The dataset , and an implementation of our model , is available at Table 1 shows some statistics of the dataset . We use two kinds of features , byte - level and instruction - level features .",Material,Data,Produce,Static Analysis of Binary Executables Using Structural SVMs,https://proceedings.neurips.cc/paper/2010/hash/a1d33d0dfec820b41b54430b50e96b5c-Abstract.html
"In Section 4 . 1 , we will describe the process to collect the data , and the method to monitor the quality of annotations . Some statistics and examples of the dataset will be given in Section 4 . 2 . The latest dataset is available on the project page : _CITE_",Material,Data,Produce,How to plan and perform a qualitative study using content analysis,https://www.sciencedirect.com/science/article/pii/S2352900816000029
We evaluate the residual transfer network against state of the art transfer learning and deep learning methods . Codes and datasets will be available at _CITE_,Material,Data,Produce,Deep Transfer Learning with Joint Adaptation Networks,http://proceedings.mlr.press/v70/long17a.html
In this paper we exploit this novel connection to show an interesting application of the SVM setup for identfying large dense subgraphs . More specifically we make the following contributions . ∗ Relevant code and datasets can be found on _CITE_,Material,Data,Produce,"The Lovász ϑ function, SVMs and finding large dense subgraphs",https://proceedings.neurips.cc/paper/2012/hash/8eefcfdf5990e441f0fb6f3fad709e21-Abstract.html
"More specifically , we record multiple peo318 { xtm , stm } M ‡ m = 1 . by the vector xi set of micophones Given the rcorded sinal the t the state of the i - th particle at time t . We also ait ∈{ 1 , ... , P } in order to denote the particle that precedes the gnals Speakers may stat speakng or become sil t corresponds to the index of the ancestor particle of xi i - th particle at time t . That is , ai collect data from several speakers from the ASCAL t . Let alsoxi1 : t xi the particle trajctory that s recursively defined as hallenge website . The voice signal for each speak example to clarify the notation . and the emission In Step 1 , we follow the slice sampling scheme for inference in BNP models based on the Indian bu et process ( IBP ) [ 19 , 23 ], which ectively transforms the model into a finite factorial model with = M + + Mnew parallel chains . Step 2 consists in sampling the elements of the matrices S and X given the current value of the global variables .",Material,Data,Produce,Infinite Factorial Dynamical Model,https://proceedings.neurips.cc/paper/2015/hash/0768281a05da9f27df178b5c39a51263-Abstract.html
"We used the standard SURF features [ 21 ] with 2000 visual words as the original domain and the recently proposed DeCAF features [ 25 ] extracted from the activation of a deep convolutional network trained in a fully supervised fashion as the privileged domain . The DeCAF features have 4096 dimensions . All features are provided with the AwA dataset . We again performed PCA for dimensionality reduction in the original and privileged domains and only kept the top 50 principal components , as well as standardised the data . Attributes as privileged information : Following the experimental setting of [ 6 ], we also used images as the original domain and attributes as the privileged domain .",Material,Data,Produce,Mind the Nuisance: Gaussian Process Classification using Privileged Noise,https://proceedings.neurips.cc/paper/2014/hash/6e2713a6efee97bacb63e52c54f0ada0-Abstract.html
"We compare our MI Uncertainty ( MIU ) and Expected Gradient Length ( EGL ) selection strategies from Section 2 against two baselines : Uncertainty ( using only the instance - model ’ s uncertainty ), and instances chosen uniformly at Random from positive bags ( to evaluate the advantage of “ passively ” labeling instances ). The MILR model uses a = 2 . 5 for the softmax function and is trained by minimizing squared loss via L - BFGS [ 7 ]. The instance - labeled MI data sets and MI learning source code used in these experiments are available online . We evaluate our methods by constructing learning curves that plot the area under the ROC curve ( AUROC ) as a function of instances queried for each data set and selection strategy . The initial point in all experiments is the AUROC for a model trained on labeled bags from the training set without any instance queries .",Material,Data,Produce,Multiple-Instance Active Learning,https://proceedings.neurips.cc/paper_files/paper/2007/hash/a1519de5b5d44b31a01de013b9b51a80-Abstract.html
We prevent gradients from ‘ exploding ’ as we backpropagate through time by truncating the length of gradients whose norm is above a threshold . For all models in this paper we consistently used hidden dimensionality of 200 and a mini - batch size of 100 . To facilitate research in DKTs we have published our code and relevant preprocessed data . The training objective for knowledge tracing is to predict a student ’ s future performance based on their past activity . This is directly useful – for instance formal testing is no longer necessary if a student ’ s ability undergoes continuous assessment .,Material,Data,Produce,Preventing Gradient Explosions in Gated Recurrent Units,https://proceedings.neurips.cc/paper/2017/hash/f2fc990265c712c49d51a18a32b39f0c-Abstract.html
"These figures show that the improvement in recall is consistent over the full range of false positive rates . For further comparisons , our data and code are available online . Compactness of our kernels . In many applications of feature matching , the compactness of the descriptor is important . In Table 3 , we compare to other methods by grouping them according to their memory footprint .",Material,Data,Produce,Comprehensive benchmarking and ensemble approaches for metagenomic classifiers,https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1299-7
"The UIUC dataset contains 314 cluttered indoor images , of which the ground - truth is two label maps of background layout with / without foreground objects . Our dataset contains 220 images which cover six indoor scene categories : bedroom , living room , kitchen , classroom , office room , and corridor . The dataset is available on the project webpage . The ground - truths are hand labeled segments for scene components for each image . Our algorithm usually takes 20s in clustering , 40s in sampling , and 1m in preparing input features .",Material,Data,Produce,"Scene Parsing by Integrating Function, Geometry and Appearance Models",https://openaccess.thecvf.com/content_cvpr_2013/html/Zhao_Scene_Parsing_by_2013_CVPR_paper.html
The datasets generated during and / or analysed during the current study are available in the documentation webpage ( ) of the software that is deposited to the CRAN ( http :// cran . r - project . org / package = XGR ).,Material,Data,Produce,"Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences",https://link.springer.com/article/10.1186/gb-2010-11-8-r86
"Data from PSG , NET - PD , and the PPMI studies are managed by the Center for Human Experimental Therapeutics ( CHET ) at the University of Rochester . The CHET coordinating center currently houses data from over 40 PD clinical studies enrolling 7000 PD participants as well as from observational studies , including data from physician - rated clinical scales such as the UPDRS , Mini - Mental State Examination ( MMSE ) and the Beck Depression Inventory , as well as patient - reported outcomes data , imaging , laboratory and biomarkers , genetics , and demographics . The PSG hosts a list of data on the website , a short narrative about what the study covers , and guidance on how to access the data ( ). The review process is coordinated by the Michael J Fox Foundation and any researcher can apply . There have been over 200 publications resulting from the use of these data to date and future use is encouraged , especially for modeling disease progression Data used in modeling is only about 20 % of the data available through the PSG , but additional data sources are relevant for this purpose ( Table 1 ).",Material,Data,Produce,Precompetitive Data Sharing as a Catalyst to Address Unmet Needs in Parkinson’s Disease,https://content.iospress.com/articles/journal-of-parkinsons-disease/jpd150570
"Funding We would like to acknowledge NIH grants # P30AG050911 and # P20GM103636 for supporting this work . Publication charges were paid for by # P20GM103636 . Availability of data and materials The code for label extraction , along with the database of extracted labels , is available at _CITE_",Material,Data,Produce,ALE: automated label extraction from GEO metadata,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1888-1
"permits unrestricted use , distribution , and reproduction in any medium , provided the original author and source are credited . Data Availability Statement : Data and code from the current study is located here : master . Due to ethical restrictions , participant data including participant identifiers , are not available without restriction . However , all interested researchers can request and obtain the raw . qtm files by contacting the corresponding author ( cleveland . barnett @ ntu . ac . uk ).",Material,Data,Produce,Data and code availability statements in systematic reviews of interventions were often missing or inaccurate: a content analysis,https://www.sciencedirect.com/science/article/abs/pii/S0895435622000646
"Python packages used for analysis include numpy ( Oliphant , 2007 ; Van der Walt , Colbert & Varoquaux , 2011 ), matplotlib ( Hunter , 2007 ), sqlalchemy ( Bayer , 2014 ), pandas ( McKinney , 2010 ), macroecotools ( Xiao et al ., 2016 ), and retriever ( Morris & White , 2013 ). R packages used for analysis include ggplot2 ( Wickham , 2009 ), magrittr ( Bache & Wickham , 2014 ), tidyr ( Wickham , 2016 ), and dplyr ( Wickham & Francois , 2016 ). All of the code and all of the publicly available data necessary to replicate these analyses is available at and archived on Zenodo ( Baldridge et al ., 2016 ). The CBC datasets and NABA datasets are not publicly available and therefore are not included .",Material,Data,Produce,An extensive comparison of species-abundance distribution models,https://peerj.com/articles/2823/
"Given the size of the datasets (~ 150 2 h imaging sessions ), we provide MATLAB data containing solely deconvolved images and labels for each stimulus ( concept or sentence ). The raw and processed NIFTI imaging datasets , as well as associated event files , will be shared via a repository ( http :// www . openfmri . org ), after re - processing . Any updates on the data and scripts will be posted on the paper website ( crwz7 ).",Material,Data,Produce,Toward a universal decoder of linguistic meaning from brain activation,https://www.nature.com/articles/s41467-018-03068-4
"In the previous NAR manuscript update ( 5 ), we reported that we were working in the development of ‘ PRIDE - Q ’, a resource that would show the high - quality identification data coming from PRIDE . The name of this resource was later changed to ‘ PRIDE Proteomes ’. Here , we are just giving a brief update about this new PRIDE resource ( in beta , ). PRIDE Proteomes provides a quality - filtered , across - dataset view on the identification data available in PRIDE Archive . The PSMs reported in PRIDE Archive are first qualityfiltered using a spectrum clustering approach : all the identified spectra coming from the public experiments in PRIDE Archive are clustered using a refined version of the ‘ PRIDE Cluster ’ algorithm ( 47 ).",Material,Data,Produce,2016 update of the PRIDE database and its related tools,https://academic.oup.com/nar/article-abstract/44/D1/D447/2502640
The dataset ( s ) supporting the conclusions of this article is ( are ) available in the project ’ site repository at _CITE_,Material,Data,Produce,FLOSSmole: A Collaborative Repository for FLOSS Research Data and Analyses,https://www.igi-global.com/article/international-journal-information-technology-web/2610
"We use a complex four - class classification problem , where new tweets can be assigned to the classes “ crash ”, “ fire ”, “ shooting ”, and a neutral class “ not incident related ”. This goes beyond related work with a focus on two - class classification . Our classes were identified as the most common incident types in Seattle using the Fire Calls data set ( ), an official incident information source . As ground truth data , we collected several cityspecific datasets using the Twitter Search API . These datasets were collected in a 15 km radius around the city centres of Boston ( USA ), Brisbane ( AUS ), Chicago ( USA ), Dublin ( IRE ), London ( UK ), Memphis ( USA ), New York City ( USA ), San Francisco ( USA ), Seattle ( USA ), Sydney ( AUS ).",Material,Data,Use,"More Features Are Not Always Better: Evaluating Generalizing Models in
Incident Type Classification of Tweets",https://aclanthology.org/D15-1048.pdf
"However , the Manipuri news is available only in PDF format from these websites . A web based Manipuri news corpus collection is reported ( Singh and Bandyopadhyay , 2010a ) using the Bengali script in Unicode format . The resource constrained Manipuri language news corpus is collected from At present , there is a Manipuri news monolingual corpus of 4 million wordforms in Bengali script Unicode format . Our experiment makes use of this corpus on news domain .",Material,Data,Use,"Bidirectional Bengali Script and Meetei Mayek
Transliteration of Web Based Manipuri News Corpus",https://aclanthology.org/W12-5016.pdf
"Ancestor F1 : Measures the precision , recall , and F1 = 2PR /( P + R ) of correctly predicted ances12This is somewhat different from our general setup where we work with any given set of terms ; they start with a large set of leaves which have substantial Web - based relational information based on their selected , hand - picked patterns . Their data is available at downloads . html .",Material,Data,Use,Structured Learning for Taxonomy Induction with Belief Propagation,https://aclanthology.org/P14-1098.pdf
This gives a higher weight to the extended word and retains its contribution to the sentiment of the tweet . Chat lingo normalization : Words used in chat / Internet language that are common in tweets are not present in the lexical resources . We use a dictionary downloaded from . A chat word is replaced by its dictionary equivalent .,Material,Data,Use,C-Feel-It: A Sentiment Analyzer for Micro-blogs,https://aclanthology.org/P11-4022.pdf
"We have collected from Livejournal2 a total of 346723 weblogs ( mood - annotated by authors ) in z_CITE_ English , from which almost half are annotated with a mood belonging to one of the four quadrants , described as follows : Quadrant1 bellicose , tense , alarmed , envious , hateful , angry , enraged , defiant , annoyed , jealous , indignant , frustrated , distressed , disgusted , suspicious , discontented , bitter , insulted , distrustful , startled , contemptuous and impatient . Quadrant2 apathetic , disappointed , miserable , dissatisfied , taken aback , worried , languid , feel guilt , ashamed , gloomy , sad , uncomfortable , embarrassed , melancholic , depress , desperate , hesitant , bored , wavering , droopy , tired , insecured , anxious , lonely and doubtful .",Material,Data,Use,Towards a validated model for affective classification of texts,https://aclanthology.org/W06-0308.pdf
"To avoid inconsistency between vote and perspective , we use data from pro - choice and pro - life nongovernmental organizations , NARAL and NRLC , that track legislators ’ votes on abortion - related bills , showing the percentage of times a legislator supported the side the organization deems consistent with its perspective . We removed 22 legislators with a mixed record , that is , those who gave 20 - 60 % support to one of the positions . 2 Death Penalty ( DP ) blogs : We use University of Maryland Death Penalty Corpus ( Greene and Resnik , 2009 ) of 1085 texts from a number of proand anti - death penalty websites . We report 4 - fold cross - validation ( DP - 4 ) using the folds in Greene and Resnik ( 2009 ), where training and testing data come from different websites for each of the sides , as well as 10 - fold cross - validation performance on the entire corpus , irrespective of the site . 3 Bitter Lemons ( BL ): We use the GUEST part of the BitterLemons corpus ( Lin et al ., 2006 ), containing 296 articles published in 2001 - 2005 on by more than 200 different Israeli and Palestinian writers on issues related to the conflict . Bitter Lemons International ( BL - I ): We collected 150 documents each by a different per",Material,Data,Use,Vocabulary Choice as an Indicator of Perspective,https://aclanthology.org/P10-2047.pdf
"This mapping is described in Henrich et al . ( 2011 ). The resulting resource consists of a web - harvested corpus WebCAGe ( short for : Web - Harvested Corpus Annotated with GermaNet Senses ), which is freely available at : The remainder of this paper is structured as follows : Section 2 provides a brief overview of the resources GermaNet and Wiktionary . Section 3 introduces the mapping of GermaNet to Wiktionary and how this mapping can be used to automatically harvest sense - annotated materials from the web . The algorithm for identifying the target words in the harvested texts is described in Section 4 .",Material,Data,Use,WebCAGe – A Web-Harvested Corpus Annotated with GermaNet Senses,https://aclanthology.org/E12-1039.pdf
"After the SemEval task , we crawled the full articles from , cleaned the corpus and annotated it with the exact publication date of the article , its title and the URL from which it was retrieved . The Daikon Corpus is made up of articles from the British Spectator news magazine from year 828 to 2008 . The Daikon corpus can be used for future diachronic studies and epoch identification tasks ; it provides a complementary dataset to the gold standard provided by task .",Material,Data,Use,USAAR-CHRONOS: Crawling the Web for Temporal Annotations,https://aclanthology.org/S15-2143.pdf
"We have performed two Reliability Tests in order to 1 ) to check the transferability and applicability of MIPVU , which was originally designed for English , to Russian - language material and 2 ) to assess the reliability of MIPVU on Russianlanguage material by measuring the rate of interannotator agreement . The Reliability Tests had the following setup : – 3 annotators ( PhDs and current PhD students with prior experience in conceptual metaphor studies ); – a collection of 4 text excerpts ( 500 - 600 words each ), representing the 4 genres : fiction , transcribed spoken , popular science / academic , and news texts ; – POS - tagged files from the National Russian Corpus ( ) in xhtmlformat ; – 2 dictionaries used to define the word meanings : ( Dictionary of the Russian Language , 1981 - 1984 , Dictionary of the Russian Language , 1999 ). The inter - annotator agreement was measured by Fleiss ' kappa ( Artstein and Poesio , 2008 ) using binary classification , i . e . 1 for any metaphorrelated word and 0 for otherwise .",Material,Data,Use,"Annotating a Russian corpus of conceptual metaphor: a bottom-up
approach ",https://aclanthology.org/W13-0910.pdf
"Khaltar and Fujii ’ s method was also evaluated for comparison . We used Moses ( Koehn et al ., 2007 ) with the standard configuration and GIZA ++ ( Och et al ., 2003 ) with the grow - diag - final - and heuristic for word - alignment . Our parallel data set was collected from web sites ( and http :// mongolia . usembassy . gov /), and consists of law and news domains . Example En - Mn sentence pairs in our data are shown below . En1 : Occupational safety and health measures shall not involve any expenditure for the workers .",Material,Data,Use,"Enhancing Lemmatization for Mongolian and
its Application to Statistical Machine Translation",https://d1wqtxts1xzle7.cloudfront.net/31118220/W12-52-libre.pdf?1392203696=&response-content-disposition=inline%3B+filename%3DRepairing_Bengali_Verb_Chunks_for_Improv.pdf&Expires=1685967764&Signature=NEdqlWey3GlTcmLQrjPFCwiVyE65OgzSMhXu6mdxh-LKDoXVy2MSjrp4OwR33ww26H~fXKnVqeGL3-xIcAj8dzjqc0J-xmXjSJXGgWi59Yo7rA8YT83y4ZFQFywdDHfm6-Z3yQQgKMPC2gCxlN8fUPBn3LbUirkeBI0U~3ejnjkrKdeUiD-0k95AN60JPScXnoG-rpzB9k38LkAcGBBw~jQWSBKYNrhYLIuD3rJv9kgOZO~TH8t7vrmbDJtKYlnbbGnhnwqfsTErsV3pa19T47P5K-B1bGhXElgxa2A7OtP5kzXlZT6QFuPPZG422wzMCEom5QtEcCVWDw5rkOyqFQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA#page=125
"A non - applicable parameter for a particular type of expression would receive a “ Null ” value . The annotation of text fragments has been guided by the presence of evaluative expressions and other criteria as explained in section III . For annotation purposes , we have collected the editorials from two online newspapers ( , http :// kantipuronline . com / ktmpost . php ) of different dates of the year 2007 , amounting to a total of 16 text files and approximately 320 sentences with an average of 20 sentences per editorial . Two annotators having a fairly good understanding of the English",Material,Data,Use,"Towards an Analysis of Opinions in News
Editorials: How positive was the year?",https://aclanthology.org/W09-3723.pdf
"Theoretically , the algorithm should also distinguish between all literal senses so that the contexts of the same meaning appear in the same cluster and the contexts of different meanings - in different clusters . Therefore , ideally , the algorithm should solve word sense discrimination and non - literal usages detection tasks simultaneously . For each Russian word shown in Table 3 , we extracted from the Russian National Corpora ( ) several literal and non - literal occurences . Some of these words have more than one meaning in Russian , e . g . KnFo - i can be translated as a key or water spring and the word Koca as a plait , scythe or spit .",Material,Data,Use,"A Framework for Figurative Language Detection Based on Sense
Differentiation",https://aclanthology.org/P10-3012.pdf
"To test the consistence of the results obtained by our method , they will be compared with the Edinburgh Association Thesaurus , a collection of 8000 words whose association norms were produced by presenting each of the stimulus words to about 100 subjects each , and by collecting their responses . The subjects were 17 to 22 year old British students . To perform the tests , we take a sample ( EAT : ) consisting in 100 words . For building a network to deal with the specific task of producing word associations we have used the British National Corpus ( BNC ) as a source . The way the network has been constructed has also some interest and impact in the final results .",Material,Data,Use,"Retrieving Word Associations with a Simple Neighborhood Algorithm
in a Graph-Based Resource ",https://aclanthology.org/W14-4708.pdf
"As a consequence , the precisions at different cut - offs have a significantly higher value with Moby as reference than with WordNet as reference . Finally , the results of Table 2 are compatible with those of ( Lin , 1998 ) for instance ( R - prec . = 11 . 6 and MAP = 8 . 1 with WM as reference for all entries of the thesaurus at ) if we take into account the fact that the thesaurus of Lin was built from a much larger corpus and with syntactic co - occurrences .",Material,Data,Use,"Identifying Bad Semantic Neighbors for Improving Distributional
Thesauri",https://aclanthology.org/P13-1055.pdf
"We extract further information indicating whether a named entity , as identified by the Stanford NE Recognizer ( Finkel et al ., 2005 ) begins at wi . These features are relevant as there 5Realization of the classes D and N as lexical items is straightforward . To convert I into a or an , we use the CMU pronouncing dictionary ( ) and select an if wi starts with a phonetic vowel .",Material,Data,Use,Design Challenges and Misconceptions in Named Entity Recognition,https://aclanthology.org/W09-1119.pdf
"The weight computation is done by emergence along with the gaming activity . Obviously by intuition , the relation cat --> animal is stronger than cat --> ball of wool , none withstanding their types . The lexical network has been made available ( at ) and free to use by their authors , giving the research community a resource to play with . The question of the evaluation of its quality , usability in WSD and word recollection ( Tip of the Tongue problem ), and distributional properties are the main subjects of this article . One specific question is whether low weight but still important relations can be captured by some similar approaches and to which extend they are useful .",Material,Data,Use,Long Tail in Weighted Lexical Networks,https://aclanthology.org/W12-5102.pdf
"Each entry includes an ID number and a Nonliteral , Literal , or Unannotated tag . Annotations are from testing or from active learning during example - base construction . The TroFi Example Base is available at Further unsupervised expansion of the existing clusters as well as the production of additional clusters is a possibility .",Material,Data,Use,"A Clustering Approach for the Nearly Unsupervised Recognition of
Nonliteral Language",https://aclanthology.org/E06-1042.pdf
where β is a weighted constant often set to 1 . We test the baseline system on the newswire test data for the 1999 IEER evaluation in Mandarin ( 99 . htm ). Table 2 in section 4 summarizes the result of baseline model .,Material,Data,Use,"Chinese Named Entity Recognition Combining a Statistical Model with
Human Knowledge ",https://aclanthology.org/W03-1509.pdf
"words for training and 100 thousand words for validation from the Harry Potter fan fiction database ( ). We restricted the vocabulary to the top 100 thousand words which covered all but 4 words from Chapter 9 of Harry Potter and the Sorcerer ’ s Stone . For the RNNLM , we trained models with different hidden layers and learning rates and found the RNNLM with 250 hidden units to perform best on the validation set .",Material,Data,Use,"Aligning context-based statistical models of language
with brain activity during reading",https://aclanthology.org/D14-1030.pdf
The training corpus is part of the JRC - ACQUIS ( - last accessed on 18 . 04 . 09 ). Two types of alignments are available on the corpus homepage : Vanilla and HunAlign . The alignments realized with the Vanilla aligner7 were used for the experiments presented here .,Material,Data,Use,SMT experiments for Romanian and German using JRC-ACQUIS,https://dl.acm.org/doi/abs/10.5555/1859119.1859122
"These are byproducts of protein - interaction extraction in our project . The corresponding ‘ official symbol ’ was searched using a partial match of registered names , and finally was checked manually . Compound names were gathered from the index of the biochemical dictionary , KEGG ( ), mesh terms , and UMLS ( http :// www . nlm . nih . gov / research / umls /) and were registered in GENA . Some high - concept terms were removed manually . Compound name searches were not evaluated in this study .",Material,Data,Use,Gene/protein/family name recognition in biomedical literature,https://aclanthology.org/W04-3102.pdf
"Word categories are identified by using the LingPipe ’ s general English part - of - speech ( POS ) tagger trained on the Brown Corpus ( ). We leverage POS information to collect , for each sentence , nominal groups that are potential keyphrases .",Material,Data,Use,Single Document Keyphrase Extraction Using Sentence Clustering and Latent Dirichlet Allocation,https://hal.science/hal-01151516/
"The experiments of this paper utilize the first medium - sized corpus for Amharic ( available at ). The corpus consists of all 1065 news texts ( 210 , 000 words ) from the Ethiopian year 1994 ( parts of the Gregorian years 2001 – 2002 ) from the Walta Information Center , a private news service based in Addis Ababa . It has been morphologically analysed and manually partof - speech tagged by staff at ELRC , the Ethiopian Languages Research Center at Addis Ababa University ( Demeke and Getachew , 2006 ).",Material,Data,Use,Methods for Amharic part-of-speech tagging,https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1042595&dswid=-801
"Roughly speaking , the rules were extracted from a parallel English - Chinese corpus , based on the assumption that two English phrases 01 and 02 that are often aligned to the same Chinese phrase � are 5We trained GA - EXTR on approximately 1 , 050 pairs of source sentences and gold human extractive compressions , obtained from Edinburgh ’ s ‘ written ’ extractive dataset ; see The source sentences of that dataset are from 82 documents . The 1 , 050 pairs that we used had source sentences from 52 out of the 82 documents .",Material,Data,Use,"A New Sentence Compression Dataset and Its Use in an Abstractive
Generate-and-Rank Sentence Compressor",https://aclanthology.org/W11-2701.pdf
"In other words , as long as a candidate has been confirmed once , it is assumed to be a protein throughout . In this way , there are two filtering alternatives M31 and M32 from M1 and M2 , respectively . To get more objective evaluation , we utilized another corpus of 101 abstracts used by Yapex [ Using the test corpus and answer keys supported in Yapex project , the evaluation results on filtering strategies are listed in Table 1 .",Material,Data,Use,Enhancing Performance of Protein Name Recognizers Using Collocation,https://aclanthology.org/W03-1304.pdf
"The synset 00198451 - n is translated as 晋什 jìnshén , which should have been 晋升 jìnsheng ‘ promotion ’. 00198451 - n promotion “ act of raising in rank or position ” ( iii ) Need M de / A de to match the English POS The synset 01089369 - a is an adjectival , but the translation 兼职 jidnzhí ‘ part time ’ is a verb / noun , so we add 的 de to it ( 1 . 3 ). 01089369 - a part - time ; part time “ involving less than the standard or customary time for an activity ”: parttime employees ; a part - time job To improve the coverage and accuracy of COW , we make reference not only to many authoritative bilingual dictionaries , such as The American Heritage Dictionary for Learners of English ( Zhao , 2006 ), The 21st Century Unabridged EnglishChinese Dictionary ( Li , 2002 ), Collins COBUILD Advanced Learner ' s English - Chinese Dictionary ( Ke , 2011 ), Oxford Advanced Learner ' s EnglishChinese Dictionary ( 7th Edition ) ( Wang , Zhao , & Zou , 2009 ), Longman Dictionary of Contemporary English ( English - Chinese ) ( Zhu , 1998 ), etc ., but also online bilingual dictionaries , such as iciba , youdao , lingoes10 , dreye11 and bing12 . For example , the English synset 00203866 - v can be translated as 变坏 biàn huài ‘ decline ’ and 恶化 èhuà ‘ worsen ’, which are not available in the current wordnet , so we added them to COW . 00203866 - v worsen ; decline “ grow worse ”: Conditions in the slum worsened PWN groups nouns , verbs , adjectived and adverbs into synonyms ( synsets ), most of which are linked to other synsets through a number of semantic relations .",Material,Data,Use,Building the Chinese Open Wordnet (COW): Starting from Core Synsets ,https://aclanthology.org/W13-4302.pdf
"We use the data that were recorded and preprocessed by Mitchell et al . ( 2008 ), available for download in their supporting online material . Full details of the experimental protocol , data acquisition and preprocessing can be found in Mitchell et al . ( 2008 ) and the supporting material . Key points are that there were nine right - handed adult participants ( 5 female , age between 18 and 32 ).",Material,Data,Use,"Of words, eyes and brains:
Correlating image-based distributional semantic models
with neural representations of concepts",https://aclanthology.org/D13-1202.pdf
"We leave the exploitation of other mechanisms of incorporating prior knowledge into model training as future work . The document sentiment is classified based on P ( l | d ), the probability of sentiment label given document , which can be directly obtained from the document - sentiment distribution . We define that a document d is classified as positive We conducted experiments on the four corpora which were derived from product reviews harvested from the website IT168 with each corresponding to different types of product reviews including mobile phones , digital cameras , MP3 players , and monitors . All the reviews were tagged by their authors as either positive or negative overall . The statistics of the four corpora are shown in Table 2 .",Material,Data,Use,Exploring English lexicon knowledge for Chinese sentiment analysis,http://oro.open.ac.uk/25092/
"For this purpose , we created the Paraphrase for Plagiarism corpus ( P4P ) annotating a portion of the PAN - PC - 10 corpus for plagiarism detection ( Potthast et al . 2010 ) on the basis of a paraphrase typology , and we mapped the annotation results with those of the Second International Competition on Plagiarism Detection ( Pan - 10 competition , hereafter ). The results obtained provide critical insights for the improvement of automatic plagiarism detection systems . The rest of the article is structured as follows . Section 2 sets out the paraphrase typology used in this research work .",Material,Data,Use,Plagiarism Meets Paraphrasing: Insights for the Next Generation in Automatic Plagiarism Detection,https://direct.mit.edu/coli/article/39/4/917/1450/Plagiarism-Meets-Paraphrasing-Insights-for-the
"In ( Alkhouli et al ., 2015 ), it is shown that approximate RNN integration into the phrase - based decoder has a slight advantage over n - best rescoring . Therefore , we apply RNNs in rescoring in this work , and to allow for a direct comparison between FFNNs and RNNs , we apply FFNNs in rescoring as well . We perform experiments on the largescale IWSLT 2013 ( Cettolo et al ., 2014 ) German → English , WMT 2015 German → English and the DARPA BOLT Chinese → English tasks . The statistics for the bilingual corpora are shown in Table 2 . Word alignments are generated with the GIZA ++ toolkit ( Och and Ney , 2003 ).",Material,Data,Use,"A Comparison between Count and Neural Network Models Based on
Joint Translation and Reordering Sequences",https://aclanthology.org/D15-1165.pdf
"The corpus comes from a collection of blog postings from 2004 on . These blog postings come from around the world , and in a variety of languages . We view this as an excellent example of an unstructured corpus for event detection since it is composed of blog articles harvested by BlogLines . The documents come from some standard news sources , but also from any blogging service which provides rss feeds , such as livejournal , local newspapers , wordpress , and many more . For this experiment , we collected only English articles from the blog corpus , but the algorithm could be used in practice with any language .",Material,Data,Use,Event Detection in Blogs using Temporal Random Indexing,https://aclanthology.org/W09-4302.pdf
"The main source of our parallel data was CzEng 1 . 0 ( Bojar et al ., 2012b ). We also used Europarl ( Koehn , 2005 ) as made available by WMT13 organizers . The English - Czech part of the new Common Crawl corpus was quite small and very noisy , so we did not include it in our training data . Table 2 provides basic statistics of the data . Processing large parallel data can be challenging in terms of time and computational resources required .",Material,Data,Use,Chimera – Three Heads for English-to-Czech Translation,https://aclanthology.org/W13-2208.pdf
"This is good since we want similar words to be close together but not have exactly the same input vector . The words that are still clustered to the same input are mostly numbers or typing mistakes like “ YouTube ” and “ Youtube ”. The translation system for the German - to - English task was trained on the European Parliament corpus , News Commentary corpus , the BTEC corpus and TED talks . The data was preprocessed and compound splitting was applied for German . Afterwards the discriminative word alignment approach as described in Niehues and Vogel ( 2008 ) was applied to generate the alignments between source and target words .",Material,Data,Use,"Letter N-Gram-based Input Encoding for Continuous Space Language
Models",https://aclanthology.org/W13-3204.pdf
"In this paper , we obtained a subset of Slovnyk for two language pairs : English - Ukrainian , and Ukrainian - Spanish . This has been converted into RDF , with a separate lexicon for each language using the lemon model ( McCrae et al ., 2011 ), and a translation set for each language pair . As Slovnyk mainly contains nouns and noun phrases , we automatically extracted verbs from the Apertium Russian - Ukrainian bilingual lexicon . Apertium ( Corbí Bellot et al ., 2005 ) was an opensource rule - based Machine Translation platform , which therefore heavily relies on bilingual lexica and grammars . It is now supported by an online community10 .",Material,Data,Use,"The GuanXi network:
a new multilingual LLOD for Language Learning applications",https://aclanthology.org/W15-5507.pdf
"Thanks to the fact that it is translated into English , it is open to international audiences . To the best of our knowledge , most correspondence seminars are organised in the area of former Czechoslovakia . The Slovak seminars include KMS ( mathematics ), FKS ( physics ), and STROM ( mathematics ). The last mentioned one claims to have the longest tradition in the area of former Czechoslovakia , having been established in 1976 . Correspondence seminars organised in the Czech Republic include MKS ( mathematics ; founded 1981 ), FYKOS ( physics ; 1986 ), and KSICHT ( chemistry ; 2002 ; cf .",Material,Data,Use,Correspondence Seminar: Bringing Linguistics to High Schools,https://aclanthology.org/W13-3407.pdf
"As our last experiment , we evaluate the word spaces on a dialogue act tagging task ( Stolcke et al ., 2000 ) over the Switchboard corpus ( Godfrey et al ., 1992 ). Switchboard is a collection of approximately 2500 dialogs over a telephone line by 500 speakers from the U . S . on predefined topics . The experiment pipeline follows ( Milajevs and Purver , 2014 ). The input utterances are preprocessed so that the parts of interrupted utterances are concatenated ( Webb et al ., 2005 ). Disfluency markers and commas are removed from the utterance raw texts .",Material,Data,Use,"Evaluating Neural Word Representations in
Tensor-Based Compositional Settings",https://arxiv.org/pdf/1408.6179.pdf
"We define context words to be 5 words to the left / right for all considered methods . We use three word similarity datasets each containing 353 , 3000 , and 2034 word pairs . We report the average similarity score across these datasets under the label AVG - SIM . We use two word analogy datasets that we call SYN ( 8000 syntactic analogy questions ) and MIXED ( 19544 syntactic and semantic analogy questions ). We implemented the template in Figure 2 in C ++.",Material,Data,Use,Model-based Word Embeddings from Decompositions of Count Matrices,https://aclanthology.org/P15-1124.pdf
"See table 1 for the complete list of all words selected for the Spanish lexical sample task . The words can belong only to one of the syntactic categories . The fourteen words selected to be translation - equivalents to English has been : The corpus was collected from two different sources : "" El Periodico "" ( a Spanish newspaper ) and LexEsp ( a balanced corpus of 5 . 5 million words ). The length of corpus samples is the sentence . The lexicon provided was created specifically for the task and it consists of a definition for each sense linked to the Spanish version of EuroWordNet and , thus , to the English WordNet 1 . 5 .",Material,Data,Use,Framework and Results for the Spanish SENSEVAL ,https://aclanthology.org/S01-1010.pdf
"We built several corpora using two different strategies . The first set was built using Wikipedia and the interlingual links available on articles ( that points to another version of the same article in another language ). We started from the list of all French articles and randomly selected articles that provide a link to Spanish and English versions . We downloaded those , and clean them by removing the wikipedia formatting tags to obtain raw UTF8 texts . Articles were not selected based on their sizes , the vocabulary used , nor a particular topic .",Material,Data,Use,Rare Word Translation Extraction from Aligned Comparable Documents,https://aclanthology.org/P11-1133.pdf
"Nouns were extracted from WordNet ’ s noun list . Words starting with lower case and upper case letters were determined as NN and NNP , respectively . Nouns in NNS and NNPS categories were collected from the results of POS tagging articles from Plos Biology Journal with TreeTagger . Verbs were extracted from WordNet ’ s verb list . We manually curated VBD , VBN , VBG and VBZ verbs with irregular inflections based on WordNet .",Material,Data,Use,How to make the most of NE dictionaries in statistical NER,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-S11-S5
"Further variants include different formalizations of norms for parameter regularization , e . g ., f1 , 2 regularization ( Obozinski et al ., 2010 ) or Ei regularization ( Quattoni et al ., 2009 ), where only the features that are most important across all tasks are kept in the model . In our experiments , we apply parameter regularization for multi - task learning to minimum error rate training for patent translation . Our work on patent translation is based on the MAREC patent data corpus . MAREC contains over 19 million patent applications and granted patents in a standardized format from four patent organizations ( European Patent Office ( EP ), World Intellectual Property Organization ( WO ), United States Patent and Trademark Office ( US ), Japan Patent Office ( JP )), from 1976 to 2008 . The data for our experiments are extracted from the EP and WO collections which contain patent documents that include translations of some of the patent text .",Material,Data,Use,Structural and Topical Dimensions in Multi-Task Patent Translation,https://aclanthology.org/E12-1083.pdf
"They also prove that our approach , employing MLN to automatically learn the patterns of semantic triple grouping , is effective . Our system can answer more questions and obtain better performance than the traditional methods based on manually designed heuristic rules . DBpedia and some classes from Yago . These knowledge bases ( KBs ) are composed of many ontological and instance statements , and all statements are expressed by SPO triple facts . Figure 1 shows some triple fact samples from DBpedia .",Material,Data,Use,Question Answering over Linked Data Using First-order Logic,https://aclanthology.org/D14-1116.pdf
"This is also the method applied during the recent WMTs , where humans are asked to rank machine translation output by using APPRAISE ( Federmann , 2012 ), a software tool that integrates facilities for such a ranking task . In WMT , human MT evaluation is carried out by the MT development teams , usually computer scientists or computational linguists , sometimes involving crowd - sourcing based on Amazon ’ s Mechanical Turk . Being aware of the two communities , machine translation and translation studies , we took the available online data from the WMT2013 and tried to reproduce the ranking task with translation studies students for the English to German translations . The three questions we want to answer are : We concentrate on English - German data since the majority of our evaluators were native speakers of German and since , from a translation studies point of view , professional translation should be performed only into the mother tongue . 2 The WMT2013 English - German Data Before presenting the experimental setting and outcomes , we present the WMT data .",Material,Data,Use,Predicting Machine Translation Adequacy with Document Embeddings,https://aclanthology.org/W15-3051.pdf
"In our experiments we show an increase in the performance of TED based approach to textual entailment , by optimizing the cost of edit operations . In the following subsections , the framework and dataset of our experiments are elaborated . Our experiments were conducted on the basis of the Recognizing Textual Entailment ( RTE ) datasets , which were developed under PASCAL RTE challenge . Each RTE dataset includes its own development and test set , however , RTE - 4 was released only as a test set and the data from RTE - 1 to RTE - 3 were used as development set . More details about the RTE datasets are illustrated in Table 5 . 1 .",Material,Data,Use,"Optimizing Textual Entailment Recognition Using Particle Swarm
Optimization",https://aclanthology.org/W09-2505.pdf
"Members are typically affiliated with either the Democratic Party or the Republican Party . Congressional election and Presidential election coincide every four years . The Corpus We use a corpus of public statements released by members of Congress in both the Senate and The House of Representatives , collected by Project Vote Smart . An example of a public statement is presented in Figure 1 . In this work we use all individual statements and press releases in a span of four years ( 20102013 ), a total of 134000 statements made by 641 representatives .",Material,Data,Use,"A Frame of Mind: Using Statistical Models for Detection of Framing and
Agenda Setting Campaigns",https://aclanthology.org/P15-1157.pdf
"It contains organoleptic labels and the chemical compounds — or more accurately the perfume raw materials ( PRMs )— that produce them . By automatically scraping the catalog we obtained a total of 137 organoleptic smell labels from SAFC , with a total of 11 , 152 associated PRMs . We also experimented with Flavornet and the LRI and odour database , but found that the data from these were more noisy and generally of lower quality . For each of the smell labels in SAFC we count the co - occurrences of associated chemical compounds , yielding a bag of chemical compounds ( BoCC ) model . Table 2 shows an example subspace of this model .",Material,Data,Use,Grounding Semantics in Olfactory Perception,https://aclanthology.org/P15-2038.pdf
"In this step , the set of core frame elements which function as the obligatory arguments of the required lexeme are matched with their corresponding ontology concepts . The algorithm that is applied to carry out this process utilizes the FE Taxonomy and the ontology class hierarchy . Matching is based on the class hierarchies . For example : Actor , which is a subclass of Person is matched with the core element Creator , which is a subclass of Agent because they are both characterized as animate objects that have human properties . Similarly , Represented Object , which is a subclass of Conceptual Object , is matched with the core element Represented , which is a subclass of Entity because they are both characterized as the results of a human creation that comprises nonmaterial products of the human mind .",Material,Data,Use,"Applying semantic frame theory to automate natural language
template generation from ontology statements",https://aclanthology.org/W10-4219.pdf
"To compute the preference of a word w in the grammatical context of a PMW t ( the target ) towards each of t ’ s possible senses , we consider each relation ( w , R , t ), where R is the grammatical relation . The set C of word collocations are extracted from the BNC and used to compute a preference score Psi for each sense si E S : where supersense ( wj , si ) is true if si is a supersense of one of wj ’ s senses ; isa ( wj , si ) is true if si is a hypernym of one of wj ’ s senses in WordNet , or is a fact extracted from Wikipedia . To determine the supersense and isa relation we use WordNet 3 . 0 , and a set of 7 , 578 , 112 isa relations extracted by processing the page and category network of Wikipedia ( Nastase and Strube , 2008 ). The collocations extracted from BNC contain numerous named entities , most of which are not part of WordNet . If an isa relation between a collocate from the corpus wj and a possible sense of a PMW si cannot be established using supersense information ( for the supersenses ) or through transitive closure in the hypernymhyponym hierarchy in WordNet ( for company and organization ) for any sense of wj , it is tried against the Wikipedia - based links .",Material,Data,Use,"Combining Collocations, Lexical and Encyclopedic Knowledge
for Metonymy Resolution",https://aclanthology.org/D09-1095.pdf
"IBM models 1 , 2 and 3 yielded subpar results , so we will not discuss them . To evaluate the alignments , we used 484 goldaligned sentences from Och and Ney ( 2000 ). We used the F - score of correct sure and possible links ( Fraser and Marcu , 2007 ) for a general evaluation , which we will call Fall . 6 In order to specifically evaluate pronoun alignment , we used the F - score of the subset of links that align the two sets of pronouns we are interested in , Fpro . For all alignment models , grow - diag - final - and symmetrization performed best on the pronoun metric , followed by grow - diag and intersection , which also performed best for general alignments . Table 7 shows the results for different models with grow - diag - final - and symmetrization .",Material,Data,Use,Pronoun-Focused MT and Cross-Lingual Pronoun Prediction: Findings of the 2015 DiscoMT Shared Task on Pronoun Translation,https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A853680&dswid=7882
"Because we do not know the relative quality of different permutations , our corpus includes only pairwise rankings that comprise the original document and one of its permutations . Given k original documents , each with n randomly generated permutations , we obtain k · n ( trivially ) annotated pairwise rankings for training and testing . Using the technique described herein , we collected data in two different genres : newspaper articles and accident reports written by government officials . The first collection consists of Associated Press articles from the North American News Corpus on the topic of earthquakes ( Earthquakes ). The second includes narratives from the National Transportation Safety Board ’ s aviation accident database ( Accidents ).",Material,Data,Use,Modeling Local Coherence: An Entity-Based Approach,https://direct.mit.edu/coli/article/34/1/1/1969/Modeling-Local-Coherence-An-Entity-Based-Approach
"However , their methods are handicapped by the built - in assumption that a sentence does not express a relation unless it mentions two entities which participate in the relation in the knowledge base , leading to false negatives . In reality , knowledge bases are often incomplete , giving rise to numerous false negatives in the training data . We sampled 1834 sentences that contain two entities in the New York Times 2006 corpus and manually evaluated whether they express any of a set of 50 common Freebase relations . As shown in Figure 1 , of the 133 ( 7 . 3 %) sentences that truly express one of these relations , only 32 ( 1 . 7 %) are covered by Freebase , leaving 101 ( 5 . 5 %) false negatives . Even for one of the most complete relations in Freebase , Employee - of ( with more than 100 , 000 entity pairs ), 6 out of 27 sentences with the pattern ‘ PERSON executive of ORGANIZATION ’ contain a fact that is not included in Freebase and are thus mislabeled as negative .",Material,Data,Use,"Filling Knowledge Base Gaps for Distant Supervision
of Relation Extraction",https://aclanthology.org/P13-2117.pdf
"Also , we observe that the best fusion scheme consistently outperforms the Lexical + Lexical approach for 10 − 100 neighbors . Here , we compare the performance of semantic and affective features ( described in Section 6 ) for the discrimination of word pairs the fall into two categories , synonyms and antonyms . The word pairs were taken from two sets of WordNet synonyms and opposites We retained those pairs that were included in the networks described in Section 7 . 1 . In total , 172 pairs are contained in each category for a total of 344 pairs . The experimental dataset include pairs such as ( happiness , felicity ) and ( comedy , tragedy ) that correspond to synonyms and antonyms , respectively .",Material,Data,Use,Feeling is Understanding: From Affective to Semantic Spaces,https://aclanthology.org/W15-0121.pdf
"We show good mining performance for En - Hi and En - Ta . We perform error analysis for En - Ar , and identify sources of error ( Section 6 . 5 ). To understand the various issues in mining MWNE equivalents from comparable corpora , we took a random sample of 100 comparable En - Hi news article pairs from the Indian news portal WebDunia . The English articles had 682 unique NEs of which 252 ( 37 %) were person names , 130 ( 19 %) were location names , and 300 ( 44 %) were organization names . A substantial percentage of the names comprised of more than one word : locations 25 %, person names 96 %, and organizations 98 %.",Material,Data,Use,Mining Multi-word Named Entity Equivalents from Comparable Corpora,https://aclanthology.org/W11-3210.pdf
"If � kXL + U is equal to kXL , then there is no new sense in XU . Otherwise (� kXL + U > kXL ) new senses of w may be represented by the groups in which there is no instance from XL . We evaluated the ELP based model order identification algorithm on the data in English lexical sample task of SENSEVAL - 3 ( including all the 57 English words ) , and further empirically compared it with other state of the art classification methods , including SVM 10 ( the state of the art method for supervised word sense disambiguation ( Mihalcea et al ., 2004 )), a one - class partially supervised classification algorithm ( Liu et al ., 2003 ) 11 , and a semi - supervised k - means clustering based model order identification algorithm . The data for English lexical samples task in SENSEVAL - 3 consists of 7860 examples as official training data , and 3944 examples as official test data for 57 English words . The number of senses of each English word varies from 3 to 11 .",Material,Data,Use,Mining Multi-word Named Entity Equivalents from Comparable Corpora,https://aclanthology.org/W11-3210.pdf
"DD / TD data sets are used as information for format that the system responds the retrieval results and so on . In the next section , we describe how application developers prepare DD / TI and DD / TD data sets . We used Chasen as Japanese morphological analysis and PostgreSQL as a database retrieval management system . We have constructed Semantics Modules based on the Mt . Fuji sightseeing guidance system ( Nakagawa et al ., 2000 ) with separating task dependent and independent parts .",Material,Data,Use,Interpreter for Highly Portable Spoken Dialogue System,https://aclanthology.org/W03-2109.pdf
"We sketch a formal analysis of the response categories in the framework of KoS . Responding to a query with a query is a common occurrence , representing on a rough estimate more than 20 % of all responses to queries found in the British National Corpus . Research on dialogue has long recognized the existence of such responses . However , with the exception of one of its subclasses — albeit a highly substantial one — the class of query responses has not been characterized empirically in previous work . The class that has been studied in some detail are Clarification Requests ( CRs ) ( Rodriguez and Schlangen , 2004 ; Rieser and Moore , 2005 ).",Material,Data,Use,A corpus-based taxonomy of question responses,https://hal.science/hal-01138036/
"Table 1 presents statistics of these in - domain data . The data extracted from HAL were used to adapt a generic system to the scientific literature domain . The generic system was mostly trained on data provided for the shared task of Sixth Workshop on Statistical Machine Translation ( WMT 2011 ), described in Table 2 . Table 3 presents results showing , in the English – French direction , the impact on the statistical engine of introducing the resources extracted from HAL , as well as the impact of domain adaptation techniques . The baseline statistical engine is a standard PBSMT system based on Moses ( Koehn et al ., 2007 ) and the SRILM tookit ( Stolcke , 2002 ).",Material,Data,Use,Collaborative machine translation service for scientific texts,https://wlv.openrepository.com/handle/2436/623593
"All the sentences are collected from students ’ written essays . All the data are in traditional Chinese . The dictionary used in SSSP algorithm is SogouW dictionary from Sogou inc ., which is in simplified Chinese . The OpenCC converter is used to convert it into traditional Chinese . For similar character map the data set provided by ( Liu et al ., 2011 ) is used .",Material,Data,Use,Graph Model for Chinese Spell Checking,https://aclanthology.org/W13-4416.pdf
"Both STACKING and 2STEPSML systems rely on several kinds of features , which vary from lexical to semantic ones . Features are grouped in seven main classes , as follows : We adopt several similarity measures using semantic distributional models ( see Section 2 . 5 ), the Resnik ’ s knowledge - based approach ( Resnik , 1995 ) and the point - wise mutual information as suggested by Turney ( Turney , 2001 ) computed on British National Corpus . For all the features , the idf is computed relying on UKWaC corpus ( Baroni et al ., 2009 ). measure which counts the number of possible paraphrasings belonging to the two texts . Given two texts T1 and T2 , for each token in T1 a list of paraphrasings is extracted using a dictionary .",Material,Data,Use,UNIBA-CORE: Combining Strategies for Semantic Textual Similarity,https://aclanthology.org/S13-1024.pdf
"We train ℓ2 - regularized logistic regression classifiers using the LIBLINEAR package ( Fan et al , 2008 ) with the learned embeddings . To build the component - enhanced character embeddings , we employ the GB2312 character set and extract all their component lists . It is easy to obtain the first components ( i . e ., the radicals ), as they are readily available in the online Xinhua Dictionary . For the rest radical - like components , we extract them by matching the patterns like “� k ( from )+ X ” in the Xinhua dictionary . Such a pattern indicates that a character has a component of X .",Material,Data,Use,Component-Enhanced Chinese Character Embeddings,https://arxiv.org/pdf/1508.06669.pdf
"The English corpus we used was the New York Times ( 1994 - 2002 ) material available in the LDC Gigaword Corpus ( NYT ) ( Graff , 2003 ). For Dutch we used both the ILK Corpus and the Twente Corpus ( TWC ). For French we used 8 years (' 91 -' 98 ) of Roularta Magazines . Statistics on these corpora are presented in table 2 . A TISC lexicon is derived from a large corpus of tokenised , but otherwise raw text , from which all xmL or other tags have been discarded .",Material,Data,Use,Multilingual text induced spelling correction,https://aclanthology.org/W04-2216.pdf
We already described the training data for supervised and semi - supervised classifiers in previous sections . In this section we will compare their dialect classification accuracies . We select two test sets : 9 . 5K sentences from the AOC corpus as the AOC test set and 2 . 3K sentences from the Facebook data set as the FB test set . Both test sets have the dialect of each sentence labeled by human . The accuracy is computed as the percentage of sentences whose classified label is the same as the human label .,Material,Data,Use,Improved Arabic Dialect Classification with Social Media Data,https://aclanthology.org/D15-1254.pdf
"Second , we consider two methods for predicting comment polarity from post content : support vector machine classification , and sLDA , a topic - modeling - based approach . Finally , we demonstrate that emotional reactions are indeed community - specific , compare the accuracy of this approach to the more traditional approach of predicting sentiment of a text from the text itself , and present our conclusions . In this study , we use a collection of blog posts from five blogs : Carpetbagger ( CB ) , Daily Kos ( DK ) , Matthew Yglesias ( MY ) , Red State ( RS ) , and Right Wing News ( RWN ) , that focus on American politics made available by ( Yano et al ., 2009 ). The posts were collected during November 2007 to October 2008 , which preceded the US presidential elections held in November 2008 . The blogs included in the dataset vary in political idealogy with blogs like Daily Kos that are Democrat - leaning and blogs like Red State tending to be much more conservative .",Material,Data,Use,"What pushes their buttons? Predicting comment polarity from the content
of political blog posts",https://aclanthology.org/W11-0703.pdf
Our multilingual book collection consists of around 800k books in German and English languages . It is a subset of a larger Internet Archive collection of books in over 200 languages . The whole collection consists of OCRed books incorporating a small number of human transcribed books from Project Gutenberg . The collection was initially annotated with author and language information using the existing database obtained from the Internet Archive . This database originally contained incorrect language metadata .,Material,Data,Use,"A Minimally Supervised Approach for Detecting and Ranking Document
Translation Pairs",https://aclanthology.org/W11-2125.pdf
"Finally , we picked Finnish – English for the rich agglutinative morphology of Finnish . Statistical machine translation systems are typically trained on sentence - aligned parallel corpora . We selected Europarl , a freely available parallel corpus in eleven languages . In addition , we also made a word alignment available , which was derived using a variant of the current default method for word alignment – Och and Ney ( 2003 )’ s refined method . Figure 1 details some properties of the parallel corpora .",Material,Data,Use,Shared Task: Statistical Machine Translation between European Languages,https://aclanthology.org/W05-0820.pdf
"We also point to some additional problems that arise when one moves on to OWL DL and OWL FULL . The discussion is based on experiments we conducted with more than a dozen of existing OWL ontologies . One of the main difficulties is that OWL ( all versions ) allows multiple inheritance , while M - PIRO does not ( section 2 ). Importing an ontology with multiple inheritance currently causes the process to fail . The need for multiple inheritance has also been noted by authors , who often encounter cases where , for example , a person has to be categorized as both painter and potter .",Material,Data,Use,Exploiting OWL Ontologies in the Multilingual Generation of Object Descriptions,https://aclanthology.org/W05-1617.pdf
"According to Reyes et . al ( 2013 ), these hashtags were selected for three main reasons : ( i ) to avoid manual selection of tweets , ( ii ) to allow irony analysis beyond literary uses , and because ( iii ) irony hashtag may “ reflect a tacit belief about what constitutes irony .” Another corpora is employed in our approach to measure the frequency of word usage . We adopted the Second Release of the American National Corpus Frequency Data ( Ide and Suderman , 2004 ), which provides the number of occurrences of a word in the written and spoken ANC . From now on , we will mean with “ frequency of a term ” the absolute frequency the term has in the ANC . In order to process the tweets we use the freely available vinhkhuc Twitter Tokenizer which allows us to recognise words in each tweet .",Material,Data,Use,"Modelling Sarcasm in Twitter, a Novel Approach",https://aclanthology.org/W14-2609.pdf
"The results show an overall significant improvement over the other methods , with the added advantage of being computationally efficient . Next we evaluated our method on a word translation task , introduced in ( Mikolov et al ., 2013b ) and used in ( Gouws et al ., 2015 ). The words were extracted from the publicly available WMT11 corpus . The experiments were done for two sets of translation : English to Spanish and Spanish to English . ( Mikolov et al ., 2013b ) extracted the top 6K most frequent words and translated them with Google Translate .",Material,Data,Use,"Trans-gram, Fast Cross-lingual Word-embeddings",https://arxiv.org/pdf/1601.02502.pdf
"Method : To evaluate the performance of our system , we measure how well the relationships discovered compare with manually selected PPI sentences . To do so , we follow the same procedure and data sets used to evaluate semi - supervised classification of PPI sentences ( Erkan et al ., 2007 ). The two data sets are AIMED and CB , which have been marked for protein entities and interaction phrases . For each sentence in which n proteins appear , we build ( 2 ) phrases . Each phrase consists of the words between each entity combination , and is labeled as positive if it describes a PPI , or negative otherwise .",Material,Data,Use,Seeded Discovery of Base Relations in Large Corpora,https://aclanthology.org/D08-1062.pdf
"To verify that the annotation rules were reasonable and led to a problem that could potentially be solved by a computer , we had each of the annotators mark up a small shared set of a few hundred words from each of eight documents , in order to measure the inter - annotator agreement . The average actual agreement was 0 . 988 , with 0 . 5 agreement expected by chance for a kappa of 0 . 975 . Following Scannell ( 2007 ), we collected small monolingual samples of 643 languages from four sources : the Universal Declaration of Human Rights , non - English Wikipedias , the Jehovah ’ s Witnesses website , and the Rosetta project ( Landsbergen , 1989 ). Only 30 of these languages ended up being used in experiments . Table 3 shows the sizes of the monolingual samples of the languages used in this paper .",Material,Data,Use,"Labeling the Languages of Words in Mixed-Language Documents using
Weakly Supervised Methods",https://aclanthology.org/N13-1131.pdf
"The final weight is of the form : This term is proportional to perplexities , as the exponent of entropy is perplexity by definition . One could also use filtering for TM adaptation , but , as shown in ( Mansour and Ney , 2012 ), filtering for TM could only reduce the size and weighting performs better than filtering . The experiments are done on the recent Germanto - English WMT 2013 translation task . For test data statistics : the number of sentence pairs ( Sent ), German ( De ) and English ( En ) words are given . German - English WMT 2013 , the common - crawl bilingual corpus was introduced , enabling more impact for TM adaptation on the SMT system quality .",Material,Data,Use,Unsupervised Adaptation for Statistical Machine Translation,https://aclanthology.org/W14-3359.pdf
"Rule 3 . 1 then infers that the writer is positive toward the agent of E4 , Obama . In summary , we infer that the writer is positive toward E1 , health care reform , E2 , patients , E4 , and Obama , and negative toward E3 and private insurance companies . We use the data described in ( Deng et al ., 2013 ), which consists of 134 documents about a controversial topic , “ the Affordable Care Act .” The documents are editorials and blogs , and are full of opinions . In the data , gfbf triples are annotated specifying the spans of the gfbf event , its agent , and its object , as well as the polarity of the gfbf event ( GOODFOR or BADFOR ), and the writer ’ s attitude toward the agent and object ( positive , negative , or neutral ). Influencers are also annotated .",Material,Data,Use,Sentiment Propagation via Implicature Constraints,https://aclanthology.org/E14-1040.pdf
"We then investigated whether lexical normalization can decrease the number of out - of - vocabulary words . For the 793 ill - spelled words , we counted how many of their surface forms and normal forms were not registered in the JUMAN dictionary . The result suggests that 411 ( 51 . 8 %) and 74 ( 9 . 3 %) are not registered in the dictionary . This indicates the effectiveness of lexical normalization for decreasing out - of - vocabulary words . This section gives an overview of our joint model with lexical normalization for accurate word segmentation and POS tagging .",Material,Data,Use,"Accurate Word Segmentation and POS Tagging for Japanese Microblogs:
Corpus Annotation and Joint Modeling with Lexical Normalization",https://aclanthology.org/D14-1011.pdf
"To obtain the Viterbi alignments , which are required for phrase extraction ( Koehn et al ., 2003 ), we select for each aj the most frequent value in the M collected samples . For TurkishHEnglish experiments , we used the 20K - sentence travel domain BTEC dataset ( Kikui et al ., 2006 ) from the yearly IWSLT evaluations for training , the CSTAR 2003 test set for development , and the IWSLT 2004 test set for testing . For CzechHEnglish , we used the 95K - sentence news commentary parallel corpus from the WMT shared task for training , news2008 set for development , news2009 set for testing , and the 438M - word English and 81 . 7M - word Czech monolingual news corpora for additional language model ( LM ) training . For ArabicHEnglish , we used the 65K - sentence LDC2004T18 ( news from 2001 - 2004 ) for training , the AFP portion of LDC2004T17 ( news from 1998 , single reference ) for development and testing ( about 875 sentences each ), and the 298M - word English and 215M - word Arabic AFP and Xinhua subsets of the respective Gigaword corpora ( LDC2007T07 and LDC2007T40 ) for additional LM training . All language models are 4 - gram in the travel domain experiments and 5 - gram in the news domain experiments .",Material,Data,Use,Bayesian Word Alignment for Statistical Machine Translation,https://aclanthology.org/P11-2032.pdf
"For example , target word selection is possible based on co - occurrence relationship extracted from a monolingual corpus ( Suzuki et al ., 2005 ). Furthermore , we have developed a word sense disambiguation based on a monolingual corpus in the target domain , and it has been applied to Japanese - Korean and KoreanJapanese translation systems ( Kumano 2013 , Tanaka et al ., 2014 ). On the other hand , open Asian parallel corpora including ASPEC , NTCIR PatentMT and JPO Patent Corpus are available for the research of machine translation systems . By using the parallel corpora , we have confirmed advantages which apply statistical post editing ( SPE ) to RBMT in domain adaptation ( Suzuki , 2011 ). In the last workshop ( Nakazawa et al ., 2014 ), we participated in Japanese - English and Japanese - Chinese tasks with SPE approach and obtained higher evaluation results than RBMT .",Material,Data,Use,Toshiba MT System Description for the WAT2015 Workshop,https://aclanthology.org/W15-5005.pdf
"Working with the official key file and scoring software , the intersection combination with MFS backoff gives an F - measure of 0 . 78713 corresponding to the 6th best result . The same combination method but without MFS backoff achieves a precision of 0 . 80559 but at the cost of a very low F - measure ( 0 . 41492 ). For this task , LexPar and SynWSD were further trained on a 12 million POS tagged and lemmatized balanced corpus . The run that was submitted was the intersection combination with the MFS backoff strategy which obtained an F - measure of 0 . 527 . This score puts our algorithm on the 8th position out of 14 competing systems .",Material,Data,Use,RACAI: Meaning Affinity Models,https://aclanthology.org/S07-1061.pdf
"We present a novel method to adapt a supervised coreference resolution system trained on newswire to short narrative stories without retraining the system . The idea is to perform inference via an Integer Linear Programming ( ILP ) formulation with the features of narratives adopted as soft constraints . When testing on the UMIREC and N2 corpora with the - stateof - the - art Berkeley coreference resolution system trained on OntoNotes , our inference substantially outperforms the original inference on the CoNLL 2011 metric . Coreference resolution is the task of partitioning the set of mentions of discourse referents in a text into classes ( or ‘ chains ’) corresponding to those referents ( Stede , 2011 ). To solve the problem , contextual and grammatical clues , as well as semantic information and world knowledge are necessary for either learning - based ( Bengtson and Roth , 2008 ; Stoyanov et al ., 2010 ; Haghighi and Klein , 2010 ) or rule - based ( Haghighi and Klein , 2009 ; Lee et al ., 2011 ) coreference systems .",Material,Data,Use,Adapting coreference resolution for narrative processing,https://lirias.kuleuven.be/1572155?limo=0
"In addition , BLUE allows propositions to themselves be arguments to other propositions as a nested structure , e . g ., for modals : ;;; "" The man wanted to leave the house "" As described earlier , BLUE currently uses two alternative conceptual vocabularies , namely the concepts in WordNet ( with minor extensions ) or the Component Library . BLUE ’ s relational vocabulary is approximately 100 semantic relations drawn from the Component Library . We illustrate our system using an example from Project Halo ( Clark et al ., 2007 ), where the system is used to interpret multi - sentence science questions posed to a knowledge - based system . While BLUE produces a slightly better output for this text using the Component Library ontology , we illustrate it using WordNet ’ s ontology for consistency with our output for the other shared task texts ( we use WordNet for these as WordNet has broader coverage ). We also discuss our system further in Section 4 on additional sentences .",Material,Data,Use,Boeing's NLP system and the challenges of semantic representation,https://aclanthology.org/W08-2221.pdf
"In this paper , we report the experiments carried out by the NLP CT Laboratory at University of Macau for WMT2014 medical sentence translation task on six language pairs : Czech - English ( cs - en ), French - English ( fr - en ), German - English ( de - en ) and the reverse direction pairs ( i . e ., en - cs , en - fr and en - de ). As data in specific domain are usually relatively scarce , the use of web resources to complement the training resources provides an effective way to enhance the SMT systems ( Resnik and smith , 2003 ; Esplà - Gomis and Forcada , 2010 ; Pecina et al ., 2011 ; Pecina et al ., 2012 ; Pecina et al ., 2014 ). In our experiments , we not only use all available training data provided by the WMT2014 standard translation task ( generaldomain data ) and medical translation task ( indomain data ), but also acquire addition indomain bilingual translations ( i . e . dictionary ) and monolingual data from online sources . First of all , we collect the medical terminologies from the web .",Material,Data,Use,Domain Adaptation for Medical Text Translation Using Web Resources,https://aclanthology.org/W14-3328.pdf
"Figure 1 is a sample lexical entry from the main output of CPA , the Pattern Dictionary of English Verbs ( PDEV ). This tells us that , for the verb abolish , three patterns were found . For each pattern it tells us the percentage of the data that it accounted for , its grammatical structure and the semantic type ( drawn from a shallow ontology of 225 semantic types ) of each of the arguments in this structure . For instance , pattern 1 means : i ) that the subject is preferably a word referring to [[ Human ]] or [[ Institution ]] ( semantic alternation ), and ii ) that the object is preferably [[ Action ]], [[ Rule ]] or [[ Privilege ]]. It also tells us the implicature ( which is similar to a “ definition ” in a traditional dictionary ) of a sentence exemplifying the pattern : that is , if we have a sentence of the pattern [[ Institution | Human ]] abolish [[ Action = Punishment | Rule | Privilege ]], then we know that [[ Institution | Human ]] formally declares that [[ Action = Punishment | Rule | Privilege ]] is no longer legal or operative .",Material,Data,Use,SemEval-2015 Task 15: A Corpus Pattern Analysis Dictionary-Entry-Building Task,https://aclanthology.org/S15-2053.pdf
"Consequently , CUI - less facts are ignored in our evaluation framework . In this work , we will focus only on the fact types of Disorders and Procedures , and use SNOMED as our medical taxonomy . We also use Linkbase as our knowledge - base for descriptions of the fact codes . Some of the unique characteristics of medical fact coding compared to the traditional entity recognition are as follows : In the official data of the Semeval task , it is reported that at least a quarter of the annotated facts are CUI - less ( Pradhan et al ., 2014 ). Hence ignoring these facts essentially renders a comparison of our evaluation numbers with the official Semeval numbers meaningless .",Material,Data,Use,Shallow Training is cheap but is it good enough? Experiments with Medical Fact Coding,https://aclanthology.org/W15-3806.pdf
"Consider the adjective “ frigid ”, which may be judged to be simpler than “ gelid ” if referring to temperature , but perhaps less simple than “ ice - cold ” when characterizing someone ’ s personality . These differences in word sense are taken into account by measuring the similarity between corpus documents and substitution contexts and use these values to provide a weighted average of the syntactic complexity measures . The unlabeled data set was generated by a threestep procedure involving synonyms extracted from Wordnet and sentences from the UKWAC corpus . mas in Wordnet . The synsets must have more than three synonyms .",Material,Data,Use,EMNLP@CPH: Is frequency all there is to simplicity?,https://aclanthology.org/S12-1054.pdf
"Similarly , we hypothesize that helpful peer reviews are closely related to domain topics that are shared by all students papers in an assignment . Our domain topic set contains 288 words extracted from the collection of student papers using topic - lexicon extraction software ; our feature ( domainWord ) counts how many words of a given review belong to the extracted set . For sentiment polarities , we extract positive and negative sentiment words from the General Inquirer Dictionaries , and count their appearance in reviews in terms of their sentiment polarity ( posWord , negWord ). The section of the essay on African Americans needs more careful attention to the timing and reasons for the federal governments decision to stop protecting African American civil and political rights . The review has only one sentence , in which one regular expression is matched with “ the section of ” thus regTag % = 1 ; no demonstrative determiner , thus dDeterminer = 0 ; “ African ” and “ Americans ” are domain words appearing between the subject “ section ” and the object “ attention ”, so soDomain is true for this sentence and thus soDomain % = 1 for the given review .",Material,Data,Use,Understanding Differences in Perceived Peer-Review Helpfulness using Natural Language Processing,https://aclanthology.org/W11-1402.pdf
"The first set of the experiments was performed on the base of training data released by the organisers in May 2015 . The second set consisted of evaluation runs on test data released in June and the results for these experiments were provided by the organizers . For the DSL shared task 2015 edition , the organizers released two new versions of the DSL corpus collection ( DSLCC ), the version 2 . 0 and 2 . 1 . The version 2 . 0 is the standard shared task training material whereas the version 2 . 1 can be used for the unshared task track or as additional training material . The collection is described in ( Tan et al ., 2014 ).",Material,Data,Use,Discriminating between Similar Languages Using PPM,https://aclanthology.org/W15-5410.pdf
"For Croatian , preliminary work on tagger evaluation for tagger voting has been conducted ( Agi ´ c et al ., 2010 ). SETIMES . HR is a new manually lemmatized and MSD - tagged corpus of Croatian . It is built on top of the SETimes parallel newspaper corpus involving 10 languages from the SEE region , Croatian and Serbian included . This initial dataset selection was deliberate in terms of enabling us with possibility of cross - lingual annotation projection and other cross - lingual experiments . SETIMES . HR was annotated by experts using the Croatian Lemmatization Server ( HML ) ( Tadi ´ c , 2005 ) to facilitate the process .",Material,Data,Use,Lemmatization and Morphosyntactic Tagging of Croatian and Serbian,https://aclanthology.org/W13-2408.pdf
"a set of directed , binary dependency relations holding exclusively between lexical units . This conversion is defined by Ivanova et al . ( 2012 ) and seeks to ( a ) project some aspects of construction semantics onto word - to - word dependencies ( for example introducing specific dependency types for compounding or implicit conjunction ) and ( b ) relate the linguistically informed ERG - internal tokenization to the conventions of the PTB . 3 Seeing as both is called the LOGON SVN trunk as of January 2014 ; see for detail . 2Conversely , semantically vacuous parts of the original input ( e . g . infinitival particles , complementizers , relative pronouns , argument - marking prepositions , auxiliaries , and most punctuation marks ) were not represented in the MRS in the first place , hence have no bearing on the conversion .",Method,Algorithm,Introduce,In-House: An Ensemble of Pre-Existing Off-the-Shelf Parsers,https://aclanthology.org/S14-2056.pdf
"As a research testbed and target resource to expand / domain - tune , we use the LinGO English Resource Grammar ( LinGOERG ), a linguistically - precise HPSG - based grammar under development at CSLI ( Copestake and Flickinger , 2000 ; Flickinger , 2000 ). The particular MWE type we target for extraction is the English verb - particle construction . Verb - particle constructions (“ VPCs ”) consist of a l_CITE_ head verb and one or more obligatory particles , in the form of intransitive prepositions ( e . g . hand in ), adjectives ( e . g . cut short ) or verbs ( e . g .",Method,Algorithm,Introduce,Deep lexical acquisition of verb–particle constructions,https://www.sciencedirect.com/science/article/abs/pii/S0885230805000070
"Unlike most computational grammars , the Core defines analyses for phenomena not restricted to one language , but for the union of all languages for which c - profiles have been defined . ( In this respect it resembles the HPSG Grammar Matrix (‘ the Matrix ’ - see Bender et . al , and ); we comment on its relationship to this system below .) The mediation between the Core and the cprofiles is induced by special type files : - one file for each c - profile ( of which there are currently three , for Ga , Norwegian and Kistaninya ) - one general file , called Labeltypes , for defining CL labels as types in terms of the Core types . This architecture can be summed up as follows ( with ‘ Ga c - types ’ meaning ‘ types corresponding to the templates constituting the c - profile for Ga ’, and items in boldface being items defined inside the TypeGram system ): Thus , what communicates between the Core and the construction specifications in the CL code is Labeltypes , which in turn feeds into the language specific template definition files .",Method,Algorithm,Introduce,From Descriptive Annotation to Grammar Specification,https://aclanthology.org/W10-1826.pdf
"They also separately tabulate the results achieved for unknown targets . Our full model , denoted by “ FullGraph ,” outperforms all the baselines for both tasks . Note that the Self - training model even falls 13_CITE_ software . html # comparator short of the supervised baseline SEMAFOR , unlike what was observed by Bejan ( 2009 ) for the frame identification task . The model using a graph constructed solely from the thesaurus ( LinGraph ) outperforms both the supervised and the self - training baselines for all tasks , but falls short of the graph constructed using the similarity metric that is a linear combination of distributional similarity and supervised frame similarity . This indicates that a graph constructed with some knowledge of the supervised data is more powerful .",Method,Algorithm,Introduce,Semi-Supervised Frame-Semantic Parsing for Unknown Predicates,https://aclanthology.org/P11-1144.pdf
"Enclitics in Manipuri fall into six categories : determiners , case markers , the copula , mood markers , inclusive / exclusive and pragmatic peak markers and attitude markers . The role of the enclitics used and its meaning differs based on the context . Using factored approach , a tighter integration of linguistic information into the translation model is done for two reasons : ■ Translation models that operate on more general representations , such as lemma instead of surface forms of words , can draw on richer statistics and overcome the data sparseness problem caused by limited training data . ■ Many aspects of translation can be best explained at a morphological , syntactic or semantic level . Having such information available to the translation model allows the direct modeling of these aspects .",Method,Algorithm,Introduce,Morphology Driven Manipuri POS Tagger,https://aclanthology.org/I08-3015.pdf
"The pre - processing step connects our MRS elements to a domain ontology and it can create additional states and roles . The pipeline can be reused by other grammars from the Delph - In network . NorSource ( Beermann and Hellan , 2004 ; Hellan and Beermann , 2005 ), a grammar for Norwegian , is a Head - Driven Phrase Structure Grammar ( HPSG ) ( Sag et al ., 2003 ), developed and maintained with the Linguistic Knowledge Builder ( LKB ) tool ( Copestake , 2002 ), and originally based on the HPSG Grammar Matrix , which is a starter kit for developing HPSG grammars ( Bender et al ., 2002 ). An HPSG grammar can use Minimal Recursion Semantics ( MRS ) as meaning representation ( Copestake et al ., 2005 ). In order to speed up the parsing process ( the unification algorithm ), a HPSG grammar can be compiled and run ( parsing ) with the PET tool ( Callmeier , 2001 ).",Method,Algorithm,Introduce, A cluster of applications around a Deep Grammar,http://ltc.amu.edu.pl/a2015/book/papers/PAR-2.pdf
"Unstructured Information Management Architecture ( UIMA ) ( Ferrucci and Lally , 2004 ) is a framework that supports the interoperability of mediaprocessing software components by defining common data structures and interfaces the components exchange and implement . The architecture has been gaining interest from academia and industry alike for the past decade , which resulted in a multitude of UIMA - supporting repositories of analytics . Notable examples include METANET4U components ( Thompson et al ., 2011 ) featured in U - Compare , DKPro ( Gurevych et al ., 2007 ), cTAKES ( Savova et al ., 2010 ), BioNLP - UIMA Component Repository ( Baumgartner et al ., 2008 ), and JULIE Lab ’ s UIMA Component Repository ( JCoRe ) ( Hahn et al ., 2008 ). However , despite conforming to the UIMA standard , each repository of analytics usually comes with its own set of type systems , i . e ., representations of data models that are meant to be shared between analytics and thus ensuring their interoperability . At present , UIMA does not facilitate the alignment of ( all or selected ) types between type systems , which makes it impossible to combine analytics coming from different repositories without an additional programming effort .",Method,Algorithm,Introduce,Making UIMA Truly Interoperable with SPARQL,https://aclanthology.org/W13-2311.pdf
"The semantic textual similarity prediction problem involves finding a function f approximating the semantic textual similarity score given two sentences , S1 and S2 : We approach f as a supervised learning problem with ( S1 , S2 , q ( S1 , S2 )) tuples being the training data and q ( S1 , S2 ) being the target similarity score . We model the problem as a translation task where one possible interpretation is obtained by translating S1 ( the source to translate , S ) to S2 ( the target translation , T ). Since linguistic processing can reveal deeper similarity relationships , we also look at the translation task at different granularities of information : plain text ( R for regular ) , after lemmatization ( L ), after part - of - speech ( POS ) tagging ( P ), and after removing 128 English stop - words ( S ) . Thus , and the Shared Task , pages 234 – 240 , Atlanta , Georgia , June 13 - 14 , 2013 . c � 2013 Association for Computational Linguistics we obtain 4 different perspectives on the binary relationship between S1 and S2 . Referential translation machines ( RTMs ) we develop provide a computational model for quality and semantic similarity judgments using retrieval of relevant training data ( Bic ¸ ici and Yuret , 2011a ; Bic ¸ ici , 2011 ) as interpretants for reaching shared semantics ( Bic ¸ ici , 2008 ).",Method,Algorithm,Introduce,CNGL-CORE: Referential Translation Machines for Measuring Semantic Similarity,https://aclanthology.org/S13-1034.pdf
"However these are difficult to develop and domain sensitive . To surmount these obstacles , application of machine learning approaches to NER became a research subject . Various state - of - the - art machine learning algorithms such as Maximum Entropy ( Borthwick , 1999 ), AdaBoost ( Carreras et al ., 2002 ), Hidden Markov Models ( Bikel et al ., ), Memory - based Based learning ( Tjong Kim Sang , 2002b ), have been used . ( Klein et al ., 2003 ), ( Mayfield et al ., 2003 ), ( Wu et al ., 2003 ), ( Kozareva et al ., 2005c ) among others , combined several classifiers to obtain better named entity coverage rate . Nevertheless all these machine learning algorithms rely on previously hand - labeled training data .",Method,Algorithm,Introduce,Bootstrapping Named Entity Recognition with Automatically Generated Gazetteer Lists,https://aclanthology.org/E06-3004.pdf
"A word unit is more or less fixed and there is no syntactic interference in the inside of the word unit . In the practical sense , it is useful for the further syntactic parsing because it is not decomposable by syntactic processing and also frequently occurred in corpora . There are a series of linguistic annotation standards in ISO : MAF ( morpho - syntactic annotation framework ), SynAF ( syntactic annotation framework ), and others in ISO / TC37 / SC4 . These standards describe annotation methods but not for the meaningful units of word segmentation . In this aspect , MAF and SynAF are to annotate each linguistic layer horizontally in a standardized way for the further interoperability .",Method,Algorithm,Introduce,Getting Serious about Word Sense Disambiguation,https://aclanthology.org/W97-0201.pdf
"Chemical compound names , i . e . names of molecules , are terms which prominently occur in scientific publications , patents and in biochemical databases . Any chemical compound can be unambiguously denoted by its molecular structure , either graphically or by certain representation standards . Established representation formats are SMILES strings ( Simplified Molecular Input Line Entry System ( Weininger , 1988 )) and InChIs . For example , a SMILES string such as CC ( OH ) CCC unambiguously describes a chain of five carbon ( C ) atoms connected by single bonds having an oxygen ( O ) and a hydrogen ( H ) atom connected to the second carbon atom by another single bond ( Figure 1 ). However , for communication purposes , e . g . in scientific publications and even in databases , it is common to use names for chemical compounds instead of a structural representation .",Method,Algorithm,Introduce,Molecular representations in AI-driven drug discovery: a review and practical guide,https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00460-5
"In this sense , our work aims to take a first step towards closing the gap between the detection and comparative approaches to cross - linguistic transfer . The second area of research , language typology , deals with the documentation and comparative study of language structures ( Song , 2011 ). Much of the descriptive work in the field is summarized in the World Atlas of Language Structures ( WALS ) ( Dryer and Haspelmath , 2013 ) in the form of structural features . We use the WALS features as our source of typological information . Several previous studies have used WALS features for hierarchical clustering of languages and typological feature prediction .",Method,Algorithm,Introduce,Reconstructing Native Language Typology from Foreign Language Usage,https://arxiv.org/pdf/1404.6312.pdf
"( Lin and Pantel , 2001 ; Shinyama et al ., 2002 ; Szpektor et al ., 2004 ; Bhagat and Ravichandran , 2008 ), identifying appropriate contexts for their application ( Pantel et al ., 2007 ) and utilizing them for inference ( de Salvo Braz et al ., 2005 ; BarHaim et al ., 2007 ). Although current available rule bases are still quite noisy and incomplete , the progress made in recent years suggests that they may become increasingly valuable for text understanding applications . Overall , applied knowledge - based inference is a prominent line of research gaining much interest , with recent examples including the series of workshops on Knowledge and Reasoning for Answering Questions ( KRAQ ) and the planned evaluation of knowledge resources in the forthcoming 5th Recognizing Textual Entailment challenge ( RTE - 5 ) . While many applied systems utilize semantic knowledge via such inference rules , their use is typically limited , application - specific , and quite heuristic . Formalizing these practices seems important for applied semantic inference research , analogously to the role of well - formalized models in parsing and machine translation .",Method,Algorithm,Introduce,Contextual Preferences,https://aclanthology.org/P08-1078.pdf
"A new style for exchanging and sharing information is social media . Social media refers to the means of interaction among people in which they create , share , and exchange information and ideas in virtual communities and networks ( like Twitter and Facebook ). According to CNN , more Americans get their news from the Internet than from newspapers or radio , and three - fourths say they hear of news via e - mail or updates on social media sites . Social media , in many cases , provide more up - to - date information than conventional sources like online news . To make use of this vast amount of information , it is required to extract structured information out of these heterogeneous unstructured information .",Method,Algorithm,Introduce,Limitations of information extraction methods and techniques for heterogeneous unstructured big data,https://journals.sagepub.com/doi/pdf/10.1177/1847979019890771
"The first RTE challenge aimed to provide the NLP community with a new benchmark to test progress in recognizing textual entailment , and to compare the achievements of different groups . This goal proved to be of great interest , and the community & apos ; s response encouraged the gradual expansion of the scope of the original task . The Second RTE challenge built on the success of the first , with 23 groups from around the world ( as compared to 17 for the first challenge ) submitting the results of their systems . Representatives of participating groups presented their work at the PASCAL Challenges Workshop in April 2006 in Venice , Italy . The event was successful and the number of participants and their contributions to the discussion demonstrated that Textual Entailment is a quickly growing field of NLP research .",Method,Algorithm,Introduce,The Third PASCAL Recognizing Textual Entailment Challenge,https://aclanthology.org/W07-1401.pdf
"Then , Wikipedia titles a page for a proboxer to “ FA '"" 3L — Oa ” instead of his proper name “ FA吉丈 — Oa ”, and then guides us to the page , even if we , on top of Wikipedia , search a page with the proper name “ FA吉丈 — Oa ”. We must take care of extended kanji characters with surrogate pairs in data resources . N - Triples is a line - based , plain text format for encoding an RDF graph , but the character encoding in string is designated to 7 - bit US - ASCII . So , nonASCII characters must be made available by \ escape sequences , such as ‘\ u3042 ’ for Japanese hiragana ‘ あ ’ ( U + 3042 ). 10 RDF / XML syntax11 designates %- encoding for disallowable characters that do not correspond to permitted US - ASCII in URI encoding , in spite that the UNICODE string as UTF - 8 is designated to the RDF / XML representation . Therefore , the disallowed URL http :// ja . dbpedia . org / page / K � 1 t — M must be escaped as http :// ja . dbpedia .",Method,Algorithm,Introduce,RDFization of Japanese Electronic Dictionaries and LOD,https://aclanthology.org/W13-5510.pdf
"For study # 1 , our base system ( Spitkovsky et al ., 2010b ) is an instance of the popular ( unlexicalized ) Dependency Model with Valence ( Klein and Manning , 2004 ). This model was trained using hard EM on WSJ45 ( WSJ sentences up to length 45 ) until successive changes in per - token cross - entropy fell below 2 − 20 bits ( Spitkovsky et al ., 2010b ; 2010a , § 4 ). We confirmed that the base model had indeed converged , by running 10 steps of hard EM on WSJ45 and verifying that its objective did not change much . Next , we applied a single alternation of simple lateen EM : first running soft EM ( this took 101 steps , using the same termination criterion ), followed by hard EM ( again to convergence — another 23 iterations ). The result was a decrease in hard EM ’ s cross - entropy , from 3 . 69 to 3 . 59 bits per token ( bpt ), accompanied by a 2 . 4 % jump in accuracy , from 50 . 4 to 52 . 8 %, on Section 23 of WSJ ( see Table 1 ).",Method,Algorithm,Introduce,"Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction",https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37144.pdf
"The main reference model of the painting ontology is the OWL 2 imple mentation of the CRM . The additional models that are correctly integrated in the ontology are : SOCH , Time Ontology , SUMO and Mid - LevelOntology . The painting ontology was constructed manually using the Prot ´ eg ´ e editing tool . Integration of the ontology concepts are accomplished by using the OWL construct : intersectionOf as specified below : The schemata that are stated in the above example are denoted with the following prefixes : painting ontology (& painting ), SOCH (& ksamsok ), Mid - Level - Ontology (& milo ) and CIDOCCRM ontology (& core ). In this example , the class Painting is defined in the painting ontology as a subclass of E22 Man - Made Object class from the CIDOC - CRM ontology and is an intersection of two classes , i . e .",Method,Algorithm,Introduce,A Framework for Improved Access to Museum Databases in the Semantic Web,https://aclanthology.org/W11-4102.pdf
"Additionally , we experimented with a set of features ( 9 ) that exploit the co - occurrence statistics of the Proceedings of the 5th International Workshop on Semantic Evaluation , ACL 2010 , pages 210 – 213 , Uppsala , Sweden , 15 - 16 July 2010 . c � 2010 Association for Computational Linguistics nominals and a set of clue words chosen manually , examining the relation definitions and examples provided by the organizers . The clues characterize the relations addressed in the task ( e . g . cargo , goods , content , box , bottle characterize the Content - Container relation ) . Each feature type was distinguished from the others using a prefix . All but the semantic relatedness features we used were binary , denoting whether a specific word , lemma , POS tag , etc .",Method,Algorithm,Introduce,TUD: semantic relatedness for relation classification,https://aclanthology.org/S10-1046.pdf
"This machine is then used to evaluate the systems , which makes the experiments directly reproducible in the future . System submissions are currently becoming increasingly popular in shared tasks . For example , the CoNLL 2015 shared task on shallow discourse parsing applies this technology . We plan to use the same system as the CoNLL task , TIRA ( Gollub et al ., 2012 ), which is already successfully applied in the PAN workshops on plagiarism detection . We propose a shared task for mining the argumentative structure in newspaper editorials .",Method,Algorithm,Introduce,A Shared Task on Argumentation Mining in Newspaper Editorials,https://aclanthology.org/W15-0505.pdf
"Simplifying assumptions about the joint measurement statistics are often made in order to yield tractable analytic forms . For example Hershey and Movellan have shown that correlations between video data and audio can be used to highlight regions of the image which are the & quot ; cause & quot ; of the audio signal . While such pragmatic choices may lead to * simple statistical measures , they do so at the cost of modeling capacity . Furthermore , these assumptions may not be appropriate for fusing modalities such as video and audio . The joint statistics for these and many other mixed modal signals are not well understood and are not well - modeled by simple densities such as multi - variate exponential distributions .",Method,Algorithm,Introduce,Learning Joint Statistical Models for Audio-Visual Fusion and Segregation,https://proceedings.neurips.cc/paper_files/paper/2000/file/11f524c3fbfeeca4aa916edcb6b6392e-Paper.pdf
"nitive science and visual neuroscience topics . The interested reader is invited to visit to interactively explore this model , including the topics , their connections , and the articles that exhibit them . We compared the CTM to LDA by fitting a smaller collection of articles to models of varying numbers of topics . This collection contains the 1 , 452 documents from 1960 ; we used a vocabulary of 5 , 612 words after pruning common function words and terms that occur once in the collection .",Method,Algorithm,Introduce,Discussoo: Towards an intelligent tool for multi-scale participatory modeling,https://www.sciencedirect.com/science/article/abs/pii/S1364815221000876
"It has long been recognized in the image processing community that wavelet transforms form an excellent basis for representation of images . Within the class of linear transforms , it represents a compromise between many conflicting but desirable properties of image representation such as multi - scale and multi - orientation representation , locality both in space and frequency , and orthogonality resulting in decorrelation . A particularly suitable wavelet transform which forms the basis of the best denoising algorithms today is the over - complete steerable wavelet pyramid [ 4 ] freely downloadable from In our experiments we have confirmed that the best results were obtained using this wavelet pyramid . In the following we will describe a model for the statistical dependencies between wavelet coefficients .",Method,Algorithm,Introduce,Products of “Edge-perts”,https://is.mpg.de/uploads_file/attachment/attachment/65/gehler05edgeperts.pdf
"Different mechanisms have been proposed , some relying on the average firing rates of the pre - and post - synaptic neurons , ( rate - based Hebbian learning ), others based on tight constraints on the time lags between pre - and post - synaptic spikes (“ Spike - Timing - Dependent - Plasticity ”). The synaptic circuits described in what follows implement a stochastic version of rate - based Hebbian learning . In the last decade , it has been realized that general constraints plausibly met by any concrete implementation of a synaptic device in a neural network , bear profound consequences on ∗ the capacity of the network as a memory system . Specifically , once one accepts that a synaptic element can neither have an unlimited dynamic range ( i . e . synaptic efficacy is bounded ), nor can it undergo arbitrarily small changes ( i . e .",Method,Algorithm,Introduce,A configurable analog VLSI neural network with spiking neurons and self-regulating plastic synapses which classifies overlapping patterns,https://proceedings.neurips.cc/paper_files/paper/2007/file/500e75a036dc2d7d2fec5da1b71d36cc-Paper.pdf
"This approach was entitled multiple kernel learning ( MKL ). Research in the subsequent years focused on speeding up the initially demanding optimization algorithms [ 22 , 26 ]— ignoring the fact that empirical evidence for the superiority of MKL over trivial baseline approaches ( not optimizing the kernel ) was missing . In 2008 , negative results concerning the accuracy of MKL in practical applications accumulated : at the NIPS 2008 MKL workshop [ 6 ] several researchers presented empirical evidence showing that traditional MKL rarely helps in practice and frequently is outperformed by a regular SVM using a uniform kernel combination , see Subsequent research ( e . g ., [ 10 ]) revealed further negative evidence and peaked in the provocative question “ Can learning kernels help performance ?” posed by Corinna Cortes in an invited talk at ICML 2009 [ 5 ]. Consequently , despite all the substantial progress in the field of MKL , there remained an unsatisfied need for an approach that is really useful for practical applications : a model that has a good chance of improving the accuracy ( over a plain sum kernel ).",Method,Algorithm,Introduce,The Local Rademacher Complexity of `p-Norm Multiple Kernel Learning,https://proceedings.neurips.cc/paper_files/paper/2011/file/996009f2374006606f4c0b0fda878af1-Paper.pdf
"To illustrate the general idea , a first example of GIOHMM is provided by the bidirectional IOHMMs ( Figure 1 ) introduced in [ 2 ] to process sequences and predict protein structural features , such as secondary structure . Unlike standard HMMs or IOHMMS used , for instance in speech recognition , this architecture is based on two hidden markov chains running in opposite directions to leverage the fact that biological sequences are spatial objects rather than temporal sequences . Bidirectional IOHMMs have been used to derive a suite of structural feature predictors [ 12 , 13 , 4 ] available through These predictors have accuracy rates in the 75 - 80 % range on a per amino acid basis .",Method,Algorithm,Introduce,Prediction of Protein Topologies Using Generalized IOHMMs and RNNs,https://proceedings.neurips.cc/paper_files/paper/2002/file/ffedf5be3a86e2ee281d54cdc97bc1cf-Paper.pdf
"The problem of inference , recovering the topic distributions from such a collection of documents , is provably NP - hard . Existing literature pursues techniques such as variational methods [ 2 ] or MCMC procedures [ 3 ] for approximating the maximum likelihood estimates . ∗ Given the intractability of the problem one needs further assumptions on topics to derive polynomial time algorithms which can provably recover topics . A possible ( strong ) assumption is that each document has only one topic but the collection can have many topics . A document with only one topic is sometimes referred as a pure topic document .",Method,Algorithm,Introduce,A provable SVD-based algorithm for learning topics in dominant admixture corpus,https://proceedings.neurips.cc/paper_files/paper/2014/file/b1563a78ec59337587f6ab6397699afc-Paper.pdf
"Another important aspect of multi - class settings is that the use of more classes which is discriminated by the BCI device only at lower accuracy is likely to confuse the user . Current BCI research strives for enhanced information transfer rates . Several options are available : ( 1 ) training of the BCI users , which can be somewhat tedious if up to 300 hours of training would be necessary , ( 2 ) invasive BCI techniques , which we consider not applicable for healthy human test subjects , ( 3 ) improved machine learning and signal processing methods where , e . g ., new filtering , feature extraction and sophisticated classifiers are constantly tuned and improved , ( 4 ) faster trial speeds and finally ( 5 ) more classes among which the BCI user is choosing . This work analysed the theoretical and practical implications of using more than two classes , and also psychological issues were shortly discussed . In essence we found that higher a ITR is achieved with three classes , however , it seems unlikely that it can be increased by moving above four classes .",Method,Algorithm,Introduce,Increase information transfer rates in BCI by CSP extension to multi-class,https://proceedings.neurips.cc/paper_files/paper/2003/file/ea159dc9788ffac311592613b7f71fbb-Paper.pdf
"Our algorithms are shown in practice to have accuracy comparable to a Gibbs sampler in terms of topic estimation , which requires the number of topics be given . Moreover , they are one of the fastest among several state of the art parametric techniques . Statistical consistency of our estimator is established under some conditions . A well - known challenge associated with topic modeling inference can be succinctly summed up by the statement that sampling based approaches may be accurate but computationally very slow , e . g ., Pritchard et al . ( 2000 ); Griffiths & Steyvers ( 2004 ), while the variational inference approaches are faster but their estimates may be inaccurate , e . g ., Blei et al .",Method,Algorithm,Introduce,Conic Scan-and-Cover algorithms for nonparametric topic modeling,https://proceedings.neurips.cc/paper_files/paper/2017/file/9185f3ec501c674c7c788464a36e7fb3-Paper.pdf
"The architecture uses rectified linear units ( ReLU ), and gated recurrent units ( GRU ) [ 20 ], which have similar performance to long short - term memory [ 21 ] ( LSTM ) [ 22 ]. Unless stated otherwise , we set the standard deviation of noise added to the channel to σ = 2 , which was found to be essential for good performance . RIAL and DIAL share the same individual model architecture . For brevity , we describe only the DIAL model here . As illustrated in Figure 2 , each agent consists of a recurrent neural network ( RNN ), unrolled for T time - steps , that maintains an internal state h , an input network for producing a task embedding z , and an output network for the Q - values and the messages m . The input for agent a is defined as a tuple of ( oat , mat − 1 , uat − 1 , a ).",Method,Algorithm,Introduce,Learning to Communicate with Deep Multi-Agent Reinforcement Learning,https://proceedings.neurips.cc/paper_files/paper/2016/file/c7635bfd99248a2cdef8249ef7bfbef4-Paper.pdf
"Fig . 2 visualizes the structure learning process . This example is similar to that above but includes some uncorrelated random variables to show how they are treated by CorEx . We set b = 5 clusters of variables but we used m = 10 hidden variables . At each iteration , t , we show which hidden variables , Yj , are connected to input variables , Xi , through the connectivity matrix , a ( shown on top ).",Method,Algorithm,Introduce,Discovering Structure in High-Dimensional Data Through Correlation Explanation,https://proceedings.neurips.cc/paper_files/paper/2014/file/4f6ffe13a5d75b2d6a3923922b3922e5-Paper.pdf
"O which is split into two terms based on dependence on each parameter : ( 1 ) expected log - likelihood for updating V by arg maxV Eq ( X ) q ( C )[ log p ( y | C , x , V , G )]; and ( 2 ) negative KL divergence between the prior and the posterior on x for updating α by arg maxα Eq ( X ) q ( C )[ log p ( x | G , α ) − log q ( x )]. The update rules for each hyperparameter are given in the Appendix . The full EM algorithm starts with an initial value of O . In the E - step , given q ( C ), compute q ( x ) as in Eq . ( 9 ).",Method,Algorithm,Introduce,Bayesian Manifold Learning: The Locally Linear Latent Variable Model,https://proceedings.neurips.cc/paper_files/paper/2015/file/d1fe173d08e959397adf34b1d77e88d7-Paper.pdf
"Since the entire correlation graph is too large , we build a 3 - layer hierarchy by clustering the learned topics , with their learned correlation strength as the similarity measure . Fig . 4 shows a part of the hierarchy , where the subgraph A represents the top layer with 10 clusters . The subgraphs B and C are two second layer clusters ; and D and E are two correlation subgraphs consisting of leaf nodes ( i . e ., learned topics ). To represent their semantic meanings , we present 4 most frequent words for each topic ; and for each topic cluster , we also show most frequent words by building a hyper - topic that aggregates all the included topics .",Method,Algorithm,Introduce,Scalable Inference for Logistic-Normal Topic Models,https://proceedings.neurips.cc/paper_files/paper/2013/file/285f89b802bcb2651801455c86d78f2a-Paper.pdf
"is diagonal , the true likelihood of y given g factorizes over each datapoint : P ( y | g ) = Hi = 1 P ( yi | gi ), and standard EP algorithms for Gaussian process classification can be used [ 8 ] ( with the variance given by EE . instead of EE , and kernel matrix R instead of K ). The final algorithm defines a whole new class of relational models , depends on a single hyperparameter p which can be optimized by grid search in [ 0 , 1 ], and requires virtually no modification of code written for EP - based Gaussian process classifiers . We now compare three different methods in relational classification tasks . We will compare a standard Gaussian process classifier ( GPC ), the relational Gaussian process ( RGP ) of [ 2 ] and our method , the mixed graph Gaussian process ( XGP ).",Method,Algorithm,Introduce,Hidden Common Cause Relations in Relational Learning,https://proceedings.neurips.cc/paper_files/paper/2007/file/912d2b1c7b2826caf99687388d2e8f7c-Paper.pdf
"When we optimize over supergradients , all possible tight sets are considered . Similarly , the subgradients are optimized over B ( F ), and for any X ⊆ V there exists some sX ∈ B ( F ) tight at X . Our experiments aim to address four main questions : ( 1 ) How large is the gap between the upperand lower - bounds for the log - partition function and the marginals ? ( 2 ) How accurate are the factorized approximations obtained from a single MAP - like optimization problem ? ( 3 ) How does the accuracy depend on the amount of evidence ( i . e ., concentration of the posterior ), the curvature of the function , and the type of Bayesian submodular model considered ?",Method,Algorithm,Introduce,From MAP to Marginals: Variational Inference in Bayesian Submodular Models,https://proceedings.neurips.cc/paper_files/paper/2014/file/82161242827b703e6acf9c726942a1e4-Paper.pdf
"Lemma 3 . 2 If we set ⌧ = 1K in ( 5 ), the constraint rank ( W ) < K will be automatically satisfied . � Finally , we construct Z * = U D as instructed in corollary 3 . 1 . 1 . Note that in the intermediate iterations , we do not need to compute Z ; we need to construct the matrix Z * to find the overlapping blocks after the learning algorithm will converge . Here , we show that GRAB algorithm generalizes the K - way graph cut algorithm in two ways : 1 ) GRAB allows each variable to be in multiple blocks with soft membership ; and 2 ) GRAB updates a network structure ⇥, used as a similarity matrix , in each iteration . The proof is in the Appendix .",Method,Algorithm,Introduce,Learning Sparse Gaussian Graphical Models with Overlapping Blocks,https://proceedings.neurips.cc/paper_files/paper/2016/file/6be5336db2c119736cf48f475e051bfe-Paper.pdf
"The idea of working in the tangent space is both efficient and convenient , but comes with an element of approximation as the logarithmic map is only guarantied to preserve distances to the origin of the tangent and not between all pairs of data points . Practical experience , however , indicates that this is a good tradeoff ; see [ 19 ] for a more in - depth discussion of when the approximation is suitable . To illustrate the framework we consider an example in human body analysis , and then we analyze the scalability of the approach . But first , to build intuition , Fig . 3a show synthetically generated data samples from two classes .",Method,Algorithm,Introduce,A Geometric take on Metric Learning,https://proceedings.neurips.cc/paper_files/paper/2012/file/ec5aa0b7846082a2415f0902f0da88f2-Paper.pdf
"For example , for the quadratic loss function , in the standard WM and RWM algorithms , experts have no reason to misreport their beliefs ( see Proposition 8 ). This is not the case for other loss functions , such as the absolute loss function . The standard algorithm with the absolute loss function incentivizes extremal reporting , i . e . an expert reports 1 whenever b ( t ) i > 21 and 0 otherwise . This follows from a simple derivation or alternatively from results in the property elicitation literature .",Method,Algorithm,Introduce,Online Prediction with Selfish Experts,https://proceedings.neurips.cc/paper_files/paper/2017/file/3b3dbaf68507998acd6a5a5254ab2d76-Paper.pdf
"It is worth noting that the number of iterations to reach a target precision of ε means that − f ( αk ) − minαEQ1 − f ( α ) = maxαEQ1 f ( α ) − f ( αk ) ≤ ε . However , this does not mean the dual gap as used in [ 15 ] is less than ε . In [ 15 ], the objective function is smoothed by adding a quadratic term and then they further proposed a projected gradient algorithm and analytic center cutting plane method ( ACCPM ) . As proved in Theorem 3 , the number of iterations of the projected gradient method is usually O ( L / e ). In each iteration , the main complexity cost O ( n ) is from the eigen - decomposition .",Method,Algorithm,Introduce,Analysis of SVM with Indefinite Kernels,https://proceedings.neurips.cc/paper_files/paper/2009/file/7f1de29e6da19d22b51c68001e7e0e54-Paper.pdf
"The VGG network , which contains 11 - 19 weight layers depending on the typical architecture [ 3 ], takes 2 to 3 weeks on a system equipped with 4 NVIDIA Titan Black GPUs for training a single net . The residual network ResNet , which achieved state - of - the - art results in image classification and detection in 2015 [ 4 ], takes 3 . 5 days for the 18 - layer model and 14 days for the 101 - layer model using 4 NVIDIA Kepler GPU . Could we evaluate a network structure without taking a long time to train it ? There are some prior works to deal with this issue but they deal with much shallow networks [ 21 ]. In future work , we will address this issue by utilizing the untrained network to attempt to compare networks quickly without having to train them .",Method,Algorithm,Introduce,A Powerful Generative Model Using Random Weights for the Deep Image Representation,https://proceedings.neurips.cc/paper_files/paper/2016/file/58238e9ae2dd305d79c2ebc8c1883422-Paper.pdf
"The potentials were (− θi , θi ) for nodes and ( θij , − θij ; − θij , θij ) for edges . ( 3 ) Restricted Boltzmann Machines ( RBMs ): From the Probabilistic Inference Challenge 2011 . ( 4 ) Horses : Large ( N ≈ 12000 ) MRFs representing images from the Weizmann Horse Data ( Borenstein and Ullman , 2002 ) with potentials learned by Domke ( 2013 ). ( 5 ) Chinese Characters : An image completion task from the KAIST Hanja2 database , compiled in OpenGM by Andres et al . ( 2012 ).",Method,Algorithm,Introduce,Barrier Frank-Wolfe for Marginal Inference,https://proceedings.neurips.cc/paper_files/paper/2015/file/0c74b7f78409a4022a2c4c5a5ca3ee19-Paper.pdf
"As we show , fixed - k estimators can also exhibit superior rates of convergence . As shown in Table 1 , several authors have derived bias corrections necessary for fixed - k estimators of entropies and divergences , including , most famously , the Shannon entropy estimator of [ 20 ]. The estimators in Table 1 estimators are known to be weakly consistent , but , except for Shannon entropy , expectations are over X ∼ P . r ( t ) = f ∞ xt − 1e − x dx is the gamma function , and ψ ( x ) = ddx log ( r ( x )) is the digamma function . a E R \{ 1 } is a free parameter . ∗ For KL divergence , bias corrections for p and q cancel .",Method,Algorithm,Introduce,Finite-Sample Analysis of Fixed-k Nearest Neighbor Density Functional Estimators,https://proceedings.neurips.cc/paper_files/paper/2016/file/2dea61eed4bceec564a00115c4d21334-Paper.pdf
"_CITE_ section Materials and methods ) used in CePa , the most influential genes were the nodes with the highest betweenness centrality .",Method,Algorithm,Introduce,A critical comparison of topology-based pathway analysis methods,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0191154
"Many of these cell lines will grow as subcutaneous xenografts , thus cell lines sensitive to an agent in vitro were often subjected to further analyses in xenografts derived from those cell lines . The NCI - 60 panel has been extensively molecularly characterized , with data available for gene expression , DNA variation ( mutation and SNPs ), protein expression , DNA methylation , microRNA expression and metabolomics ( http :// dtp . cancer . gov / mtargets / mt_index . html ) [ 3 - 9 ]. The COMPARE algorithm ( compare . html ) allows investigators to correlate NCI - 60 drug activity profiles with all other open agents in the database and with molecular characteristics of the cells [ 10 ]. While the in vitro grown cells have been characterized , the corresponding subcutaneous xenografts had not . However , other studies have succeeded in molecular profiling of other xenografts [ 2 , 11 , 12 ].",Method,Algorithm,Introduce,Gene expression profiling of 49 human tumor xenografts from in vitro culture through multiple in vivo passages - strategies for data mining in support of therapeutic studies,https://link.springer.com/article/10.1186/1471-2164-15-393
"Another improvement will come with the use of absent phenotypes . For example , the lung phenotype of UDP_2700 mapped well to Fraser syndrome but the absence of syndactyly and severe neurological symptoms was not considered , and thus Fraser syndrome ranked inappropriately high . These improvements are currently being implemented in the OWLsim algorithm ( ) 25 and will be incorporated into the next version of Exomiser . Some patients likely have genetic disorders unsolvable by exome sequencing and Exomiser alone . Besides the possibility that the initial assumption of a germline genetic basis for the disease might be invalid , exome data only cover 2 % of the genome and are insensitive to certain types of mutations , including copy number variations and trinucleotide repeats .",Method,Algorithm,Introduce,Computational evaluation of exome sequence data using human and model organism phenotypes improves diagnostic efficiency,https://www.nature.com/articles/gim2015137
"version has been already publically released . The whole VALLEX 1 . 0 can be downloaded from the Internet after filling the on - line registration form at the following address : From the very beginning , VALLEX 1 . 0 was designed with an emphasis on both human and machine readability . Therefore both linguists and developers of applications within the Natural Language Processing domain can use and critically evaluate its content . In order to satisfy different needs of these different potential users , VALLEX 1 . 0 contains the data in the following three formats : Browsable version .",Method,Algorithm,Produce,Valency Frames of Czech Verbs in VALLEX 1.0,https://aclanthology.org/W04-2711.pdf
"Its output is a ( time - varying ) 3d model that can be displayed by Partiview , an external data viewer . Future plans include adding more scalable embedding algorithms , and allowing other output formats . Ndaona , documentation , and examples of models created with it , can be found at _CITE_",Method,Algorithm,Produce,Automating the Creation of Interactive Glyph-supplemented Scatterplots for Visualizing Algorithm Results,https://aclanthology.org/N06-4008.pdf
"The grammar is implemented in the LKB using the T DL formalism ( Krieger and Schäfer , 1994 ), based on unification and on typed feature structures , and whose types are organized in a multiple inheritance hierarchy . For more information , please refer to a detailed implementation report ( Branco and Costa , 2008a ) or on pages 31 – 43 of this volume ( Branco and Costa , 2008b ). A free version of the grammar can also be obtained at , under an ELDA research license . Section 2 introduces the main features of the Minimal Recursion Semantics format , which is employed in the semantic representations produced by LXGram . In Section 3 , the sample text that the LXGram team submitted is described , together with an explanation of the representations derived by the grammar .",Method,Algorithm,Produce,LXGram in the Shared Task “Comparing Semantic Representations” of STEP 2008,https://aclanthology.org/W08-2224.pdf
"Qualitative analysis of these word clusters yields insights about NLP and linguistic phenomena in this genre . Additionally , we contribute the first POS annotation guidelines for such text and release a new dataset of English language tweets annotated using these guidelines . Tagging software , annotation guidelines , and large - scale word clusters are available at : This paper describes release 0 . 3 of the “ CMU Twitter Part - of - Speech Tagger ” and annotated data .",Method,Algorithm,Produce,Improved Part-of-Speech Tagging for Online Conversational Text with Word Clusters,https://aclanthology.org/N13-1039.pdf
"We have proved the need of a temporal analysis at document level . For that , we have proposed a simple strategy that acquires implicit relations and it obtains a more complete time - anchoring . The approach has been evaluated on the TimeLine extraction task and the results show that the performance can be doubled when using implicit relations . As future work , we plan to explore in more detail this research line by applying more sophisticated approaches in the temporal analysis at document level . However , this is not the only research line that we want to go in depth .",Method,Algorithm,Produce,Document Level Time-anchoring for TimeLine Extraction,https://aclanthology.org/P15-2059.pdf
We evaluate the quality of our linguistic vectors on a number of tasks that have been proposed for evaluating distributional word vectors . We show that linguistic word vectors are comparable to current state - ofthe - art distributional word vectors trained on billions of words as evaluated on a battery of semantic and syntactic evaluation benchmarks . We construct linguistic word vectors by extracting word level information from linguistic resources . Table 1 shows the size of vocabulary and number of features induced from every lexicon . We now describe various linguistic resources that we use for constructing linguistic word vectors .,Method,Algorithm,Produce,Non-distributional Word Vector Representations,https://arxiv.org/pdf/1506.05230.pdf
"By providing scalar factuality judgments for events , our models enable more fine - grained reasoning than previously considered . The corpus and learned models are available online . While event definitions have been proposed in several prior studies , existing approaches vary in how they model various linguistic forms such as nominal events , stative events , generic events , and light verbs ( Pustejovsky et al ., 2003 ; Palmer et al ., 2005 ; Meyers et al ., 2004 ; Kim et al ., 2009 ; Song et al ., 2015 ). Even with a formal and precise account of events , training annotators to learn all such linguistic intricacies remains a practical challenge . Instead of definition - driven instructions , we propose example - driven instructions and show their effectiveness .",Method,Algorithm,Produce,Event Detection and Factuality Assessment with Non-Expert Supervision,https://aclanthology.org/D15-1189.pdf
"We present an efficient approximate approach for learning this environment model as part of a policygradient reinforcement learning algorithm for text interpretation . This design enables learning for mapping high - level instructions , which previous statistical methods cannot handle . In this paper , we introduce a novel method for mapping high - level instructions to commands in an external environment . These instructions specify goals to be achieved without explicitly stating all the required steps . For example , consider the first instruction in Figure 1 — “ open control panel .” The three GUI commands required for its successful execution are not explicitly described in the text , and need to be inferred by the user .",Method,Algorithm,Produce,Reading Between the Lines: Learning to Map High-level Instructions to Commands,https://aclanthology.org/P10-1129.pdf
"We present a method to analyze calibration , and apply it to compare the miscalibration of several commonly used models . We also contribute a coreference sampling algorithm that can create confidence intervals for a political event extraction task . Natural language processing systems are imperfect . Decades of research have yielded analyzers that mis - identify named entities , mis - attach syntactic relations , and mis - recognize noun phrase coreference anywhere from 10 - 40 % of the time . But these systems are accurate enough so that their outputs can be used as soft , if noisy , indicators of language meaning for use in downstream analysis , such as systems that perform question answering , machine translation , event extraction , and narrative analysis ( McCord et al ., 2012 ; Gimpel and Smith , 2008 ; Miwa et al ., 2010 ; Bamman et al ., 2013 ).",Method,Algorithm,Produce,Posterior calibration and exploratory analysis for natural language processing models,https://arxiv.org/pdf/1508.05154.pdf
"( 2006 ) ( see Section 3 ). We show that metrics based on deeper linguistic information ( syntactic / shallow - semantic ) are able to produce more reliable system rankings than those produced by metrics which limit their scope to the lexical dimension , specially when the systems under evaluation are of a different nature . For our experiments , we have compiled a representative set of metrics at different linguistic levels . We have resorted to several existing metrics , and we have also developed new ones . Below , we group them according to the level at which they operate .",Method,Algorithm,Produce,Linguistic Features for Automatic Evaluation of Heterogenous MT Systems,https://aclanthology.org/W07-0738.pdf
"We evaluate our mixture model on four different test sets . On the three most AAC - like test sets , we found substantial reductions in not only perplexity but also in potential keystroke savings when used in a predictive keyboard interface . Finally , to aid other AAC researchers , we have publicly released our crowdsourced AAC collection , word lists and best - performing language models . As we mentioned in the introduction , there are unfortunately no publicly available sources of genuine conversational AAC messages . We conjectured we could create surrogate data by asking workers on Amazon Mechanical Turk to imagine they were a user of an AAC device and having them invent things they might want to say .",Method,Algorithm,Produce,The Imagination of Crowds: Conversational AAC Language Modeling using Crowdsourcing and Large Data Sources,https://aclanthology.org/D11-1065.pdf
"PropBank ( Hwang et al ., 2010 ), and WordNet ( Vincze et al ., 2012 ). In this paper , we propose a formal representation of LVCs in the valency lexicon of Czech verbs , VALLEX . The VALLEX lexicon is a collection of rich linguistically annotated data resulting from an attempt at a formal description of the valency behavior of Czech verbs . It provides the information on the valency structure of Czech verbs in the form of valency frames , each valency frame corresponding to a single verbal lexical unit . For the description of valency , the valency theory formulated within the Functional Generative Description ( FGD ) – a dependency based framework – has been adopted ( Sgall et al ., 1986 ).",Method,Algorithm,Produce,The Representation of Czech Light Verb Constructions in a Valency Lexicon,https://aclanthology.org/W13-3717.pdf
"Table 4 summarizes the results of the techniques for injecting external knowledge . It is important to note that , although the world class model was learned on the superset of CoNLL03 data , and although the Wikipedia gazetteers were constructed based on CoNLL03 annotation guidelines , these features proved extremely good on all datasets . Word class models discussed in Section 6 . 1 are computed offline , are available online , and provide an alternative to traditional semi - supervised learning . It is important to note that the word class models and the gazetteers and independednt and accumulative . Furthermore , despite the number and the gigantic size of the extracted gazetteers , the gazeteers alone are not sufficient for adequate performance .",Method,Algorithm,Produce,Design Challenges and Misconceptions in Named Entity Recognition∗ † ‡,https://aclanthology.org/W09-1119.pdf
"As the form of the subordinated verb depends heavily on the conjunction in the subordinated Spanish clause and the semantics of the main verb , we extracted this information from two treebanks and trained different classifiers on this data . We tested the best classifier on a set of 4 texts , increasing the correct subordinated verb forms from 80 % to 89 %. As part of our research project SQUOIA , we have developed several tools and resources for Cuzco Quechua . These include a treebank , currently consisting of around 500 sentences , and a rule - based MT system Spanish - Cuzco Quechua . The treebank is currently being enhanced with more annotated text and should reach about 4000 sentences upon project completion .",Method,Algorithm,Produce,Machine Learning Disambiguation of Quechua Verb Morphology,https://www.zora.uzh.ch/id/eprint/80083/1/W13-2804.pdf
"For each pair , corresponding sequences were chosen from the respective pools at random . The volunteers were only told that the sequences were either real or artificial , and were asked to either select the real video or to indicate that they could not decide . The test is kept available on - line for validation at The results are shown in Table 1 . The first row , e . g ., shows that when comparing Brand ’ s model with the DPDS , people thought that the sequence generated with the former model was real in 5 cases , could not make up their mind in 7 cases , and thought the sequence generated with DPDS was real in 54 instances .",Method,Algorithm,Produce,A Probabilistic Model for Generating Realistic Lip Movements from Speech,https://proceedings.neurips.cc/paper_files/paper/2007/file/c203d8a151612acf12457e4d67635a95-Paper.pdf
"We now empirically explore our method ’ s behavior . All of our code , data , and experiments may be found on the CodaLab worksheet for this paper at , which also contains more detailed plots beyond those shown here . We would like to answer the following questions :",Method,Algorithm,Produce,Learning with Relaxed Supervision,https://proceedings.neurips.cc/paper_files/paper/2015/file/f18a6d1cde4b205199de8729a6637b42-Paper.pdf
"The advantage of our method is that we can jointly learn the optimal feature representation and the optimal domain transformation parameter , which are aware of the subsequent transductive inference procedure . Following the standard evaluation protocol in the unsupervised domain adaptation community , we evaluate our method on the digit classification task using MNIST [ 19 ] and SVHN [ 21 ] as well as the object recognition task using the Office [ 25 ] dataset , and demonstrate state of the art performance in comparison to all existing unsupervised domain adaptation methods . Learned models and the source code can be reached from the project webpage _CITE_",Method,Algorithm,Produce,Learning Transferrable Representations for Unsupervised Domain Adaptation,https://proceedings.neurips.cc/paper_files/paper/2016/file/b59c67bf196a4758191e42f76670ceba-Paper.pdf
"The random working set selection from the samples not fulfilling the KKT conditions is the best option if the working is be large , because it reduces the number of chunks to be solved . This strategy benefits from the IRWLS procedure , which allows to work with large training data set . All these modifications have been concreted in the SVC "" tht solving procedure , publicly available at _CITE_",Method,Algorithm,Produce,Fast Training of Support Vector Classifiers,https://proceedings.neurips.cc/paper_files/paper/2000/file/6ae07dcb33ec3b7c814df797cbda0f87-Paper.pdf
"This output distribution can be seen as a saliency map from the point of view of the person inside the picture . To train and evaluate our model , we also introduce GazeFollow , a large - scale benchmark dataset for gaze - following . Our model , code and dataset are available for download at Related Work ( Saliency ): Although strongly related , there are a number of important distinctions between gaze - following [ 3 ] and saliency models of attention [ 8 ]. In traditional models of visual attention , the goal is to predict the eye fixations of an observer looking at a picture , while in gazefollowing the goal is to estimate what is being looked at by a person inside a picture .",Method,Algorithm,Produce,Where are they looking?,https://proceedings.neurips.cc/paper_files/paper/2015/file/ec8956637a99787bd197eacd77acce5e-Paper.pdf
"We used a soft - max operation with an increasing temperature parameter to model the non - differentiable color channel selection at each point , which allowed us to train the pattern effectively . Finally , we demonstrated that our learned pattern enabled better reconstructions than past designs . An implementation of our method , along with trained models , data , and results , is available at our project page at Our results suggest that learning measurement strategies jointly with computational inference is both useful and possible . In particular , our approach can be used directly to learn other forms of optimized multiplexing patterns — e . g ., spatio - temporal multiplexing for video , viewpoint multiplexing in lightfield cameras , etc .",Method,Algorithm,Produce,Learning Sensor Multiplexing Design through Back-propagation,https://proceedings.neurips.cc/paper_files/paper/2016/file/aa486f25175cbdc3854151288a645c19-Paper.pdf
"At the same time , it is also usually able to correctly estimate the depth of large and texture - less planar regions ( but , see column 6 for an example failure case ). Our overall inference method ( network predictions and globalization ) takes 24 seconds per - image when using an NVIDIA Titan X GPU . The source code for implementation , along with a pre - trained network model , are available at _CITE_",Method,Algorithm,Produce,Depth from a Single Image by Harmonizing Overcomplete Local Network Predictions,https://proceedings.neurips.cc/paper_files/paper/2016/file/f3bd5ad57c8389a8a1a541a76be463bf-Paper.pdf
"But an understanding of how these methods relate and when one method is preferable to another is still lacking . Here , we present a novel unified approach to interpreting model predictions . Our approach leads to three potentially surprising results that bring clarity to the growing space of methods : The best explanation of a simple model is the model itself ; it perfectly represents itself and is easy to understand . For complex models , such as ensemble methods or deep networks , we cannot use the original model as its own best explanation because it is not easy to understand . Instead , we must use a simpler explanation model , which we define as any interpretable approximation of the original model .",Method,Algorithm,Produce,A Unified Approach to Interpreting Model Predictions,https://proceedings.neurips.cc/paper_files/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf
"GANs train two deep networks in concert : a generator network that maps random noise , usually drawn from a multi - variate Gaussian , to data items ; and a discriminator network that estimates the likelihood ratio of the generator network to the data distribution , and is trained using an adversarial principle . Despite an enormous amount of recent work , GANs are notoriously fickle to train , and it has been observed [ 1 , 19 ] that they often suffer from mode collapse , in which the generator network learns how to generate samples from a few modes of the data distribution but misses many other modes , even though samples from the missing modes occur throughout the training data . To address this problem , we introduce VEEGAN , a variational principle for estimating implicit probability distributions that avoids mode collapse . While the generator network maps Gaussian random noise to data items , VEEGAN introduces an additional reconstructor network that maps the true data distribution to Gaussian random noise . We train the generator and reconstructor networks jointly by introducing an implicit variational principle , which encourages the reconstructor network not only to map the data distribution to a Gaussian , but also to approximately reverse the action of the generator .",Method,Algorithm,Produce,VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning,https://proceedings.neurips.cc/paper_files/paper/2017/file/44a2e0804995faf8d2e3b084a1e2db1d-Paper.pdf
"With smaller amounts , however , this isn ' t always possible , and when it is possible , it can produce worse actual running times than a disk - based approach . As our goal is to judge streaming algorithms under low memory conditions , we used the first approach , which is more fitting to such a constraint . Each algorithm was programmed in C / C ++, compiled with g ++, and run under Ubuntu Linux ( 10 . 04 LTS ) on HP Pavilion p6520f Desktop PC , with an AMD Athlon II X4 635 Processor running at 2 . 9 GhZ and with 6 GB main memory ( although nowhere near the entirety of this was used by any algorithm ). For StreamKM ++, the authors ' implementation [ 2 ], also in C , was used instead . With all algorithms , the reported cost is determined by taking the resulting k facilities and computing the k - means cost across the entire dataset .",Method,Algorithm,Produce,Fast and Accurate k-llleans For Large Datasets,https://proceedings.neurips.cc/paper_files/paper/2011/file/52c670999cdef4b09eb656850da777c4-Paper.pdf
"Other more advanced optimization methods , such as L - BFGS and Newton ’ s method are also applicable . In this section , we demonstrate our algorithm on a set of real - world graphical models from recent UAI inference challenges , including two diagnostic Bayesian networks with 203 and 359 variables and max domain sizes 7 and 6 , respectively , and several MRFs for pedigree analysis with up to 1289 variables , max domain size of 7 and clique size 5 . We construct marginal MAP problems on these models by randomly selecting half of the variables to be max nodes , and the rest as sum nodes . We implement several algorithms that optimize the same primal marginal MAP bound , including our GDD ( Algorithm 1 ), the WMB algorithm in [ 16 ] with ibound = 1 , which uses the same cliques and a fixed point heuristic for optimization , and an off - the - shelf L - BFGS implementation that directly optimizes our decomposed bound . For comparison , we also computed several related primal bounds , including standard mini - bucket [ 2 ] and elimination reordering [ 27 , 38 ], limited to the same computational limits ( ibound = 1 ).",Method,Algorithm,Produce,Decomposition Bounds for Marginal MAP,https://proceedings.neurips.cc/paper_files/paper/2015/file/faacbcd5bf1d018912c116bf2783e9a1-Paper.pdf
"We present a posterior inference algorithm based on Gibbs sampling , and establish posterior consistency of our regression model . Our method is evaluated with extensive experiments on simulated data and demonstrated to be able to identify meaningful interactions in applications in genetics and retail demand forecasting . A fundamental challenge in supervised learning , particularly in regression , is the need for learning functions which produce accurate prediction of the response , while retaining the explanatory power for the role of the predictor variables in the model . The standard linear regression method is favored for the latter requirement , but it fails the former when there are complex interactions among the predictor variables in determining the response . The challenge becomes even more pronounced in a high - dimensional setting – there are exponentially many potential interactions among the predictors , for which it is simply not computationally feasible to resort to standard variable selection techniques ( cf .",Method,Algorithm,Produce,Multi-way Interacting Regression via Factorization Machines,https://proceedings.neurips.cc/paper_files/paper/2017/file/fcdf25d6e191893e705819b177cddea0-Paper.pdf
"The algorithms under comparison are : ( i ) CCIT - Algorithm 3 in our paper where we use XGBoost [ 6 ] as the classifier . In our experiments , for each data - set we boot - strap the samples and run our algorithm B times . The results are averaged over B bootstrap runs . ( ii ) KCIT - Kernel CI test from [ 32 ]. We use the Matlab code available online .",Method,Algorithm,Produce,Model-Powered Conditional Independence Test,https://proceedings.neurips.cc/paper_files/paper/2017/file/02f039058bd48307e6f653a2005c9dd2-Paper.pdf
"The differences between inhomogenous , homogenous , and pairwise - relation based cuts are even more evident for large graphs and they may lead to significantly different partitioning performance in a number of important partitioning applications . The problem of inhomogeneous hypergraph clustering has not been previously studied in the literature . The main results of the paper are efficient algorithms for inhomogenous hypergraph partitioning with theoretical performance guarantees and extensive testing of inhomogeneous partitioning in applications such as hierarchical biological network studies , structure learning of rankings and subspace clustering ( All proofs and discussions of some applications are relegated to the Supplementary Material ). The algorithmic methods are based on transforming hypergraphs into graphs and subsequently performing spectral clustering based on the normalized Laplacian of the derived graph . A similar approach for homogenous clustering has been used under the name of Clique Expansion [ 14 ].",Method,Algorithm,Produce,Inhomogeneous Hypergraph Clustering with Applications,https://proceedings.neurips.cc/paper_files/paper/2017/file/a50abba8132a77191791390c3eb19fe7-Paper.pdf
"Typically , these Bayesian approaches aim to explicitly represent the unknown objective function of ( 1 ) by entertaining a posterior distribution over the space of objective functions . In contrast , we aim to model directly the distribution of the maximum of ( 2 ) conditioned on observations . Our model is intuitively straightforward and easy to implement . Let h ( x ) : X → R be an estimate of the mean ¯ f ( x ) constructed from data Dt := {( xi , yi )} ti = 1 ( Figure 1a , left ). This estimate can easily be converted into a posterior pdf over the location of the maximum by first multiplying it with a precision parameter α > 0 and then taking the normalized exponential ( Figure 1a , right ) In this transformation , the precision parameter α controls the certainty we have over our estimate of the maximizing argument : α ≈ 0 expresses almost no certainty , while α → ∞ expresses certainty .",Method,Algorithm,Produce,A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function,https://proceedings.neurips.cc/paper_files/paper/2012/file/a9be4c2a4041cadbf9d61ae16dd1389e-Paper.pdf
OWL versions of the information models ; descriptions of interview protocols ; models of stakeholders and users ; competency questions ; and other supporting documents can be found at Raw data and other materials will be made available upon request to the corresponding author .,Method,Algorithm,Produce,An information model for computable cancer phenotypes,https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-016-0358-4
"VIPUR is currently available as an independent Python module requiring BLAST +, ROSETTA and PROBE ( all freely available for academic use ). Please see the VIPUR code for usage and analysis details , available at https :// osf . io / bd2h4 . The full predictions for all variants below , including structural models , are also available at Classifying ClinVar annotated single nucleotide variant phenotypes We demonstrate that VIPUR ’ s deleterious predictions are an accurate indication of variant pathogenicity by classifying variants in the ClinVar database ( 29 ). ClinVar is a collection of human variants with annotated phenotypic effects , including variants with causative ‘ pathogenic ’ effects and ‘ benign ’ variants with no known disease effect .",Method,Algorithm,Produce,Database resources of the National Center for Biotechnology Information,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7778943/
"The triplestore contains administrative and accountancy data of more than 300K companies , amounting to almost 50M triples . The complexity of the schema is moderate / low , consisting of 11 classes , 16 object properties and 59 datatype properties ( see an excerpt in Fig 1 ). We have set up a PepeSearch instance to query this triplestore , available at In order to assess the effectiveness of PepeSearch , we arranged a search challenge with an award of a 1000 kroner book voucher for the best performer . This competition was advertised at the University of Oslo and at the Oslo Akershus University College .",Method,Algorithm,Produce,PepeSearch: Semantic Data for the Masses,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0151573
"It therefore makes sense to think of this as a separable part of the theory , the “ upper ontology ”. At the top level , datastructures ( instances of Object ) belong to one of the concepts Ordered , Set and Primitive . Ordered structures are divided ' These are both available in full from up in terms of the number of components ( concepts Arity - 1 , Arity - 2 etc ) and whether they are Tuples or Sequences . For convenience , union types such as Arity - atleast - 2 are also defined . The RAGS NLG ontology ( see Figure 3 for an overview ) contains the main substance of the RAGS type definitions .",Method,Algorithm,Use,Ontological Representation of Light Wave Camera Data to Support Vision-Based AmI,https://www.mdpi.com/1424-8220/12/9/12126
"The DRI is an international & quot ; grassroots & quot ; effort that seeks to share corpora that have been tagged with the core features of interest to the discourse community . In order to use the core scheme , it is anticipated that each group will need to refine it for their particular purposes . A usable draft core scheme is now available for experimentation ( see ). Whereas several groups are working with the unadapted core DRI scheme ( Core and Allen , 1997 ; Poesio and Traum , 1997 ), we have attempted to adapt it to our corpus and particular research questions . First we describe our corpus , and the issue of tracking agreement .",Method,Algorithm,Use,Community foundations as advocates: social change discourse in the philanthropic sector,https://link.springer.com/article/10.1057/s41309-018-0039-z
"Otherwise , we may alter the coherence of the text and decrease its readability . This leaves us with 19 simplification rules . To apply them , the candidate structures for simplification first need to be detected using regular expressions , via Tregex ( Levy and Andrew , 2006 ) that allows the retrieval of elements and relationships in a parse tree . In a second step , syntactic trees in which a structure requires simplification are modified according a set of operations implemented through Tsurgeon . The operations to perform depend on the type of rules : 1 .",Method,Algorithm,Use,Syntactic Sentence Simplification for French,https://hal.science/hal-00955176/
"The model uses standard features : lemma and part of speech in a narrow context window ( 2 words either side ) and a wide context window ( 50 words either side ), as well as dependency labels leading to parent , children , and siblings of the target word , and lemmas and part of speech of parent , child , and sibling nodes . Table 3 shows sample model features for an occurrence of add in the British National Corpus ( BNC ) ( Leech , 1992 ). The model uses a maximum entropy learner , training one binary classifier per sense . ( With n - ary classifiers , the model ’ s performance is slightly worse .) The model is thus not highly optimized , but fairly standard .",Method,Algorithm,Use,Graded Word Sense Assignmen,https://aclanthology.org/D09-1046.pdf
"( 6 ) We experimentally test our M method in the context of the HOO shared task . The HOO test data consists of text fragments from NLP papers together with manually - created gold - standard corrections ( see ( Dale and Kilgarriff , 2011 ) for details ). We test our method by re - scoring the best runs of the participating teams in the HOO shared task with our M scorer and comparing the scores with the official HOO scorer , which simply uses GNU wdiff to extract system edits . We obtain each system ’ s output and segment it at the sentence level according to the gold standard sentence segmentation . The source sentences , system hypotheses , and corrections are tokenized using the Penn Treebank standard ( Marcus et al ., 1993 ).",Method,Algorithm,Use,Better Evaluation for Grammatical Error Correction,https://aclanthology.org/N12-1067.pdf
"We have developed a first prototype of the system which uses simulated data to produce handover reports . This runs on standard desktop PCs . For our second prototype , which is currently being developed , we port the NLG algorithm onto a GETAC Z710 tablet which has been chosen for it ’ s robustness , capacitative touch screen , and long battery life ( Figure 2 ). Our research also includes the establishment of a connection between the tablet and sensors , the recording of the incoming data stream and the development of an interface for the tablet , which can be used by the CFR to enter observations and actions taken or any other useful information . At the ENLG workshop we will present our first hardware prototype alongside the desktop computer version , highlighting the challenges that the project faces in developing a handover report generator for pre - hospital care .",Method,Algorithm,Use,Rapid prototyping and performance evaluation of MEC-based applications,https://arxiv.org/abs/2203.13511
"We use two machine learning methods in this section . They are maximum entropy method ( ME ) ( Beger et al . 96 ) and support vector machine ( SVM ) ( cristianini00 ) , both of which have been shown to be quite effective in natural language processing . The task of a machine learning method is to make a classifier that can decide whether a response is paraphrasable by te - hoshii or not . A response X is tagged possible if it is paraphrasable Given training data , a machine learning method produces a classifier that outputs possible or impossible according to a given feature vector .",Method,Algorithm,Use,Tuning Support Vector Machines for Biomedical Named Entity Recognition,https://aclanthology.org/W02-0301.pdf
"The output layer is a SoftMax classifier that predicts , after the “ GO ” symbol is read , one of the following three labels : 1 , if a word is to be retained in the compression , 0 if a word is to be deleted , or EOS , which is the output label used for the “ GO ” input and the end - of - sentence final period . Input representation : In the simplest implementation , that we call LSTM , the input layer has 259 dimensions . The first 256 contain the embedding - vector representation of the current in put word , pre - trained using the Skipgram model ( Mikolov et al ., 2013 ). The final three dimensions contain a one - hot - spot representation of the goldstandard label of the previous word ( during training ), or the generated label of the previous word ( during decoding ). For the LSTM + PAR architecture we first parse the input sentence , and then we provide as input , for each input word , the embedding - vector representation of that word and its parent word in the dependency tree .",Method,Algorithm,Use,Sentence Compression by Deletion with LSTMs,https://aclanthology.org/D15-1042.pdf
"In ( Bunt , 2006 ); ( Bunt and Girard , 2005 ) a dimension in dialogue act analysis is defined as an aspect ofparticipating in dialogue which can be addressed : The independence of dimensions , required by this definition , has the effect that an utterance may have a function in one dimension independent of the functions that it may have in other dimensions , and helps to explain why utterances may have multiple functions . Moreover , it leads to more manageable and more adaptable annotation schemas ( compared to , for instance , DAMSL and its derivatives ), since it allows annotators to leave out certain dimensions that they are not interested in , or to extend the schema with additional dimensions ; and it allows restricting or modifying the set of tags in a particular dimension without affecting the rest of the schema . Based on the above definition and extensive theoretical and empirical studies , 10 dimensions are defined in the DIT ++ dialogue act annotation scheme : the domain or task / activity ( Task ); feedback on the processing of previous utterances by the speaker ( Auto - feedback ) or by other interlocutors ( Allofeedback ); managing difficulties in the speaker ’ s utterance production ( Own - Communication Management , OCM ) or that of other interlocutors ( Partner Communication Management , PCM ); the speaker ’ s need for time to continue the dialogue ( Time Management ); establishing and maintaining contact ( Contact Management ); the allocation of the next turn ( Turn Management ); the way the speaker is planning to structure the dialogue ( Dialogue Structuring ); and attention for social aspects of the interaction ( Social Obligations Management , SOM ). This paper investigates the independence of these ten dimensions . In Section 2 we discuss the notion of independence of dimensions and how it can be tested .",Method,Algorithm,Use,Individual‐vs. culture‐level dimensions of individualism and collectivism: Effects on preferred conversational styles,https://www.tandfonline.com/doi/abs/10.1080/03637759609376373
"The file format was also fixed for the plain spreadsheet one , keeping into consideration the discomfort faced by the linguists and data entry persons with the XML data format . The latest size of the lexicon is 37 , 000 root words with their parts of speech category specified . Wherever more than one category is possible , multiple categories have been entered with the comma as the separator . The Nepali POS Tagset designed in the beginning consisted of 112 tags . These tags were used to manually and semi - automatically annotate the written corpus as well . Experiences , however , showed that error rates of annotation could be much higher when the size of the tagset was a big one , the reason primarily being the chances of assigning incorrect tags to the words out of confusion while manually annotating the the training data itself .",Method,Algorithm,Use,Towards Building Advanced Natural Language Applications - An Overview of the Existing Primary Resources and Applications in Nepali,https://aclanthology.org/W09-3424.pdf
"However , the PMI is known to be sensitive to low count words and bigrams , overemphasising them over high frequency words . To account for this , we express the mutual information of a word bigram by means of Lexicographer ’ s Mutual Information ( LMI ). The LMI , introduced by Kilgarriff et al . ( 2004 ), offers an advantage to Pointwise Mutual Information ( PMI ), as the scores are multiplied by the bigram frequency , boosting more frequent combinations of word ( w ) and context ( c ). We compute the LMI over a corpus of positive , respectively negative tweets , in order to obtain positive ( LMIpos ) and negative ( LMIneg ) bigram scores .",Method,Algorithm,Use,The phraseological dimension in interlanguage complexity research,https://journals.sagepub.com/doi/pdf/10.1177/0267658317694221
"BLEU should be calculated on a large test set with multiple reference texts . We used BLEU - 4 ( that is , BLEU calculated using n - grams of size up to n = 4 ) because this version of BLEU is the main metric used in recent NIST Machine Translation evaluations ( and indeed seems to have become a standard in the MT community ). We also used the NIST MT evaluation score ( Doddington 2002 ); this is an adaptation of BLEU which gives more weight to less frequent n - grams which are assumed to be more informative . There are several different ROUGE metrics . The simplest is ROUGE - N , which computes the highest proportion in any reference text of n - grams of length N that are matched by the generated text .",Method,Algorithm,Use,Comparing Automatic and Human Evaluation of NLG Systems,https://aclanthology.org/E06-1040.pdf
"We have used a Bengali news corpus ( Ekbal and Bandyopadhyay , 2008 ) developed from the webarchives of a widely read Bengali newspaper . A portion of the Bengali news corpus containing 1500 sentences have been POS tagged using a Maximum Entropy based POS tagger ( Ekbal et al ., 2008 ). The POS tagger was developed with a tagset of 26 POS tags , defined for the Indian languages . The POS tagger demonstrated an accuracy of 88 . 2 %. We have also developed a rulebased chunker to chunk the POS tagged data with an overall accuracy of 89 . 4 %.",Method,Algorithm,Use,Bengali Verb Subcategorization Frame Acquisition - A Baseline Model,https://aclanthology.org/W09-3411.pdf
"Therefore , we suspect that DMV training assigns an increased amount of probability mass to dependency paths along structures which are truly related to these relations . We used the DMV implementation from Cohen and Smith ( 2009 ) 4 . For the supervised Nivre arc - eager parser we used MALT ( Nivre et al ., 2007 ) with a pre - trained Penn Treebank ( Marcus et al ., 1993 ) model . As a baseline , we tested left branching parses i . e . dependency trees solely consisting of head - todependent edges from the right to the left .",Method,Algorithm,Use,Unsupervised Parsing for Generating Surface-Based Relation Extraction Patterns,https://aclanthology.org/E14-4020.pdf
", ( p ,,,, r ,,,)} be the set of such problem - reply pairs from across threads in the discussion forum . We are interested in finding a subset C ' of C such that most of the pairs in C ' are problem - solution pairs , and most of those in C − C ' are not so . In short , we would like to find problemsolution pairs from C such that the F - measure for solution identification is maximized . Central to our approach is the assumption of lexical correlation between the problem and solution texts . At the word level , this translates to assuming that there exist word pairs such that the presence of the first word in the problem part predicts the presence / absence of the second word in the solution part well .",Method,Algorithm,Use,Fast Approximation Algorithms for the Knapsack and Sum of Subset Problems,https://dl.acm.org/doi/pdf/10.1145/321906.321909
"We conclude this paper with a discussion of the experimental methodology and an outlook . Current survey articles cover the spectrum of recent methods and results for biomedical named entity recognition and identification ( Cohen and Hersh , 2005 ; Leser and Hakenberg , 2005 ). A recent assessment of named entity recognition and identification was done during the BioCreAtIvE 2 evaluation . Official results will be available in April 2007 . Naturally , a number of systems proposed before are highly related to the method presented in this paper .",Method,Algorithm,Use,Licensed Spectrum Sharing Schemes for Mobile Operators: A Survey and Outlook,https://ieeexplore.ieee.org/abstract/document/7500126
"( 2006 ) presented a probabilistic model for taxonomy induction which considers as features paths in parse trees between related taxonomy nodes . They show that the best performing taxonomy was the one adding 30 , 000 hyponyms to WordNet . We created an entailment rule for each new hyponym added to WordNet by their algorithm . LCC ’ s extended WordNet ( XWN & apos ;°): In ( Moldovan and Rus , 2001 ) WordNet glosses were transformed into logical form axioms . From this representation we created a rule e ’ ==& gt ;- e for each e0 in the gloss which was tagged as referring to the same entity as e . CBC : A knowledgebase of labeled clusters generated by the statistical clustering and labeling algorithms in ( Pantel and Lin , 2002 ; Pantel and Ravichandran , 2004 ) .",Method,Algorithm,Use,A Metric-based Framework for Automatic Taxonomy Induction,https://aclanthology.org/P09-1031.pdf
"We use maximum likelihood estimators ( MLE ) for estimating the parameters ( p , Oz ). The MLEs for Bernoulli and MVN parameters have analytical solutions . Dirichlet parameters were estimated using an estimation method proposed and implemented by Tom Minka . We experiment with three model setups : Supervised , semi - supervised , and unsupervised . In the supervised setup we use the training data described in Section 3 . 1 for parameter estimation and then use thus fitted models to classify the tuning and test dataset .",Method,Algorithm,Use,A Measurement Error Approach for Modeling Consumer Risk Preference,https://pubsonline.informs.org/doi/abs/10.1287/mnsc.31.1.1
"To tag a training window w of a training term t with ATTW and ROUGE - W , we obtain a set Ct of definitions of t from encyclopedias . Stop - words , punctuation , and non - alphanumeric characters are removed from Ct and w , and a stemmer is applied ; the testing windows undergo the same preprocessing . For each definition d E Ct , we find the longest common word subsequence of w and d . If w is the word sequence ( A , B , F , C , D , E ) and d = ( A , B , E , C , G , D ), the longest common subsequence is ( A , B , C , D ). The longest common subsequence is divided into consecutive matches , producing in our example ( A , B | C | D ). We then compute the following score ( weighted longest common subsequence ), where m is the number of consecutive matches , ki is the length of the i - th consecutive match , and f is a weighting function .",Method,Algorithm,Use,Finding Short Definitions of Terms on Web Pages,https://aclanthology.org/D09-1132.pdf
"TER is an error metric and it gives an edit ratio ( often referred to as edit rate or error rate ) in terms of how much editing is required to convert a sentence into another with respect to the length of the first sentence . Allowable edit operations include insert , delete , substitute and shift . We use the TER metric ( using tercom - 7 . 251 ) to find the edit rate between a test sentence and the TM reference sentences . Simard and Fujita ( 2012 ) first proposed the use of MT evaluation metrics as similarity functions in implementing TM functionality . They experimented with several MT evaluation metrics , viz .",Method,Algorithm,Use,A Unified View of Performance Metrics: Translating Threshold Choice into Expected Classification Loss,https://www.jmlr.org/papers/volume13/hernandez-orallo12a/hernandez-orallo12a.pdf
"Furthermore , they have been shown to model quite well the semantic composition of short phrases via simple vector addition ( Mikolov et al ., 2013b ). To build a vector for a sentence , we simply sum the distributed vectors of the individual words . For both representations , we remove the stopwords before building the vectors . To compute the similarity between two sentences , we compute the cosine similarity between their corresponding vectors . Semantic textual similarity ( STS ): Following on the work of Boltuˇzi ´ c and ˇSnajder ( 2014 ), we use an off - the - shelf STS system developed by ˇSari ´ c et al .",Method,Algorithm,Use,From Paraphrase Database to Compositional Paraphrase Model and Back,https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00143/43285/From-Paraphrase-Database-to-Compositional
"We add a full stop ourselves to avoid them being connected with the first sentence . For Chinese , we split sentences according to ending punctuation marks , while for other nine languages , the full stop “.” could have other functions . We adopt machine learning method . After some experiments , we choose Support Vector Machine model for English and French , Naïve Bayes model for other 7 languages . We add ICTCLAS word segmentation to Chinese to make all languages have the same word separator .",Method,Algorithm,Use,A framework for authorship identification of online messages: Writing-style features and classification techniques,https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.20316
"Using two different sets of morpho - syntactic features results in more effective models , as they create a kind of agreement for a given word in case of match . Concerning the PCFG model , grammars , tree binarization and the different tree representations are created with our own scripts , while entity tree parsing is performed with the chart parsing algorithm described in ( Johnson , 1998 ). All results are expressed in terms of Slot Error Rate ( SER ) ( Makhoul et al ., 1999 ) which has a similar definition of word error rate for ASR systems , with the difference that substitution errors are split in three types : i ) correct entity type with wrong segmentation ; ii ) wrong entity type with correct segmentation ; iii ) wrong entity type with wrong segmentation ; here , i ) and ii ) are given half points , while iii ), as well as insertion and deletion errors , are given full points . Moreover , results are given using the well known F1 measure , defined as a function of precision and recall . In this section we provide evaluations of the models described in this work , based on combination of CRF and PCFG and using different tree representations of named entity trees .",Method,Algorithm,Use,Models Cascade for Tree-Structured Named Entity Detection,https://aclanthology.org/I11-1142.pdf
"Evaluation results using different alignment methods based on the same data sets are given in Tables 5 and 7 . The system built based on GIZA ++/ Moses pipeline as a baseline system is given in Table 5 . We also show the evaluation results obtained by the WAT 2015 automatic evaluation in Table 6 and 8 . The results in Table 7 and 8 show that there are no significant differences among the evaluation results based on different versions of Moses , different Anymalign timeouts or different versions of Cutnalign . However , the training times changed considerably depending on the timeouts for Anymalign .",Method,Algorithm,Use,Better Alignments = Better Translations?,https://repository.upenn.edu/grasp_papers/42/
"Especially when using bag - ofwords term weighting , such as in our evaluation , information on what is not relevant to the query only introduces noise . Thus , we select the most noisy field of the query to test whether the application of our hypotheses indeed results in the reduction of noise . During indexing , we remove stopwords , and stem the collections and the queries , using Porter ’ s stemming algorithm . We use the Terrier IR platform , and apply five different weighting schemes to match query terms to document descriptors . In IR , term weighting schemes estimate the relevance of a document for a query , as : , where is a term in , is the query term weight , and is the weight of document for term .",Method,Algorithm,Use,Examining the Content Load of Part of Speech Blocks for Information Retrieval,https://aclanthology.org/P06-2069.pdf
"Klein - Braley ( 1984 ) performs a linear regression analysis with only two difficulty indicators – average sentence length and type - token ratio – obtaining good results for her target group . Eckes ( 2011 ) intend to calibrate C - test difficulty using a Rasch model in order to compare different C - tests and build a test pool . Kamimoto ( 1993 ) was the first to perform classical item analysis on the gap level . He created a tailored C - test that only contains selected gaps in order to better discriminate between the students . However , the gap selection is based on previous test results instead of specific gap features and thus cannot be applied on new tests .",Method,Algorithm,Use,A survey of research on the C-Test1,https://journals.sagepub.com/doi/abs/10.1177/026553228400100202?journalCode=ltja
"A few observations we made while working on blog dataset were : Much of the information present in telegraph . co . uk the blog ( s ) were factual , most of the opinions expressed were either in comparison format or negatively orientated . In this subsection , we explain the method used for evaluating our approach . We hired three human annotators for this task and calculation of their mutual agreement is done using Cohen ’ s Kappa measurement . Validation task was divided into three basic steps 2 . Modifier Identification : After step 1 , they were asked to mark and decide the orientation ( positive or negative ) for all the modifier words ( adjectives , adverbs and verbs ) from the text .",Method,Algorithm,Use,Entity Centric Opinion Mining from Blogs,https://aclanthology.org/W12-5306.pdf
"We replaced these ‘ correct answers ’ with their explicit names . We also removed zeros in quoted sentences because they are quite different from other sentences . In addition , we decided to use the output of ChaSen 2 . 2 . 9 and CaboCha 0 . 34 instead of the morphological information and the dependency information provided by the Kyoto Corpus since classification of the joshi ( particles ) in the Corpus was not satisfactory for our purpose . Since CaboCha was trained by Kyoto Corpus 3 . 0 , CaboCha ’ s dependency output is very similar to that of the Corpus . In this paper , we combine heuristic ranking rules and machine learning .",Method,Algorithm,Use,Japanese Zero Pronoun Resolution based on Ranking Rules and Machine Learning,https://aclanthology.org/W03-1024.pdf
"Table 1 gives some details about this training data . We use ROUGE as a metric to maximize because it is also used in DUC and TAC . However , it should be noted that any automatic metric could be used instead of ROUGE . In particular we use ROUGE 1 ( R - 1 ), ROUGE 2 ( R - 2 ) and ROUGE SU4 ( R - SU4 ). R - 1 and R - 2 compute the number give detail about the number of documents ( descriptions ) for each place , number of sentences for each place and document ( description ) and the lengths of the sentences .",Method,Algorithm,Use,Recent automatic text summarization techniques: a survey,https://link.springer.com/article/10.1007/s10462-016-9475-9
"The probability of each cluster being in each state depends on the sum of the biases involved . Figure 1 shows that the mixing rate of the sampling process is improved by using Swendsen - Wang allowing us to find accurate marginals for a single position in a couple of seconds . 2URL : Loopy Belief Propagation In order to perform very rapid ( approximate ) inference we used the loopy belief propagation ( BP ) algorithm [ 9 ] and the results are examined in Section 4 . This algorithm is similar to an influence function [ 10 ], as often used by Go programmers to segment the board into Black and White territory and for this reason is laid out below . For each board vertex j E N , create a data structure called a node containing :",Method,Algorithm,Use,Adaptive Cluster Sampling,https://www.tandfonline.com/doi/abs/10.1080/01621459.1990.10474975
"We refer to this problem as selective labeling , in contrast to conventional random labeling . To achieve the goal of selective labeling , it is crucial to consider the out - of - sample error of a specific learner . We choose Laplacian Regularized Least Squares ( LapRLS ) as the learner [ 4 ] because it is a l_CITE_ state - the - art semi - supervised learning method , and takes many linear regression methods as special cases ( e . g ., ridge regression [ 15 ]). We derive a deterministic out - of - sample error bound for LapRLS trained on subsampled data , which suggests to select the data points to label by minimizing this upper bound . The resulting selective labeling method is a combinatorial optimization problem .",Method,Algorithm,Use,Selective Labeling via Error Bound Minimization,https://proceedings.neurips.cc/paper/2012/hash/045117b0e0a11a242b9765e79cbf113f-Abstract.html
"SVMs have since been successfully applied on many tasks but primarily in the areas of data mining and pattern classification . With the present study we explore the feasibility and usefulness of one - class SVM classification [ 5 ] for tasks faced by AIBO robots within the legged league environment of RoboCup [ 6 ]. We focus on two particularly critical issues : detection of objects based on ∗ correct colour classification and detection of robot - to - robot collisions . Both issues seemed not to be sufficiently solved and implemented by the teams of RoboCup2002 and caused significant deterioration in the quality of play even in the world - best teams of that league . The article has five more sections addressing the environment and tasks , the methods , followed by the experiments and applications for colour classification and collision detection , respectively .",Method,Algorithm,Use,A Comprehensive Survey on Support Vector Machine in Data Mining Tasks: Applications & Challenges,https://d1wqtxts1xzle7.cloudfront.net/53937368/A_Comprehensive_Survey_on_Support_Vector_Machine_in_Data_mining_applications_and_challenges-libre.pdf?1500652518=&response-content-disposition=inline%3B+filename%3DA_Comprehensive_Survey_on_Support_Vector.pdf&Expires=1686156490&Signature=MUynF3mZwB04QT8gJz0LvHUrscM9UXxacG0m9UIxQtN~pEEc6BRMzOff4VKLgvy8aZn505FB6u8gAbQC0xJNw1jSRVIWHHMjArwouUSTkRLvgnXXf0d6wTe9TBAl3A5TkZK-g0tNdZJ7ca-yzkn8uDYz0TtLV7PwBRk4hlZIGB-a75loaEw5UJJL4UO9mgwvsCUgUIHepU~PI3qfFgvkBkD50T3UuNzopTlisd0-W8ysYKzq-t8wLWWCPH3wz2eGgQfTfAX5M7HNvHH-BYmPQGrQNtFWjYPAhkOJrp~U-Vx91aNXnj4ln7vfl8Ghb12hLy~Fjctn5uNNvfwpdD0egw__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA
"We have assessed the ability of the ADIOS model to deal with novel inputs by training it on the CHILDES collection and then subjecting it to a grammaticality judgment test , in the form of multiple choice questions used in English as Second Language ( ESL ) classes . The particular test ( ) has been administered to more than 10 , 000 people in the G ¨ oteborg ( Sweden ) education system as a diagnostic tool when assessing students on upper secondary levels ( that is , children who typically had 9 years of school , but only 6 - 7 years of English ; a test designed for assessing proficiency of younger subjects in their native language would be more suitable , but is not available ). The test consists of 100 three - choice questions ; a score lower than 50 % is considered pre - intermediate , 50 %− 70 % intermediate , and a score greater than 70 % – advanced , with 65 % being the average score for the population mentioned . For each of the three choices in a given question , our algorithm provided a grammaticality score .",Method,Algorithm,Use,Unsupervised Context Sensitive Language Acquisition from a Large Corpus,https://proceedings.neurips.cc/paper/2003/hash/250413d2982f1f83aa62a3a323cd2a87-Abstract.html
"For continuous data , we use the hierarchical component analysis for modeling handwritten digits ( ). This dataset contains 3823 handwritten digits as a training set and",Method,Algorithm,Use,Variational Inference for the Nested Chinese Restaurant Process,https://proceedings.neurips.cc/paper/2009/hash/ca46c1b9512a7a8315fa3c5a946e8265-Abstract.html
"Similar results were obtained for both larger and smaller training sample sizes . For the UCI experiments , the results are very similar to the synthetic networks , showing good results again for the convex EM relaxation . Finally , we conducted additional experiments on three real world Bayesian networks : Alarm , Cancer and Asian ( downloaded from ). We picked one well connected node from each model to serve as the hidden variable , and generated data by sampling from the models . Table 1 shows the experimental results for these three Bayesian networks .",Method,Algorithm,Use,Isolation Forest,https://ieeexplore.ieee.org/abstract/document/4781136
"For improving single - MLP performance , one might employ two layers of hidden nodes ( rather than one large hidden layer ; see the letter problem below ), which increases nB while reducing nA , rendering Algorithm 2 less efficient ( i . e ., slower ). Alternatively , one might introduce direct connections between the input and terminal output layers , which increases CA , the column size of Ak , retaining nice parameter separability . Yet another approach ( if applicable ) is to use a “ comple ∗ The floating - point operation counts were measured by using PAPI ( Performance Application Programming Interface ); see mentary mixtures of Z MLP - experts ” model ( or a neuro - fuzzy modular network ) that combines Z smaller - size MLPs complementarily ; the associated residual vector to be minimized becomes : r ( 6 ) = y ( 6 ) − t = [ EZi = 1 wioi ] − t , where scalar wi , the ith output of the integrating unit , is the ith ( normalized ) mixing proportion assigned to the outputs ( F - vector oi ) of expert - MLP i . Note that each expert learns “ residuals ” rather than “ desired outputs ” ( unlike in the committee method below ) in the sense that only the final combined outputs y must come close to the desired ones t . That is , there are strong coupling effects ( see page 80 in [ 5 ]) among all experts ; hence , it is crucial to consider the global Hessian across all experts to optimize them simultaneously [ 7 ].",Method,Algorithm,Use,Iterative Scaled Trust-Region Learning in Krylov Subspaces via Pearlmutter's Implicit Sparse Hessian,https://proceedings.neurips.cc/paper/2003/hash/6ee69d3769e832ec77c9584e0b7ba112-Abstract.html
The number of hidden neurons in the MLP network was 40 . The learning algorithm was run for 2000 iterations . ferent approximations plotted against reference values evaluated by sampling . The left subfigure shows the values from experiments using the proposed approximation and the right subfigure from experiments using the Taylor approximation . Fig .,Method,Algorithm,Use,Learning a Self-Expressive Network for Subspace Clustering,https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_a_Self-Expressive_Network_for_Subspace_Clustering_CVPR_2021_paper.html?ref=https://githubhelp.com
"We assume that we have already completed 50 iterations of an optimization of the same model on the related USPS digits task . The USPS data is only 1 / 6 the size of MNIST and each image contains 16 x 16 pixels , so it is considerably cheaper to evaluate . Convolutional neural networks on pixels We applied convolutional neural networks ( CNNs ) to the Street View House Numbers ( SVHN ) [ 21 ] dataset and bootstrapped from a previous run of Bayesian optimization using the same model trained on CIFAR - 10 [ 22 , 6 ]. At the time , this model represented the state - of - the - art . The SVHN dataset has the same input dimension as CIFAR - 10 , but is 10 times larger .",Method,Algorithm,Use,Multi-Task Bayesian Optimization,https://proceedings.neurips.cc/paper/2013/hash/f33ba15effa5c10e873bf3842afb46a6-Abstract.html
"( 6 ) does include a sum over distinct pairs of units , as well as a sum over coupled triplets of units , such triplets are excluded by the bipartite structure of the RBM . However , coupled quadruplets do contribute to the fourth - order term and therefore fourth - and higher - order approximations require much more expensive computations [ 21 ], though it is possible to utilize adaptive procedures [ 19 ]. To evaluate the performance of the proposed deterministic EMF RBM training algorithm , we perform a number of numerical experiments over two separate datasets and compare these results with both CD - 1 and PCD . We first use the MNIST dataset of labeled handwritten digit images [ 25 ]. The dataset is split between 60 000 training images and 10 000 test images .",Method,Algorithm,Use,Training Restricted Boltzmann Machine via the ￼Thouless-Anderson-Palmer free energy,https://proceedings.neurips.cc/paper/2015/hash/13f3cf8c531952d72e5847c4183e6910-Abstract.html
"Our goal is not to reproduce the success of deep learning in face verification [ 7 , 14 ], but to stress the importance of robust training and to compare the proposed Euc - DRT objective with popular alternatives . Note also that it is difficult to compare with deep learning methods when training sets are proprietary [ 12 – 14 ]. We adopt the experimental framework used in [ 2 ], and train a deep network on the WDRef dataset , where each face is described using a high dimensional LBP feature [ 3 ] ( available at ) that is reduced to a 5000 - dimensional feature using PCA . The WDRef dataset is significantly smaller than the proprietary datasets typical of deep learning , such as the 4 . 4 million labeled faces from 4030 individuals in [ 14 ], or the 202 , 599 labeled faces from 10 , 177 individuals in [ 12 ]. It contains 2 , 995 subjects with about 20 samples per subject .",Method,Algorithm,Use,Discriminative Robust Transformation Learning,https://proceedings.neurips.cc/paper/2015/hash/d554f7bb7be44a7267068a7df88ddd20-Abstract.html
"For a fair comparison , we use the same parameter ranges and fully connected layers for our network ( c . f . the supplementary material for more details ), and adopt results of GAN and mode regularized GAN ( Reg - GAN ) from [ 5 ]. For evaluation , we first train a simple , yet effective 3 - layer convolutional nets that can obtain 0 . 65 % error on MNIST testing set , and then employ it to predict the label probabilities and compute MODE scores for generated samples . Fig . 3 ( left ) shows the distributions of MODE scores obtained by three models .",Method,Algorithm,Use,Dual Discriminator Generative Adversarial Nets,https://proceedings.neurips.cc/paper/2017/hash/e60e81c4cbe5171cd654662d9887aec2-Abstract.html
"The Hessian of a Gaussian distribution is then given by the expression : This expression is then used to learn the optimal local metric . We compare the performance of our method ( GLML — Generative Local Metric Learning ) with recent metric learning discriminative methods which report state - of - the - art performance on a number of datasets . These include Information - Theoretic Metric Learning ( ITML ) [ 3 ], Boost Metric ( BM ) [ 21 ], and Largest Margin Nearest Neighbor ( LMNN ) [ 26 ]. We used the implementations downloaded from the corresponding authors ’ websites . We also compare with a local metric given by the Fisher kernel [ 12 ] assuming a single Gaussian for the generative model and using the location parameter to derive the Fisher information matrix .",Method,Algorithm,Use,Generative Local Metric Learning for Nearest Neighbor Classification,https://proceedings.neurips.cc/paper/2010/hash/01386bd6d8e091c2ab4c7c7de644d37b-Abstract.html
"This part tests the above three algorithms with synthetic data . To make a fair comparison , some implementation details are clarified as follows : ( 1 ) Since domain transformations are not considered in Li ’ s work , we assume the synthetic data are well aligned . ( 2 ) To eliminate the influence of different optimization methods , RASL is implemented with the following four optimization methods : APG ( Accelerated Proximal Gradient ), APGP ( Accelerated Proximal Gradient with partial SVDs ), ALM ( Augmented Lagrange Multiplier ) and IALM ( Inexact Augmented Lagrange Multiplier ) . Moreover , since RASL is applied to one mode of the tensor , to make it more competitive , we apply RASL to each mode of the tensor and take the mode that has the minimal reconstruction error . For synthetic data , we first randomly generate two data tensors : ( 1 ) a pure low - rank tensor Lo ∈ R50 × 50 × 50 whose rank is ( 10 , 10 , 10 ); ( 2 ) an error tensor E ∈ R50 × 50 × 50 in which only a fraction c of entries are non - zero ( To ensure the error to be sparse , the maximal value of c is set to 40 %).",Method,Algorithm,Use,Simultaneous Rectification and Alignment via Robust Recovery of Low-rank Tensors,https://proceedings.neurips.cc/paper/2013/hash/1aa48fc4880bb0c9b8a3bf979d3b917e-Abstract.html
"In our case , the level - set projection is a convex quadratic problem with ` p - norm constraints and can again be approximated by successive second - order Taylor expansions . In this section we study non - sparse MKL in terms of efficiency and accuracy . We apply the method of [ 21 ] for ` 1 - norm results as it is contained as a special case of our cutting plane strategy . We write B ,,,- norm MKL for a regular SVM with the unweighted - sum kernel K = Em Km . We demonstrate the efficiency of our implementations of non - sparse MKL .",Method,Algorithm,Use,Fast Approximation Algorithms for a Class of Non-convex QCQP Problems Using First-Order Methods,https://ieeexplore.ieee.org/abstract/document/7891594
"Algorithm 1 Blocked Gibbs sampler for GP - modulated renewal process on the interval [ 0 , T ] Input : Set of event times G , set of thinned times ˜ Gprev and l instantiated at G U ˜ Gprev . The gamma prior on λ ∗ is conjugate to the Poisson , resulting in a gamma posterior . We resampled the GP hyperparameters using slice sampling [ 23 ] , while parameters of the hazard function were updated using Metropolis - Hastings moves along with equation ( 8 ). The inferential bottleneck in our model is the Gaussian process : sampling a GP on a set of points is , in the worst case , cubic in the size of that set . In our model , each iteration sees on average | G |+ 2 | E | values of the GP , where | G | is the number of observations and | E | is the average number of points sampled from the subordinating Poisson process .",Method,Algorithm,Use,Gaussian process modulated renewal processes,https://proceedings.neurips.cc/paper/2011/hash/ff49cc40a8890e6a60f40ff3026d2730-Abstract.html
"The Hessian of a Gaussian distribution is then given by the expression : This expression is then used to learn the optimal local metric . We compare the performance of our method ( GLML — Generative Local Metric Learning ) with recent metric learning discriminative methods which report state - of - the - art performance on a number of datasets . These include Information - Theoretic Metric Learning ( ITML ) [ 3 ], Boost Metric ( BM ) [ 21 ], and Largest Margin Nearest Neighbor ( LMNN ) [ 26 ]. We used the implementations downloaded from the corresponding authors ’ websites . We also compare with a local metric given by the Fisher kernel [ 12 ] assuming a single Gaussian for the generative model and using the location parameter to derive the Fisher information matrix .",Method,Algorithm,Use,Generative Local Metric Learning for Nearest Neighbor Classification,https://proceedings.neurips.cc/paper/2010/hash/01386bd6d8e091c2ab4c7c7de644d37b-Abstract.html
"We also test our methods on Named Entity Recognition ( NER ) in CoNLL 2003 [ 46 ] and OntoNote 5 . 0 [ 20 ] datasets using the CNN from Strubell et al . [ 45 ]. Similar to Question Type , the model is too complex for our approaches . So we ( i ) only use 3 layers instead of 4 layers , ( ii ) reduce the number of filters from 300 to 100 , ( iii ) add 0 . 001 L2 regularization , ( iv ) make the 50 dimension word embedding from Collobert et al . [ 9 ] non - trainable .",Method,Algorithm,Use,Deep Active Learning for Named Entity Recognition,https://arxiv.org/abs/1707.05928
"The left column of Fig . 2 presents a screen from the annotation process , while the right column shows how we inform annotators about their mistakes . As an alternative to human annotators , we propose an automatic method to evaluate samples , which we find to correlate well with human evaluation : We apply the Inception model [ 20 ] to every generated image to get the conditional label distribution p ( y | x ). Images that contain meaningful objects should have a conditional label distribution p ( y | x ) with low entropy . Moreover , we expect the model to generate varied images , so the marginal f p ( y | x = G ( z )) dz should have high entropy .",Method,Algorithm,Use,Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question,https://proceedings.neurips.cc/paper/2015/hash/fb508ef074ee78a0e58c68be06d8a2eb-Abstract.html
"Each 6 - core processor is equipped with a three - level memory hierarchy as follows : ( i ) 64 KB of L1 cache for data and 512 KB of L2 cache that are private to each core , and ( ii ) 12 MB of L3 cache that is shared among the 6 cores . Each 6 - core processor is linked to a 32 GB memory bank with independent memory controllers leading to a total system memory of 256 GB ( 32 x 8 ) that can be globally addressed from each core . The four sockets are interconnected using HyperTransport - 3 technology . Datasets A variety of datasets were chosen for experimentation ; these are summarized in Table 1 . We consider four datasets : ( i ) NEWS20 contains about 20 , 000 UseNet postings from 20 newsgroups .",Method,Algorithm,Use,Dissecting GPU Memory Hierarchy Through Microbenchmarking,https://ieeexplore.ieee.org/abstract/document/7445236
"Figure 1 shows the “ Amari Index ” [ 1 ] of estimated W by three methods , at several factors a and sample sizes , with ten runs for every condition . In each run , the true mixing matrix was given by inverting W randomly generated from standard Gaussian and then row - normalized to have unit norms . The three methods were : 1 ) FastICA with the tanh nonlinearity , 2 ) Our method ( symmetric model ) without energy - dependence ( NoDep ) initialized by FastICA , and 3 ) Our full method ( symmetric model ) initialized by NoDep . NoDep was the same as the full method except that the off - diagonal elements of H was kept zero . Note that our two algorithms used exactly the same criterion for termination of algorithm , while FastICA used a different one .",Method,Algorithm,Use,Structural equations and divisive normalization for energy-dependent component analysis,https://proceedings.neurips.cc/paper/2011/hash/a89cf525e1d9f04d16ce31165e139a4b-Abstract.html
"Our variance measurement experiments in Table 1 includes a comparison to the estimator featured in [ 19 ], which we found to be much higher variance than the baseline RGE . In this section we empirically examine the variance properties of RV - RGEs and stochastic optimization for two real - data examples — a hierarchical Poisson GLM and a Bayesian neural network . surements were taken for λ values at three points during the optimization algorithm ( early , mid , late ). The parenthetical rows labeled “ MC abs ” denote the absolute value of the standard Monte Carlo reparameterization gradient estimator . The other rows compare estimators relative to the pure MC RGE variance — a value of 100 indicates equal variation L = 10 samples , a value of 1 indicates a 100 - fold decrease in variance ( lower is better ).",Method,Algorithm,Use,Reducing Reparameterization Gradient Variance,https://proceedings.neurips.cc/paper/2017/hash/325995af77a0e8b06d1204a171010b3a-Abstract.html
"On this data set , our method performs competitively with RVM and VRVM and much better than SVM ( specially in terms of sparseness ). To allow the comparisons , we chose , as in [ 20 ]. Table 3 also reports the numbers of errors achieved by the proposed method and by several state - of - the - art techniques on three well - known benchmark problems : the Pima Indians diabetes , the Leptograpsus crabs , and the Wisconsin breast cancer ( WBC ). For the WBC , we report average results over 30 random partitions ( 300 / 269 training / testing , as in [ 26 ]). All the inputs are normalized to zero mean and unit variance , and the kernel width was set to , for the Pima and crabs problems , and to for the WBC .",Method,Algorithm,Use,Adaptive sparseness for supervised learning,https://ieeexplore.ieee.org/abstract/document/1227989
"In this prior - free framework , we obtain competitive shape and illumination estimation results under a variety of models and lighting conditions , requiring fewer assumptions than competing methods . The generic viewpoint assumption ( GVA ) [ 5 , 9 , 21 , 22 ] postulates that what we see in the world is not seen from a special viewpoint , or lighting condition . Figure 1 demonstrates this idea with the famous Necker cube example . A three dimensional cube may be observed with two vertices or edges perfectly aligned , giving rise to a two dimensional interpretation . Another possibility is a view that exposes only one of the faces of the cube , giving rise to a square .",Method,Algorithm,Use,Shape and Illumination from Shading using the Generic Viewpoint Assumption,https://proceedings.neurips.cc/paper/2014/hash/7e7757b1e12abcb736ab9a754ffb617a-Abstract.html
"Specifically , we tested two settings in our experiments : For each of the settings we trained our dual - NMT algorithm for one week . We set the beam search size to be 2 in the middle translation process . All the hyperparameters in the experiments were set by cross validation . We used the BLEU score [ 8 ] as the evaluation metric , which are computed by the multi - bleu . perl script . Following the common practice , during testing we used beam search [ 12 ] with beam size of 12 for all the algorithms as in many previous works . We report the experimental results in this section .",Method,Algorithm,Use,Dual Learning for Machine Translation,https://proceedings.neurips.cc/paper_files/paper/2016/hash/5b69b9cb83065d403869739ae7f0995e-Abstract.html
"This is followed by a search in [ 0 , tr ], by interval nesting or by interpolation of the collected function and gradient values , e . g . with cubic splines . As the line search is only an auxiliary step within a larger iteration , it need not find an exact root of f ; it suffices to find a point ‘ sufficiently ’ close to a minimum . The Wolfe [ 21 ] conditions are a widely accepted formalization of this notion ; they consider t acceptable if it fulfills and interpolation ( ➄ , ➏ ), but receives unreliable , noisy function and gradient values . These are used to construct a GP posterior ( top .",Method,Algorithm,Use,Probabilistic Line Searches for Stochastic Optimization,https://proceedings.neurips.cc/paper/2015/hash/812b4ba287f5ee0bc9d43bbf5bbe87fb-Abstract.html
"At the end of the pruning step , we denote the resulting tree by T . The sketch . For each point xi E X the sketch stores the index of the leaf vi that contains it . In addition it stores the structure of the tree T , encoded using the Eulerian Tour Technique . Specifically , starting at the root , we traverse T in the Depth First Search ( DFS ) order . In each step , DFS either explores the child of the current node ( downward step ), or returns to the parent node ( upward step ).",Method,Algorithm,Use,Practical Data-Dependent Metric Compression with Provable Guarantees,https://proceedings.neurips.cc/paper/2017/hash/49b8b4f95f02e055801da3b4f58e28b7-Abstract.html
"The conventional HMM has a large number of covariance parameters because it has a 6 - D output variable ; whereas the CHMM architecture has two 3 - D output variables . In consequence , due to their larger dimensionality HMMs need much more training data than equivalent CHMMs before yielding good generalization results . Our second experiment was with a pedestrian video surveillance task ; the goal was first to recognize typical pedestrian behaviors in an open plaza ( e . g ., walk from A to 13 , run from C to D ), and second to recognize interactions between the pedestrians ( e . g ., person X greets person Y ). The task is to reliably and robustly detect and track the pedestrians in the scene . We use in this case 2 - D blob features for modeling each pedestrian .",Method,Algorithm,Use,Graphical Models for Recognizing Human Interactions,https://proceedings.neurips.cc/paper/1998/hash/3a20f62a0af1aa152670bab3c602feed-Abstract.html
"We record the average running time over 100 trials in Figure 2 and from the results we can see that on the classification problems above , our proposed coordinate descent method is much faster than the CVX solver which demonstrates the efficiency of our proposed method . Here we study a multi - task regression problem to learn the inverse dynamics of a seven degree - offreedom SARCOS anthropomorphic robot arm . The objective is to predict seven joint torques based on 21 input features , corresponding to seven joint positions , seven joint velocities and seven joint accelerations . So each task corresponds to the prediction of one torque and can be formulated as a regression problem . Each task has 2000 data points .",Method,Algorithm,Use,Heterogeneous-Neighborhood-based Multi-Task Local Learning Algorithms,https://proceedings.neurips.cc/paper/2013/hash/8f468c873a32bb0619eaeb2050ba45d1-Abstract.html
"The smoothness of the estimates is further indicating the viability of the approach , as the pitch estimates are frame - local . The algorithm was further evaluated on real room recordings that were also used in [ 17 ]. Two male speakers synchronously count in English and Spanish ( F3 = 16kHz ). The mixtures were degraded with noise ( SNR ∼ 20dB ). The filter length , the frame length , the order of the AR - process and the number of harmonics were set to L = 25 , T = 320 , p = 1 and K = 40 , respectively .",Method,Algorithm,Use,A Harmonic Excitation State-Space Approach to Blind Separation of Speech,https://proceedings.neurips.cc/paper/2004/hash/bbeb0c1b1fd44e392c7ce2fdbd137e87-Abstract.html
"This is naturally accomplished using our framework by computing [ a ∗ 1 ,. .. , a ∗ n ]& gt ; = arg maxαi & gt ; 0 f ( α ; K ) for fixed K = KLS ( G , σ , S ) and picking the sentences with the highest a ∗ i . We apply this method to the multi - document summarization task of DUC - 04 . We let Sij be the TF - IDF sentence similarity described by Lin & Bilmes [ 18 ], and let Qi = ( Ej Sij ) . State - of - theart systems , purpose - built for summarization , achieve around 0 . 39 in recall and F1 score [ 18 ].",Method,Algorithm,Use,LexPageRank: Prestige in Multi-Document Text Summarization,https://aclanthology.org/W04-3247.pdf
"As mentioned in Sec . 1 , one important contribution of our method is its ability to use arbitrary deep learning generative and classification models . For the generative model , we use the C - GAN [ 22 ] , and for the classification model we rely on the ResNet18 [ 15 ] and ResNetpa [ 16 ]. The architectures of the generator and authenticator networks , which are kept unchanged for all three datasets , can be found in the supplementary material . For training , we use Adadelta ( with learning rate = 1 . 0 , decay rate = 0 . 95 and epsilon = 1e − 8 ) for the Classifier ( C ), Adam ( with learning rate 0 . 0002 , and exponential decay rate 0 . 5 ) for the Generator ( G ) and SDG ( with learning rate 0 . 01 ) for the Authenticator ( A ).",Method,Algorithm,Use,A Bayesian Data Augmentation Approach for Learning Deep Models,https://proceedings.neurips.cc/paper/2017/hash/076023edc9187cf1ac1f1163470e479a-Abstract.html
"More precisely , we extracted more advanced text features instead of simple term frequency ( TF ) features . For the images representation , we extracted SURF descriptors [ 21 ] and constructed a codebook of 100 visual words using the k - means clustering . For the text representation , we extracted 200 dimensional continuous word - vectors using a neural network skip - gram architecture [ 22 ] . To convert this word representation into a fixed - length sentence representation , we constructed a codebook of 100 word - vectors using again k - means clustering . We note that a more elaborate approach to transform word to sentence or document features has recently been developed [ 23 ], and we are planning to explore this in the future .",Method,Algorithm,Use,A Novel Image Retrieval Based on Visual Words Integration of SIFT and SURF,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0157428
"Here we use them for evaluating ranking performance . We compare our method against SVM for ranking ( e . g . [ 4 , 6 ]) using the SVM - light package 2 and an efficient Gaussian process method ( the informative vector machine ) [ 7 ]. These datasets were originally designed for regression , thus the continuous target values for each dataset were discretized into five equal size bins . We use these bins to define our ranking constraints : all the datapoints with target value falling in the same bin were grouped together .",Method,Algorithm,Use,kernlab - An S4 package for kernel methods in R,https://research.wu.ac.at/en/publications/kernlab-an-s4-package-for-kernel-methods-in-r-14
"This representation enables us to train two logistic regression classifiers , both with small loss on the labeled data set , while satisfying two constraints to ensure feature decomposition and e - expandability . Our final classifier has the weight vector w = u + v . We refer to the resulting algorithm as CODA ( Cotraining for Domain Adaptation ), which can be stated concisely with the following optimization problem : The optimization is non - convex . However , as it is not particularly sensitive to initialization , we set u , v randomly and optimize with standard conjugate gradient descent . Due to space constraints we do not include a pseudo - code implementation of CODA . The implementation is essentially identical to that of SEDA ( Algorithm 1 ) where the above optimization problem is solved instead of eq .",Method,Algorithm,Use,Fairness Constraints: Mechanisms for Fair Classification,http://proceedings.mlr.press/v54/zafar17a.html
"Question Type ( QT ) [ 28 ]), which contains 1000 training examples and 500 testing examples . We use the CNN architecture proposed by Kim [ 22 ]. Like many other NLP tasks , the dataset is relatively small and this CNN classifier does not inject noise to inputs like the implementation of residual networks in CIFAR 100 , so this complicated model reaches 100 % training accuracy within a few epochs . To address this , we reduced the model complexity by ( i ) decreasing the number of filters from 128 to 64 , ( ii ) decreasing convolutional filter widths from 3 , 4 , 5 to 2 , 3 , 4 , ( iii ) adding L2 regularization with scale 0 . 01 , ( iv ) performing PCA to reduce the dimension of pre - trained word embedding from 300 to 50 and fixing the word embedding during training . Then , the proposed active bias methods perform better than other baselines in this smaller model .",Method,Algorithm,Use,BSNN: Towards Faster and Better Conversion of Artificial Neural Networks to Spiking Neural Networks with Bistable Neurons,https://arxiv.org/abs/2105.12917
"We draw problem instances from each domain by generating pairs of random initial states and goal conditions . The goal conditions specify block configurations involving all blocks in blocks worlds , and destinations for all packages in logistics worlds . Throughout , we use the domain - independent FF heuristic [ 13 ]. Each experiment specifies a planning domain and an initial policy and then iterates API until “ no more progress ” is made . We evaluate each policy on 1000 random problem instances , recording the success We use discount factor 1 and select large enough horizons to accurately rank most policies : 4xn for BW ( n ) and SBW ( n ), 6xn for SPW ( n ), 12xp for LW ( l , t , p ) and SLW ( l , c , t , p ).",Method,Algorithm,Use,Approximate Policy Iteration with a Policy Language Bias,https://proceedings.neurips.cc/paper/2003/hash/7cf64379eb6f29a4d25c4b6a2df713e4-Abstract.html
"The results from SGD - SD and SGD - WD confirm this finding while selecting uncertain examples can give us a similar or larger boost . Furthermore , we test the robustness of our methods by randomly reassigning the labels of 10 % of the images , and the results indicate that the SGD - WPV improves the performance of SGD - Scan even more while SGD - SD overfits the data seriously . We test a simple multi - class logistic regression on CIFAR 10 [ 24 ]. Images are down - sampled significantly to 32 × 32 × 3 , so many examples are difficult , even for humans . SGD - SPV and SGD - SE perform significantly better than SGD - Uni here , consistent with the idea that avoiding difficult examples increases robustness to outliers .",Method,Algorithm,Use,Using Pre-Training Can Improve Model Robustness and Uncertainty,https://proceedings.mlr.press/v97/hendrycks19a.html
"[ 9 ] we used an averaged perceptron trained for 10 epochs , for all the experiments . Test - time classification : Use the classifier trained in the previous step on the Reuters test set for language Y , using the word representations WY to represent the documents . We trained the following autoencoders : BAE - cr which uses reconstruction error based decoder training ( see Section 2 . 1 ) and BAE - tr which uses tree - based decoder training ( see Section 2 . 2 ). Models were trained for up to 20 epochs using the same data as described earlier . BAE - cr used mini - batch ( of size 20 ) stochastic gradient descent , while BAE - tr used regular stochastic gradient .",Method,Algorithm,Use,An Autoencoder Approach to Learning Bilingual Word Representations,https://proceedings.neurips.cc/paper/2014/hash/2bcab9d935d219641434683dd9d18a03-Abstract.html
"The task was to construct a network of I & F neurons that could recognize each of the 10 spoken words . Each of the 500 input files had been encoded in the form of 40 spike trains , with at most one spike per spike train 6 signaling onset , peak , or offset of activity in a particular frequency band . A network was presented in [ 8 ] that could solve this task with an error of 0 . 15 for recognizing the pattern “ one ”. No better result had been achieved by any competing networks constructed during a widely publicized internet competition [ 7 ]. The network constructed in [ 8 ] transformed the 40 input spike trains into linearly decaying input currents from 800 pools , each consisting of a “ large set of closely similar unsynchronized neurons ” [ 8 ].",Method,Algorithm,Use,A Model for Real-Time Computation in Generic Neural Microcircuits,https://proceedings.neurips.cc/paper/2002/hash/6211080fa89981f66b1a0c9d55c61d0f-Abstract.html
"The prevalence curves of each concomitant co - morbidity were modelled stratified for diabetes with fractional polynomials ( Software r Version 2 . 15 . 1 http :// cran . r - project . org , Paket mfp ) [ 29 , 30 ]. For each model the fit ( R2 ) was assessed . The intersection of the semi - maximum values and the prevalence curves were determined with the Ridders method ( Software r Version 2 . 15 . 1 , Paket pracma ) [ 31 ]. The interpolated age at the respective intersections was subsequently compared between persons with and without type 2 diabetes by calculating the difference .",Method,Algorithm,Use,"Prevalence, incidence and concomitant co-morbidities of type 2 diabetes mellitus in South Western Germany - a retrospective cohort and case control study in claims data of a large statutory health insurance",https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-015-2188-1
"To prevent positional effects on plant growth , all plates were randomized every 2 days . We set out to grow all genotypes simultaneously in three repeats , but due to germination issues with some seed batches , a total of 5 experiments have been performed to obtain three repeats for each genotype , with the exception of the cross ANTOE - da1 - 1 for which we could obtain results in one repeat . At 21 DAS , individual leaves ( cotyledons and rosette leaves ) were dissected at the base of the petiole and their area was measured with ImageJ v1 . 45 ( NIH ; ).",Method,Algorithm,Use,"GrowScreen-PaGe, a non-invasive, high-throughput phenotyping system based on germination paper to quantify crop phenotypic diversity and plasticity of root traits under varying nutrient supply",https://www.publish.csiro.au/FP/FP16128
"RH data recorded in 2007 were arranged in a matrix comprised by 432 observations ( time instants , in rows ) by 25 variables ( RH sensors , in columns ). This matrix was row - centered as described in [ 21 ]. Next , a principal components analysis ( PCA ) was carried out using the software SIMCA - P 10 . 0 ( ). The same analysis was repeated with sensor data recorded in 2008 with 409 , 312 observations and 2010 with 429 , 012 observations . Results from these three models were compared in order to check if the relationships among sensors were maintained year after year .",Method,Algorithm,Use,Long-Term Monitoring of Fresco Paintings in the Cathedral of Valencia (Spain) Through Humidity and Temperature Sensors in Various Locations for Preventive Conservation,https://www.mdpi.com/1424-8220/11/9/8685
"The score on this task was the mean response time in milliseconds across trials which contained matching pairs . Cronbach ’ s alpha for this task has previously been reported as 0 . 85 [ 11 ]. Visual memory : A visual memory test was administered , labelled ‘ pairs - matching ’ ( ), where participants were asked to memorize the positions of six card pairs , and then match them from memory while making as few errors as possible . Scores on the pairs - matching test are for the number of errors that each participant made ; therefore , higher scores reflect poorer cognitive function . The Pairs matching task had two versions : 3 - pair and 6 - pair .",Method,Algorithm,Use,Are Auditory and Visual Processing Deficits Related to Developmental Dyslexia?,https://onlinelibrary.wiley.com/doi/abs/10.1002/dys.1439
"For our analysis we used a slightly changed posterior parameter estimate Frontiers in Neuroscience | Brain Imaging Methods February 2015 | Volume 9 | Article 43 | 4 Arand et al . Parameter identifiability in DCM for fMRI θ ± 0 . 1 from model inversion as initial guesses . With real data , the easiest way to define start values is to use the connectivity priors as defined in SPM ( ). DCMs depend sensitively on their parameter values as models with circular connections start oscillating for certain parameter sets . Additionally , DCMs can diverge if the inhibitory self - connections are not strong enough to prevent run - away excitation ( Friston et al ., 2003 ).",Method,Algorithm,Use,"Heschl's Gyrus, Posterior Superior Temporal Gyrus, and Mid-Ventrolateral Prefrontal Cortex Have Different Roles in the Detection of Acoustic Changes",https://journals.physiology.org/doi/full/10.1152/jn.01083.2006
"DSS does a much better job than metilene in this respect , although informME is clearly the best method among the three to accomplish this goal . For this reason , we provide in the following a further assessment of the performance of informME and DSS when applied on real data . We used gene ontology ( GO ) enrichment analysis ( ) [ 44 ] to compare performance by evaluating the potential of informME to that of DSS for addressing a specific problem of interest to epigenetic biology : identifying biological processes that are significantly enriched in epigenetically dysregulated genes . By using GO enrichment analysis on gene lists of equal size formed by selecting genes with the largest detected methylation discordance at their promoters , we can remove the issue of sensitivity and specificity and focus on the ability of each method to produce biologically relevant results . It is important to note that the gene selection method used in [ 16 ] selects a gene by checking whether a statistic T , which counts the number of the top 2000 differentially methylated CpG sites in the gene , is above a threshold t = 4 .",Method,Algorithm,Use,An information-theoretic approach to the modeling and analysis of whole-genome bisulfite sequencing data,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2086-5
"( B ) Topology cartoon of AtPDF , free ( left ) or actinonin bound ( right ), in the same color code as ( A ). Actinonin ( represented by the yellow arrow ) binding to the ligand binding site allows the linkage of the two distinct b - sheets into one single b - sheet , by mimicking an additional b - strand . PDB sum ( ) was used . ( C ) 3 - D structure of AtPDF is represented showing the position of the residues discussed in the text , indicated in red . ( EPS ) Figure S2 Microcalorimetric titration of AtPDF with actinonin .",Method,Algorithm,Use,Trapping Conformational States Along Ligand-Binding Dynamics of Peptide Deformylase: The Impact of Induced Fit on Enzyme Catalysis,https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001066
"Exact implementations and specifications differ between pseudotime approaches particularly in the way “ similarity ” is defined . When applied to molecular data , pseudotime analysis typically captures some dominant mode of variation that corresponds to the continuous ( de ) activation of a set of biological pathways1 . Pseudotime analysis has gained particular popularity in the domain of single - cell gene expression analysis ( where each “ individual ” is now a single cell ) in which it has been applied to model the differentiation of single - cells2 – 9 ( a comprehensive catalogue of single - cell pseudotime algorithms can be obtained from ). Using advanced machine learning techniques , these methods can be applied to characterise complex , nonlinear behaviours , such as cell cycle , and modelling branching behaviours to allow , for example , the possibility of cell fate decision making and lineage reconstruction . However , these single - cell applications were predated b1y more general applications in modeling cancer progression 10 – 2 , as well as other progressive diseases1 - 16 Examples of such work provided early inspiration for single - cell pseudotime methods , e . g ., Monocle2 .",Method,Algorithm,Use,Uncovering pseudotemporal trajectories with covariates from single cell and bulk expression data,https://www.nature.com/articles/s41467-018-04696-6
"KO mice could not be generated for three genes , as heterozygous Pstk mice were infertile and , confirming published observations , KO of Cask49 and Dll450 resulted in heterozygous lethality . Lexicon ’ s KO strategies for Agpat2 , Clcn7 , Cldn18 , Fam20c , Gnptab , Lrp5 , Lrrk1 , Sgpl1 , Stk36 , Tph1 , Tph2 and Wnt16 are provided in the publications of these phenotypes . KO strategies used to generate 4077 of Lexicon ’ s KO mouse lines are provided at the Taconic Farms website ( ). Supplementary Table S1 summarizes KO strategies for all 93 genes discussed in this review . A total of 139 X - linked genes were KO ’ d , with bone data for 133 KOs reported .",Method,Algorithm,Use,High-throughput screening of mouse gene knockouts identifies established and novel skeletal phenotypes,https://www.nature.com/articles/boneres201434
"Individual tag ID was used as a random effect in the GAMMs to account for autocorrelation within each track . Deviance explained was calculated as the ratio of the deviance of the full model compared to the deviance of the null model . Potential confounding between statistically significant covariates was investigated with variance inflation factors ( VIF ) [ 49 – 51 ] using the corvif function available at [ 50 , 51 ]. Model selection was performed manually , one variable at a time , and we retained candidate predictors that were statistically significant at the 0 . 05 level , maximized the amount of deviance explained and exhibited a VIF lower than 3 . Once the final model was chosen , the number of knots ( k ) was sometimes manually decreased based on the appearance of the smooth plots , to further reduce overfitting .",Method,Algorithm,Use,Characterizing a Foraging Hotspot for Short-Finned Pilot Whales and Blainville’s Beaked Whales Located off the West Side of Hawai‘i Island by Using Tagging and Oceanographic Data,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142628
The quality filtered FASTQ files ( Paired end ) for each sample were then mapped against the Human Reference Genome build hg19 ( http :// hgdownload . soe . ucsc . edu / goldenPath / hg19 / bigZips / chromFa . tar . gz ) usingthe Burrows Wheeler alignment ( BWA ) tool version 0 . 7 . 10 ( http :// bio - bwa . sourceforge . net /). The whole genome alignment was performed using ‘ BWA - MEM ’ algorithm with default parameters [ 28 ]. The aligned reads in the Sequence Alignment / Map ( SAM ) format were then sorted using ‘ SortSam ’ algorithm of Picard tool v . 1 . 118 ( ). The Sorted SAM file was converted to binary version of a SAM file ( BAM file ) using the SAMtools ( http :// samtools . sourceforge . net /). The resulting BAM file was then sorted and indexed using SAMtools ( http :// samtools . sourceforge . net /) for variant calling .,Method,Algorithm,Use,Quality control of next-generation sequencing data without a reference,https://www.frontiersin.org/articles/10.3389/fgene.2014.00111/full
"Mapping Brain Networks Using EEG toolbox . Accordingly , all EEG datasets later used for source localization had the same number of signals . Subsequently , we band - pass filtered the EEG data in the frequency range 1 – 80 Hz and we decomposed them into ICs by using the fast fixed - point ICA ( FastICA ) algorithm , to identify and remove artifacts of biological origin ( Mantini et al ., 2008 ). Artifactual ICs were automatically identified by using information from the signal kurtosis , the power spectrum and the correlation with horizontal and vertical electrooculogram ( hEOG and vEOG ) and electromyogram ( EMG ). Finally , we re - referenced the cleaned EEG signals using the average reference approach ( Liu et al ., 2015 ).",Method,Algorithm,Use,"Detecting Large-Scale Brain Networks Using EEG: Impact of Electrode Density, Head Modeling and Source Localization",https://www.frontiersin.org/articles/10.3389/fninf.2018.00004/full
“−” denotes the data set with punctuations removed . reported so far . Our code will be available at _CITE_,Method,Code,Produce,"Punctuation Processing for Projective Dependency Parsing∗ Ji Ma† , Yue Zhang‡ and Jingbo Zhu†",https://aclanthology.org/P14-2128.pdf
"Analysis scripts and primary data and results files are available for download from When no target segment is found by the algorithm for the speech of one caregiver , this results in missing data , as no recall , purity , or collocation can be calculated in these conditions . Therefore , we excluded from inspection all settings of the similarity threshold that resulted in missing data prior to carrying out statistical analyses .",Method,Code,Produce,Motif discovery in infant- and adult-directed speech,https://aclanthology.org/W15-2413.pdf
"We apply our semantic parser on two datasets : WEBQUESTIONS ( Berant et al ., 2013 ), which contains 5 , 810 question - answer pairs with common questions asked by web users ; and FREE917 ( Cai and Yates , 2013 ), which has 917 questions manually authored by annotators . On WEBQUESTIONS , we obtain a relative improvement of 12 % in accuracy over the state - of - the - art , and on FREE917 we match the current best performing system . The source code of our system PARASEMPRE is released at _CITE_",Method,Code,Produce,Semantic Parsing via Paraphrasing,https://aclanthology.org/P14-1133.pdf
"We have presented a new top - down left - to - right parsing model . Its performance of 89 . 4 % is a 20 % error reduction over the previous singleparser performance , and indeed is a small improvement ( 0 . 6 %) over the best combinationparser result . The code is publically available . 1 l_CITE_",Method,Code,Produce,Top-Down Nearly-Context-Sensitive Parsing,https://aclanthology.org/D10-1066.pdf
"Experimental results show that though the compact decomposition requires more running time for each iteration , it achieves consistently tighter bounds and outperforms the naive dual decomposition . The two experiments demonstrate that our method works for general graphs , even if the graph can not be decomposed into a few spanning trees ( for example , if the graph has large complete subgraphs or large factors ). Our code is available at _CITE_",Method,Code,Produce,2-Slave Dual Decomposition for Generalized Higher Order CRFs,https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00187/43335/2-Slave-Dual-Decomposition-for-Generalized-Higher
"The StandOff axis steps are part of release 0 . 10 of the open - source MonetDB / XQuery product , which can be downloaded from In addition to the StandOff axis steps , a keyword search function has been added to the XQuery system to allow queries asking for regions containing specific words . This function is called so - contains ($ node , $ needle ) which will return a boolean specifying whether $ needle occurs in the given region represented by the element $ node .",Method,Code,Produce,Representing and Querying Multi-dimensional Markup for Question Answering,https://aclanthology.org/W06-2701.pdf
"Furthermore , the results indicate that target features is the most informative of the tested feature classes . The neural network is implemented in Theano ( Bergstra et al ., 2010 ), and is publicly available on Github . Nous avons cette banniere dans nos bureaux ˆ Palo Alto number of preceding POS tags . Window size is varied in a symmetrical fashion of n + n . When varying window size , 3 preceding POS tags are used .",Method,Code,Produce,Part-of-Speech Driven Cross-Lingual Pronoun Prediction with Feed-Forward Neural Networks,https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A853685&dswid=-8485
"Our results demonstrate that , despite their simplicity , deterministic models for coreference resolution obtain competitive results , e . g ., we obtained the highest scores in both the closed and open tracks ( 57 . 8 and 58 . 3 respectively ). The code used for this shared task is publicly released . We thank the shared task organizers for their effort . This material is based upon work supported by the Air Force Research Laboratory ( AFRL ) under prime contract no . FA8750 - 09 - C - 0181 .",Method,Code,Produce,Stanford’s Multi-Pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task,https://aclanthology.org/W11-1902.pdf
"However , the hope is that by choosing the right value of i , these estimates will be accurate enough to affect the search quality only slightly , which is analogous to “ almost admissible ” heuristics in A * search ( Soricut , 2006 ). We test our methods on two large - scale English - toChinese translation systems : a phrase - based system and our tree - to - string system ( Huang et al ., 2006 ). We implemented Cubit , a Python clone of the Pharaoh decoder ( Koehn , 2004 ), and adapted cube pruning to it as follows . As in Pharaoh , each bin i contains hypotheses ( i . e ., + LM items ) covering i words on the source - side . But at each bin ( see Figure 5 ), all + LM items from previous bins are first partitioned into − LM items ; then the hyperedges leading from those − LM items are further grouped into hyperedge bundles ( Figure 6 ), which are placed into the priority queue of the current bin .",Method,Code,Produce,Forest Rescoring: Faster Decoding with Integrated Language Models,https://aclanthology.org/P07-1019.pdf
"We give a full spectrum evaluation of all three stages of IR + QA : document retrieval , passage retrieval and answer extraction , to examine thoroughly the effectiveness of the method . All of our code and datasets are publicly available . Besides Predictive Annotation , our work is closest to structured retrieval , which covers techniques of dependency path mapping ( Lin and Pantel , 2001 ; Cui et al ., 2005 ; Kaisser , 2012 ), graph matching with Semantic Role Labeling ( Shen and Lapata , 2007 ) and answer type checking ( Pinchak et al ., 2009 ), etc . Specifically , Bilotti et al . ( 2007 ) proposed indexing text with their semantic roles and named entities .",Method,Code,Produce,Automatic Coupling of Answer Extraction and Information Retrieval,https://aclanthology.org/P13-2029.pdf
"We found that MAD , a recently proposed graph - based SSL algorithm , is consistently the most effective across the various experimental conditions . We also showed that class - instance acquisition performance can be significantly improved by incorporating additional semantic constraints in the class - instance acquisition process , which for the experiments in this paper were derived from instance - attribute pairs available in an independently developed knowledge base . All the data used in these experiments was drawn from publicly available datasets and we plan to release our code to foster reproducible research in this area . Topics for future work include the incorporation of other kinds of semantic constraint for improved class - instance acquisition , further investigation into per - node sparsity constraints in graph - based SSL , and moving beyond bipartite graph constructions . We thank William Cohen for valuable discussions , and Jennifer Gillenwater , Alex Kulesza , and Gregory Malecha for detailed comments on a draft of this paper .",Method,Code,Produce,Experiments in Graph-based Semi-Supervised Learning Methods for Class-Instance Acquisition,https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36414.pdf
"These rules rely on the use of affixes that classify drugs according to their chemical structure , indication or mechanism of action . For example , analgesics substances can receive affixes such as - adol -, - butazone , -� enine , - eridine and fentanil . In the present work , we focus , particulary , on the implementation of a set of 531 affixes approved by the USAN Council and published in 2007 . The affixes allow a specific classification of drugs on pharmacological families , which ULMS Semantic NetWork is unable to provide . The system consists of four main modules : a basic text processing module , WordNet look - up module , UMLS look - up module and the USAN rules module , as shown in Figure 1 .",Method,Code,Produce,A preliminary approach to recognize generic drug names by combining UMLS resources and USAN naming conventions,https://aclanthology.org/W08-0618.pdf
"Nonetheless , automatic metrics are far from perfection : when used in isolation , they tend to stress specific aspects of the translation quality and neglect others ( particularly during tuning ); they are often unable to capture little system improvements ( enhancements in very specific aspects of the translation process ); and they may make unfair comparisons when they are not able to reflect real differences among the quality of different MT systems ( Gim ´ enez , 2008 ). ASIYA , the core of our approach , is an opensource suite for automatic machine translation evaluation and output analysis . It provides a rich set of heterogeneous metrics and tools to evaluate and analyse the quality of automatic translations . The ASIYA core toolkit was first released in 2009 ( Gim ´ enez and M ` arquez , 2010a ) and has been continuously improved and extended since then ( Gonz ` alez et al ., 2012 ; Gonz ` alez et al ., 2013 ). In this paper we first describe the most recent enhancements to ASIYA : ( i ) linguistic - based metrics for French and German ; ( ii ) an extended set of source - based metrics for English , Spanish , German , French , Russian , and Czech ; and ( iii ) the integration of mechanisms to exploit the alignments between sources and translations .",Method,Code,Produce,IPA and STOUT: Leveraging Linguistic and Source-based Features for Machine Translation Evaluation,https://aclanthology.org/W14-3351.pdf
"Features are pruned to less than 10 , 000 according to their pairwise Pearson correlation with the labels . The code is available on GitHub . Section 2 presents related work . Section 3 describes the dataset the methods are evaluated on . Section 4 provides an overview of the architecture of our method and describes the classification method .",Method,Code,Produce,A two-level classifier for discriminating similar languages,https://aclanthology.org/W15-5412.pdf
"We implemented this functionality on top of the coreference resolution error analysis toolkit cort ( Martschat et al ., 2015 ). Hence , this toolkit now provides functionality for devising , implementing , comparing and analyzing approaches to coreference resolution . cort is released as open source and is available from the Python Package Index . In this section we briefly describe a structured prediction framework for coreference resolution . The popular mention pair approach ( Soon et al ., 2001 ; Ng and Cardie , 2002 ) operates on a list of mention pairs .",Method,Code,Produce,Plug Latent Structures and Play Coreference Resolution,https://aclanthology.org/P15-4011.pdf
"The results from the service can be stored in a database , and can be later replayed . We also developed a Widget version of the annotator that can be embedded in other websites , and integrated in widget frameworks like Sefarad . The project is completely open source and can be downloaded from its Github repository . This section demonstrates how it would be possible to integrate sentiment analysis of different modes using SPARQL . In particular , it covers two scenarios : fusion of results from different modes , and detection of complex patterns using information from several modes .",Method,Code,Produce,A Linked Data Model for Multimodal Sentiment and Emotion Analysis,https://oa.upm.es/67517/
"The parameters were estimated using maximum likelihood on the training set ; we also implemented a simple absolute discounting smoothing method ( Zhai and Lafferty , 2001 ) that improves the results for both tasks . Table 2 shows the results ( F - measures ) for the problem of finding the most likely sequence of roles given the features observed . In this case , the relation is hidden and we marginalize over it . We experimented with different values for the smoothing factor ranging from a minimum of 0 . 0000005 to a maximum of 10 ; the results shown fix the smoothing factor at its minimum value . We found that for the dynamic models , for a wide range of smoothing factors , we achieved almost identical results ; nevertheless , in future work , we plan to implement cross - validation to find the optimal smoothing factor .",Method,Code,Produce,Classifying Semantic Relations in Bioscience Texts,https://aclanthology.org/P04-1055.pdf
"We verify that the empirical time complexity of inference in SBTDM increases sub - linearly in the number of topics , and show that for large topic spaces SBTDM is more than an order of magnitude more efficient than the hierarchical Pachinko Allocation Model ( Mimno et al ., 2007 ) and nHDP . Lastly , we release an implementation of SBTDM as open - source software . The intuition in SBTDM that topics are naturally arranged in hierarchies also underlies several other models from previous work . Paisley et al . ( 2015 ) introduce the nested Hierarchical Dirichlet Process ( nHDP ), which is a tree - structured generative model of text that generalizes the nested Chinese Restaurant Process ( nCRP ) ( Blei et al ., 2010 ).",Method,Code,Produce,Efficient Methods for Inferring Large Sparse Topic Hierarchies,https://aclanthology.org/P15-1075.pdf
"In this study , we aim to construct such a system and to demonstrate that it outperforms strict string matching approaches . We refer to our system as SimSem , as in “ Similarity ” and “ Semantic ”. SimString is a software library utilising the CPMerge algorithm ( Okazaki and Tsujii , 2010 ) to enable fast approximate string matching . The software makes it possible to find matches in a collection with over ten million entries using cosine similarity and a similarity threshold of 0 . 7 in approximately 1 millisecond with modest modern hardware . This makes it useful for querying a large collection of strings to find entries which may differ from the query string only superficially and may still be members of the same semantic category .",Method,Code,Produce,SimSem: Fast Approximate String Matching in Relation to Semantic Category Disambiguation,https://d1wqtxts1xzle7.cloudfront.net/30785822/W11-02.pdf?1362344076=&response-content-disposition=inline%3B+filename%3DLearning_phenotype_mapping_for_integrati.pdf&Expires=1686014723&Signature=dq4GXug04iGiBJ4~d~pNE-SHcViMU1dKBmRlvguZZM6SwCTW5JwH~2XXzourPbSGCnvfPjlr-ZNyR7oU5lfwu2-ro4lo~dhg1TYTonwG1kIzk9AMEoYhUwcgTfVI2QVpYqvhvlqWaAwMI8E7ur9kyWviaCAKWZB7lg3CiKFSsyhGdtHI~c3oDTtbTmDKKUOYHu7Dsf9ZLzYRLjF3hT9ktYgoIQQFsrIXlfxxrQCzcgk7Gg6-AwnEzh2ZrfNTjHni9tYqdVuceuUVzAy~3pzjWwqDIPNa~ejJAc0bmBVTZv6zbbRW4GomqJHdiTw0Lc~ZO~CdOnOpCG3JqGQGQExU6A__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA#page=148
"The ACL Anthology is a comprehensive electronic collection of scientific papers in our own field ( Bird et al ., 2008 ). It is updated regularly with new publications , but also older papers have been scanned and are made available electronically . We have implemented the ACL Anthology Searchbench for two reasons : Our first aim is to provide a more targeted search facility in this collection than standard web search on the anthology website . In this sense , the Searchbench is meant to become a service to our own community . Our second motivation is to use the developed system as a showcase for the progress that has been made over the last years in precision - oriented deep linguistic parsing in terms of both efficiency and coverage , specifically in the context of the DELPHIN community .",Method,Code,Produce,The ACL Anthology Searchbench,https://aclanthology.org/P11-4002.pdf
"The corpus , de scribed in details in ( Fraser et al ., 2013 ), contains a training set of 40472 sentences , a development and a test set of both 5000 sentences . We consider the two tagging tasks , with first a coarse tagset ( 54 tags ), and then a morpho - syntactical rich tagset ( 619 items observed on the the training set ). All the models are implemented with the Theano library ( Bergstra et al ., 2010 ). For optimization , we use Adagrad ( Duchi et al ., 2011 ), with a learning rate of 0 . 1 . The other hyperparameters are : the window sizes , d , and dw , respectively set to 5 and 9 , the dimension of character embeddings , word embeddings and of the hidden layer , n ,, nf and nh , that are respectively of 100 , 200 and 200 .",Method,Code,Produce,Non-lexical neural architecture for fine-grained POS Tagging,https://aclanthology.org/D15-1025.pdf
"Second , we compared the performance of GP - Vol against standard econometric models GARCH , EGARCH and GJRGARCH on fifty real financial time series . Finally , we compared RAPCF with the batch MCMC method PGAS in terms of accuracy and execution time . The code for RAPCF in GP - Vol is publicly available at _CITE_",Method,Code,Produce,Gaussian Process Volatility Model,https://proceedings.neurips.cc/paper/2014/hash/a733fa9b25f33689e2adbe72199f0e62-Abstract.html
"Thus we will focus on making comparison to the PGBN with a single layer , with its layer width set to be large to approximate the performance of the gamma - negative binomial process PFA . We evaluate the PGBNs ’ performance by examining both how well they unsupervisedly extract low - dimensional features for document classification , and how well they predict heldout word tokens . Matlab code will be available in We use Algorithm 1 to learn , in a layer - wise manner , from the training data the weight matrices ( D ( 1 ),...,( D ( Tmax ) and the top - layer hidden units ’ gamma shape parameters r : to add layer T to a previously trained network with T − 1 layers , we use BT iterations to jointly train ( D ( T ) and r together with {( D ( t )} 1 , T − 1 , prune the inactive factors of layer T , and continue the joint training with another CT iterations . We set the hyper - parameters as a0 = b0 = 0 . 01 and e0 = f0 = 1 .",Method,Code,Produce,The Poisson Gamma Belief Network,https://proceedings.neurips.cc/paper/2015/hash/f3144cefe89a60d6a1afaf7859c5076b-Abstract.html
"This quantity is an estimate of type - I error under H0 , and corresponds to test power when H1 is true . We set α = 0 . 01 in all the experiments . All the code and preprocessed data are available at Optimization The parameter tuning objective ˆλtrn / 2 ( θ ) is a function of θ consisting of one real - valued σ and J test locations each of d dimensions . The parameters θ can thus be regarded as a Jd + 1 Euclidean vector .",Method,Code,Produce,Interpretable Distribution Features with Maximum Testing Power,https://proceedings.neurips.cc/paper/2016/hash/0a09c8844ba8f0936c20bd791130d6b6-Abstract.html
"We have performed some preliminary evaluations of semantic precision using unsupervised AQBC , and we have found it to work very well for retrieving semantic neighbors for extremely high - dimensional sparse data ( like the 20 Newsgroups dataset ), while ITQ currently works better for lower - dimensional , denser data . In the future , we plan to investigate how to improve the semantic precision of AQBC using either unsupervised or supervised learning . Additional resources and code are available at Acknowledgments . We thank Henry A . Rowley and Ruiqi Guo for helpful discussions , and the reviewers for helpful suggestions . Gong and Lazebnik were supported in part by NSF grants IIS 0916829 and IIS 1228082 , and the DARPA Computer Science Study Group ( D12AP00305 ).",Method,Code,Produce,Angular Quantization-based Binary Codes for Fast Similarity Search,https://proceedings.neurips.cc/paper/2012/hash/f5deaeeae1538fb6c45901d524ee2f98-Abstract.html
"In the tested cases the appearance of the found motifs did not change drastically while varying the Bl penalty within one order of magnitude , so fine - tuning it is not necessary . Instead of specifying the penalty a on the B0 norm of the activations directly , we chose to stop the matching pursuit algorithm when adding an additional assembly appearance increases the reconstruction error or when the difference of reconstruction errors from two consecutive steps falls below a small threshold . All code for the proposed method is available at : Sparse - convolutional - coding - for - neuronal - assembly - detection",Method,Code,Produce,Sparse convolutional coding for neuronal assembly detection,https://proceedings.neurips.cc/paper/2017/hash/aebf7782a3d445f43cf30ee2c0d84dee-Abstract.html
"( 2016 ), and the aligned and cropped version of CelebA was scaled from 218 x 178 pixels to 78 x 64 pixels and center - cropped at 64 x 64 pixels ( Liu et al ., 2015 ). We used the Adam optimizer ( Kingma and Ba , 2014 ) and the Theano framework ( Al - Rfou et al ., 2016 ). More details are in Appendix and code for training and generation is at _CITE_",Method,Code,Produce,Sparse convolutional coding for neuronal assembly detection,https://proceedings.neurips.cc/paper/2017/hash/aebf7782a3d445f43cf30ee2c0d84dee-Abstract.html
"For the NOC - SVM method , we used the implementation provided by the authors 6 . The LibSVM package [ 1 ] was used to implement the HMVE and I - OCSVM methods . An implementation of our q - OCSVM estimator is available from : All experiments were carried out with a Gaussian kernel ( γ = 1 2 . 5",Method,Code,Produce,q-OCSVM: A q-Quantile Estimator for High-Dimensional Distributions,https://proceedings.neurips.cc/paper/2013/hash/819f46e52c25763a55cc642422644317-Abstract.html
"In our experiments on both synthetic functions and tuning practical machine learning algorithms , q - KG consistently finds better function values than other parallel BO algorithms , such as parallel EI [ 2 , 19 , 25 ], batch UCB [ 5 ] and parallel UCB with exploration [ 3 ]. q - KG provides especially large value when function evaluations are noisy . The code in this paper is available at The rest of the paper is organized as follows . Section 2 reviews related work .",Method,Code,Produce,The Parallel Knowledge Gradient Method for Batch Bayesian Optimization,https://proceedings.neurips.cc/paper/2016/hash/18d10dc6e666eab6de9215ae5b3d54df-Abstract.html
"We now present empirical results on byte - prediction tasks and partially - observable RL . Our code and instructions for its use is publicly available at : Byte Prediction We compare the performance of D2 - CTW against CTW on the 18 - file variant of the Calgary Corpus [ 3 ], a benchmark of text and binary data files . For each file , we ask the algorithms to predict the next byte given the preceding data , such that | E |= 256 across all files .",Method,Code,Produce,Dynamic-Depth Context Tree Weighting,https://proceedings.neurips.cc/paper/2017/hash/c366c2c97d47b02b24c3ecade4c40a01-Abstract.html
This material is based upon work supported by the National Science Foundation under Grant No . 1125228 . The code as an R package is available at : _CITE_,Method,Code,Produce,A Conditional Multinomial Mixture Model for Superset Label Learning,https://proceedings.neurips.cc/paper/2012/hash/aaebdb8bb6b0e73f6c3c54a0ab0c6415-Abstract.html
In our case we showed this through the influence of spatial frequency on speed estimation . We have thus provided just one example of how the optimized motion stimulus and accompanying theoretical work might serve to improve our understanding of inference behind perception . The code associated to this work is available at _CITE_,Method,Code,Produce,Biologically Inspired Dynamic Textures for Probing Motion Perception,https://proceedings.neurips.cc/paper/2015/hash/6eb6e75fddec0218351dc5c0c8464104-Abstract.html
"Then , we provide empirical evidence that our algorithm is more robust to artifacts and outliers than three competing CSC methods [ 6 , 7 , 12 ]. Finally , we consider LFP data , where we illustrate that our algorithm can reveal interesting properties in electrophysiological signals without supervision , even in the presence of severe artifacts . The source code is publicly available at Synthetic simulation setup : In our synthetic data experiments , we simulate N trials of length T by first generating K zero mean and unit norm atoms of length L . The activation instants are integers drawn from a uniform distribution in Q0 , T − L �. The amplitude of the activations are drawn from a uniform distribution in [ 0 , 1 ].",Method,Code,Produce,Learning the Morphology of Brain Signals Using Alpha-Stable Convolutional Sparse Coding,https://proceedings.neurips.cc/paper/2017/hash/6f2268bd1d3d3ebaabb04d6b5d099425-Abstract.html
"We implemented misoKG ’ s statistical model and acquisition function in Python 2 . 7 and C ++ leveraging functionality from the Metrics Optimization Engine [ 23 ]. We used a gradient - based optimizer [ 28 ] that first finds an optimizer via multiple restarts for each IS B separately and then picks ( B ( n + 1 ), x ( n + 1 )) with maximum misoKG factor among these . An implementation of our method is available at We compare to misoEI of Lam et al . [ 18 ] and to MTBO +, an improved version of Multi - Task Bayesian Optimization proposed by Swersky et al .",Method,Code,Produce,Multi-Information Source Optimization,https://proceedings.neurips.cc/paper/2017/hash/df1f1d20ee86704251795841e6a9405a-Abstract.html
"In this section , we discuss our experiments on a synthetic dataset and three real text corpora . The TDM and DDM implementations are available at For both models we initialized the hyperparameters to be αd , t = 1 and βt , w = √ 1V for all d , t , and w . The reason that βt , w was not initialized to 1 was to encourage the algorithm to find topics with more concentrated word distributions .",Method,Code,Produce,Online Bayesian Moment Matching for Topic Modeling with Unknown Number of Topics,https://proceedings.neurips.cc/paper/2016/hash/0233f3bb964cf325a30f8b1c2ed2da93-Abstract.html
We define loss as the cross entropy between predicted and demonstrated action sequences and use RMSProp [ 35 ] for training . See Appendix C . 7 for details . Our implementation in Tensorflow [ 1 ] is available online at _CITE_,Method,Code,Produce,QMDP-Net: Deep Learning for Planning under Partial Observability,https://proceedings.neurips.cc/paper/2017/hash/e9412ee564384b987d086df32d4ce6b7-Abstract.html
"The analyses were performed in Python . We used nilearn to handle the large quantities of neuroimaging data [ 1 ] and Theano for automatic , numerically stable differentiation of symbolic computation graphs [ 5 , 7 ]. All Python scripts that generated the results are accessible online for reproducibility and reuse ( ).",Method,Code,Produce,Semi-Supervised Factored Logistic Regression for High-Dimensional Neuroimaging Data,https://proceedings.neurips.cc/paper/2015/hash/06a15eb1c3836723b53e4abca8d9b879-Abstract.html
We chose the hyperparameter settings that produced the highest quality images . We note that we found no correlation between the activation of a neuron and the recognizability of its visualization . Our code and parameters are available at _CITE_,Method,Code,Produce,Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,https://proceedings.neurips.cc/paper/2016/hash/5d79099fcdf499f12b79770834c0164a-Abstract.html
"For FSSD tests , we use J = 5 ( see Section A for an investigation of test power as J varies ). All tests with optimization use 20 % of the sample size n for parameter tuning . Code is available at Figure 2 shows the rejection rates of the six tests for the two problems , where each problem is repeated for 200 trials , resampling n points from q every time . In Figure 2a ( Gaussian vs . Laplace ), high performance of FSSD - opt indicates that the test performs well when there are local differences between p and q .",Method,Code,Produce,A Linear-Time Kernel Goodness-of-Fit Test,https://proceedings.neurips.cc/paper/2017/hash/979d472a84804b9f647bc185a877a8b5-Abstract.html
"For AlexNet , the Caffe reimplementation is used which is slightly different from the original architecture ( pooling and normalization layers are swapped ). We use a fork of MatConvNet framework for all experiments , except for fine - tuning of AlexNet and VGG - 16 , for which we use a fork of Caffe . The source code is available at , https :// github . com / mfigurnov / perforated - cnn - caffe . We begin our experiments by comparing the proposed perforation masks in a common benchmark setting : acceleration of a single AlexNet layer . Then , we compare whole - network acceleration with the best - performing masks to baselines such as decrease of input images size and an increase of strides .",Method,Code,Produce,PerforatedCNNs: Acceleration through Elimination of Redundant Convolutions,https://proceedings.neurips.cc/paper_files/paper/2016/hash/f0e52b27a7a5d6a1a87373dffa53dbe5-Abstract.html
"Our approach provides a first step towards surpassing this limitation , by not just anticipating but certifying the reliability of a defender , thus implicitly considering an infinite number of attacks before they occur . Reproducibility . The code and data for replicating our experiments is available on GitHub ( ) and Codalab Worksheets ( http :// bit . ly / cl - datapois ). Acknowledgments . JS was supported by a Fannie & John Hertz Foundation Fellowship and an NSF Graduate Research Fellowship .",Method,Code,Produce,Certified Defenses for Data Poisoning Attacks,https://proceedings.neurips.cc/paper/2017/hash/9d7311ba459f9e45ed746755a32dcd11-Abstract.html
"Note that , while a naive implementation of the arg max in Algorithm 3 requires evaluating the objective for each item in U , here we can exploit the fact that DPPs are closed under conditioning to compute all necessary values with only two matrix inversions [ 5 ]. We report baseline runtimes using this optimized greedy algorithm , which is about 10 times faster than the naive version at N = 200 . The code and data for all experiments can be downloaded from _CITE_",Method,Code,Produce,Near-Optimal MAP Inference for Determinantal Point Processes,https://proceedings.neurips.cc/paper/2012/hash/6c8dba7d0df1c4a79dd07646be9a26c8-Abstract.html
"Such a case is shown in Figure 4 ( f ), where n = 10000 data points were generated ( but only a small subset of these was actually plotted ). Here the polygonal line algorithm approximates the generating curve with much better accuracy than the HS algorithm . The Java implementation of the algorithm is available at the WWW site _CITE_",Method,Code,Produce,A Polygonal Line Algorithm for Constructing Principal Curves,https://proceedings.neurips.cc/paper/1998/hash/97d0145823aeb8ed80617be62e08bdcc-Abstract.html
"We sorted the magnitudes of the signal coefficients , normalized them by their corresponding value of R . We then plotted the results on a log - log scale in Fig . 1 . At , we provide a MATLAB routine ( randcs . m ) so that it is easy to repeat the same experiment for the rest of the distributions in Table 4 .",Method,Code,Produce,Learning with Compressible Priors,https://proceedings.neurips.cc/paper/2009/hash/5c936263f3428a40227908d5a3847c0b-Abstract.html
"proposed extended DMD [ 35 ], which works on pre - determined basis functions instead of the monomials of observables . Although in extended DMD the Koopman mode is defined as the eigenvector of the corresponding operator of coefficients on basis functions , the resulting procedure is similar to the robust - version of our algorithm . & apos ; The Matlab code is available at In system control , subspace identification [ 23 , 14 ], or called the eigensystem realization method , has been a popular approach to modeling of dynamical systems . This method basically identifies low - dimensional ( hidden ) states as canonical vectors determined by canonical correlation analysis , and estimates parameters in the governing system using the state estimates . This type of method is known as a spectral method for dynamical systems in the machine learning community and has recently been applied to several types of systems such as variants of hidden Markov models [ 31 , 19 ], nonlinear dynamical systems [ 15 ], and predictive state - representation [ 17 ].",Method,Code,Produce,Dynamic Mode Decomposition with Reproducing Kernels for Koopman Spectral Analysis,https://proceedings.neurips.cc/paper/2016/hash/1728efbda81692282ba642aafd57be3a-Abstract.html
This condition provably holds in a finite number of iterations and still guarantees that || fk + 1 - fk || 2 -+ 0 . The concrete decay estimate provided by SD algorithm therefore allows us to give precise meaning to “ sufficiently lowers the energy .” We investigate these aspects of the algorithm and prove convergence for this practical implementation in future work . Reproducible research : The code is available at Acknowledgements : This work supported by AFOSR MURI grant FA9550 - 10 - 1 - 0569 and Hong Kong GRF grant # 110311 .,Method,Code,Produce,Convergence and Energy Landscape for Cheeger Cut Clustering,https://proceedings.neurips.cc/paper/2012/hash/17c276c8e723eb46aef576537e9d56d0-Abstract.html
"In this section , we demonstrate Algorithm 1 on an exploration task . We consider the setting in [ 14 ], the exploration of the surface of Mars with a rover . The code for the experiments is available at For space exploration , communication delays between the rover and the operator on Earth can be prohibitive . Thus , it is important that the robot can act autonomously and explore the environment without risking unsafe behavior .",Method,Code,Produce,Safe Exploration in Finite Markov Decision Processes with Gaussian Processes,https://proceedings.neurips.cc/paper/2016/hash/9a49a25d845a483fae4be7e341368e36-Abstract.html
"As methods based on GPs require the inversion of n x n matrices , where n is the number of training examples , we are looking into methods such as query selection for large dataset problems . Other future research directions include the investigation of different covariance functions and improvements on the approximations employed . We hope to make our MATLAB code available from _CITE_",Method,Code,Produce,Gaussian Processes for Bayesian Classification via Hybrid Monte Carlo,https://proceedings.neurips.cc/paper/1996/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html
"SSL is a generic regularization to adaptively adjust multiple structures in DNN , including structures of filters , channels , filter shapes within each layer , and structure of depth beyond the layers . SSL combines structure regularization ( on DNN for classification accuracy ) with locality optimization ( on memory access for computation efficiency ), offering not only well - regularized big models with improved accuracy but greatly accelerated computation ( e . g ., 5 . 1x on CPU and 3 . 1x on GPU for AlexNet ). Our source code can be found at _CITE_",Method,Code,Produce,Learning Structured Sparsity in Deep Neural Networks,https://proceedings.neurips.cc/paper/2016/hash/41bfd20a38bb1b0bec75acf0845530a7-Abstract.html
"Similar comments also apply to the regularisation of the process variances for the NCNM . However , these preliminary results appear encouraging for the NCNM . Code for recreating all our experiments is available at _CITE_",Method,Code,Produce,Semi-supervised Learning via Gaussian Processes,https://proceedings.neurips.cc/paper/2004/hash/d3fad7d3634dbfb61018813546edbccb-Abstract.html
"PSVM distributedly loads training data on parallel machines , reducing memory requirement through approximate factorization on the kernel matrix . PSVM solves IPM in parallel by cleverly arranging computation order . We have made PSVM open source at _CITE_",Method,Code,Produce,Parallelizing Support Vector Machines on Distributed Computers,https://proceedings.neurips.cc/paper/2007/hash/ddb30680a691d157187ee1cf9e896d03-Abstract.html
"The method was implemented on GPflow [ 20 ] and compared against GPflow ’ s version of the following baselines : exact GP ( GP ), sparse GP using the collapsed bound ( SGP ), and stochastic variational inference using the uncollapsed bound ( SVI ). In all the experiments , the RBF kernel with ARD lengthscales is used , but this is not a limitation required by the new methods . An implementation of the proposed method can be found at Full experimental results and additional discussion points are included in the appendix .",Method,Code,Produce,Streaming Sparse Gaussian Process Approximations,https://proceedings.neurips.cc/paper/2017/hash/f31b20466ae89669f9741e047487eb37-Abstract.html
"In this section we present the results of an extensive empirical evaluation of the dynamical ensemble pruning method described in the previous section . The experiments are performed in a series of benchmark classification problems from the UCI Repository [ 1 ] and synthetic data [ 4 ] using Random Forests [ 5 ]. The code is available at : The protocol for the experiments is as follows : for each problem , 100 partitions are created by 10 x 10 - fold cross - validation for real datasets and by random sampling in the synthetic datasets . All the classification tasks considered are binary , except for New - thyroid , Waveform and Wine , which have three classes .",Method,Code,Produce,An urn model for majority voting in classification ensembles,https://proceedings.neurips.cc/paper/2016/hash/d1a21da7bca4abff8b0b61b87597de73-Abstract.html
"They lead to improved semi - supervised learning peformance and improved sample generation . We hope that some of them may form the basis for future work , providing formal guarantees of convergence . All code and hyperparameters may be found at _CITE_",Method,Code,Produce,Improved Techniques for Training GANs,https://proceedings.neurips.cc/paper/2016/hash/8a3363abe792db2d8761d6403605aeb7-Abstract.html
"The guide policy chooses steps using qφ ( zt | ct − 1 , x ), We train the primary / guide policy components ωθ , pθ , and qφ simultaneously on the objective : minimize E E [ τ ∼ qφ ( E - log q ( xu | cT )] + KL ( q ( τ | xu , xk )|| p ( τ | xk )) ( 17 ) θ , φ x ∼ DX m ∼ DM τ | Xu � k ) where q ( xu | cuT ) , p ( xu | cuT ). We train our models using Monte - Carlo roll - outs of q , and stochastic backpropagation as in [ 6 , 14 ]. Full implementations and test code are available from _CITE_",Method,Code,Produce,Data Generation as Sequential Decision Making,https://proceedings.neurips.cc/paper/2015/hash/09b15d48a1514d8209b192a8b8f34e48-Abstract.html
"For each of these samples , we then approximate the corresponding entropy function H [ p ( y | Dn , x , x ( i ) ? )] using expectation propagation [ 18 ]. The code for all these operations is publicly available at _CITE_",Method,Code,Produce,Predictive Entropy Search for Efficient Global Optimization of Black-box Functions,https://proceedings.neurips.cc/paper/2014/hash/069d3bb002acd8d7dd095917f9efe4cb-Abstract.html
"For all MLPs and CNNs , we universally use SGD with learning rate 10 − 3 , momentum 0 . 9 , L2 weight decay 10 − 3 and batch size 128 to reduce the grid search complexity by focusing on architectural hyperparameters . All networks are trained for 100 epochs on MNIST and CIFAR10 , and 20 epochs on SVHN2 , without data augmentation . The source code and scripts for reproducing our experiments are available at Table 1 summarizes our experimental results , including both one - pass ( i . e . first - epoch ) and asymptotic ( i . e .",Method,Code,Produce,Tensor Switching Networks,https://proceedings.neurips.cc/paper/2016/hash/b1563a78ec59337587f6ab6397699afc-Abstract.html
"Interestingly , we show Wasserstein GAN [ 8 ] is the special case of the proposed MMD GAN under certain conditions . The unified view shows more connections between moment matching and GAN , which can potentially inspire new algorithms based on well - developed tools in statistics [ 15 ]. Our experiment code is available at _CITE_",Method,Code,Produce,MMD GAN: Towards Deeper Understanding of Moment Matching Network,https://proceedings.neurips.cc/paper/2017/hash/dfd7468ac613286cdbb40872c8ef3b06-Abstract.html
"Leave - one - out ( LOO ) is a standard procedure in predicting the generalization power of a trained classifier , both from a theoretical and empirical perspective [ 12 ], It is naturally implemented by decremental unlearning , adiabatic reversal of incremental learning , on each of the training data from the full trained solution . Similar ( but different ) bookkeeping of elements migrating across 5 , E and R applies as in the incremental case . & apos ; Matlab code and data are available at _CITE_",Method,Code,Produce,Incremental and Decremental Support Vector Machine Learning,https://proceedings.neurips.cc/paper/2000/hash/155fa09596c7e18e50b58eb7e0c6ccb4-Abstract.html
"We then present two applications on real - world data , where we assess differences in the persistent homology of functions on 3D surfaces of lateral ventricles and corpora callosa with respect to different group assignments ( i . e ., age , demented / non - demented ). In all experiments , filtrations and the persistence diagrams are obtained using DrPaA2 , which can directly handle our types of input data . Source code to reproduce the experiments is available at _CITE_",Method,Code,Produce,Statistical Topological Data Analysis - A Kernel Perspective,https://proceedings.neurips.cc/paper/2015/hash/74563ba21a90da13dacf2a73e3ddefa7-Abstract.html
The last building block is a method for sampling from convex bodies . We suggest the hit and run [ 9 ] random walk for this purpose in section 4 . A Matlab implementation of KQBC is available at The empirical part of this work is presented in section 5 . We demonstrate how KQBC works on two binary classification tasks .,Method,Code,Produce,Query by Committee Made Real,https://proceedings.neurips.cc/paper/2005/hash/340a39045c40d50dda207bcfdece883a-Abstract.html
"In the third experiment we demonstrate the ability of our method to infer the spectrum of airline passenger data , to perform long - range extrapolations on real data , and to demonstrate the utility of accounting for uncertainty in the kernel . In the final experiment we demonstrate the scalability of our method through training the model on a 100 , 000 data point sound waveform . Code is available at f ( X )",Method,Code,Produce,Scalable Levy Process Priors for Spectral Kernel Learning,https://proceedings.neurips.cc/paper/2017/hash/02b1be0d48924c327124732726097157-Abstract.html
"Implementation . All experiments were implemented in PyTorch3 , using DIPHA4 and Perseus [ 23 ]. Source code is publicly - available at _CITE_",Method,Code,Produce,Deep Learning with Topological Signatures,https://proceedings.neurips.cc/paper/2017/hash/883e881bb4d22a7add958f2d6b052c9f-Abstract.html
"We compared performance of RETAIN to RNNs and traditional machine learning methods . Given space constraints , we only report the results on the learning to diagnose ( L2D ) task and summarize the disease progression modeling ( DPM ) in Appendix C . The RETAIN source code is publicly available at_CITE_",Method,Code,Produce,RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism,https://proceedings.neurips.cc/paper/2016/hash/231141b34c82aa95e48810a9d1b33a79-Abstract.html
"In particular , we achieve a 25 % higher recall for 2K proposals than the state - of - the - art RGB - D method MCG - D [ 14 ]. Combined with CNN scoring , our method outperforms all published results on object detection for Car , Cyclist and Pedestrian on KITTI [ 11 ]. Our code and data are online : _CITE_",Method,Code,Produce,3D Object Proposals for Accurate Object Class Detection,https://proceedings.neurips.cc/paper/2015/hash/6da37dd3139aa4d9aa55b8d237ec5d4a-Abstract.html
"In high - dimensional complex domain , the ADMM algorithm demonstrates superior performance in our simulated examples and real images . Finally , the paper also provides practical guidelines to practitioners at large working on other similar nonsmooth SDP applications . To aid peer evaluation , the source code of all the algorithms have been made available at : _CITE_",Method,Code,Produce,CPRL -- An Extension of Compressive Sensing to the Phase Retrieval Problem,https://proceedings.neurips.cc/paper/2012/hash/3a066bda8c96b9478bb0512f0a43028c-Abstract.html
"All models are implemented in Theano [ 16 ], based on the implementation of restricted - capacity uRNNs by [ 10 ], available from https :// github . com / amarshah / complex_RNN . All code to replicate our results is available from All models use RMSprop [ 15 ] for optimization , except that full - capacity uRNNs optimize their recurrence matrices with a fixed learning rate using the update step ( 6 ) and optional RMSprop - style gradient normalization .",Method,Code,Produce,Full-Capacity Unitary Recurrent Neural Networks,https://proceedings.neurips.cc/paper_files/paper/2016/hash/d9ff90f4000eacd3a6c9cb27f78994cf-Abstract.html
"The heuristic computes the error for a given validation image at level k in the pyramid as Lk ( Ik ) = min { z ;}|| Gk ( zj , u ( Ik + 1 )) − hk || 2 where { zj } is a large set of noise vectors , drawn from pnozse ( z ). In other words , the heuristic is asking , are any of the generated residual images close to the ground truth ? Torch training and evaluation code , along with model specification files can be found at For all models , the noise vector zk is drawn from a uniform [- 1 , 1 ] distribution .",Method,Code,Produce,Deep Generative Image Models using a ￼Laplacian Pyramid of Adversarial Networks,https://proceedings.neurips.cc/paper/2015/hash/aa169b49b583a2b5af89203c2b78c67c-Abstract.html
"The advantage of our method is that we can jointly learn the optimal feature representation and the optimal domain transformation parameter , which are aware of the subsequent transductive inference procedure . Following the standard evaluation protocol in the unsupervised domain adaptation community , we evaluate our method on the digit classification task using MNIST [ 19 ] and SVHN [ 21 ] as well as the object recognition task using the Office [ 25 ] dataset , and demonstrate state of the art performance in comparison to all existing unsupervised domain adaptation methods . Learned models and the source code can be reached from the project webpage _CITE_",Method,Code,Produce,Learning Transferrable Representations for Unsupervised Domain Adaptation,https://proceedings.neurips.cc/paper/2016/hash/b59c67bf196a4758191e42f76670ceba-Abstract.html
"I thank Jack Crago , John Lloyd , Kirsty Aquilina , Kevin Gurney and Giovanni Pezzulo for discussions related to this research . The code used to generate the results and figures for this paper is at _CITE_",Method,Code,Produce,Threshold Learning for Optimal Decision Making,https://proceedings.neurips.cc/paper/2016/hash/96c5c28becf18e71190460a9955aa4d8-Abstract.html
"The issue is particularly serious for large data , where direct second order methods cannot be used due to the computational constraints . While many approximate second - order methods are available , they rely on low - rank approximations and , as we discuss below , lead to over - regularization ( approximation bias ). In the second part of the paper we propose EigenPro iteration ( see for the code ), a direct and simple method to alleviate slow convergence resulting from fast eigen - decay for kernel ( and covariance ) matrices . EigenPro is a preconditioning scheme based on approximately computing a small number of top eigenvectors to modify the spectrum of these matrices . It can also be viewed as constructing a new kernel , specifically optimized for gradient descent .",Method,Code,Produce,Diving into the shallows: a computational perspective on large-scale shallow learning,https://proceedings.neurips.cc/paper/2017/hash/bf424cb7b0dea050a42b9739eb261a3a-Abstract.html
"Figure 1 shows results from the simulation of the flanker task , recovering the characteristic early below - chance performance in incongruent trials . This simulation supports the assertion that our theory generalizes the flanker model of [ 5 ], though we are not sure why our scale on timesteps appears different by about 5x in spite of using what we think are equivalent parameters . A library for simulating tasks that fit in our framework and code for generating all simulation figures in this paper can be found at For the AX - CPT behavior , we compare qualitative patterns from our model to a heterogeneous dataset of humans performing this task ( n = 59 ) across 4 different manipulations with 200 trials per subject [ 24 ]. The manipulations were different variants of “ proactive ”- behavior inducing manipulations in the sense of [ 25 ].",Method,Code,Produce,A Theory of Decision Making Under Dynamic Context,https://proceedings.neurips.cc/paper/2015/hash/4e8412ad48562e3c9934f45c3e144d48-Abstract.html
"1 . We show how to incorporate this information in Policy Gradient RL [ 30 ], and show that we can improve over RL that has access to the same amount of ground - truth captions . Our code and data will be released ( ) to facilitate more human - like training of captioning models .",Method,Code,Produce,Teaching Machines to Describe Images with Natural Language Feedback,https://proceedings.neurips.cc/paper/2017/hash/8e68c3c7bf14ad0bcaba52babfa470bd-Abstract.html
"Through evolution , structure is more conserved than sequence , so that detecting even very subtle sequence similarities , or remote homology , is important for predicting function . The major methods for homology detection can be split into three basic groups : pairwise sequence comparison algorithms [ 1 , 2 ], generative models for protein families [ 3 , 4 ], and discriminative classifiers [ 5 , 6 , 7 ]. Popular sequence comparison methods such as BLAST * Supplemental information for the paper , including the data sets and Matlab source code can be found on this author ’ s web page at and Smith - Waterman are based on unsupervised alignment scores . Generative models such as profile hidden Markov models ( HMMs ) model positive examples of a protein family , but they can be trained iteratively using both positively labeled and unlabeled examples by pulling in close homologs and adding them to the positive set . A compromise between these methods is PSI - BLAST [ 8 ], which uses BLAST to iteratively build a probabilistic profile of a query sequence and obtain a more sensitive sequence comparison score .",Method,Code,Produce,Semi-supervised Protein Classification Using Cluster Kernels,https://proceedings.neurips.cc/paper/2003/hash/12ffb0968f2f56e51a59a6beb37b2859-Abstract.html
is the maximum possible pixel value and Qe is the mean - square error between the noisy and original images . We also tested the AMC - SSDA as pre - processing step in an image classification task by corrupting MNIST database of handwritten digits [ 19 ] with various types of noise and then denoising and classifying the digits with a classifier trained on the original images ( Section 4 . 2 ). Our code is available at : _CITE_,Method,Code,Produce,Adaptive Multi-Column Deep Neural Networks with Application to Robust Image Denoising,https://proceedings.neurips.cc/paper/2013/hash/e49b8b4053df9505e1f48c3a701c0682-Abstract.html
"Meanwhile , our results are achieved at a test - time speed of 170ms per image using ResNet - 101 , which is 2 . 5x to 20x faster than the Faster R - CNN + ResNet - 101 counterpart in [ 10 ]. These experiments demonstrate that our method manages to address the dilemma between invariance / variance on translation , and fully convolutional image - level classifiers such as ResNets can be effectively converted to fully convolutional object detectors . Code is made publicly available at : _CITE_",Method,Code,Produce,R-FCN: Object Detection via Region-based Fully Convolutional Networks,https://proceedings.neurips.cc/paper/2016/hash/577ef1154f3240ad5b9b413aa7346a1e-Abstract.html
"The PROP - diff , PROP - WL and the WL kernel were each run with 10 iterations . In the CSM kernel , the clique size parameter was set to k = 5 . Our kernel implementations and datasets ( with the exception of AIRWAYS ) can be found at Classification experiments were made on four datasets : ENZYMES , PROTEINS , AIRWAYS and SYNTHETIC . ENZYMES and PROTEINS are sets of proteins from the BRENDA database [ 22 ] and the dataset of Dobson and Doig [ 23 ], respectively .",Method,Code,Produce,Scalable kernels for graphs with continuous attributes,https://proceedings.neurips.cc/paper/2013/hash/a2557a7b2e94197ff767970b67041697-Abstract.html
"We trained the networks using an implementation based on Caffe [ 25 ]. Details on the training , the hyperparameter settings , and an analysis of the performance depending on the network architecture is provided in the supplementary material . Our code and training data are available at . We applied the feature representation to images of arbitrary size by convolutionally computing the responses of all the network layers except the top softmax . To each feature map , we applied the pooling method that is commonly used for the respective dataset : 1 ) 4 - quadrant max - pooling , resulting in 4 values per feature map , which is the standard procedure for STL - 10 and CIFAR - 10 [ 26 , 10 , 27 , 12 ]; 2 ) 3 - layer spatial pyramid , i . e .",Method,Code,Produce,Discriminative Unsupervised Feature Learning with Convolutional Neural Networks,https://proceedings.neurips.cc/paper/2014/hash/07563a3fe3bbe7e3ba84431ad9d055af-Abstract.html
"We tested PEA regularization in three scenarios : supervised learning on MNIST digits , semi - supervised learning on MNIST digits , and semi - supervised transfer learning on a dataset from the NIPS 2011 Workshop on Challenges in Learning Hierarchical Models [ 13 ]. Full implementations of our methods , written with THEANO [ 3 ], and scripts / instructions for reproducing all of the results in this section are available online at : _CITE_",Method,Code,Produce,Learning with Pseudo-Ensembles,https://proceedings.neurips.cc/paper/2014/hash/66be31e4c40d676991f2405aaecc6934-Abstract.html
"Finally , using our method – which we dub Bayesian Optimization with Hamiltonian Monte Carlo Artificial Neural Networks ( BOHAMIANN ) – we demonstrate state - of - the - art performance for a wide range of optimization tasks . This includes multi - task BO , parallel optimization of deep residual networks , and deep reinforcement learning . An implementation of our method can be found at _CITE_",Method,Code,Produce,Bayesian Optimization with Robust Bayesian Neural Networks,https://proceedings.neurips.cc/paper/2016/hash/a96d3afec184766bfeca7a9f989fc7e7-Abstract.html
"We also find that a low rank version is able to achieve approximately 23 × compression of the original data , with the optimal solution very close to the full rank optimum . Our method is a superior predictor to the existing regional model for visual system data , and the success of the low rank version suggests that this approach will be able to reveal whole - brain structural connectivity at unprecedented scale . All of our supplemental material and data processing and optimization code is available for download from : _CITE_",Method,Code,Produce,High resolution neural connectivity from incomplete tracing data using nonnegative spline regression,https://proceedings.neurips.cc/paper/2016/hash/f337d999d9ad116a7b4f3d409fcc6480-Abstract.html
"Box 5 has a different structural status than the other boxes : it marks the ends of sentences . We included box 5 , placing it in the center of the visual array , and making it smaller than the other boxes , to make the task easier relative to a pilot version in which Box 5 was absent . 2 . 1 Simulation Experiment We employed Michal Cernansky ’ s implementation of Elman ( 1990 )’ s Simple Recurrent Network ( ). The network had five input units , five output units and ten hidden units . Activations changed as specified in ( 1 ) and weights changed according to ( 2 ).",Method,Code,Use,Fractal Unfolding: A Metamorphic Approach to Learning to Parse Recursive Structure,https://aclanthology.org/W12-1704.pdf
"The ASR check condition also involved issuing a warning flag , but in contrast with the previous condition , every audio segment was compared to an expected input , and this time the expected transcript was produced by ASR . String overlap was also calculated using Equation 1 , but to account for the higher WER for the ASR output than a human transcript , we lowered the threshold of overlap to 20 % in comparison with the 30 % overlap for expert - produced transcripts . 1JavaScript implementation taken from : A total of 149 users participated in the transcription tasks of EGY audio . The average WER for each user was calculated based on comparing each transcript to the four other user - provided transcripts for each item . As shown in Figure 3 , there were different distributions of above - average and below - average users across conditions .",Method,Code,Use,Best Practices for Crowdsourcing Dialectal Arabic Speech Transcription,https://aclanthology.org/W15-3211.pdf
"The data for BWI was obtained using the TIES implementation [ tcc . itc . it / research / textec / toolsresources / ties . html ]. The data for the LP2 learning curve was obtained from ( Ciravegna , 2003 ). The results for ELIE were generated by the current implementation [ For the CRF results , we used MALLET ’ s SimpleTagger ( McCallum , 2002 ), with each token encoded with a set of binary features ( one for each observed literal , as well as the eight token generalizations ). Our results in Fig .",Method,Code,Use,Transductive Pattern Learning for Information Extraction,https://aclanthology.org/W06-2204.pdf
To test our approach for PLSA initialization we developed an LSA implementation based on the SVDLIBC package ( dr / SVDLIBC /) for computing the singular values of sparse matrices . The PLSA implementation was based on an earlier implementation by Brants et al . ( 2002 ).,Method,Code,Use,Improving Probabilistic Latent Semantic Analysis with Principal Component Analysis,https://aclanthology.org/E06-1014.pdf
"Further information ( terms and frequencies ) is displayed thanks to tooltips ( see Figure 2 ), using the JavaScript overLIB libray ( ).",Method,Code,Use,Multilingual Term Extraction from Domain-specific Corpora Using Morphological Structure,https://aclanthology.org/E06-2022.pdf
"( Fujii et al ., 2008 ) We applied CaboCha ( Kudo and Matsumoto , 2002 ) to the reference sentences , and manually corrected the dependency trees because Japanese dependency parsers are not satisfactory in terms of sentence accuracy ( Tamura et al ., 2007 ). To support this manual correction , CaboCha ’ s XML output was automatically converted to dependency tree pictures by using cabochatrees package for LATEX . uploads / cabochatrees . pdf . Then , it is easy to find mistakes of the dependency trees . In addition , CaboCha ’ s dependency accuracy is very high ( 89 – 90 %) ( Kudo and Matsumoto , 2002 ).",Method,Code,Use,Dependency-based Automatic Enumeration of Semantically Equivalent Word Orders for Evaluating Japanese Translations,https://aclanthology.org/W14-3335.pdf
"However , because text - processing is more advanced in this regard than image - processing , we shall concentrate on NER , which is performed with a system called Oscar . A preliminary overview of the system was presented by Corbett and Murray - Rust ( 2006 ). Oscar is open source and can be downloaded from As a first step in representing biomedical content , we identify Gene Ontology ( GO ) terms in full text . 1 ( The Gene Ontology Consortium , 2000 ) We have chosen a relatively simple starting point in order to gain experience in implementing useful semantic markup in a publishing workflow without a substantial word - sense disambiguation effort . GO terms are largely compositional ( Mungall , 2004 ), hence incomplete matches will still be useful , and that there is generally a low level of semantic ambiguity . For example , there are only 133 single - word GO terms , which significantly reduces the chance of polysemy for the 20000 or so others .",Method,Code,Use,Semantic enrichment of journal articles using chemical named entity recognition,https://aclanthology.org/P07-2012.pdf
"We also investigated the contribution of the feature nodes by running HTP without them . In addition , we ran HTP on a bipartite graph , i . e ., one created from English - foreign phrase alignments only without any phrase alignments between foreign languages . We used Callison - Burch ( 2008 )’ s implementation of SBP that is publicly available at SBP is based on BCB ( Bannard and Callison - Burch , 2005 ) which computes the probability that English phrase E ' is a paraphrase of E using the following formula :",Method,Code,Use,Hitting the Right Paraphrases in Good Time,https://aclanthology.org/N10-1017.pdf
"Of course , the results on both tracks are welcomed . Scoring was done automatically using a combination of Perl and shell scripts . The scripts ( Sproat and Emerson , 2003 , 2005 ) used for scoring can be downloaded from The bakeoff organizer provided an on - line scoring system to all the participants who had submitted their bakeoff results for their follow - up experiments .",Method,Code,Use,The CIPS-SIGHAN CLP 2010 Chinese Word Segmentation Bakeoff,https://aclanthology.org/W10-4126.pdf
"We use regular expression pattern to detect . errors in words by using word weight ( Wazn ) and affixes . For example we can detect that words with the 1 The script is named AkhtaBot , which is applied to arabic wikipedia , the Akhtabot is available on weight INFI ' AL لﺎﻌﻔﻧا must be written by Hamza Wasl , and we consider the form لﺎﻌﻔﻧإ * as wrong . Then , we represent all forms of this weight with all possible affixes .",Method,Code,Use,Autocorrection Of Arabic Common Errors For Large Text Corpus,https://aclanthology.org/W14-3616.pdf
"We formu late our problem in terms of MALLET ’ s SimpleTagger class which is a command line interface to the MALLET CRF class . We modify the SimpleTagger class in order to include the provision for producing corresponding posterior probabilities of the predicted labels which are used later for ranking sentences . We build the MaxEnt system using Dr . Dekang Lin ’ s MaxEnt package . To define the exponential prior of the A values in MaxEnt models , an extra parameter α is used in the package during training . We keep the value of α as default .",Method,Code,Use,Supervised Approaches to Complex Question Answering,https://www.sadidhasan.com/sadid-PACLING.pdf
"Metric : We use the case - insensitive 4gram NIST BLEU as our evaluation metric , with statistical significance test with signtest ( Collins et al ., 2005 ) between the proposed models and two baselines . We use the tagCNN and inCNN joint language models as additional decoding features to a dependency - to - string baseline system ( Dep2Str ), and compare them to the neural network joint model with 11 source context words ( Devlin et al ., 2014 ). We use the implementation of an open source toolkit with default configuration except the global settings described in Section 5 . 1 . Since our tagCNN and inCNN models are source - totarget and left - to - right ( on target side ), we only take the source - to - target and left - to - right type NNJM in ( Devlin et al ., 2014 ) in comparison . We call this type NNJM as BBN - JM hereafter .",Method,Code,Use,Encoding Source Language with Convolutional Neural Network for Machine Translation,https://arxiv.org/abs/1503.01838
An additional data - set was added with random data to act as an outlier to root the tree . PHILOLOGICON software was then used to calculate the lexical metrics corresponding to the individual data files and to measure KL divergences and Rao distances between them . The program NEIGHBOR from the PHYLIP package was used to construct trees from the results . The tree based on Rao distances is shown in figure 1 . The discussion follows this tree except in those few cases mentioning differences in the KL tree .,Method,Code,Use,Measuring Language Divergence by Intra-Lexical Comparison,https://dl.acm.org/doi/pdf/10.3115/1220175.1220210
"Section 2 includes an overview of these debate forum data sets . In the experiments , classification accuracy was estimated via five repeats of 5 - fold crossvalidation . In each fold , we ran logistic regression using the scikit - learn software package , using the default settings , except for the L1 regularization trade - off parameter C which was tuned on a within - fold hold - out set consisting of 20 % of the discussions within the fold . For the collective models , weight learning was performed on the same in - fold tuning sets . We trained via 700 iterations of structured perceptron , and ran the ADMM MAP inference algorithm to convergence at test time .",Method,Code,Use,Joint Models of Disagreement and Stance in Online Debate,https://aclanthology.org/P15-1012.pdf
"We experimented with various combinations of E1 - and E2 - loss SVMs , with both E1 and E2 - regularization , but in the end opted to use the E2 - regularized logistic regression due to slightly superior performance and the ease with which we could extract eleven values of P ( H ) for inclusion in our ensemble . Another component that was tested in development of our ensemble systems was a maximum entropy classifier . This particular effort used the implementation from JCarafe , which uses L - BFGS for optimization . We approached the NLI task as document classification , following a typical JCarafe recipe ( Gibson et al ., 2007 ). The class of the document is the native language of the author .",Method,Code,Use,Discriminating Non-Native English with 350 Words,https://aclanthology.org/W13-1713.pdf
"This result is much lower than the best F1 score for English reported at the CoNLL - 2000 chunking competition : 94 . 13 %. However , this comparison should be treated with caution since we did no special adaptation of the features to Bulgarian . We should also note that the ChunkLink script , used at CoNLL - 2000 , was tailored to the Penn Treebank tagset , and was thus not very suitable to our collapsed BulTreeBank tagset . The syntactic parser : Unfortunately , we were unable to evaluate our parser with the full morphosyntactic tagset of the BulTreeBank ; this would have required coding efforts for some parts of speech , e . g ., nouns , that go beyond simple adaptation . On our collapsed tagset , we achieved an F1 score of 77 . 56 %.",Method,Code,Use,Cross-lingual Adaptation as a Baseline: Adapting Maximum Entropy Models to Bulgarian,https://aclanthology.org/W09-4105.pdf
"When the training data is much smaller , the upper bound of the CL approach would decrease tremendously , whereas the upper bound of the CoRef approach remains the same . As mentioned before , most existing language ID algorithm falls into this category . We chose TextCat , an implementation of Cavnar - Trenkle ’ s algorithm ( 1994 ), as an example of these algorithms . In order to take advantage of the context information , we trained several classifiers ( e . g ., decision tree , Naive Bayes , and maximum entropy ) using the Mallet package ( McCallum , 2002 ) and a SVM classifier using the libSVM package ( Chang and Lin , 2001 ). The result is in Table 7 .",Method,Code,Use,Language ID in the Context of Harvesting Language Data off the Web,https://aclanthology.org/E09-1099.pdf
"For policy training , we train a linear SVM classifier using Liblinear ( Fan et al ., 2008 ). For all languages , we run DAgger for 20 iterations and se lect the best policy evaluated on the development set among the 20 policies obtained from each iteration . We use the publicly available implementation of MSTParser ( with modifications to the feature computation ) and its default settings , so the feature weights of the projective and non - projective parsers are trained by the MIRA algorithm ( Crammer and Singer , 2003 ; Crammer et al ., 2006 ). Our feature set contains most features proposed in the literature ( McDonald et al ., 2005a ; Koo and Collins , 2010 ). The basic feature components include lexical features ( token , prefix , suffix ), POS features ( coarse and fine ), edge length and direction .",Method,Code,Use,Dynamic Feature Selection for Dependency Parsing,https://aclanthology.org/D13-1152.pdf
"In order to do so , we index target documents t in the collection thanks to an indexing strategy φ that will be described shortly . Then , for a source document s , we first index it , that is , we compute φ ( s ), and query the retrieval engine with φ ( s ), which in turn returns the N most similar target documents found in the collection . In our experiments , we used the Lucene retrieval library . We tested two indexing strategies : one reduces a document to the sequence of hapax words it contains ( φ - hap ), the other one reduces it to its sequence of numerical entities ( φ - num ). Hapax words have been found very useful in identifying parallel pairs of documents ( Enright and Kondrak , 2007 ) as well as for word - aligning bitexts ( Lardilleux and Lepage , 2007 ).",Method,Code,Use,Identifying Parallel Documents from a Large Bilingual Collection of Texts: Application to Parallel Article Extraction in Wikipedia.,https://aclanthology.org/W11-1212.pdf
"The data from the tweets was cleaned by removing the tweets that were not in English as well as the retweets ; i . e ., re - publications of a tweet by a different user . We deduplicated the 16 , 000 extracted URLs into 6 , 003 unique addressed , then extracted and preprocessed their contents . The newspaper package was used to extract article text and the title from the web page . Since we are interested in text articles that can serve as the source text for summarization algorithms , we needed to remove photos and video links such as those from Instagram and YouTube . To do so , we removed those links that contained fewer than a threshold of 150 words .",Method,Code,Use,Indicative Tweet Generation: An Extractive Summarization Problem?,https://aclanthology.org/D15-1014.pdf
"Due to MaxEnt ’ s capability to combine multiple and dependent knowledge sources , we employed MaxEnt as our machine learning model . Features we used to train the model include meta information features and collocation features . Meta Information Features include three features : We use the OpenNLP MaxEnt Java library as the MaxEnt trainer and classifier . For each hedge cue , the training is iterated 100 times , with no cut off threshold for events . We first ran experiments to evaluate the performance of the entire system .",Method,Code,Use,A Lucene and Maximum Entropy Model Based Hedge Detection System,https://aclanthology.org/W10-3016.pdf
"With these two resources combined , there are four stages of word level matching in our system : exact match , stem match , WordNet match and unigram paraphrase match . The stemming module uses Porter ’ s stemmer implementation and the WordNet module uses the JAWS WordNet interface . Our metric only considers unigram paraphrases , which are extracted from the paraphrase database in TERP using the script in the METEOR metric . The metric described in ( Owczarzak et al ., 2007 ) does not explicitly consider word order and fluency . METEOR , on the other hand , utilizes this information through a chunk penalty .",Method,Code,Use,The DCU dependency-based metric in WMT-MetricsMATR 2010,https://doras.dcu.ie/15796/
"We also use the same development set and test set provided by the shared task . The in - domain test set includes 2 , 000 sentences and the out - of - domain test set includes 1 , 064 sentences for each language . To perform phrase - based SMT , we use Koehn ' s training scripts and the Pharaoh decoder ( Koehn , 2004 ). We run the decoder with its default settings and then use Koehn ' s implementation of minimum error rate training ( Och , 2003 ) to tune the feature weights on the development set . The translation quality was evaluated using a well - established automatic measure : BLEU score ( Papineni et al ., 2002 ).",Method,Code,Use,Pivot Language Approach for Phrase-Based Statistical Machine Translation,https://www.jstor.org/stable/30219554
"Concretely , the following features were computed from the original Twitter messages : We used the L2 - regularized logistic regression implementation from scikit - learn . Given a set of m instance - label pairs ( xi , yi ), with i = 1 , ... , m , xi E Rn , and yi E {− 1 , + 1 }, learning the classifier involves solving the following optimization problem , where C & gt ; 0 is a penalty parameter . In scikit - learn , the problem is solved through a trust region Newton method , using a wrapper over the implementation available in the liblinear package . For multi - class problems , scikitlearn uses the one - vs - the - rest strategy . This particular implementation also suports the introduction of class weights , which we set to be inversely proportional to the class frequency in the training data , thus making each class equally important .",Method,Code,Use,TUGAS: Exploiting Unlabelled Data for Twitter Sentiment Analysis,https://aclanthology.org/S14-2120.pdf
"In this task , Yamcha obtained the best performance for a quadratic kernel with a c value of 0 . 5 . All results presented here use this setting . For CRF , we used the Mallet software package . Experiments are done only with order - 0 CRFs . CRFs proved to marginally improve the prediction accuracy while substantially improving the speed .",Method,Code,Use,Uncertainty Learning Using SVMs and CRFs,https://aclanthology.org/W10-3019.pdf
"FreebaseEasy is a processed version of Freebase ( Bollacker et al ., 2008 ), which contains a unique meaningful name for every entity , together with canonical binary relations . For our experiments , we selected only the sentences containing at least two entities linked to FreebaseEasy , which corresponded to 1 . 2 million sentences . With the full articles set , we computed word embeddings with the skip - gram model using the word2vec implementation from Mikolov et . al . ( 2013a ).",Method,Code,Use,Semi-Supervised Bootstrapping of Relationship Extractors with Distributional Semantics,https://aclanthology.org/D15-1056.pdf
"The detailed definition of this measure as applied for each formalism is provided in ( Clark and Curran , 2003 ; Miyao and Tsujii , 2008 ; Cahill et al ., 2004 ). For CCG , we use the evaluation script from the C & C tools . For HPSG , we evaluate all types of dependencies , including punctuations . For LFG , we consider the preds - only dependencies , which are the dependencies between pairs of words . Secondly , we also evaluate using unlabeled PARSEVAL , a standard measure for PCFG parsing ( Petrov and Klein , 2007 ; Charniak and Johnson , 2005 ; Charniak , 2000 ; Collins , 1997 ).",Method,Code,Use,Transfer Learning for Constituency-Based Grammars,https://aclanthology.org/P13-1029.pdf
"We only need to parse the source side of the tuning and test sets , and the only features that look at the source - side parse are those from § 4 . 3 . To obtain Brown clusters for the target tree features in § 4 . 1 , we used code from Liang ( 2005 ). We induced 100 clusters from the English side of the parallel corpus concatenated with 10M words of randomly - selected Gigaword sentences . Only words that appeared at least twice in this data were considered during clustering . An additional cluster was created for all other words ; this allowed us to use phrase dependency cluster features even for out - ofvocabulary words .",Method,Code,Use,Quasi-Synchronous Phrase Dependency Grammars for Machine Translation,https://aclanthology.org/D11-1044.pdf
"While POS taggers such as TreeTagger are common , and there some supertaggers are available , notably that of Clark and Curran ( 2007 ) for CCG , no standard supertagger exists for HPSG . Consequently , we developed a Maximum Entropy model for supertagging using the OpenNLP implementation . Similarly to Zhang and Kordoni ( 2006 ), we took training data from the gold – standard lexical types in the treebank associated with ERG ( in our case , the July - 07 version ). For each token , we extracted features in two ways . One used features only from the input string itself : four characters from the beginning and end of the target word token , and two words of context ( where available ) either side of the target .",Method,Code,Use,Enhancing Performance of Lexicalised Grammars,https://aclanthology.org/P08-1070.pdf
"We used this model for searching in - vocabulary queries . To handle OOV queries , a combination of word and phonetic search was presented by Mamou ( Mamou et al ., 2007 ). In this paper , we explore fuzzy phonetic search extending Lucene , an Apache open source search library written in Java , for indexing and search . When searching for these OOVs in word - fragment indexes , they are represented phonetically ( and subsequently using wordfragments ) using letter - to - phoneme ( L2P ) rules . Each transcript is composed of basic units ( e . g ., word , word - fragment , phones ) associated with a begin time , duration and posterior probability .",Method,Code,Use,Fast decoding for open vocabulary spoken term detection,https://aclanthology.org/N09-2070.pdf
"We use maximum likelihood estimators ( MLE ) for estimating the parameters ( p , Oz ). The MLEs for Bernoulli and MVN parameters have analytical solutions . Dirichlet parameters were estimated using an estimation method proposed and implemented by Tom Minka . We experiment with three model setups : Supervised , semi - supervised , and unsupervised . In the supervised setup we use the training data described in Section 3 . 1 for parameter estimation and then use thus fitted models to classify the tuning and test dataset .",Method,Code,Use,Dictionary Definitions based Homograph Identification using a Generative Hierarchical Model,https://dl.acm.org/doi/pdf/10.5555/1557690.1557713
"We therefore experiment with three types of machine learning algorithms : a standard classifier , an ordinal ( ranking ) classifier and a regressor . Each algorithm assumes different relations among the groups : the classifier assumes no relation , the ordinal classifier assumes that the groups are ordered , and the regressor assumes that the groups are continuous . As classifier we use the Support Vector Machines ( SVM ) implementation in the Weka toolkit ( SMO ). As ordinal classifier we use a meta classifier in Weka which takes SMO as the base classification algorithm and performs pairwise classifications ( OrdinalClassClassifier ). For regression we use the SVM regression implementation in Weka ( SMO - reg ).",Method,Code,Use,Readability Assessment for Text Simplification,https://aclanthology.org/W10-1001.pdf
"The CBOW and skip - gram embeddings were induced using the word2vec tool , while we used our own implementation of the structured skipgram . The default values in word2vec were employed for most of the parameters , but we set the negative sampling rate to 25 words ( Goldberg and Levy , 2014 ). For the GloVe model , we used the available implementation with the default parameters . In all the models , words occurring less than 100 times in the corpus were discarded , resulting in a vocabulary of around 210 , 000 tokens . Finally , embeddings of different sizes were built , with 50 , 200 , 400 and 600 dimensions .",Method,Code,Use,INESC-ID: A Regression Model for Large Scale Twitter Sentiment Lexicon Induction,https://www.cs.cmu.edu/~lingwang/papers/semeval1.pdf
"acquired web pages that have almost the same content ) are reviewed and compared in Theobald et al . ( 2008 ). Efficient focused web crawlers can be built by adapting existing open - source frameworks like Heritrix , Nutch and Bixo . For instance , Combine is an open - source focused crawler that is based on a combination of a general web crawler and a text classifier . Other approaches make use of search engines APIs to identify in - domain web pages ( Hong et al ., 2010 ) or multilingual web sites ( Resnik and Smith , 2003 ).",Method,Code,Use,Domain adaptation of statistical machine translation with domain-focused web crawling,https://link.springer.com/article/10.1007/s10579-014-9282-3
"In other words , we intersected the terms in sentence 1 with all the conceptual term lists in sentence 2 . After computing all the co - occurrences , we used these values to calculate the Jaccard ’ ( Jaccard , 1901 ), Lin ’ ( Lin , 1998 ) and PMI ’ ( Turney , 2001 ) scores . This feature takes advantage of the Align , Disambiguate and Walk ( ADW ) library ( Pilehvar et al ., 2013 ), a WordNet - based approach for measuring semantic similarity of arbitrary pairs of lexical items . It is important to mention that this feature is the only one that only works for English , which explains why we have a translation model ( see section 2 . 1 . 3 ). In other words , when we are dealing with Spanish text , we use the trained model to translate from Spanish to English .",Method,Code,Use,MiniExperts: An SVM Approach for Measuring Semantic Textual Similarity,https://aclanthology.org/S15-2017.pdf
"We first removed the XML tags from data and then transformed the abbreviations to their normal form s , i . e ., “ don ’ t ” to “ do not ”. We used Stanford Parser tools for tokenization , POS tagging and parsing . Finally , the WordNet - based Lemmatizer implemented in NLTK was adopted to lemmatize words to their base forms with the aid of their POS tags . In this work , we used three types of features : sentiment lexicon features , linguistic features and domain - specific features . All features were extracted from pending words as described above .",Method,Code,Use,ECNU: Extracting Effective Features from Multiple Sequential Sentences for Target-dependent Sentiment Analysis in Reviews,https://aclanthology.org/S15-2125.pdf
"However , in larger sets , e . g . “ autism ”, it took 46 . 9 and 31 . 3 seconds for LDA and PAV - EM , respectively . We also ran another implementation of LDA , which was 30 times slower than Mallet . While PAV - EM and LDA can be implemented in parallel computation , this indicates that PAV - EM may be more efficient to obtain themes for a larger set of PubMed documents . The PAV - EM algorithm automatically learns themes from unlabeled PubMed documents , hence the performance measures that are used in supervised learning cannot be applied to our setup .",Method,Code,Use,Summarizing topical contents from PubMed documents using a thematic analysis,https://aclanthology.org/D15-1094.pdf
"Thus an average ROUGE score is assigned to each sentence in the document . We choose the top N sentences based on ROUGE scores to have the label + 1 ( summary sentences ) and the rest to have the label − 1 ( non - summary sentences ). Basic Element ( BE ) Overlap Measure We extract BEs , the “ head - modifier - relation ” triples for the sentences in the document collection using BE package 1 . 0 distributed by ISI . The ranked list of BEs sorted according to their Likelihood Ratio ( LR ) scores contains important BEs at the top which may or may not be relevant to the abstract summary sentences . We filter those BEs by checking possible matches with an abstract sentence word or a related word .",Method,Code,Use,Selecting Sentences for Answering Complex Questions,https://aclanthology.org/D08-1032.pdf
"For the knowledge - based measures , we use the WordNet - based implementation of the word - toword similarity metrics , as available in the WordNet :: Similarity package ( Patwardhan et al ., 2003 ). For latent semantic analysis , we use the InfoMap package . For ESA , we use our own implementation of the ESA algorithm as described in ( Gabrilovich and Markovitch , 2006 ). Note that all the word similarity measures are normalized so that they fall within a 0 – 1 range . The normalization is done by dividing the similarity score provided by a given measure with the maximum possible score for that measure .",Method,Code,Use,Text-to-text Semantic Similarity for Automatic Short Answer Grading,https://aclanthology.org/E09-1065.pdf
"We call clusters that satisfy this property singleton clusters . To obtain Brown clusters for the source and target languages , we used code from Liang ( 2005 ). We used the data from the news commentary corpus along with the first 500K sentences of the additional monolingual newswire data also provided for the WMT shared tasks . We used 300 clusters , ignoring words that appeared only once in this corpus . We did not use the hierarchical information from the clusters but merely converted each cluster name into a unique integer , using one additional integer for unknown words .",Method,Code,Use,Generative Models of Monolingual and Bilingual Gappy Patterns,https://aclanthology.org/W11-2165.pdf
"At the start of the session the relative positions of the MEG and EEG sensors were determined using a Polyhemus 3 - D digitisation system . Data preprocessing was conducted using the MNE , FieldTrip and EEGLAB packages . The data was band - pass filtered at 1 - 50Hz to remove slow drifts in the signal and high - frequency noise , and then down - sampled to 125Hz . Eye and muscle artefacts were not removed , but these lie outside the range of frequencies that were considered in the analysis described below . The analysis method first applies a time / frequency filter to select an information - rich band and interval for the distinction of interest ; a supervised decomposition to extract components of whole - scalp synchronous activity that are sensitive to this class distinction ( Common Spatial Patterns , or CSP – see Parra et al ., 2005 ; Model and Zibulevsky , 2006 ; Philiastides et al ., 2006 for examples of other applications to cognitive neuroscience ); and a general purpose machine learning algorithm ( SupportVector Machine or SVM ) that uses the resulting measures of signal power to predict the semantic class of each trial .",Method,Code,Use,Detecting Semantic Category in Simultaneous EEG/MEG Recordings,https://aclanthology.org/W10-0605.pdf
"The data set includes a list of 11 , 340 notable individuals with the link to their Wikipedia page in multiple languages , plus a number of additional information such as date and place of birth , category and language editions , which we do not consider for our study . Only the persons whose Wikipedia page is translated in at least 25 languages are included in Pantheon , as a proxy of prominent world personalities . For each person in the list , we download the corresponding Wikipedia page in English and preprocess it using TheWikiMachine library . Overall , we collect 11 , 075 pages , while 265 pages could not be retrieved because of problems with the links ( mainly redirection links ). We randomly select 100 pages as development set , 500 pages for test and the remaining 10 , 475 for building the training set .",Method,Code,Use,Recognizing biographical sections in wikipedia,https://cris.fbk.eu/handle/11582/301635
"The first step involves extraction of semantic and temporal features for the annotated medical concepts , as described in Section 4 from both corpora . The semantic relatedness scores are computed using the kDLS ( Xiang et al ., 2011 ) method to calculate the relationship between concepts in the UMLS with value of - y set to 7 . The type of relation between medical concepts is derived by matching word stems in each medical concept using the Lucene implementation of the Porter stemming algorithm . We query the latest release ( UMLS 2011AB ) of the UMLS Metathesaurus for finding a match between medical concept and the UMLS definition or UMLS atoms . The WordNet similarity score is computed using Java API for WordNet Searching ( JAWS ). 10 Explicit temporal expressions annotated in the corpora are included in our temporal feature set .",Method,Code,Use,Exploring semi-supervised coreference resolution of medical concepts using semantic and temporal features,https://www.researchgate.net/publication/262153328_Exploring_semi-supervised_coreference_resolution_of_medical_concepts_using_semantic_and_temporal_features
"The system behavior can be controlled by passing arguments through the command line interface . For example , the user can specify which clustering algorithm should be used . To facilitate using the system for research purposes , the system comes with a clustering evaluation component that uses the ClusterEvaluator package . . If the input to the system contains subgroup labels , it can be run in the evaluation mode in which case the system will output the scores of several different clustering evaluation metrics such as purity , entropy , f - measure , Jaccard , and RandIndex . The system also has a Java API that can be used by researchers to develop other systems using our code .",Method,Code,Use,Subgroup Detector: A System for Detecting Subgroups in Online Discussions,https://aclanthology.org/P12-3023.pdf
"In this illustration , for computational reasons , the data is sub - sampled to 100 data - points . Figure 1 shows visualisations of the data using both PCA and our GPLVM algorithm which required 766 iterations of SCG . The positions for the GPLVM model were initialised using PCA ( see for the MATLAB code used ). The gradient based optimisation of the RBF based GPLVM ’ s latent space shows results which are clearly superior ( in terms of greater separation between the different flow domains ) to those achieved by the linear PCA model . Additionally the use of a Gaussian process to perform our ‘ mapping ’ means that there is uncertainty in the positions of the points in the data space .",Method,Code,Use,Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data,https://proceedings.neurips.cc/paper/2003/hash/9657c1fffd38824e5ab0472e022e577e-Abstract.html
"We use a Riemannian trust - region ( RTR ) method [ ABG07 ] to minimize ( 10 ), via the freely available Matlab package GenRTR ( version 0 . 3 . 0 ) with its default parameter values . The package is available at this address : At the current iterate OZI = col ( U ), the RTR method uses the retraction RU ( 8 ) to build a quadratic model mU : TUg ( m , r ) → ] IR of the lifted objective function f o RU ( lift ). It then classically minimizes the model inside a trust region on this vector space ( solve ), and retracts the resulting tangent vector H to a candidate U + = RU ( H ) on the Grassmannian ( retract ).",Method,Code,Use,RTRMC: A Riemannian trust-region method for low-rank matrix completion,https://proceedings.neurips.cc/paper/2011/hash/37bc2f75bf1bcfe8450a1a41c200364c-Abstract.html
"In the experiments , we compared our ODC with four different clustering algorithms , i . e ., the conventional K - means [ 1 ], normalized cut ( NC ) [ 9 ], DisCluster [ 3 ] and DisKmeans [ 13 ]. It is worth noting that two discriminative clustering algorithms : DisCluster [ 3 ] and DisKmeans [ 13 ], are very closely related to our ODC , because they are derived from the discriminant analysis criteria in essence ( also see the analysis in Section 3 . 3 ). In addition , the implementation code for NC is available at For the sake of simplicity , the parameter Q2 in ODC is sought from the range Q2 E { 10 − 3 , 10 − 2 . 5 , 10 − 2 , 10 − 1 . 5 , 10 − 1 , 10 − 0 . 5 , 100 , 100 . 5 , 101 , 101 . 5 , 102 , 102 . 5 , 103 }. Similarly , the parameters in other clustering algorithms compared here are also searched in a wide range .",Method,Code,Use,Optimal Scoring for Unsupervised Learning,https://citeseerx.ist.psu.edu/viewdoc/download?rep=rep1&type=pdf&doi=10.1.1.214.8963
"Additionally , the proposed method for constructing splits based on fitting sub - clusters is , to our knowledge , the first parallelizable split algorithm for mixture models . Results on both synthetic and real data demonstrate that the speed of the sampler is orders of magnitude faster than other exact MCMC methods . Publicly available source code used in this work can be downloaded at _CITE_",Method,Code,Use,Parallel Sampling of DP Mixture Models using Sub-Clusters Splits,https://proceedings.neurips.cc/paper_files/paper/2013/file/bca82e41ee7b0833588399b1fcd177c7-Paper.pdf
"Table 1 reports the results obtained with PEWA on each individual image for different values of standard deviation of noise . Table 2 compares the average PSNR values on these 25 images obtained by PEWA ( after 1 and 2 iterations ) and two state - of - the - art denoising methods [ 6 , 12 ]. We used the implementations provided by the authors : BM3D ( ) and NL - Bayes ( www . ipol . im ). The best PSNR values are in bold and the results are quantitatively quite comparable except for very high levels of noise . We compared PEWA to the baseline NL - means [ 2 ] and DCT [ 26 ] ( using the implementation of www . ipol . im ) since they form the core of PEWA .",Method,Code,Use,PEWA: Patch-based Exponentially Weighted Aggregation for image denoising,https://www.academia.edu/55977625/PEWA_Patch_based_Exponentially_Weighted_Aggregation_for_image_denoising
"In this section , we show the denoising results of Neural DUDE for the synthetic binary data , real binary images , and real Oxford Nanopore MinION DNA sequence data . All of our experiments were done with Python 2 . 7 and Keras package ( ) with Theano [ 17 ] backend .",Method,Code,Use,Neural Universal Discrete Denoiser,https://proceedings.neurips.cc/paper/2016/hash/f83630579d055dc5843ae693e7cdafe0-Abstract.html
"We take the Theano implementation of DRAW provided at draw and use it to model the MNIST data set of handwritten digits . We then make a single modification to the model : we apply weight normalization to all weight vectors . As can be seen in figure 4 , this significantly speeds up convergence of the optimization procedure , even without modifying the initialization method and learning rate that were tuned for use with the normal parameterization .",Method,Code,Use,Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks,https://proceedings.neurips.cc/paper/2016/hash/ed265bc903a5a097f61d3ec064d96d2e-Abstract.html
"The measure III ( S ; R ; C ) thus translates all the conceptual features of intersection information into a well - defined analytical tool : Eq . 3 defines how III ( S ; R ; C ) can be computed numerically from real data once the distribution p ( s , r , c ) is estimated empirically . In practice , the estimated p ( s , r , c ) defines the space Ap where the problem defined in Eq . 2 should be solved . We developed a gradient - descent optimization algorithm to solve these problems numerically with a Matlab package that is freely available for download and reuse through Zenodo and Github ( see Supp . Info Sec . 2 ).",Method,Code,Use,Quantifying how much sensory information in a neural code is relevant for behavior,https://proceedings.neurips.cc/paper/2017/hash/a9813e9550fee3110373c21fa012eee7-Abstract.html
"Image intensity or RGB values are normalized to [ 0 1 ]. We extracted all low level features with 16x16 image patches over dense regular grids with spacing of 8 pixels . We used publicly available dense SIFT code at lazebnik [ 13 ], which includes spatial binning , soft binning and truncation ( nonlinear cutoff at 0 . 2 ), and has been demonstrated to obtain high accuracy for object recognition . For our gradient kernel descriptors we use the same gradient computation as used for SIFT descriptors . We also evaluate the performance of the combination of the three kernel descriptors ( KDES - A ) by simply concatenating the image - level features vectors .",Method,Code,Use,Kernel Descriptors for Visual Recognition,https://proceedings.neurips.cc/paper_files/paper/2010/hash/4558dbb6f6f8bb2e16d03b85bde76e2c-Abstract.html
"Comparison with RAPPOR [ 10 ]. Here we compare our implementation with the only publicly available code for locally private frequency estimation . We took the snapshot of the RAPPOR code base ( ) on May 9th , 2017 . To perform a fair comparison , we tested our algorithm against one of the demo experiments available for RAPPOR ( Demo3 using the demo . sh script ) with the same privacy parameter e = ln ( 3 ), the number of data samples n = 1 million , and the data set to be the same data set generated by the demo . sh script . In Figure 2 we observe that for higher frequencies both RAPPOR and our algorithm perform similarly , with ours being slightly better .",Method,Code,Use,Practical Locally Private Heavy Hitters,https://proceedings.neurips.cc/paper/2017/file/3d779cae2d46cf6a8a99a35ba4167977-Paper.pdf
"We evaluated the scalability of CO - Linear and CO - Quad by generating social networks of varying sizes , constructing CCMRFs with them , and measuring the running time required to find a MPE . We compared our approach to the previous state - of - the - art approach for finding MPEs in CCMRFs , which uses an interior point method implemented in MOSEK , a commercial optimization package ( ). Next we describe the social - network and CCMRF generation procedure , the implementations and setup , and then present the results .",Method,Code,Use,Scaling MPE Inference for Constrained Continuous Markov Random Fields with Consensus Optimization,https://proceedings.neurips.cc/paper/2012/hash/c5d736809766d46260d816d8dbc9eb44-Abstract.html
"The 20 amino acid types are represented by the letters A , C , D , E , F , G , H , I , K , L , M , N , P , Q , R , S , T , V , W , Y . Besides , a “ gap ” ( represented as “–”) is used as a 21st character to account for insertions and deletions . For the purpose of this work , all the input alignments have been generated with jackhmmer , part of HMMER package ( version 3 . 1b2 , ) run against the UniParc database released in summer 2015 . The alignment has been constructed with the E - value inclusion threshold of 1 , allowing for inclusion of distant homologs , at a risk of contaminating the alignment with potentially evolutionarily unrelated sequences . The resultant multiple sequence alignments have not been modified in any way , except for removal of inserts ( positions that were not present in the protein sequence of interest ).",Method,Code,Use,Protein contact prediction from amino acid co-evolution using convolutional networks for graph-valued images,https://proceedings.neurips.cc/paper/2016/hash/2cad8fa47bbef282badbb8de5374b894-Abstract.html
"Algorithms for solving this problem are nearly as efficient as those for solving regular min - cost flow problems . In case of word alignment , the running time scales with the cube of the sentence length . We use publicly - available code for solving this problem [ 8 ] ( see ).",Method,Code,Use,Structured Prediction via the Extragradient Method,https://proceedings.neurips.cc/paper/2005/hash/e465ae46b07058f4ab5e96b98f101756-Abstract.html
"Each results figure plots the progression of minxn f ( xn ) over the number of function evaluations or time , averaged over multiple runs of each algorithm . If not specified otherwise , xeext = argmaxx a ( x ) is computed using gradientbased search with multiple restarts ( see supplementary material for details ). The code used is made publicly available at _CITE_",Method,Code,Use,Practical Bayesian Optimization of Machine Learning Algorithms,https://proceedings.neurips.cc/paper_files/paper/2012/hash/05311655a15b75fab86956663e1819cd-Abstract.html
"More details concerning the experimental setup can be found at http :// www1 . cs . columbia . edu / compbio / svm - pairwise . In all experiments , we use an SVM classifier with a small soft margin parameter , set as in [ 7 ] . The SVM computations are performed using the freely available Spider Matlab machine learning package available at More information concerning the experiments , including data and source code scripts , can be found at http :// www . kyb . tuebingen . mpg . de / bs / people / weston / semiprot . Semi - supervised setting .",Method,Code,Use,Semi-supervised Protein Classification Using Cluster Kernels,https://proceedings.neurips.cc/paper/2003/hash/12ffb0968f2f56e51a59a6beb37b2859-Abstract.html
We studied the performance of the nonequilibrium marginal likelihood estimators on various challenging probabilistic models including Markov random fields and Gaussian mixture models . A python package implementing the work simulations and evidence estimators can be downloaded from _CITE_,Method,Code,Use,Model evidence from nonequilibrium simulations,https://proceedings.neurips.cc/paper_files/paper/2017/file/4da04049a062f5adfe81b67dd755cecc-Paper.pdf
"We show that a network with Leaky ReLU [ 17 ] and Batch Normalization [ 11 ] coupled with long - horizon training and progressive curriculum beats the rule - based built - in AI more than 70 % of the time in full - game Mini - RTS . We also show stronger performance in others games . ELF and its RL platform , is open - sourced at _CITE_",Method,Code,Use,"ELF: An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games",https://proceedings.neurips.cc/paper/2017/hash/3fb451ca2e89b3a13095b059d8705b15-Abstract.html
"We compare HMP to SIFT based single layer sparse coding because of its success in both computer vision and machine learning communities [ 24 , 23 , 5 , 6 ]. We extract SIFT with 16x16 image patches over dense regular grids with spacing of 8 pixels . We use the publicly available dense SIFT code at [ 14 ]. We perform sparse coding feature extraction using 1 , 000 visual words learned from 1 , 000 , 000 SIFT features , and compute image - level features by running spatial pyramid max pooling on 1 x 1 , 2 x 2 and 4 x 4 sub - regions [ 24 ].",Method,Code,Use,Hierarchical Matching Pursuit for Image Classification: Architecture and Fast Algorithms,https://www.researchgate.net/publication/267206536_Hierarchical_Matching_Pursuit_for_Image_Classification_Architecture_and_Fast_Algorithms
"This is the main tool of experimental nonlinear dynamics [ 8 ]; but the assumption of determinism is crucial and false , for almost any interesting neural system . While classical state - space reconstruction won ’ t work on stochastic processes , such processes do have state - space representations [ 11 ], and , in the special case of discretevalued , discrete - time series , there are ways to reconstruct the state space . Here we use the CSSR algorithm , introduced in [ 12 ] ( code available at ). This produces causal state models , which are stochastic automata capable of statistically - optimal nonlinear prediction ; the state of the machine is a minimal sufficient statistic for the future of the observable process [ 13 ]. 1 The basic idea is to form a set of states which should be ( 1 ) Markovian , ( 2 ) sufficient statistics for the next observable , and ( 3 ) have deterministic transitions ( in the automata - theory sense ). The algorithm begins with a minimal , one - state , IID model , and checks whether these properties hold , by means of hypothesis tests .",Method,Code,Use,Measuring Shared Information and Coordinated Activity in Neuronal Networks,https://arxiv.org/pdf/q-bio/0506009.pdf
"10 - 8 and Ek We run the code provided in and use default parameter settings to report the VB results . We also implemented the Rec - MCEM approach but only observed shrinkage of edges , not nodes .",Method,Code,Use,Scalable Model Selection for Belief Networks,https://proceedings.neurips.cc/paper/2017/hash/a6ea8471c120fe8cc35a2954c9b9c595-Abstract.html
"An implementation of semi - CRFs is available at , and a NER package using this package is available on http :// minorthird . sourceforge . net .",Method,Code,Use,Semi-Markov Conditional Random Fields for Information Extraction,https://www.cs.cmu.edu/~wcohen/postscript/semiCRF.pdf
"This is the same rate as for a wellspecified case where W  2 ([ 0 , 1 ] d ) was assumed for the construction of weighted points . Namely , we have shown that these methods are adaptive to the unknown smoothness of the integrand . For the algorithm by Bach [ 2 ], we conducted simulation experiments to support this observation , by using code available from The setting is what we have described with d = 1 , and weights are obtained without regularization as in [ 2 ]. The result is shown in Figure 1 , where r (= a ) denotes the assumed smoothness , and s (= a0 ) is the ( unknown ) smoothness of an integrand .",Method,Code,Use,Convergence guarantees for kernel-based quadrature rules in misspecified settings,https://arxiv.org/pdf/1605.07254.pdf
"We also use a larger minibatch size ( 64 ) which we found to be more efficient on our hardware ( Amazon Elastic Compute Cloud g2 . 2xlarge GPU instance ). Apart from these changes we follow [ 25 ] as closely as possible in terms of parameter settings and evaluation methods . However , we use a Python / Theano / Lasagne reimplementation of their work , adapted from the implementation available at , so there may be small additional differences in implementation . Figure 5 shows the training curves obtained using DQN with the standard parameterization and with weight normalization on Space Invaders . Using weight normalization the algorithm progresses more quickly and reaches a better final result .",Method,Code,Use,Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks,https://arxiv.org/pdf/1602.07868.pdf
"In this section , we empirically compare LLCA with the spectral clustering approach of [ 10 ] as well as with k - means clustering . For the last discretization step of LLCA ( cf . section 3 . 6 ), we use the same code contained in the implementation of the spectral clustering algorithm , available at _CITE_",Method,Code,Use,A Local Learning Approach for Clustering,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=115f7c6eb074cb71575dce430161ae551efe5dc4
"For the univariate densities , we use a standard Gaussian kernel density estimator ( see , for example , [ Bowman and Azzalini , 1997 ]). Using an identical procedure , we learn a linear Gaussian BN baseline where Xi ∼ N ( apai , Qi ) so that each variable Xi is normally distributed around a linear combination of its parents Pai ( see [ Koller and Friedman , 2009 ] for details on this standard approach to structure learning ). For the GCBN model , we also compare to Nonparametric BP ( NBP ) [ Sudderth et al ., 2010a ] using D . Bickson ’ s code [ Bickson , 2008 ] and A . Ihlers KDE Matlab package ( ihler / code / kde . html ), which relies on a mixture of Gaussians for message representation . In this case , since our univariate densities are constructed using Gaussian kernels , there is no approximation in the NBP representation and all approximations are due to message computations . To carry out message products , we tried all 7 sampling - based methods available in the KDE package .",Method,Code,Use,Nonparanormal Belief Propagation (NPNBP),https://proceedings.neurips.cc/paper/2012/hash/41ae36ecb9b3eee609d05b90c14222fb-Abstract.html
"All the code used for performing the experiments is available from 6By one - shot we mean that , given the algorithm above , each experiment was only run once with one setting of the random seed and the values of and given . If we were producing a visualisation for only one dataset this would leave us open to the criticism that our one - shot result was ‘ lucky ’.",Method,Code,Use,Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data,https://proceedings.neurips.cc/paper/2003/hash/9657c1fffd38824e5ab0472e022e577e-Abstract.html
"SSGP is similar to the recent models of Le et al . [ 8 ] and Rahimi and Recht [ 9 ], except it learns the locations of the point masses through marginal likelihood optimization . We use the SSGP implementation provided by the authors at To further test the importance of the fast inference ( section 2 . 1 ) used in GPatt , we compare to a GP which uses the SMP kernel of section 2 but with the popular fast FITC [ 10 , 24 ] inference , which uses inducing inputs , and is implemented in GPML ( http :// www . gaussianprocess . org / gpml ). We also compare to GPs with the popular squared exponential ( SE ), rational quadratic ( RQ ) and Mat ´ ern ( MA ) ( with 3 degrees of freedom ) kernels , catalogued in Rasmussen and Williams [ 1 ], respectively for smooth , multi - scale , and finitely differentiable functions .",Method,Code,Use,Fast Kernel Learning for Multidimensional Pattern Extrapolation,cs.cmu.edu/~andrewgw/manet.pdf
"[ 8 ] and Rahimi and Recht [ 9 ], except it learns the locations of the point masses through marginal likelihood optimization . We use the SSGP implementation provided by the authors at http :// www . tsc . uc3m . es /˜ miguel / downloads . php . To further test the importance of the fast inference ( section 2 . 1 ) used in GPatt , we compare to a GP which uses the SMP kernel of section 2 but with the popular fast FITC [ 10 , 24 ] inference , which uses inducing inputs , and is implemented in GPML ( gpml ). We also compare to GPs with the popular squared exponential ( SE ), rational quadratic ( RQ ) and Mat ´ ern ( MA ) ( with 3 degrees of freedom ) kernels , catalogued in Rasmussen and Williams [ 1 ], respectively for smooth , multi - scale , and finitely differentiable functions . Since GPs with these kernels cannot scale to the large datasets we consider , we combine these kernels with the same fast inference techniques that we use with GPatt , to enable a comparison . 3 Moreover , we stress test each of these methods in terms of speed and accuracy , as a function of available data and extrapolation range , and number of components .",Method,Code,Use,Fast Kernel Learning for Multidimensional Pattern Extrapolation,https://proceedings.neurips.cc/paper/2014/hash/77369e37b2aa1404f416275183ab055f-Abstract.html
"The models are chosen for comparability , since they all embed nodes into a Euclidean latent space . Experiments for all three models were performed using reference implementations by the respective authors . The network exhibits stochastic equivalence ( visible as block structure in the matrix ) and homophily ( concentration of points around the diagonal ). Right : Maximum a posteriori estimate of the function Θ , corresponding to the function in Fig . 1 ( middle ).",Method,Code,Use,Random function priors for exchangeable arrays with applications to graphs and relational data,https://proceedings.neurips.cc/paper/2012/hash/df6c9756b2334cc5008c115486124bfe-Abstract.html
"In Tab . 2 we report the mean angle the object would need to be rotated ( on a fixed 3D axis ) to move from the predicted to the ground truth pose [ 12 ]. All the models were implemented using TensorFlow [ 1 ] and were trained with Stochastic Gradient Descent plus momentum [ 27 ]. Our initial learning rate was multiplied by 0 . 9 every 20 , 000 steps ( mini - batches ). We used batches of 32 samples from each domain for a total of 64 and the input images were mean - centered and rescaled to [− 1 , 1 ].",Method,Code,Use,Domain Separation Networks,https://proceedings.neurips.cc/paper_files/paper/2016/hash/45fbc6d3e05ebd93369ce542e8f2322d-Abstract.html
"We now expect 1000 modes in this data set , corresponding to the number of possible triples of digits . Again , to focus the evaluation on the difference in the learning algorithms , we use the same generator architecture for all methods . In particular , the generator architecture is an off - the - shelf standard implementation of DCGAN [ 17 ]. measure ( IvOM ), and sample quality ( as measured by KL ) on Stacked - MNIST and CIFAR . VEEGAN captures the most modes and also achieves the highest quality .",Method,Code,Use,VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning,https://proceedings.neurips.cc/paper/2017/hash/44a2e0804995faf8d2e3b084a1e2db1d-Abstract.html
The dropout is added to some fully connected layers or locally connected layers . The rectified linear activation function is used for all neurons . All the experiments are conducted using the cuda - convnet library . The training procedure is similar to [ 9 ] using mini - batch SGD with momentum ( 0 . 9 ). The size of mini - batch is fixed to 128 .,Method,Code,Use,Improved Dropout for Shallow and Deep Learning,https://proceedings.neurips.cc/paper/2016/hash/7bb060764a818184ebb1cc0d43d382aa-Abstract.html
"Even as the tensor fluctuates in magnitude by more than a factor of two , the maximum absolute value of the mantissa P is safely prevented from overflowing . The cost of this approach is that in the last example P reaches 3 bits below the cutoff , leaving the top bits zero and using only 13 of the 16 bits for representing data . The experiments described below were performed on Nvidia GPUs using the neon deep learning framework . In order to simulate the flex16 + 5 data format we stored tensors using an int16 type . Computations such as convolution and matrix multiplication were performed with a set of GPU kernels which convert the underlying int16 data format to float32 by multiplying with κ , perform operations in floating point , and convert back to int16 before returning the result as well as P . The kernels also have the ability to compute only P without writing any outputs , to prevent writing invalid data during exponent initialization .",Method,Code,Use,Flexpoint: An Adaptive Numerical Format for Efficient Training of Deep Neural Networks,https://arxiv.org/pdf/1711.02213.pdf
"Our model takes around 5 days to train on a Nvidia Tesla K40m . To binarize predicted masks we simply threshold the continuous output ( using a threshold of . 1 for PASCAL and . 2 for COCO ). All the experiments were conducted using Torch7 . In this section , we evaluate the performance of our approach on the PASCAL VOC 2007 test set [ 7 ] and on the first 5000 images of the MS COCO 2014 validation set [ 21 ]. Our model is trained on the COCO training set which contains about 80 , 000 images and a total of nearly 500 , 000 segmented objects .",Method,Code,Use,Learning to Segment Object Candidates,https://proceedings.neurips.cc/paper_files/paper/2015/hash/4e4e53aa080247bc31d0eb4e7aeb07a0-Abstract.html
"Moreover , we employed the Weisfeiler - Lehman subtree kernel [ 13 ], denoted as KWL , as the state - of - the - art graph kernel , which has a parameter h of the number of iterations . We first compared the geometric random walk kernel KGR to other kernels in graph classification . The classification accuracy of each graph kernel was examined by 10 - fold cross validation with multiclass C - support vector classification ( libsvm was used ), in which the parameter C for CSVC and a parameter ( if one exists ) of each kernel were chosen by internal 10 - fold cross validation ( CV ) on only the training dataset . We repeated the whole experiment 10 times and reported average Second , the two random walk kernels KGR and Kk × show greater accuracy than naive linear kernels on edge and vertex histograms , which indicates that halting is not occurring in these datasets . It is also noteworthy that employing a Gaussian RBF kernel on vertex - edge histograms leads to a clear improvement over linear kernels on all three datasets .",Method,Code,Use,Halting in Random Walk Kernels,https://proceedings.neurips.cc/paper/2015/hash/31b3b31a1c2f8a370206f111127c0dbd-Abstract.html
"For the Conceptnet and the Movielens datasets , we used only two train / test splits and at most 30 clusters , which made our experiments faster . We report test root mean squared error ( RMSE ) and the area under the precision recall curve ( AUC ) [ 9 ]. For the IRM we make predictions as follows . The IRM partitions the data into blocks ; we compute the smoothed mean of the observed entries of each block and use it to predict the test entries in the same block . We first applied BCTF to the Animals , Kinship , and the UML datasets using 20 and 40 - dimensional vectors .",Method,Code,Use,Modelling Relational Data using Bayesian Clustered Tensor Factorization,https://www.cs.cmu.edu/~rsalakhu/papers/pmfcrp.pdf
"All the model parameters have a physical interpretation and thus expert knowledge was used to set priors which produce realistic wind fields . We will also use ( 10 ) to help set ( hyper ) priors using real data in Z °. MCMC using the Metropolis algorithm ( Neal , 1993 ) is used to sample from ( 10 ) using the NETLAB library . Convergence of the Markov chain is currently assessed using visual inspection of the univariate sample paths since the generating parameters are known , although other diagnostics could be used ( Cowles and Carlin , 1996 ). We find that the procedure is insensitive to the initial value of the GP parameters , but that the parameters describing the location of the front ( Of , cif ) need to be initialised & apos ; close & apos ; to the correct values if the chain is to converge on a reasonable time - scale .",Method,Code,Use,Modelling Frontal Discontinuities in Wind Fields,https://www.academia.edu/24539900/Modelling_Frontal_Discontinuities_in_Wind_Fields
"clusters : The graph shows the cosine similarity between today ’ s English language cluster ( Final hole being drilled ...) and seven clusters identified during five previous days . Only clusters with a similarity above 0 . 5 will be retained . ( ) do not link related news over time either . NewsTin ( http :// www . newstin . com ) is the only one to offer more languages ( ten ) and to categorise news into a number of broad categories , but they , again , do not link related news over time or across languages .",Method,Tool,Introduce,NewsExplorer – combining various text analysis tools to allow multilingual news linking and exploration,https://www.researchgate.net/profile/Bruno-Pouliquen/publication/252074421_NewsExplorer_-_combining_various_text_analysis_tools_to_allow_multilingual_news_linking_and_exploration/links/0c960529ed8414000c000000/NewsExplorer-combining-various-text-analysis-tools-to-allow-multilingual-news-linking-and-exploration.pdf
"In the US DARPA Communicator project which addresses spoken language and multimodal dialogue systems , for instance , all participants start from shared core technologies without having to build these themselves ( http :// fofoca . mitre . org /). In the German SmartKom project which addresses multimodal communication systems , the budget is large enough for the participants to build and integrate the technologies needed ( ). In the European Intelligent Information Interfaces ( i3 , http :// www . i3net . org /) and CLASS ( http :// www . class - tech . org /) initiatives , whilst the traditional 3 - year small - scale project topology has been preserved , major efforts are being made to promote cross - project collaboration , synergy , and critical mass . For reasons too obvious to mention , relatively small - scale research should continue to exist , of course .",Method,Tool,Introduce,Evaluation and usability of multimodal spoken language dialogue systems,https://www.sciencedirect.com/science/article/abs/pii/S0167639304000184
"In this paper , we propose an approach for designing the confirmation strategies and implementing error recover and user - modelling techniques in a Railway Information system . During last decade , the performance of spoken dialogue system for traveling information has improved substantially . One spoken dialogue project is the DARPA Communicator ( Pellom , 2000 ; Rudnicky , 2000 ) that enables to access information about airline flights , hotels and rental cars . In Europe , one important project concerning railway information is ARISE ( Lamel , 2000 ; Baggia , 2000 ).",Method,Tool,Introduce,Designing Confirmation Mechanisms and Error Recover Techniques in a Railway Information System for Spanish,https://aclanthology.org/W01-1618.pdf
"Whilst these initiatives have made good progress on written language and current coding practice , none of them have focused on the creation of standards and tools for cross - level spoken language corpus annotation . It is only recently that there has been a major effort in this domain . The project Multi - level Annotation Tools Engineering ( MATE ) ( ) was launched in March 1998 in response to the need for standards and tools in support of creating , annotating , evaluating and exploiting spoken language resources . The central idea of MATE has been to work on both annotation theory and practice in order to connect the two through a flexible framework which can ensure a common and user - friendly approach across annotation levels . On the tools side , this means that users are able to use level - independent tools and an interface representation which is independent of the internal coding file representation .",Method,Tool,Introduce,Annotating Communication Problems Using the MATE Workbench,http://lrec.elra.info/proceedings/lrec2000/pdf/134.pdf
"The Organising Committee would like to thank the Programme Committee , who responded with very fast but also substantial reviews for the workshop programme . This workshop would not have been possible iii without the support received from the EXPERT project ( FP7 / 2007 - 2013 under REA grant agreement no . 317471 , ).",Method,Tool,Introduce,Natural Language Processing for Translation Memories (NLP4TM),https://aclanthology.org/W15-5200.pdf
"The NESPOLE interlingua has been under development for the last two years as part of the NESPOLE project ( ). FigI would like to make a hotel reservation for the fourth through the seventh of july c : request - action + reservation + temporal + hotel ( time =( start - time = md4 , end - time =( md7 , july )))",Method,Tool,Introduce,Balancing Expressiveness and Simplicity in an Interlingua for Task Based Dialogue,https://aclanthology.org/W02-0708.pdf
"Note that the temporalOrdering property only says it is transitive , not that it is a transitive version of precedes . DAML + OIL does not currently allow us to express this relation . ( see ). Frame Elements may also inherit from each other . We use the rdfs : subPropertyOf to specify this dependences .",Method,Tool,Introduce,FrameNet Meets the Semantic Web: Lexical Semantics for the Web,https://link.springer.com/chapter/10.1007/978-3-540-39718-2_49
"This property makes SVM highly competitive , compared with other traditional pattern recognition methods , in terms of computational efficiency and predictive accuracy ( Yang and Liu , 1999 ). In recent years , Joachims has done much research on the application of SVM to text categorization ( Joachims , 1998 ). His SVMlight system published via SVM_LIGHT / svmlight . eng . html is used in our benchmark experiments .",Method,Tool,Introduce,A new electricity price prediction strategy using mutual information-based SVM-RFE classification,https://www.sciencedirect.com/science/article/abs/pii/S1364032116309297
"subordinate , attributive , and coordinate relations . In addition , each of these types can be endocentric or exocentric , depending of the presence ( endocentric ) or absence ( exocentric ) of a head constituent . In a project on automatic compound processing ( the AuCoPro project ; see ), we investigated various aspects related to the computational processing of compounds ( Verhoeven et al ., 2014 ). In a specific subpart of this project , we aimed to gain more insight in compound semantics in general by drawing from perspectives from computational semantics ( i . e . î Seaghdha , 2008 ), typological studies ( e . g .",Method,Tool,Introduce,A Taxonomy for Afrikaans and Dutch Compounds,https://aclanthology.org/W14-5704.pdf
"Further , prior tools are often in the form of discrete components , hard to extend or to integrate with other systems . Some good corpus resources are available , most recently the Copenhagen Dependency Treebank 1E . g . CST ’ s non - commercial - only anonymisation tool , at ( CDT ) ( Buch - Kromann and Korzen , 2010 ), which built on and included previously - released corpora for Danish . This 200K - token corpus is taken from news articles and editorials , and includes document structure , tokenisation , lemma , part - ofspeech and dependency relation information . The application demonstrated , DKIE , draws only on open corpus resources for annotation , and the annotations over these corpora are released openly .",Method,Tool,Introduce,Multi-level annotation in the Emu speech database management system,https://www.sciencedirect.com/science/article/abs/pii/S0167639300000698
"We would like to thank Marc Brysbaert and his colleagues for making their excellent resources available to the research community . We also thank the anonymous reviewers for their useful feedback . This research was funded by LEAD Graduate School ( GSC 1028 , lead ), a project of the Excellence Initiative of the German federal and state governments .",Method,Tool,Introduce,Moving beyond Kučera and Francis: A critical evaluation of current word frequency norms and the introduction of a new and improved word frequency measure for American English,https://link.springer.com/article/10.3758/BRM.41.4.977
"This work has been partially funded by the European Union under the EuroMatrix Plus project ( , IST - 2007 . 2 . 2FP7 - 231720 )",Method,Tool,Introduce,A Web-Based Interactive Computer Aided Translation Tool,https://aclanthology.org/P09-4005.pdf
"We are also grateful to our colcan be dealt with using direct verbalisation ( in con - leagues in the Open University ’ s Natural Lantrast with low frequency of , e . g ., FactQ ). guage Generation group for stimulating discussions and feedback . The research reported in this paper was carried out as part of the CODA research project ( ) which was funded by the UK ’ s Engineering and",Method,Tool,Introduce,Content Validity—Establishing and Reporting the Evidence in Newly Developed Patient-Reported Outcomes (PRO) Instruments for Medical Product Evaluation: ISPOR PRO Good Research Practices Task Force Report: Part 1—Eliciting Concepts for a New PRO Instrument,https://www.sciencedirect.com/science/article/pii/S1098301511033237
"The difference between reading and dictation times ( SRT ) is statistically significant at p - value = 0 . 0022 measured across all participants . This is unsurprising when comparing SRT mean ( 128 . 3s ) and SD ( 29 . 57s ) to reading aloud . A Wilcoxon signed rank - test was used to calculate 4 The tool , developed by Peter Kleiweg , is available for free 5 Unfortunately , the other nine participants were no longer at : available to perform this task . Proceedings of the 20th Nordic Conference of Computational Linguistics ( NODALIDA 2015 ) 205 the p - value because normal distribution of task times cannot be assumed and , with a small sample size , a robust method is needed to calculate statistical significance .",Method,Tool,Introduce,Assessing the Performance of Automatic Speech Recognition Systems When Used by Native and Non-Native Speakers of Three Major Languages in Dictation Workflows,https://aclanthology.org/W15-1825.pdf
"in data recording , storage , and coding methods in recent decades . Thanks to corpora and tools such as those developed in the context of the CHILDES project ( ), researchers in areas such as morphology and syntax have enjoyed a convenient and powerful method to analyze the morphosyntactic properties of adult languages and their acquisition by first and second language learners . In the area of phonetics , the Praat system ( http :// www . fon . hum . uva . nl / praat /) has expanded our abilities to conduct phonological modeling , computational simulations based on a variety of theoretical approaches , and articulatory synthesis . In this rapidly - expanding software universe , phonologists interested in the organization of sound systems ( e . g .",Method,Tool,Introduce,Phon: A Computational Basis for Phonological Database Building and Model Testing,https://link.springer.com/chapter/10.1007/978-3-642-31863-4_2
"The UNESCO - funded project The Tenth - Century Cyrillic Manuscript Codex Suprasliensis aims at digitizing the largest Old Church Slavonic manuscript , the Codex Suprasliensis ( ). This early Cyrillic manuscript has been dated to the end of the tenth or the beginning of the eleventh century and has been published three times on paper ( Miklošič , 1851 ; Severjanov , 1904 ; Zaimov and Capaldo , 1982 – 83 ). The most recent of these , the two - volume edition by Zaimov and Capaldo ( 1982 , 1983 ), was published more than two decades ago and contains photographic images of the entire manuscript ; a transcription reproduced from Severjanov , 1904 and corrected ( not entirely without error ) against the facsimile ; and a Greek text ( compiled from multiple Byzantine sources , which necessarily implies complications in its philological interpretation ; see also Abicht and Schmidt , 1896 ).",Method,Tool,Introduce,The Tenth-Century Cyrillic Manuscript Codex Suprasliensis: the creation of an electronic corpus UNESCO project (2010–2011,https://aclanthology.org/W11-4109.pdf
"The syntactic annotation procedure , which like the POS tagging is performed semi - automatically , uses the interactive annotation environment developed within the German NEGRA project ( http :// www . coli . unisb . de / sfb378 / negra - corp us / negra - corp us . html ). A simple visualisation tool ( Portray ) for the annotation graphs is freely available from the Utrecht CGN site ( ). In a later phase of the project , the CGN exploitation software ( COREX tools ) will provide more advanced display and search facilities for the syntactic annotation .",Method,Tool,Introduce,Syntactic Annotation for the Spoken Dutch Corpus Project (CGN),https://brill.com/display/book/9789004333901/B9789004333901-s006.xml
"We used the Text :: Similarity v . 0 . 09 module to obtain the overlap value between two bags of words . Text similarity is based on counting the number of overlapping tokens between the two strings , normalized by the length of the strings . In the second approach , Sense Similarity , the basis for sense alignment is the Personalized Page Rank ( PPR ) algorithm ( Eneko and Soroa , 2009 ) relying on a lexical - semantic knowledge base model as a graph G = ( V , E ) as available in the UKB tool suite . As knowledge base we have used WN 3 . 0 extended with the “ Princeton Annotated Gloss Corpus ”. Each vertex v of the graph is a synset , and the edges represent semantic relations between synsets ( e . g .",Method,Tool,Introduce,A hybrid approach for paraphrase identification based on knowledge-enriched semantic heuristics,https://link.springer.com/article/10.1007/s10579-019-09466-4
"The authors constructed a corpus of 3000 parallel sentences , which were translated manually from monolingual online Farsi doc uments at New Mexico State University . More recently Qasemizadeh et al . ( 2007 ) participated in the Farsi part of MULTEXT - EAST project ( Erjavec , 2010 ) and developed about 6000 sentences . There is also a corpus available in ELRA consisting of about 3 , 500 , 000 English and Farsi words aligned at sentence level ( about 100 , 000 sentences ). This is a mixed domain dataset including a variety of text types such as art , law , culture , literature , poetry , proverbs , religion etc .",Method,Tool,Introduce,Developing a Dynamic Domain-specific Parallel Corpus of English and Persian Religious Texts,https://www.researchgate.net/profile/Ali-Beikian/publication/293649549_Developing_a_Dynamic_Domain-specific_Parallel_Corpus_of_English_and_Persian_Religious_Texts/links/56ba1a2c08aed47e41f38d19/Developing-a-Dynamic-Domain-specific-Parallel-Corpus-of-English-and-Persian-Religious-Texts.pdf
"For these , the literature provides a section - level alignment only . The DDD builds on the earlier efforts of the TITUS project ( Thesaurus of Indo - European Text and Language Materials , Thesaurus Indogermanischer Text - und Sprachmaterialien ) that provided digitized editions of texts in old Germanic languages as well as other Indo - European and selected non - Indo - European languages ( Gippert , 2011 ). The annotations are mostly derived from the literature and existing glossaries that provide grammatical information for all known OHG and OS words , together with their exact source . These have been digitized , automatically applied to the text , manually refined using the annotation software ELAN , augmented with metadata , and finally published via the ANNIS database ( Linde and Mittmann , 2013 ). The annotated corpus is published under a CCBY - SA license over http :// www . laudatio .",Method,Tool,Introduce,New Technologies for Old Germanic. Resources and Research on Parallel Bibles in Older Continental Western Germanic,https://aclanthology.org/W14-0604.pdf
"Second , initial manual comparison between MWE lists ranked according to all measures implemented in the UCS toolkit revealed the most convincing results for the X test . For the time being , we focus on bigram MWE extraction . While the UCS toolkit readily supports work on Unicode - based languages such as Urdu , it does not support trigram extraction ; other freely available tools such as TEXT - NSP do come with trigram support , but cannot handle Unicode script . As a consequence , we currently implement our own scripts to overcome these limitations . The clustering approach taken in this paper is based on Urdu - specific syntactic information that can be gathered straightforwardly from the corpus .",Method,Tool,Introduce,Identifying Urdu Complex Predication via Bigram Extraction,https://kops.uni-konstanz.de/server/api/core/bitstreams/2e710dca-4097-4872-884e-1f1e08f9b946/content
"Figure 1 shows the interaction of the components in our final hybrid system , producing the results submitted to the CoNLL 2014 shared task . The following sections describe each of these components in detail . The rule - based system is a component of the SelfAssessment and Tutoring ( SAT ) system , a web service developed at the University of Cambridge aimed at helping intermediate learners of English in their writing tasks ( Andersen et al ., 2013 ). The original SAT system provides three main functionalities : 1 ) text assessment , producing an overall score for a piece of text , 2 ) sentence evaluation , producing a sentence - level quality score , and 3 ) word - level feedback , suggesting specific corrections for frequent errors . Since the focus of the shared task is on strict correction ( as opposed to detection ), we only used the word - level feedback component of the SAT system .",Method,Tool,Introduce,Grammatical error correction using hybrid systems and type filtering,https://aclanthology.org/W14-1702.pdf
"Having discussed the ideas driving the web - based teaching platform and exemplified one of the tools , we now return to the courses which have informed our work on the three core modules currently being developed in terms of their content and the use of a web - and implementation environment they make . ALE ( Carpenter and Penn , 1996 ) is a conservative extension of Prolog based on typed feature structures , with a built - in parser and semantic - headdriven generator . The demand for such a utility was so great when it was beta - released in 1992 that it immediately became the subject of early work in graphical front - end development for large constraint - based grammars : first with the Pleuk system ( Calder , 1993 ), then as one of several systems supported by Gertjan van Noord ’ s HDrug , followed by an ALE - mode Emacs user interface ( Laurens , 1995 ). It also provided the computational support for one of the very first web - based computational linguistics courses , Colin Matheson ’ s widely used HPSG Development in ALE . A follow - up course on computational morphology , also by Colin Matheson , was based on ALE - RA , a morphological extension of ALE by Tomaz Erjavec .",Method,Tool,Introduce,A Web-based Instructional Platform for Constraint-Based Grammar Formalisms and Parsing,https://aclanthology.org/W02-0103.pdf
"We also describe an interface that displays multiple parses compactly and facilitates users to select the desired parse among various possible solutions with a maximum of n − 1 choices for a sentence with n words . Past decade has witnessed a lot of dynamism and upsurge of activities in the field of Sanskrit Computational Linguistics . Several computational tools became available to the Sanskrit community as a web service through the internet . With the availability of a wide coverage grammar for Sanskrit in the form of As . t .¯ adhy ¯ ay ¯ ı , there was a natural tendency to follow the grammar based approach towards the development of these tools ( Huet , 2009 ; Kulkarni et al ., 2010 ; Kulkarni and Ramakrishnamacharyulu , 2013 ; Goyal and Huet , 2013 ). Nevertheless , there were also notable efforts to use pure machine learning approaches for building these tools with a small manually tagged corpus as a boot - strap ( Hellwig , 2009 ).",Method,Tool,Introduce,A Deterministic Dependency Parser with Dynamic Programming for Sanskrit,https://aclanthology.org/W13-3718.pdf
"One limitation of our method is that it cannot achieve high yield for PHvst whenever only a small number of paraphrase patterns can be extracted from the bilingual corpus ( see also Figure 5 ). Both the ratio of PHvst to PSeed and the relative yield could probably be increased by scaling up the monolingual corpus . For instance , in the patent domain , monolingual documents 10 times larger than the one used in the above experiments are available at the NTCIR project . It would be interesting to compare the relative gains brought by in - domain versus general - purpose corpora . ( left : probability - based ( 0 . 01 < the < 0 . 9 , th , g = e ), right : similarity - based ( e < th , g < 0 . 9 , the = 0 . 01 )) Finally , we investigated how the number of paraphrase pairs varies depending on the values for the two thresholds , i . e ., thp on the conditional probability and ths on the contextual similarity , respectively .",Method,Tool,Introduce,Enlarging Paraphrase Collections through Generalization and Instantiation,https://aclanthology.org/D12-1058.pdf
"Both these systems also use variants of Wattenberg and Vi ´ egas ( 2008 )’ s word tree visualization , which gives a sequential word frequencies as a tree ( i . e ., what computational linguists might call a trie representation of a high - order Markov model ). The “ God bless ” word sense example from § 2 indicates that such statistical summarization of local contextual information may be useful to integrate ; it is worth thinking how to integrate this against the important need of document covariate analysis , while being efficient with the use of space . Many other systems , especially ones designed for literary content analysis , emphasize concordances and keyword searches within a text ; for example , Voyeur / Voyant ( Rockwell et al ., 2010 ), which also features some document covariate analysis through temporal trend analyses for individual terms . Another class of approaches emphasizes the use of document clustering or topic models ( Gardner et al ., 2010 ; Newman et al ., 2010 ; Grimmer and King , 2011 ; Chaney and Blei , 2013 ), while Overview emphasizes hierarchical document clustering paired with manual tagging . Finally , considerable research has examined exploratory visual interfaces for information retrieval , in which a user specifies an information need in order to find relevant documents or passages from a corpus ( Hearst ( 2009 ), Ch .",Method,Tool,Introduce,MITEXTEXPLORER: Linked brushing and mutual information for exploratory text data analysis,https://aclanthology.org/W14-3101.pdf
"Criterion , developed by ( Burstein et al ., 2004 ) is another Web - based learning tool which uses an automatic scoring engine to rate the input learner ’ s composition . It also shows detailed stylistic and grammatical feedback to the learner for educational purposes . Other than these , one can also find many other free or commercial English writing assistance systems including Grammarly , WhiteSmoke , and Ginger to name a few . However , all these systems assume rather static input , i . e ., focus on post - processing learners ’ compositions already finished . However , as stated in the previous section , many errors could be avoided by presenting appropriate feedback while the user is composing sentences .",Method,Tool,Introduce,BEYOND THE DESIGN OF AUTOMATED WRITING EVALUATION: PEDAGOGICAL PRACTICES AND PERCEIVED LEARNING EFFECTIVENESS IN EFL WRITING CLASSES,https://scholarspace.manoa.hawaii.edu/server/api/core/bitstreams/77d263c9-dfcf-4382-b179-7002b43cd5ef/content
"It will also be invaluable in gathering oral data from speakers of endangered languages for the production of monolingual talking dictionaries . The first of these projects is planned for the Arrernte language in central Australia . Several technological resources provide good data - gathering solutions for individual lexicographic projects , including Max Planck ’ s LEXUS ; TLex ; WeSay ; and SIL ’ s triad of Lexique Pro , Toolbox , and FLEx . Yet each of these solutions leaves gaps for the individual projects making use of them , and none is suitable for development of sophisticated multilingual dictionaries as envisioned by Kamusi . The learning curve can be steep , particularly the initial effort to set up an effective structure for a language .",Method,Tool,Introduce,"Small Languages, Big Data: Multilingual Computational Tools and Techniques for the Lexicography of Endangered Languages",https://aclanthology.org/W14-2203.pdf
"Task 2 on resolving in - sentence scopes of hedge cues , was performed by a memorybased system that relies on information from syntactic dependencies . This system scored the highest F1 ( 57 . 32 ) of Task 2 . In this paper we describe the machine learning systems that CLiPS submitted to the closed track of the CoNLL - 2010 Shared Task on Learning to Detect Hedges and Their Scope in Natural Language Text ( Farkas et al ., 2010 ). The task consists of two subtasks : detecting whether a sentence contains uncertain information ( Task 1 ), and resolving in - sentence scopes of hedge cues ( Task 2 ). To solve Task 1 , systems are required to classify sentences into two classes , “ Certain ” or “ Uncertain ”, depending on whether the sentence contains factual or uncertain information .",Method,Tool,Introduce,Memory-Based Resolution of In-Sentence Scopes of Hedge Cues,https://aclanthology.org/W10-3006.pdf
"Furthermore , it uses portable formats and format converters that would allow for combining several software components . There exist a lot of platforms dedicated to NLP , but none are fully satisfactory for various reasons . Intex ( Silberztein , 1993 ), FSM ( Mohri et al ., 1998 ) and Xelda are closed source . Unitex ( Paumier , 2003 ), inspired by Intex has its source code under LGPL license but it does not support standard formats for Language Resources ( LR ). Systems like NLTK ( Loper and Bird , 2002 ) and Gate ( Cunningham , 2002 ) do not offer functionality for Lexical Resource Management .",Method,Tool,Introduce,"Outilex, a Linguistic Platform for Text Processing",https://aclanthology.org/P06-4019.pdf
"This is due at least to the crucial need of the domain knowledge and also of the linguistic knowledge . Our approach considers that for some specific domains a semantic annotation can be achieved by a light parsing of the text which is based on the user of certain cue - words as a heuristic for describing its semantic structure . The availability of a large collection of annotated telephone calls for querying the Swiss phone - book database ( i . e the Swiss French PolyPhone corpus ) allowed us to experiment our recent findings in robust text analysis obtained in the context of the Swiss National Fund research project ROTA ( Robust Text Analysis ), and in the recent Swisscom funded project ISIS ( Interaction through Speech with Information Systems ) ( Chappelier et al ., 1999 ). This database contains 4293 simulated recordings related to the would produce the following query frame filling for the Swiss Phone - book database : Nom de famille / Firme : MOTTAZ Prenom / Autres informations : MONIQUE Rue , numero : rue du PRINTEMPS , 4 NPA , localito : SAIGNELEGIER . The goal of semantic annotation is to provide a tree structure which can be superposed over the flat sentence .",Method,Tool,Introduce,A Weighted Robust Parsing Approach to Semantic Annotation,https://aclanthology.org/A00-3004.pdf
"This may be due to the frequency of relative clauses in GENIA . 4 Parsing system and extraction of imperative and question sentences We introduce the parser and the POS tagger whose performances are examined , and the extraction of imperative or question sentences from GTREC treebank on which the performances are measured . The Enju parser ( Ninomiya et al ., 2007 ) is a deep parser based on the HPSG formalism . It produces an analysis of a sentence that includes the syntactic structure ( i . e ., parse tree ) and the semantic structure represented as a set of predicate - argument dependencies . The grammar is based on the standard HPSG analysis of English ( Pollard and Sag , 1994 ).",Method,Tool,Introduce,Parsing Natural Language Queries for Life Science Knowledge,https://aclanthology.org/W11-0221.pdf
"( 2004 ). The dataset contains 1000 positive and 1000 negative movie reviews with size varying between 700 to 1000 words . As summary generation is time consuming task ( DUC only used 25 summaries to evaluate the performance of systems ), we picked 100 positive and 100 negative reviews randomly from the dataset and their abstract summaries are generated manually with 200 words limit as budget for evaluation . These 200 summaries are used as gold standard for estimating ROUGE scores of system generated summaries . In the experiment , the partial enumeration based greedy algorithm ( Khuller et al ., 1999 ) is used for summary generation of 200 test documents within budget of 200 words .",Method,Tool,Introduce,Monotone Submodularity in Opinion Summaries,https://aclanthology.org/D15-1017.pdf
"A related issue is that of annotation tools . One possibility would be to use a generic tool supporting the annotation of either of the levels we are concerned with ( and any levels that we may want to add in the future ). The most ambitious projects we are familiar with are the MATE Workbench and the follow - up NITE Workbench for multi - level , cross - level and cross - modality annotation of language data . The MATE Workbench has been developed as a highly customizable tool for parallel annotation of arbitrary and possibly non - hierarchical layers of linguistic description . It is an open source tool written in Java and handles XML - encoded data .",Method,Tool,Introduce,Granularity in software product lines,https://dl.acm.org/doi/abs/10.1145/1368088.1368131
"Moreover , ( Hahn et al ., 2010 ) have shown that the structured information gathered from Wikipedia infoboxes can be used to answer complex questions , like “ Which Rivers flow into the Rhine and are longer than 50 kilometers ?” For this purpose , text documents need to be previously annotated using DBpedia Spotlight ( Mendes et al ., 2011 ), which automatically annotates text with links to articles in Wikipedia . The process of semantic enrichment is still largely domain - dependent ; therefore , apart from the available general - purpose knowledge bases and ontologies ( DBpedia , FOAF , DublinCore ...), the EUMSSI platform needs specialized resources for categorizing videos on different dimensions . Linked Data technologies ( Heath and Bizer , 2011 ) and the Linked Open Data cloud provide access to several of these resources , including geodata , movie databases and program information . The semantically enriched information is then used by the EUMSSI system to make personalized content - based recommendation . We propose a novel recommender system that leverages matrix factorization ( Koren , 2008 ) with implicit feedback in order to integrate content - based similarity , usage history ( i . e .",Method,Tool,Introduce,DBpedia spotlight: shedding light on the web of documents,https://dl.acm.org/doi/abs/10.1145/2063518.2063519
"For lexicographers , the computational environment fills the need for a corpus workbench which supports WSD . Results under simulated lexicographic use on the English lexical - sample task show precision comparable with supervised systems ', without using the laboriously - prepared training data . WASP - Bench is a web - based tool supporting both corpus - based lexicography and Word Sense Disambiguation . The central premise behind the initiative is that deciding what the senses for a word are , and developing a WSD program for it , should be tightly coupled . In the course of the corpus analysis , the lexicographer explores the textual clues that indicate a word is being used in one sense or another ; given an appropriate computational environment , these clues can be gathered and used to seed a bootstrapping WSD program .",Method,Tool,Introduce,WASP-Bench: a Lexicographic Tool Supporting Word Sense Disambiguation,https://aclanthology.org/S01-1037.pdf
"The second article in this part , “ Multidimensional Dialogue Management ” ( Simon Keizer , Harry Bunt , and Volha Petukhova ), is more theoretical and presents a dialog manager built using the framework of Dynamic Interpretation Theory ( Bunt 2000 ) which is able to both interpret and generate utterances using dialog acts . The article also presents briefly the way in which this dialog manager was integrated in the IMIX demonstrator . In my opinion , the editors of the book could have chosen a better title for the third part of the book : “ Fusing Text , Speech , and Images .” Both articles in this part present work done in the IMOGEN ( Interactive Multimodal Output GENeration ) project , one of the subprojects embedded in the IMIX Programme that focused on producing multimodal presentations that combine text , speech , and graphics . Only the first article focuses on the multimodal aspect of the project , however . The other one discusses only text processing .",Method,Tool,Introduce,Multidimensional Dialogue Management,https://link.springer.com/chapter/10.1007/978-3-642-17525-1_4
"This is particularly true with respect to Indian languages . In the last 15 years or so , MT into Indian languages ( especially Hindi ) has gained tremendous research interest in India and elsewhere . Many English to Hindi and Indian Languages to Indian Languages MT systems have been designed , for example AnglaBharati ( Sinha et al ., 1995 ), Anusaaraka ( Chaudhury et al ., 2010 ), Anuvadaksh , Google , Sampark , MaTra ( Ananthakrishnan et al ., 2006 ), to name just a few . However , the issue of evaluating the output of these MT systems has remained rather unexplored . The state - of - the - art methods for automatic MT evaluation are represented by BLEU ( Papineni et al ., 2002 ) and closely related NIST ( Doddington , 2002 ), METEOR ( Banerjee and Lavie , 2005 ; Lavie and Agarwal , 2007 ) and TER ( Snover et al ., 2006 ).",Method,Tool,Introduce,ANGLABHARTI: a multilingual machine aided translation project on translation from English to Indian languages,https://ieeexplore.ieee.org/abstract/document/538002
"In recent years , the adoption of standardized terminologies for the representation of clinical concepts – and their textual instantiations – has enabled meaning - based retrieval of information from electronic health records ( EHRs ). By identifying and linking key facts in health records , the ever - growing stores of clinical documentation now available to us can more readily be processed and , ultimately , leveraged to improve the quality of care . SNOMED CT has emerged as the de facto international terminology for representing clinical concepts in EHRs and is today used in more than fifty countries , despite only being available in a handful of languages . Translations into several other languages are , however , under way . This translation effort is essential for more widespread integration of SNOMED CT in EHR systems globally .",Method,Tool,Introduce,Semantic interoperability in standardized electronic health record databases,https://dl.acm.org/doi/abs/10.1145/2166788.2166789
"These heterogeneous practices prevent the automated processing of rights information . Recently , we witness the proliferation of repositories collecting LRs and their metadata descriptions from various communities and sources according to different harvesting methodologies , and publishing them into homogeneous catalogs . The most relevant initiatives for our discussion are : META - SHARE ( Piperidis , 2012 ), CLARIN , LRE - Map ( Calzolari et al ., 2012 ), OLAC ( Simons and Bird , 2003 ) and Datahub . io . Taking a closer look at the rights metadata present in these catalogs , we see the following tendencies : censes are not available over the internet ( e . g . resources from older times , when licenses were not standardised and providers asked legal experts to draft specific contracts for each resource , which were made available only to interested parties upon request ); for the LRE Map , this practice has been dictated by the fact that the metadata are submitted by authors of papers in conferences ( e . g .",Method,Tool,Introduce,CMDIfication process for textbook resources,https://www.inderscienceonline.com/doi/abs/10.1504/IJMSO.2020.108331
"Most existing HLT pipelines assume the input is pure text or , at most , HTML and either ignore ( logical ) document structure or remove it . We argue that identifying the structure of documents is essential in digital library and other types of applications , and show that it is relatively straightforward to extend existing pipelines to achieve ones in which the structure of a document is preserved . Many off - the - shelf Human Language Technology ( HLT ) pipelines are now freely available ( examples include LingPipe , OpenNLP , GATE ( Cunningham et al ., 2002 ), TextPro ( Pianta et al ., 2008 )), and although they support a variety of document formats as input , actual processing ( mostly ) takes no advantage of structural information , i . e . structural information is not used , or stripped off during preprocessing . Such processing can be considered safe , e . g .",Method,Tool,Introduce,Structure-Preserving Pipelines for Digital Libraries,https://aclanthology.org/W11-1508.pdf
"Fourth , in SemEval the words to be substituted come from various syntactic or semantic categories , while we only suggest appropriate emotion words to the learners . For writing assessment , existing works are known as automatic essay assessment ( AEA ) systems , which analyze user compositions in terms of wording , grammar and organization . PIGAI , targeted at generating suggested revisions , suggests unranked synonyms for words . However , unranked synonyms easily confuse Chinese learners ( Ma , 2013 ). E - rater ( Leading et al .",Method,Tool,Introduce,A Computer-Assistance Learning System for Emotional Wording,https://ieeexplore.ieee.org/abstract/document/7355346
"For future work , one could investigate whether the latter can be addressed by domain - adaptation techniques ( e . g . Satpal and Sarawagi ( 2007 )). To cope with DrugN entities , one could implement features derived from those resources that were used by the annotators for deciding whether a substance is approved for use in humans , e . g ., Drugs @ FDA and the WHO ATC classification system . We thank Philippe Thomas for preparing a simplified format of the corpora . We thank him and Roman Klinger for fruitful discussions .",Method,Tool,Introduce,WBI-NER: The impact of domain-specific features on the performance of identifying and classifying mentions of drugs,https://aclanthology.org/S13-2058.pdf
"− Inkurdish : a new and high - quality translation between Sorani Kurdish and English . − English Kurdish Translation : especially can translate words in Kurmanji and English together . − Freelang : supports 4000 words in kurmanji . It currently has more than 12 , 000 Sorani and 20 , 000 Kurmanji10 articles . One useful application of these entries is to build a parallel collection of named entities across both dialects .",Method,Tool,Introduce,The Kurdish Diaspora in Canada: A Study of Political Activism and The Uses of the Kurdish Language,https://ruor.uottawa.ca/handle/10393/39054
"( 2014 ), BITEXTOR and ILSP - FC have shown to be complementary , and combining both tools leads to a larger amount of parallel data . ILSP - FC ( Papavassiliou et al ., 2013 ) is a modular crawling system allowing to easily acquire domain - specific and generic corpora from the Web . This crawler includes a de - duplicator which checks all documents in a pairwise manner to identify near - duplicates . This is achieved by comparing the quantised word frequencies and the paragraphs of each pair of candidate duplicate documents . A document - pair detector also examines each document in the same manner and identifies pairs of documents that could be considered parallel .",Method,Tool,Introduce,Abu-MaTran at WMT 2015 Translation Task: Morphological Segmentation and Web Crawling,https://aclanthology.org/W15-3022.pdf
"Grefenstette ( 1995 ) compared this approach to Ingle ( 1978 ), based on the frequency of short words . The interested reader is referred to Zampieri ( 2013 ) for a review of some statistical and machine learning proposals and to both Baldwin and Lui ( 2010 ) and Lui and Baldwin ( 2011 ) for an overview of some linguistically motivated models . As Baldwin and Lui ( 2010 ) or Tiedemann and Ljubeˇsi ´ c ( 2012 ) point out , language identification is erroneously considered an easy and solved problem , in part because of some general purpose systems being available , notably TextCat , Xerox Language Identifier and , more recently , langid . py ( Lui and Baldwin , 2012 ). While it is true that it is possible to obtain brilliant results for a small number of languages ( Baldwin and Lui , 2010 ) or typologically distant languages ( Zampieri et al ., 2013 ), accurately discriminating among closely related languages or varieties of the same language has been repeatedly reported as a bottleneck for language identification systems , in particular for those based on n - grams . Back in 2004 , Padr ´ o and Padr ´ o concluded that “ since the tested systems tend to fail when distinguishing similar languages ( e . g .",Method,Tool,Introduce,Pluricentric languages : automatic identification and linguistic variation,https://publikationen.sulb.uni-saarland.de/handle/20.500.11880/23716
"We avoid distinguishing between Argument and Non - Argument segments at this stage , instead assuming that any segments left unconnected are after the structure has been identified are Non - Argument . http :// www . nltk . org / In order to establish these links , we first consider that in many cases an argument can be represented as a tree . This assumption is supported by around 95 % of the argument analyses contained in AIFdb ( Lawrence et al ., 2012 ) as well as the fact that many manual analysis tools including Araucaria ( Reed and Rowe , 2004 ), iLogos , Rationale ( Van Gelder , 2007 ) and Carneades ( Gordon et al ., 2007 ), limit the user to a tree format . Furthermore , we assume that the argument tree is generated depth first , specifically that the conclusion is presented first and then a single line of supporting points is followed as far as possible before working back up through the points made . The assumption is grounded in work in computational linguistics that has striven to produce natural - seeming argument structures ( Reed and Long , 1997 ).",Method,Tool,Introduce,An optimal algorithm for intersecting line segments in the plane,https://dl.acm.org/doi/abs/10.1145/147508.147511
"Kleene has been approved by SAP AG for release as free , open - source code under the Apache License , Version 2 . 0 , and will be available by August 2012 for downloading from http :// www . kleene - lang . org . The design , implementation , development status and future plans for the language are discussed . Kleene is a finite - state programming language in the tradition of the AT & T Lextools ( Roark and Sproat , 2007 ), the SFST - PL language ( Schmid , 2005 ), the Xerox / PARC finite - state toolkit ( Beesley and Karttunen , 2003 ) and FOMA ( Huld ´ en , 2009b ), all of which provide higher - level programming formalisms built on top of low - level finite - state libraries . Kleene itself is built on the OpenFst library ( Allauzen et al ., 2007 ), developed by Google Labs and NYU ’ s Courant Institute . The design and implementation of the language were motivated by three main principles , summarized as Syntax Matters , Licensing Matters and Open Source Matters .",Method,Tool,Introduce,"Kleene, a Free and Open-Source Language for Finite-State Programming",https://aclanthology.org/W12-6209.pdf
"Such models are useful for teaching , presentations and exploratory research ( such as showing where a classification algorithm makes mistakes ). Ndaona includes embedding and graphics parameter estimation algorithms , and generates files in the format of Partiview ( Levy , 2001 ), an existing free open - source fast multidimensional data displayer that has traditionally been used in the planetarium community . Partiview supports a number of enhancements to regular scatterplots that allow it to display more than three dimensions ’ worth of information . Scatterplots are not the most efficient way of representing information ( Grinstein et al ., 2001 ). However , they are intuitive and stable ( Wong and Bergeron , 1997 ), and can be supplemented in several ways .",Method,Tool,Introduce,Automating the Creation of Interactive Glyph-supplemented Scatterplots for Visualizing Algorithm Results,https://aclanthology.org/N06-4008.pdf
"( 2008 ), who explore the liki - Graph and score every category in order to assess its likelihood of belonging to the domain . Other tools are being developed to extract corpora from Wikipedia . Linguatools released a comparable corpus extracted from Wikipedias in 253 language pairs . Unfortunately , neither their tool nor the applied methodology description are available . CatScan2 is a tool that allows to explore and search categories recursively .",Method,Tool,Introduce,Using Wikipedia to Validate the Terminology Found in a Corpus of Basic Textbooks,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=30b3efe82d97b6974c0a11d0750d994723826954
"In Brazil , PhD students have the possibility to take their complete PhD course abroad or , alternatively , only a part of it . In both cases , students may count on Brazilian funding agencies . The area is more strongly represented and promoted by Brazilian Computer Society ( SBC ) , particularly by its Special Interest Group on NLP ( CEPLN ) , created in 2007 . It is interesting that most researchers in Brazil ( independent from their background area ) do not differentiate CL from NLP , using both terms interchangeably . Research in Brazil is carried out mainly at public universities and at a few private universities and business companies .",Method,Tool,Introduce,Computational Linguistics in Brazil: An Overview,https://aclanthology.org/W10-1601.pdf
"Major limitation of this approach is that one cannot give richer context due to the problem of scarcity . To find whether the dependency label is correct or not , apart from node and its parent information , contextual features like sibling and child information is also helpful . Current state - of - the - art dependency parsers like MSTParser and MaltParser use these features for dependency labeling ( McDonald et al ., 2006 ; Nivre et al ., 2007 ; Kosaraju et al ., 2010 ). Finding similarity between patterns and merging similar patterns would not help when we wish to take a much richer context . In this paper , we propose a probability based statistical module ( PBSM ) to overcome this problem of FBSM .",Method,Tool,Introduce,A Tale of Two Parsers: investigating and combining graph-based and transition-based dependency parsing using beam-search,https://aclanthology.org/D08-1059.pdf
"It uses Javascript , angular , and jquery to visualize the information in a web browser . Most interactive IE systems focus on annotation of text , labeling of entities , and manual writing of rules . Some annotation and labeling tools are : MITRE ’ s Callisto , Knowtator , SAPIENT ( Liakata et al ., 2009 ), brat , Melita ( Ciravegna et al ., 2002 ), and XConc Suite ( Kim et al ., 2008 ). Akbik et al . ( 2013 ) interactively helps non - expert users to manually write patterns over dependency trees .",Method,Tool,Introduce,SPIED: Stanford Pattern-based Information Extraction and Diagnostic,https://aclanthology.org/W14-3106.pdf
"These approaches performed well but are limited due to requiring large annotated training data specific to OCR spell checking in languages that are very hard to obtain . Further , research in spell checking for Vietnamese language has been understudied . Hunspell − spellcheck − vn & Aspell are interactive spell checking tools that work based on pre - defined dictionaries . According to our best knowledge , there is no work in the literature reported the task of spell checking for Vietnamese OCR - scanned text documents . In this paper , we approach this task in terms of 1 ) fully automatic scheme ; 2 ) without using any annotated corpora ; 3 ) capable of solving both non - word & real - word spelling errors simultaneously .",Method,Tool,Introduce,An Unsupervised and Data-Driven Approach for Spell Checking in Vietnamese OCR-scanned Texts,https://aclanthology.org/W12-0505.pdf
"These forms are then submitted as literal queries , and the resulting hits are summed up ( e . g ., history changes expands to & quot ; history change & quot ;, & quot ; histories change & quot ;, & quot ; history changed & quot ;, etc .). John Carroll ’ s suite of morphological tools ( morpha , morphg , and ana ) was used to generate inflected forms of verbs and nouns . In certain cases ( detailed below ), determiners were inserted before nouns in order to make it possible to recognize simple NPs . This insertion was limited to a / an , the , and the empty determiner ( for bare plurals ). All queries ( other than the ones using the NEAR operator ) were performed as exact matches ( using quotation marks in Altavista ).",Method,Tool,Introduce,The Web as a Baseline: Evaluating the Performance of Unsupervised Web-based Models for a Range of NLP Tasks,https://aclanthology.org/N04-1016.pdf
"Many of the commonly used tasks that otherwise require writing programs , can be performed with one or more queries . Overcoming the language barrier in the Indian sub - continent is a very challenging task . Sampark is an effort in this direction . Sampark has been developed as part of the consortium project called Indian Language to India Language Machine translation ( ILMT ) funded by TDIL program of Department of Information Technology , Government of India . Work on this project is contributed to by 11 major research centres across India working on Natural Language Processing .",Method,Tool,Introduce,Two sides of the coin: patient and provider perceptions of health care delivery to patients from culturally and linguistically diverse backgrounds,https://link.springer.com/article/10.1186/1472-6963-12-322
"( 2002 ), who define MWEs as : different but related phenomena [ which ] can be described as a sequence of words that acts as a single unit at some level of linguistic analysis . This generic and intentionally vague definition can be narrowed down according to the application needs . For example , for the statistical machine translation ( MT ) system used in the examples shown in Table 1 , an MWE is any sequence of words which , when not translated as a unit , generates errors : ungrammatical or unnatural verbal constructions ( sentence 1 ), awkward literal translations of idioms ( sentence 2 ) and problems of lexical choice and word order in specialised texts ( sentence 3 ). These examples illustrate the importance of correctly dealing with MWEs in MT applications and , more generally , MWEs can speed up and help remove ambiguities in many current NLP applications , for example : Despite the importance of MWEs in several applications , they are often neglected in the design and construction of real - life systems . In 1993 , Smadja pointed out that “... although disambiguation was originally considered as a performance task , the collocations retrieved have not been used for any specific computational task .” Most of the recent and current research in the MWE community still focuses on MWE acquisition instead of integration of automatically acquired or manually compiled resources into applications .",Method,Tool,Introduce,owards Best Practice for Multiword Expressions in Computational Lexicons,http://www.lrec-conf.org/proceedings/lrec2002/pdf/259.pdf
"To recognize the fact that H is “ entailed ” by T , we often need to use some background commonsense knowledge . For instance , in the example above it is essential that financing is an activity . The approach to recognizing textual entailment employed in Bos and Markert ( 2005 ) and implemented in the system Nutcracker can be summarized as follows : Related work is described in Akhmatova ( 2005 ); Fowler et al . ( 2005 ). The approach to the problem proposed in Baral et al .",Method,Tool,Introduce,CYC: Using Common Sense Knowledge to Overcome Brittleness and Knowledge Acquisition Bottlenecks,https://ojs.aaai.org/index.php/aimagazine/article/view/510
"Political debates are an interesting example : political scientists carefully analyze what gets said in debates to explore how candidates shape the debate ’ s agenda and frame issues or how answers subtly ( or not so subtly ) shift the conversation by dodging the question that was asked ( Rogers and Norton , 2011 ). Computational methods can contribute to the analysis of topical dynamics , for example through topic segmentation , dividing a conversation into smaller , topically coherent segments ( Purver , 2011 ); or through identifying and summarizing the topics under discussion ( Blei et al ., 2003 ; Blei , 2012 ). However , the topics uncovered by such methods can be difficult for people to interpret ( Chang et al ., 2009 ), and previous visualization frameworks for topic models — e . g ., ParallelTopics ( Dou et al ., 2011 ), TopicViz ( Eisenstein et al ., 2012 ), the Topical Guide , or topic model visualization ( Chaney and Blei , 2012 )— are not particularly well suited for linearly structured conversations . This paper describes Argviz , an integrated , interactive system for analyzing the topical dynamics of multi - party conversations . We bring together previous work on Interactive Topic Modeling ( ITM ) ( Hu et al ., 2011 ), which allows users to efficiently inject their needs , expertise , and insights into model building via iterative topic refinement , with Speaker Identity for Topic Segmentation ( SITS ) ( Nguyen et al ., 2012 ), a state - of - the - art model for topic segmentation and discovery of topic shifts in conversations .",Method,Tool,Introduce,Argviz: Interactive Visualization of Topic Dy,https://aclanthology.org/N13-3009.pdf
"This is the preferred method of using langid . py from other programming environments , as most languages include libraries for interacting with web services over HTTP . It also allows the language identification service to be run as a network / internet service . Finally , langid . py is WSGI - compliant , so it can be deployed in a WSGIcompliant web server . This provides an easy way to achieve parallelism by leveraging existing technologies to manage load balancing and utilize multiple processors in the handling of multiple concurrent requests for a service . LDfeatureselect . py implements the GD feature selection .",Method,Tool,Introduce,Exploring the linguistic landscape of geotagged social media content in urban environments,https://academic.oup.com/dsh/article-abstract/34/2/290/5113152
"As with its sister project LibreOffice , it is the successor of the OpenOffice . org project , whose first release dates back to 2002 . OpenOffice . org did not possess grammarchecking functionality , which made it less competitive compared to other non - open source alternatives . This motivated some NLP researchers to create CoGrOO , a Brazilian Portuguese grammar checker , a project initially sponsored by FINEP ( a Research and Projects Funding agency ). This research on CoGrOO began in 2004 , and since its first release in 2006 it has been adopted by important companies like Petrobras - the biggest company in Brazil and the 8th biggest in the world in market value - and Celepar - the Paran ´ a State information technology company , responsible for deploying software for government offices and public schools . CoGrOO accumulated over a hundred thousand downloads from its official website .",Method,Tool,Introduce,"Research script for the article ""A Comprehensive Study of Software Forks (Dates, Reasons and Outcomes)""",https://burjcdigital.urjc.es/handle/10115/11482
"Also , the viewpoint presented here is that of interlingua users who experience R & D for a given NL , and not of its authors . By ' high quality ' we mean ' at least allowing for readability and understandability by any user '. The UNL Project has been launched by the United Nations University to foster and ease international web communication by means of NLP systems . Its main strength lies on the development of the UNL , as a unique semantic ( or meaning ) representation that can be interchanged with the various languages to be integrated in the ICBMT system . In the UNL Project , plug - in software to encode NL texts onto UNL ones ( NL - UNL encoders ) and to decode UNL into NL texts ( UNL - NL decoders ) have been developed by R & D groups in their own native languages .",Method,Tool,Introduce,Does UML make the grade? Insights from the software development community,https://www.sciencedirect.com/science/article/abs/pii/S095058490400134X
"If one cannot build a lattice because no matching word can be found in the lexicon , unknown word processing is invoked . Here , candidate tokens are built using character types , such as hiragana , katakana , Chinese characters , alphabets , and numbers . Japanese part - of - speech ( POS ) tagsets used in the two major Japanese morphological analyzers ChaSen and JUMAN take the form of a hierarchical structure . For example , IPA tagset used in ChaSen consists of three categories : part - ofspeech , conjugation form ( cform ), and conjugate type ( ctype ). The cform and ctype are assigned only to words that conjugate , such as verbs and adjectives .",Method,Tool,Introduce,Applying Conditional Random Fields to Japanese Morphological Analysis,https://aclanthology.org/W04-3230.pdf
"& gt ;& gt ;& gt ; relation = wn . relations [’ hypernym ’] & gt ;& gt ;& gt ; relation [’ name ’] u ’ hypernym ’ & gt ;& gt ;& gt ; relation [’ rname ’] u ’ hyponym ’ & gt ;& gt ;& gt ; synset = wn . get (""< literal & gt ; word (’ game ’)"")[ 0 ] & gt ;& gt ;& gt ; print relation . neighbours ( synset )[ 0 ]. to_string () en - n : activity : 2 {} The example demonstrated the method neighbours , which returns the immediate neighbours of the given linguistic object . The API is used in many products of DCL like the DCL Search Engine , Bulgarian WordNet – web access ( RESTful webservice ) etc . The GUI classes were used for the open source corpora annotation tool Chooser but their use is beyond the scope of this paper . This paper was prepared within the project Integrating New Practices and Knowledge in Un dergraduate and Graduate Courses in Computational Linguistics ( BG051PO001 - 3 . 3 . 06 - 0022 ) implemented with the financial support of the Human Resources Development OP 2007 - 2013 cofinanced by the European Social Fund of the EU . The author takes full responsibility for the content and under no conditions can the conclusions be considered a position of the European Union or the Ministry of Education , Youth and Science of the Republic of Bulgaria .",Method,Tool,Introduce,Hydra: A Software System for Wordnet,https://aclanthology.org/W14-0119.pdf
"The HOG system ( Callmeier et al ., 2004 ) for the integration of shallow and deep linguistic processors ( using a pipeline making use of XML plus XSLT transformations to pass data between processors ) was developed during the Deep Thought project , as was a standard for the integration of semantic analyses produced by diverse components : RMRS ( Copestake , 2003 ) allows underspecification of semantic analyses in such a way that the analysis produced by a shallow component may be considered an underspecification of a fuller semantic analysis produced by a deeper component . Other work ( Waldron et al ., 2006 ) has provided a representation of partial analyses at the level of tokenization / morphology – using a modification of MAF ( Clement and de la Clergerie , 2005 ). Current work within the SciBorg project is investigating more fine - grained integration of shallow and deep processors . Our standoff annotation framework borrows heavily from the MAF proposal . The key components of our framework are ( i ) grounding in primary linguistic data via flexible standoff pointers , ( ii ) dec oration of individual annotations with structured content , ( iii ) representation of structural ambiguity via a lattice of annotations and ( iv ) a structure of intra - annotation dependencies .",Method,Tool,Introduce,A Standoff Annotation Interface between DELPH-IN Components,https://aclanthology.org/W06-2718.pdf
"On the other hand , in the sentence ( B ), the expression simply corresponds to a literal concatenation of the usages of the constituents : the post - positional particle “ に ( ni )” and the verb “ ついて ( tsuite )”, and has a content word meaning “ follow ”. Therefore , when considering machine translation of those Japanese sentences into English , it is necessary to precisely judge the usage of the compound expression “ に ( ni ) ついて ( tsuite )”, as shown in the English translation of the two sentences in Table 1 . There exist widely - used Japanese text processing tools , i . e ., pairs of a morphological analysis tool and a subsequent parsing tool , such as JUMAN + KNP and ChaSen + CaboCha . However , they process those compound expressions only partially , in that their morphological analysis dictionaries list only limited number of compound expressions . Furthermore , even if certain expressions are listed in a morphological analysis Grammatical Function Type # of major # of Example expressions variants post - positional subsequent to predicate 36 67 となると particle / modifying predicate ( to - naru - to ) type subsequent to nominal 45 121 にかけては / modifying predicate ( ni - kakete - ha ) subsequent to predicate , nominal 2 3 という / modifying nominal ( to - iu ) auxiliary verb type 42 146 ていい ( te - ii ) total 125 337 — dictionary , those existing tools often fail in resolving the ambiguities of their usages , such as those in Table 1 .",Method,Tool,Introduce,A Corpus for Classifying Usages of Japanese Compound Functional Expressions,http://nlp.iit.tsukuba.ac.jp/member/utsuro/research/papers/utsuro/Func0508.pdf
"In ( Widdows et al ., 2002 ) tools are presented that visualize meanings of nouns as vector space representation , using LSA ( Deerwester et al ., 1990 ) and graph models using co - occurrences . There is also a range of text - based tools , without any quantitative statistics , e . g . Textpresso ( M ¨ uller et al ., 2004 ), PhraseNet and Walden . For searching words in context , Luhn ( 1960 ) introduced KWIC ( Key Word in Context ) which allows us to search for concordances and is also used in several corpus linguistic tools e . g . ( Culy and Lyding , 2011 ), BNCWeb , Sketch Engine ( Kilgarriff et al ., 2004 ), Corpus Workbench and MonoConc ( Barlow , 1999 ).",Method,Tool,Introduce,Extracting semantic representations from word co-occurrence statistics: A computational study,https://link.springer.com/article/10.3758/BF03193020
"The enormous potential of the web as a source of material for linguistic research in a wide range of areas is well established ( Kilgarriff and Grefenstette , 2003 ), with many new opportunities created by web - scale resources ranging from simple N - grams ( Brants and Franz , 2006 ) to syntactically analyzed text ( Goldberg and Orwant , 2013 ). Yet , while the use of multilingual web data to support linguistic research is well recognized ( Way and Gough , 2003 ), cross - linguistic efforts involving syntax have so far been hampered by the lack of consistent annotation schemata and difficulties relating to coincidental differences in the syntactic analyses produced by parsers for different languages ( Nivre , 2015 ). The Universal Dependencies ( UD ) project seeks to define annotation schemata and guidelines that apply consistently across languages , standardizing e . g . part - of - speech tags , morphological feature sets , dependency relation types , and structural aspects of dependency graphs . The project further aims to create dependency treebanks following these guidelines for many languages .",Method,Tool,Introduce,The WaCky wide web: a collection of very large linguistically processed web-crawled corpora,https://link.springer.com/article/10.1007/s10579-009-9081-4
"By 1992 the creators of WordNet had demonstrated the power and utility of a searchable and open database of English words , organized around core semantic relations such as synonymy , meronymy and holonymy , hypernymy and hyponymy , and so on . Although WordNet was an inspiration to us , its purposes and structure are somewhat different from those of FrameNet . The goal of the FrameNet project ( Fillmore , Johnson , and Petruck 2003 ) was to create a database , to be used by humans and computers , that would include a list of all of the Frames that we could possibly have time to describe . Frames are the cognitive schemata that underlie the meanings of the words associated with that Frame . The example of the frame Compliance is given in Figure 4 .",Method,Tool,Introduce,The BioLexicon: a large-scale terminological resource for biomedical text mining,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-397
"In January 2000 the Nomad robot was deployed to the Elephant moraine in Antarctica for robotic meteorite searching trials . Nomad searched areas known to contain meteorites , autonomously acquiring color images and reflection spectra of both native terrestrial rocks and meteorites , and classifying them . On January 22 , 2000 Nomad successfully identified a meteorite amongst terrestrial rocks on the ice sheet ( ), Overall performance ( using spectra only , due to a problem that developed with camera zoom control ) is indicated by the ROC performance curves in Figure 6 . These were generated from a test set of rocks and meteorites ( 40 and 4 samples respectively , with multiple readings of each ) in a particular area of the moraine . Figure 6 ( i ) is using the a priori classifier built from the lab data ( used to generate Figure 5 ), acquired prior to arrival in Antarctica .",Method,Tool,Introduce,Technology and Field Demonstration of Robotic Search for Antarctic Meteorites,https://journals.sagepub.com/doi/abs/10.1177/02783640022067940?journalCode=ijra
This work is supported in part by the National Hi - Tech Project of China under grant 2008AA01Z150 and the Natural Science Foundation of China under grant 60745002 and 61175057 . Feng Wu is supported in part by the ORCHID project ( ). We are grateful to the anonymous reviewers for their constructive comments and suggestions .,Method,Tool,Introduce,KeJia: The Intelligent Domestic Robot for RoboCup@Home 2015,http://ai.ustc.edu.cn/en/robocup/atHome/files/WEHome2015TDP.pdf
"Infinite Impulse Response ( IIR ) filters have a significant advantage over Finite Impulse Response ( FIR ) filters in signal processing : the length of the impulse response is uncoupled from the number of filter parameters . The length of the impulse response is related to the memory depth of a system , and hence IIR filters allow a greater memory depth than FIR filters of the same order . However , IIR filters are * _CITE_",Method,Tool,Introduce,On multistage finite impulse response (FIR)filters with decimation,https://ieeexplore.ieee.org/abstract/document/1162692
"SSOM , however , performs only slightly worse ( approx . 1 dB ) than STVQ . Considering the fact that SSOM is computationally much less demanding than STVQ & apos ; The Lenna Story can be found at An Annealed Self - Organizing Map for Source Channel Coding 435 ( 0 ( N ) for encoding ) - due to the omission of the convolution with hrs in Eq . ( 4 ) - the result demonstrates the efficiency of SSOM for source channel coding . Figure 4 also shows the generalization behavior of a SSOM codebook optimized for a BER of 0 . 05 ( rectangles ).",Method,Tool,Introduce,An Annealed Self-Organizing Map for Source Channel Coding,https://proceedings.neurips.cc/paper/1997/hash/8fb5f8be2aa9d6c64a04e3ab9f63feee-Abstract.html
"What do Jesus and Darwin have in common ? Other than being associated with two different views on the origin of man , they also have colleges at Cambridge University named after them . If these two names are entered as a query into GoogleTM Sets ( ) it returns a list of other colleges at Cambridge . GoogleTM Sets is a remarkably useful tool which encapsulates a very practical and interesting problem in machine learning and information retrieval . 1 Consider a universe of items D . Depending on the application , the set D may consist of web pages , movies , people , words , proteins , images , or any other object we may wish to form queries on . The user provides a query in the form of a very small subset of items Dc C D . The assumption is that the elements in Dc are examples of some concept / class / cluster in the data .",Method,Tool,Introduce,Data mining from web search queries: A comparison of google trends and baidu index,https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.23201
"Different pollsters use different methodologies , reach different people , and may have sources of random errors , so generally the polls don ’ t fully agree with each other . Aggregators such as Nate Silver ’ s FiveThirtyEight , and The Upshot by the New York Times consolidate these different reports into a single prediction , and hopefully reduce random errors . FiveThirtyEight in particular has a solid track record for their predictions , and as they are transparent about their methodology we use them as a motivating example . To a first - order approximation , they operate as follows : first they take the predictions of all the different pollsters , then they assign a weight to each of the pollsters based on past performance ( and other factors ), and finally they use the weighted average of the pollsters to run simulations and make their own prediction . But could the presence of an institution that rates pollsters inadvertently create perverse incentives for pollsters ?",Method,Tool,Introduce,Why Did the Polls Overestimate Liberal Democrat Support? Sources of Polling Error in the 2010 British General Election,https://www.tandfonline.com/doi/abs/10.1080/17457289.2011.563309
"Finally , section 6 discusses future work and states our conclusions . Tools for statically analyzing binary executables differ in the details of their workings but they all share the same high level logic , which is called recursive disassembly . The tool starts by obtaining the address of the first instruction from a specific location inside the executable . It then places this address on a stack and executes the following steps while the stack is non - empty . It takes the next address from the stack and disassembles ( i . e .",Method,Tool,Introduce,Static Analysis of Binary Executables Using Structural SVMs,https://proceedings.neurips.cc/paper/2010/hash/a1d33d0dfec820b41b54430b50e96b5c-Abstract.html
"Finally , section 6 discusses future work and states our conclusions . Tools for statically analyzing binary executables differ in the details of their workings but they all share the same high level logic , which is called recursive disassembly . The tool starts by obtaining the address of the first instruction from a specific location inside the executable . It then places this address on a stack and executes the following steps while the stack is non - empty . It takes the next address from the stack and disassembles ( i . e .",Method,Tool,Introduce,Static Analysis of Binary Executables Using Structural SVMs,https://proceedings.neurips.cc/paper/2010/hash/a1d33d0dfec820b41b54430b50e96b5c-Abstract.html
"All experiments were implemented using MATLAB . Source code can be found at : https :// github . com / bianan / non - monotone - dr - submodular . As a state - of - the - art global solver , QUADPROGIP [ 39 ] can find the global optimum ( possibly in exponential time ), which were used to calculate the approximation ratios . Our problem instances are synthetic DR - submodular quadratic objectives with down - closed polytope constraints , i . e ., f ( x ) = 2xTHx + hTx + c and P = { x E Rn 1 + | Ax & lt ; b , x & lt ; ¯ u , A E Rmxn ++, b E Rm + }. Both objective and constraints were randomly generated , in the following two manners : In both the above two cases , we set b = 1m , and u ¯ to be the tightest upper bound of P by ¯ uj = miniE [ m ] Aij , dj E [ n ].",Method,Tool,Introduce,Fast approximate energy minimization via graph cuts,https://ieeexplore.ieee.org/abstract/document/969114
"The ChemAgora portal is also a long - term strategic development , to which the European Commission ’ s Joint Research Centre is fully committed . ChemAgora has already caught the attention of other initiatives , e . g . IPCheM ( ), a European Commission project , which will take advantage of the search service provided by ChemAgora .",Method,Tool,Introduce,AlertsAbout Navbar Search Filter Bioinformatics Enter search term SearchAdvanced Search Issue Cover Volume 31Issue 9 May 2015 Article Contents Abstract 1 Introduction 2 Data infrastructure and access 3 Current developments 4 Conclusion Acknowledgements Funding References Author notes Supplementary data < Previous Next > JOURNAL ARTICLE diXa: a data infrastructure for chemical safety assessmen,https://academic.oup.com/bioinformatics/article-abstract/31/9/1505/200092
"Some data types cannot be fully shared ( e . g ., EHR data — see rule 5 ), but most algorithms and summary results / statistics are shareable . Each of these types of open data necessitates a different platform for data sharing . Figshare ( ) allows users to share data involving published figures . Github ( https :// github . com /) allows users to share code that is in development or published . For code that is well developed , open - source packages can be created , for example , an R library , which can be deposited in CRAN or bioconductor .",Method,Tool,Introduce,Access and use of government data by research and advocacy organisations in India: a survey of (potential) open data ecosystem,https://dl.acm.org/doi/abs/10.1145/2691195.2691262
LanguageTool was developed by Naber ( 2003 ). It can run as a stand - alone program and as an extension for OpenOffice . Org1 and LibreOffice2 . LanguageTool is distributed through LanguageTool ’ s website : _CITE_,Method,Tool,Produce,A Grammar Checker for Tagalog using LanguageTool,https://aclanthology.org/W11-3402.pdf
"However , in contrast to our implementation and that of Shafran et al ( 2011 ), no expansion into an WFST with aligned input / output is described . Lexicographic semirings , used for PoS tagging disambiguation ( Shafran et al ., 2011 ), have been also shown to be useful in other tasks ( Sproat et al ., 2014 ), such as optimized epsilon encoding for backoff language models ( Roark et al ., 2011 ), and hierarchical phrase - based decoding with Pushdown Automata ( Allauzen et al ., 2014 ). The tools for disambiguation and WFST composition with bilingual models , along with a tutorial to replicate Section 4 . 2 , are all available at _CITE_",Method,Tool,Produce,Transducer Disambiguation with Sparse Topological Features,https://aclanthology.org/D15-1273.pdf
"Examples of the use of JSrealB , and a webbased development environment are available at : jsrealb - bilingual - text - realiser The javascript code of the realizer , the lexicon and tables are made available to the NLG community at : https :// github . com / rali - udem / JSrealB",Method,Tool,Produce,JSrealB: A bilingual text realizer for web programming ,http://rali.iro.umontreal.ca/rali/?q=en/node/1473
"Its output is a ( time - varying ) 3d model that can be displayed by Partiview , an external data viewer . Future plans include adding more scalable embedding algorithms , and allowing other output formats . Ndaona , documentation , and examples of models created with it , can be found at _CITE_",Method,Tool,Produce,Automating the Creation of Interactive Glyph-supplemented Scatterplots for Visualizing Algorithm Results,https://aclanthology.org/N06-4008.pdf
"Compared to existing frameworks , the S - Space Package supports a much wider variety of algorithms and provides significantly more reusable developer utilities for word spaces , such as tokenizing and filtering , sparse vectors and matrices , specialized data structures , and seamless integration with external programs for dimensionality reduction and clustering . We hope that the release of this framework will greatly facilitate other researchers in their efforts to develop and validate new word space models . The toolkit is available at , which includes a wiki",Method,Tool,Produce,The S-Space Package: An Open Source Package for Word Space Models,https://aclanthology.org/P10-4006.pdf
"We thank Shahar Maoz , Rami Marelly , Yoav Goldberg and three anonymous reviewers for their insightful comments on an earlier draft . This research was supported by an Advanced Research Grant to D . Harel from the European Research Council ( ERC ) under the European Community ‘ s Seventh Framework Programme ( FP7 / 2007 - 2013 ), and by a grant to D . Harel from the Israel Science Foundation ( ISF ). visual editor are available via _CITE_",Method,Tool,Produce,Semantic Parsing Using Content and Context: A Case Study from Requirements Elicitation,https://aclanthology.org/D14-1136.pdf
"Qualitative analysis of these word clusters yields insights about NLP and linguistic phenomena in this genre . Additionally , we contribute the first POS annotation guidelines for such text and release a new dataset of English language tweets annotated using these guidelines . Tagging software , annotation guidelines , and large - scale word clusters are available at : This paper describes release 0 . 3 of the “ CMU Twitter Part - of - Speech Tagger ” and annotated data .",Method,Tool,Produce,Like It or Not: A Survey of Twitter Sentiment Analysis Methods,https://dl.acm.org/doi/abs/10.1145/2938640
"MAISE can be obtained from the author ’ s webpage : The release includes MAISE ’ s source code , instructions , documentation , and a tutorial . MAISE is an open - source tool , licensed under the terms of the GNU Lesser General Public License ( LGPL ).",Method,Tool,Produce,"MAISE: A Flexible, Configurable, Extensible Open Source Package for Mass AI System Evaluation",https://aclanthology.org/W11-2114.pdf
"Furthermore , the optimal personality of the system is likely to be application - dependent ; it would thus be useful to evaluate how the user ’ s and the system ’ s personality affect task performance in different applications . The PERSONAGE language generator is available for download at http :// mi . eng . cam . ac . uk /∼ farm2 / personage , as well as the personality - annotated corpus collected for our experiments . An on - line demonstrator and a tutorial for customizing PERSONAGE for a new domain can be found at _CITE_",Method,Tool,Produce,Controlling User Perceptions of Linguistic Style: Trainable Generation of Personality Traits,https://watermark.silverchair.com/coli_a_00063.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAqowggKmBgkqhkiG9w0BBwagggKXMIICkwIBADCCAowGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMMbqEvVmV3BAXZ_IVAgEQgIICXVdw4u3yAC26PA2-_BESvRiFqUMnpYLotiAdXOjoz6DCUvX47GIEifWba4SD0FFWzuy9TTWXpowyeHHN_3w8Q16Wcq7mG6R2zbxkG48kloJGBqpJMWHsVnGfwHqZ7n8rsFsPTGfvYsodj8SHeMDY572Dkm5RRYAvUd4YqpYNOGnRh9Uc2Ev7-Vmv6sVknT_KaBGewnrd1o6YuLN46aEZX9p30dOWTpv1fMdCg89eJlPaUvVkipD_Rc-0iaoXjKEhwf47YL44EuLTZpl_3rBAbQlh0fYuHuvj-3m5ZwU2QeXxCTnDcTFL89SeqVbCbivq3zGWmPlv_qYBrsbUgomcA6fuWML0bFfpMzxp7yJcUcKiZbNWD4NI7iCb4Tg78FMJYYaJwbLhC9LQBC0H8tT4grYfXvxyGDCtWpN6WmWwU_AckjdBLJJu827JrhTWzEm3RpY8i_TsYA6kVRMxhoQtznHwZ2kCeLpez4_OSDxovUg_zeojFft1TyQIUe7oJZDl9UaY5XU_nfB6guuYGNfNLJ0BCJZ_JMtOoBMuYA40zgeK2_r8QTgVUdWtDA2si5OEmTw_SGIzFOuVNwX8MoftANBinFCj58KEUxO2X_FTjcRxueQg3uKtSVrk01xhGrVNSgiX3rWtPiOIdrTQ_iAsDaP6PpghH0z5jJelnQn8O5XxMucshftH-cfHLo1uoSjCqtuPBuyGOyOfxNjuJSMvVXzIVDGQ6UWRcq0x03LFDfkYkdZCtZJwWgNalyWsmCAeq6p_b7BNT3WafcKNW4rOaLU1d9SNtuuIvjC8LBwD
Table 3 shows the performance of our Ngrambased system using the SMR technique . First row is the WMT07 baseline system which can be reproduced following the instructions in This baseline system uses a non - monotonic search . Second row shows the results of the Ngram - based system presented in section 2 using the weighted reordering graph trained with the best configuration found in the above section ( 200 statistical classes and an Ngram of length 5 ).,Method,Tool,Produce,Analysis of statistical and morphological classes to generate weighted reordering hypotheses on a Statistical Machine Translation system,https://aclanthology.org/W07-0721.pdf
"In future work , we hope to further extend the coverage of the provided system outputs as well as their analysis to cover all participants of all tasks in the BioNLP Shared Task 2011 . We also aim to use the compiled resource in further study of appropriate criteria for the evaluation of event extraction methods and deeper analysis of the remaining challenges in event extraction . To encourage further study of all aspects of event extraction , all resources and tools introduced in this study are provided freely to the community from _CITE_",Method,Tool,Produce,BioNLP Shared Task 2011: Supporting Resources,https://aclanthology.org/W11-1816.pdf
"We have successfully combined LXGram with a part - of - speech tagger and a morphological analyzer ( more in Section 6 ). The grammar code includes mappings from the input format ( XML ) to the feature structures that are manipulated by the grammar . Availability A version of LXGram is publicly available at LXGram can be used by applications without any knowledge of the grammar ’ s implementation or internal workings . The LKB allows for applications to communicate with the grammar via sockets , accepting parser input in XML or raw text and returning semantic representations in XML , for which a DTD is available .",Method,Tool,Produce,High Precision Analysis of NPs with a Deep Processing Grammar,https://aclanthology.org/W08-2204.pdf
"Collocation segmentation is done on a separate line basis , i . e ., for each text line , which is usually a paragraph , the average and the minimum combinability values are determined and the threshold is set at 50 percent , midway between the average and the minimum . The Average Minimum Law is applied in tandem . The tool CoSegment for collocation segmentation is available at ( ). Table 3 presents the distribution of segments by length , i . e ., by the number of words . The length of collocation segments varies from 1 to 7 words .",Method,Tool,Produce,Applying Collocation Segmentation to the ACL Anthology Reference Corpus,https://aclanthology.org/W12-3207.pdf
"Regardless of actual performance , all submissions contribute to the common effort to produce an effective Chinese spell checker , and the individual reports in the Bake - off proceedings provide useful insight into Chinese language processing . We hope the data sets collected for this Bakeoff can facilitate and expedite the development of effective Chinese spelling checkers . All data sets with gold standards and evaluation tool are publicly available for research purposes at Based on the results of this Bake - off , we plan to build new language resources to improve existing and develop new techniques for computer",Method,Tool,Produce,Overview of SIGHAN 2014 Bake-off for Chinese Spelling Check,https://aclanthology.org/W14-6820.pdf
"Naturally , this is only an overall view of the results obtained . The new extended WordNet . PT version is also a crucial resource allowing for contrastive studies on lexicalization patterns depending on semantic domains or on frequency of use , for instance , for all or for specific Portuguese varieties . In order to make these data publicly available , a new WordNet . PT version , the WordNet . PTglobal has been released on the WWW . Releasing the WordNet . PT fragment extended to Portuguese varieties online involved developing an updated version of the web interface for wordnet online navigation . In Section 3 we present the main features of this web interface and how users can navigate and straightforwardly access the data on Portuguese varieties .",Method,Tool,Produce,Generation of MultilingualOntology Lexica with M-ATOLL,https://core.ac.uk/reader/211816860
"We use the German corpus ( which was developed first ) as our example throughout . The procedure was carried on a server running RH Fedora Core 3 with 4 GB RAM , Dual Xeon 4 . 3 GHz CPUs and about 2 . 5 TB hard disk space . We are making the tools we develop as part of the project freely available , in the hope of stimulating public sharing of resources and know - how . We would like a “ balanced ” resource , containing a range of types of text corresponding , to some degree , to the mix of texts we find in designed linguistic corpora ( Atkins et al ., 1992 ), though also including text types found on the Web which were not anticipated in linguists ’ corpus design discussions . We do not want a “ blind ” sample dominated by product listings , catalogues and computer scientists ’ bulletin boards .",Method,Tool,Produce,Large linguistically-processed Web corpora for multiple languages,https://dl.acm.org/doi/pdf/10.5555/1608974.1608976
"We omit to mention the argument / 1 , hasRole / 2 and role / 3 modules because they are present for all languages . A more detailed description of the formulae can be found in our MLN model files . They can be used both as a reference and as input to our Markov Logic Engine , and thus allow the reader to easily reproduce our results . Global formulae relate several hidden ground atoms . We use them for two purposes : to ensure consis tency between the decisions of all SRL stages and to capture some of our intuition about the task .",Method,Tool,Produce,"Jointly Identifying Predicates, Arguments and Senses using Markov Logic",https://aclanthology.org/N09-1018.pdf
"She has been waiting for him for 20 years . The reduplication scanner will be integrated to vnTokenizer - an open source and highly accurate tokenizer for Vietnamese texts ( Le et al ., 2008 ). The software and related resources will be distributed under the GNU General Public Lisence and it will be soon available online . We have presented for the first time a computational model for the reduplication of the Vietnamese language . We show that a large class of reduplicative words can be modeled effectively by sequential finite - state string - to - string transducers .",Method,Tool,Produce,"Knowledge, Information and Web Intelligence",https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=de1555d142a5bc0c9180cc66fd7fc814d77e0cf1
"SVM - based chunking is performed using the features to yield a protein name tagged sentence . Our morphological analysis gives ( a ) sophisticated tokenization , ( b ) part - of - speech tagging and ( c ) annotation of value - added information such as the stemmed form of a word , accession numbers to biomedical resources . Our morphological analyzer for biomedical English , cocab , is inspired by the work of Yamashita and Matsumoto ( 2000 ). We first define terms used in this paper with an illustration in Figure 2 . A lexeme is an entry in a dictionary .",Method,Tool,Produce,Protein Name Tagging for Biomedical Annotation in Text,https://aclanthology.org/W03-1309.pdf
"Although much work still needs to be done , the feedback from deaf associations was very positive . Extra details about this work can be found in ( Almeida , 2104 ) and ( Almeida et al ., 2015 ). The whole system is freely available . This paper is organised as follows : Section 2 describes the proposed architecture , and Section 3 its implementation . In Section 4 we present our prototype and , in Section 5 , a preliminary evaluation .",Method,Tool,Produce,Coupling Natural Language Processing and Animation Synthesis in Portuguese Sign Language Translation,https://aclanthology.org/W15-2815.pdf
"We show how a Wikipedia - specific Semantic Relatedness measure that leverages the link structure of Wikipedia ( Milne and Witten , 2008b ) allows 3W to be radically more precise at high levels of yield when compared to baseline Wikifiers that target general text . Our experiment shows that 3W can add on average seven new links per article at precision of 0 . 98 , adding approximately 28 million new links to 4 million articles across English Wikipedia . In this section , we define our link extraction task . A link l is a pair of a surface form sl and a concept tl . A surface form is a span of tokens in an article , and the concept is a Wikipedia article referred to by the surface form .",Method,Tool,Produce,Adding High-Precision Links to Wikipedia,https://aclanthology.org/D14-1072.pdf
"For further details and results , the reader is referred to the key papers cited herein . The first step is to crawl data from a variety of forums and mailing lists , for which we have developed open - source scraping software in the form of SITESCRAPER . SITESCRAPER is designed such that the user simply copies relevant content from a browserrendered version of a given set of pages , which it interprets as a structured record , and translates into a generalised XPATH query . Next , we perform named entity recognition ( NER ) over each thread to identify entities such as package and distribution names , version numbers and snippets of code ; as part of this , we perform version anchoring , in identifying what entity each version number relates to . To generate thread - level metadata , we classify each thread for the following three features , based on an ordinal scale of 1 – 5 ( Baldwin et al ., 2007 ): Complete : Is the problem description complete ?",Method,Tool,Produce,Intelligent Linux Information Access by Data Mining: the ILIAD Project,https://aclanthology.org/W10-0508.pdf
"When a numerical expression is accompanied by a modifier such as over , about , or more than , we updated the value and modifier fields appropriately . Internally , all values are represented by ranges ( e . g ., 75 is represented by the range [ 75 , 75 ]). We developed an extractor and a normalizer for Japanese numerical expressions . We will outline the algorithm used in the normalizer with an example sentence : “ Roughly three thousand kilograms of meats have been provided every day .” We used a dictionary to perform procedures 2 and 3 ( Table 3 ). If the words that precede or follow an extracted number match an entry in the dictionary , we change the semantic representation as described in the operation .",Method,Tool,Produce,Is a 204 cm Man Tall or Small ? Acquisition of Numerical Common Sense from the Web,https://aclanthology.org/P13-1038.pdf
"For example , in the British National Corpus ( 2007 ), “ however ” seems more negative than “ but ”. Also , compared with “ but ”, “ however ” appears more frequently at the beginning of a sentence . With this in mind , we proposed GLANCE , a text visualization tool , which presents corpus data using charts and graphs to help language learners understand the lexical phenomena of a word quickly and intuitively . In this paper , we focused on five types of lexical phenomena : polarity , position , POS , form and discipline , which will be detailed in the Section 3 . Given a single query word , the GLANCE system shows graphical representations of its lexical phenomena sequentially within a single web page .",Method,Tool,Produce,GLANCE Visualizes Lexical Phenomena for Language Learning,https://aclanthology.org/W14-3105.pdf
"The weight vector w ? in our datasets was known , so we do not evaluate EELS . This section contains a high - level description of our experimental setup , with details on our implementation , baseline algorithms , and policy classes deferred to Appendix C . Software is available at Data : We used two large - scale learning - to - rank datasets : MSLR [ 17 ] and all folds of the Yahoo ! Learning - to - Rank dataset [ 5 ].",Method,Tool,Produce,Contextual semibandits via supervised learning oracles,https://proceedings.neurips.cc/paper_files/paper/2016/file/e1d5be1c7f2f456670de3d53c7b54f4a-Paper.pdf
"We find ULURU quickly converges to the OLS estimate , although it is not able to overcome the bias induced by the corrupted datapoints despite its two - step procedure . The performance of IWS - LS relative to OLS in the airline delay problem suggests that the corrupted observation model is a more realistic modelling scenario than the standard sub - Gaussian design model for some tasks . Software is available at Acknowledgements . We thank David Balduzzi , Cheng Soon Ong and the anonymous reviewers for invaluable discussions , suggestions and comments .",Method,Tool,Produce,Fast and Robust Least Squares Estimation in Corrupted Linear Models,https://proceedings.neurips.cc/paper_files/paper/2014/file/6a9aeddfc689c1d0e3b9ccc3ab651bc5-Paper.pdf
"MMAP estimation is difficult as it corresponds to the optimization of an intractable integral , such that the optimization target is expensive to evaluate and gives noisy results . Current PPS inference engines are typically unsuited to such settings . We therefore introduce BOPP ( Bayesian optimization for probabilistic programs ) which couples existing inference algorithms from PPS , like Anglican [ 29 ], with a new Gaussian process ( GP ) [ 22 ] based Bayesian optimization ( BO ) [ 11 , 15 , 20 , 23 ] package . To demonstrate the functionality provided by BOPP , we consider an example application of engineering design . Engineering design relies extensively on simulations which typically have two things in common : the desire of the user to find a single best design and an uncertainty in the environment in which the designed component will live .",Method,Tool,Produce,Bayesian Optimization for Probabilistic Programs,https://proceedings.neurips.cc/paper_files/paper/2016/file/31fefc0e570cb3860f2a6d4b38c6490d-Paper.pdf
"We then fit a beta distribution for each of the cell types and used these distributions to calculate the probability that the score of the corresponding cell type is present in the mixture by random ( Additional file 2 : Figure S7 ). Applying this procedure to the test simulated mixtures enabled detection of about half of the non - expected nonnegligible scores as non - significant ( 46 . 9 % change — from 56 . 4 % non - negligible scores to 28 . 8 % with p value & gt ; 0 . 2 ), while detecting as non - significant only 15 . 3 % of nonnegligible scores for cell types used for generating the mixture ( from 88 . 6 % non - negligible scores to 75 . 1 %) ( Additional file 4 ). This pipeline for generating adjusted cell type enrichment scores from gene expression profiles , which we named xCell , is available as an R package and a simple web tool ( ). Validation of enrichment scores in simulated expression profiles We next compared the ability of xCell scores to infer the underlying cell type enrichments in simulated mixtures with a set of 53 previously published signatures corresponding to 26 cell types [ 6 , 12 , 27 , 28 ] ( Additional file 5 ). Our analyses showed that xCell outperformed the previously published signatures in recapitulating the underlying abundances , in mixtures generated using the training samples ( Additional file 2 : Figure S5 ) and the test samples ( Additional file 2 : Figure S6 ) and an independent data source ( GSE60424 [ 26 ]) ( Fig .",Method,Tool,Produce,xCell: digitally portraying the tissue cellular heterogeneity landscape,https://link.springer.com/article/10.1186/s13059-017-1349-1
"It may greatly enhance the utility of exome sequencing in disease studies . An R package incorporating the functionality of CANOES is available for download . The R package , documentation and source code may be obtained from _CITE_",Method,Tool,Produce,CANOES: detecting rare copy number variants from whole exome sequencing data,https://watermark.silverchair.com/gku345.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAArswggK3BgkqhkiG9w0BBwagggKoMIICpAIBADCCAp0GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM_KVAzNe_mF-hEogVAgEQgIICbrYqIzim6pqQQxJhuBm-PI8l7rWdMO2Ky_BpPVJ9Wihte6lo2ygkfALQCoxGra9dGrBA1zHDM7f5IUifUjwkGvyYjHWlZwu_Bg-pdzJrDRk5sd7JUzMyVHni7eHSShW91bhbG5bwtuC3W5_blzp0aCrTe0l3q7OaFV48Mkva4yYKsBtQeNI3BzvZFM0al1nhLeToXwbB7kFmIQB52IasKSu8yf_5NeEjEVd_SQ_TJZZ2ukvjA8Oe0T6fard2N4U0ui1Y4ZhipNJXiFgTpmOEH4xRMmJbGKj6T6Yqlwiqi_pZWwV3FcbWyw-TDGJmJVOjHGm-wEXJZpzZB-auFTkxy0ELrm8rtZPo9Mm763hqYD1anNgZuMCHoheOY-6LWTNsgZh9EKI1j7WAE456pfGv-YAU1PEv-TiSdIGeB9FmLh2NIfUOR1lAYRN5xc0bfsBhl-BIPaql6Zt-WlKsiHHrXkQuukQ99sNBzMp6MTeUwF9NQCBtkjpyuoNET7U8mjkrT25qg5mraqQKCjmvnrremLZbIoBSlDFyUPfAaA5Z6y2-UZK3XtUJt2yKxqOXtTMLPLBA6zPDGdREYL4eikgnXuajQ6MN3omjkJmjQlPI-ghqf9DL5-Q4zBDXFFNwob7qxwzMfIAWgVDTKeAbP5iFpOgBexNP7EEVm6DLah9R84WhRGvYj7D0r7l5K3Ro2OpU2VR7K15lyz1trphO8l85ESg91GcVmHMTRfDZrUzvfHUdwWIqgDdy0alhqGwmEmUX6pCbxI3STmvP8nBVgRcOJwtSxyxP_ZEugs_-24m77e_VM8Rtk4CQFeeBmQS5qU8
CROSS is freely available at new submission / cross .,Method,Tool,Produce,State of Art: Cross Lingual Information Retrieval System for Indian Languages,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=2fafb89e732a1492ce777c133ce6e411a89b43b0
"The GridCAT is openly available at the Neuroimaging Informatics Tools and Resources Clearinghouse ( NITRC ) and can be downloaded from : The GridCAT is free software and can be redistributed and / or modified under the terms of the GNU General Public License as published by the Free Software Foundation , either version 3 of the License , or ( at your option ) any later version . A copy of the GNU General Public License is",Method,Tool,Produce,The GridCAT: A Toolbox for Automated Analysis of Human Grid Cell Codes in fMRI,https://www.frontiersin.org/articles/10.3389/fninf.2017.00047/full
"The method is implemented in the add - on SpeciesNetwork for BEAST 2 ( Bouckaert et al . 2014 ), including the inference , simulation , and summary tools , and is hosted publicly on GitHub ( last accessed December 10 , 2017 ).",Method,Tool,Produce,Bayesian Inference of Species Networks from Multilocus Sequence Data,https://watermark.silverchair.com/msx307.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAr0wggK5BgkqhkiG9w0BBwagggKqMIICpgIBADCCAp8GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMTrKIuadrFKZfki7sAgEQgIICcMflMDUdFQkdktKNG9NPFO6ZxiH1Yv3v88pgEhy2EP8Fei5SKWE8H1mXLpQnJWblPVnlhSLJgJnuP4c_u0Gelps_K0DQmmdYlrGASHTnrqAJ5FiJGG5KCI0YgzGDYci1jPlot5VpJ0b0uCU7ttHi4ZXvl7IuU3teOSfg79CJUae43GPh2vTsxABSJvMtNYyW9A8jmtSHP4QIqc8HYEKFHsQL2xiLStn0QWJLtfq4l8HrO5qf5ni8rW_bgxDGi-E_EK6xbZLp2wQgmRe_A-aIvslBxY61y2IGflWdHY1ouUKobOUs2MdYQkSdND14zwxObMjaU2Ns1UNzN_q_sAmRKBKtTnFXeJjxpuBTuJic0IH7v55CzT9kA0qXc_LP_cHNiqC8CmH83EaqedKEBzcvCM0c_q4o0WmbNk9Fk6dXwcWGc5te8Ysmuom_GGzajxRsXUeC-njTSi6zUWzLEBa2qUCQOntwOMfGMsk31HkE0SaHgDV5DkCl4SOH2eq1gpGrkyPiqySQaj8Nswdh8jBIx8pk5i5MkEqm5eLFWGvJQtIGnZLS45yspwdRC306fJs0qFTXEpCOZMFcZyEuetisEGh0AmWVIbbXh71_wlu36zpCWeHVi83ffQ2dNc0ft7P-5q1x1SDNnkZgFbRxXHXUMS1iQlWxYT8PM5GFM-10O9xDZ7aTzw_W-qgf_4vUu47nj8TWGu8tlX2zMC05249LMO6l4r37_8sqydSumH915wCqStU0aYUrWww_kA_ciCuvvzHz0RhdHb3lcv0G2gAqSipYM8_xfguxWrMVDaMwkNEnwvqf0eK8F2CCza023Voy7w
"Incorporating negative evidence allows Omics Integrator to avoid unexpressed genes and avoid being biased toward highly - studied hub proteins , except when they are strongly implicated by the data . The software is comprised of two individual tools , Garnet and Forest , that can be run together or independently to allow a user to perform advanced integration of multiple types of high - throughput data as well as create condition - specific subnetworks of protein interactions that best connect the observed changes in various datasets . It is available at and on GitHub at https :// github . com / fraenkel - lab / OmicsIntegrator . This is a PLOS Computational Biology Software paper .",Method,Tool,Produce,Network-Based Interpretation of Diverse High-Throughput Datasets through the Omics Integrator Software Package,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004879
"Furthermore , experimentaldata - constrained RNA secondary structures are not available for RBP binding sites in any current database . Finally , it is often desirable to know whether RBPs can interact with RNA molecules , especially novel lncRNAs ; however , only a few online tools ( 21 , 22 ) are available for predicting RBP binding sites on given RNA sequences . Previously , we developed CLIPdb ( 20 ), which simply provided RBP binding sites without further annotation and interpretation ( ). Here , we constructed a new platform for CLIPdb version 2 , POSTAR , which focuses on POST - trAnscriptional Regulation coordinated by RNA - binding proteins ( RBPs ), to facilitate searching , annotation , visualization , integration , connection , and interpretation of data regarding multiple posttranscriptional regulatory events in humans and mice . First and foremost , POSTAR provides a comprehensive repository of experimentally probed ( i . e .",Method,Tool,Produce,POSTAR: a platform for exploring post-transcriptional regulation coordinated by RNA-binding proteins,https://watermark.silverchair.com/gkw888.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAr4wggK6BgkqhkiG9w0BBwagggKrMIICpwIBADCCAqAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM6cwCFyzuO2kST_aZAgEQgIICcQBJbVGF5eV8ZV3ioVph5G14JROEn6W7DRjYQH5pR67bAIUdF7deVrAJreMheiQlDfVEyrMlXw0TxbohMgjKRw_VmgyGYzj635prizf94qrYJa55LRmH0YX9l89mTMwQU9QfoWDOQpldoaTnhykR_37b8OMSTQUUBl5zeuhDl4QL_KrWr54WbSI-bQUYwDQnpmEp-RAwMRlaRn7G2JEmYCLArbrbvvL94V_3esNz5n3RQznGU5xDCzWxTM3MVxR4_xrxJumNtXB1SR_AsZxPrAkt4QsP2YxOgBtSRU1NWykX8U0ehRFIhah-lp83QECtknS9spxSI0XtZahhW4BrMp6RpZxfhpkN-69sSCcgnk3rXn7vnbqYNTlMHRVJGwcDLyAhro6sHV3Tkq3EO59bfZh2LougsqRDHdlttE0LUJYgGsm6FnR7HjOhoQbv1A9WRchtbActyYyu8M-nFSG-qZ1oM_X-BE3bA1bYKgm3Fpn6yDfglKuI0wOn7W0AgFdgGEcDImIcao3q9UBkuF76_THUenrluF0kzMOEylwPE4c23iGPSq_uueg-kUFisaTh60C8gXwqORM7fX-tEqDtfOESVJmIaG9iobDYRkPcTjAT7RGzW1wO74iTJ7Z5SjG_Rye_-FppEp3qoCcW80knXLjhzvniPCuOadb07ZSX8m9-tkMGTlrsBMxFrjvV37spy0SYtrpcB1MhGSKoMFatJQCDJaUJEtenl7MT8HOEe5ZUC0xhBqWR0D0jMPjqu4FpPJig7oI0MiPazMxfbfCgdv72qEzo-K6arXpCby7FnpQrCI8PoHqbn3ER5pbU-CleYEM
"Ontologized MIABIS ( OMIABIS ) ( ) was created as an OWL implementation of the BBMRI & apos ; s Minimum Information About BIobank data Sharing ( MIABIS ). It is based on the BBMRI use cases , which are mostly population and cohort based . Due to juridical and ethical reasons searching individual specimens was out of scope for the initial implementation of OMIABIS [ 8 ].",Method,Tool,Produce,GI WORKGROUP “ONTOLOGIES IN BIOMEDICINE AND LIFE SCIENCES” (OBML),https://d1wqtxts1xzle7.cloudfront.net/52384757/obml2012report-libre.pdf?1490888853=&response-content-disposition=inline%3B+filename%3DIntegration_of_the_Anatomical_Therapeuti.pdf&Expires=1686213776&Signature=MtP-Nju0NJO1tFR7DuHv4PqgoHcSsUezFe5IhPtz6xB1u5KVdERPdBNOR5ynPDZ5D8DBlkCNyDluxJuN0H64AwkHFZQF5J8HOd6apPhQ5oC2im8aVo5eli1Dla67LIYYZMrno2S6J1ErIweQI~a4bIhr-hsK~mdxndZ0-yWFc~S-CLmsUifEjltDjk9~CEHOIc~i8bleowmRlmmZs5YltQfwF6dQ7KYTSDGheoa1OStU2v4IVOZKlylRan7Ht2J8z2ufU~SUV6Kt7fh1JUxW3UkyA7I4tR9IUZUzWawjEcdQeEAqOiGXRu3B0vJL62Rm~PldCqpA7kMFTtddOIyk0g__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA#page=10
"A larger number thus indicates better performance . For each given threshold , we colored the best method with red and the second best method with blue of the effect size distribution is a key to achieve accurate prediction performance24 , 34 , 36 , we expect our non - parametric model to perform robustly well across a range of polygenic architectures . Our method is implemented in the DPR software , freely available at Simulations . We first compare the performance of DPR with several other commonly used prediction methods using simulations .",Method,Tool,Produce,Non-parametric genetic prediction of complex traits with latent Dirichlet process regression models,https://www.nature.com/articles/s41467-017-00470-2
"In addition , we integrated Cytoscape [ 23 ] Java Web Start technology so that the association network generated by eLSA can be immediately visualized . Based on these efforts , we anticipate that our novel eLSA methodology , as implemented by the newly developed pipeline software , will significantly assist researchers requiring systematic discovery of time - dependent associations . More information about the software and web services is available from the eLSA homepage at _CITE_",Method,Tool,Produce,Extended local similarity analysis (eLSA) of microbial community and other time series data with replicates,https://link.springer.com/article/10.1186/1752-0509-5-S2-S15
"All metabolic reconstructions generated by this study are publicly available at http :// hmpdacc . org / HMMRC . Taxonomic abundances derived from shotgun data are provided at http :// hmpdacc . org / HMSCP , and input Illumina reads at http :// hmpdacc . org / HMIWGS . The open source HUMAnN software can be obtained at _CITE_",Method,Tool,Produce,Metabolic Reconstruction for Metagenomic Data and Its Application to the Human Microbiome,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002358
"These functions include retrieving the druggable targets for a disease of interest , or obtaining the biological pathways for a list of disease genes . The disgenet2r package also expedites the integration of DisGeNET data with other R packages . The source code and documentation of disgenet2r package are available at group / disgenet2r .",Method,Tool,Produce,DisGeNET: a comprehensive platform integrating information on human disease-associated genes and variants,https://watermark.silverchair.com/gkw943.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAr4wggK6BgkqhkiG9w0BBwagggKrMIICpwIBADCCAqAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQM-6muVIsVOXIye-HMAgEQgIICcdj3MKFa27GnDITFlBVJluCJxJO6dKNb3CyGCxCyGK0kQsf7XBnW5TyvrZ9slLqdVkPhqg3afH8fvAJL5JZTCYBYm8Nh1flYltL-EyU_xZDv7PTO-5pYuV8ewj3efTHzxPDW9gZzL3OEpa5UKr604nUWzwCINCKQoae96MTygVM7tJo2eiFCnFICClQsvitUuOZSwL0_-6Zm34hxbryFekR1-w3XDJKmT0bKErW3N1j5KdXbKdt2slAzJBNL2Rrt-dv24QsasxWkdQJts1huvp65CzS-KuLjvq5vHu6x3_HxbsL1_MbNrLNJm6zlR4_b0pSj12wbCkFT1-AOJML-5uK4tcqWlEhB_JE1yXouZK4RIW48R0raxOxvwo5zS69XyfdG9ImuG7HxgZUhQGNO-xZXRBRAdzw1isLyQpufeAzDD7_SJGBLc8XKkeSbs6cqzSRyijnouHzgiMnyb8-2ekKPPFpI7N1mt4F_gJsXM02DNBP3zxtS-a2Ky6vQewexw5syDolvqRqShgrj093Gbnmve0XQfzJRD1t94PWmrv-Yfc81rjl2EeWIcgdw8Ek4OxrRPX3HAR2pDuuh6Q_gYkatXBaW0hpxfYdXRV6I53IGdCkq0myNnBtJFvq4GAKc96TKFhEtOwdccw9x7SXmaeicHo6ZioMT4ebmmn3L5SAiHVhcaa5HSg2VLSZjmiC9Q1Kvq68tWWxcbDy1IERojMmQLEplyHh4Y1s5agH75jsJo4JnM5aXiGzadhl40AFI0Lo8vEQT0WOTH8ABqroBiY3MIuCdjHDwR-KNMJZTEtJrTkj-pJ-0tyR8XMQ1TalTZGU
"Data exploration using the FANTOMS portal An online website is available ( ) where all data generated within the FANTOM5 project are collected , and visualization and browsing tools are publicly accessible . Users interested in downloading the whole genomic coordinates of CAGE TSSs , peaks , expression values and gene associations for macaque as well as other organisms , such as human , can access our ftp site fantom . gsc . riken . jp / 5 / datafiles / latest /.",Method,Tool,Produce,Update of the FANTOM web resource: high resolution transcriptome of diverse cell types in mammals,https://watermark.silverchair.com/gkw995.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAr4wggK6BgkqhkiG9w0BBwagggKrMIICpwIBADCCAqAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMkp1UNEMFjLoU99igAgEQgIICce3iVZlID3wBuGzPv9ftW-Ic6lOQayuV2RbnVJizW0byIhBcOMxcENCINbskF6hDS6L4GoXt2rGgc0sq2FizuK9OjYTMwKn1g14F2YKOx3G5nuw5AaUMLPhKdH2vN3dB2OYlhqDHOF2f5016f2Lp0mOeWVoqqNfKWqkzUoYni6pLJDcUzNKrdw0Ughi9seUxASSgi1SIZ2sV4oaIZfzBUih7s0xav4rjYaAz7Wod7OoYHDmMeepE1VZRZa6PkPsHIyGVwtDRmOpG-zMhUcW6PTyCSP-UymO5aPBO5NTwbTxops0tYJ5vc-XclQPvrMeiIKe_rP9-AX5DQpzqEI4VZT9q_UuKWrDHbxcF7VS-dUfDqrEjVNFmMQmmlImhi120j9qzM5E53sg3Vj2k8QjP0oVQ6W-fOGAgIorLa7NqvzUF8_-xN6HkMnDXb1PVoH7GKkk-k8SzIQHlaUAszBymTLRcIhb2xiZGx4oPOkF-Hv8wYJXu-N2a1ZJ91venTsypT_zbthTCFHtedMQTpVCwMbWvw7ISawd-y_h89315HxXqmjXCpkBWwKRNlyjCUjg3KSCpnfQFBZEhoxcbd2NNQjavkkCpp7ztOiCP1t-LGEV43YlOq6d0VzKO8l4ah1G9o3bcG-puQA6AsPb7w2bsQ04RumkqQPx1ZgY3a90FNMs8RUotOzMe0pKcDqy8CejffeW7cyDX1L6V4ODtemZPjcvEBPAV96SiiRI_hxkh6yqkNMCFg7IDmqUNajT3CoYjcKL81GAR_8PN3g58wFxlFoUhXca14zwZDv4FcT-3l2LyAtpkc9df2rSia4DFlomKNds
"Overview of GlycoPep Evaluator . GlycoPep Evaluator ( GPE ) is a freely downloadable software tool that can be used to generate decoy glycopeptides for false discovery rate analysis . GPE is available for download at research . It has incorporated functionality to score all the targets and decoys against imported spectra using a previously published scoring algorithm . 24 GPE was written in Java and developed with Java Development Kit 7 ( JDK 7 ). The program has been tested to perform successfully under Windows and Linux systems , and Java Runtime Environment 7 ( JRE 7 ) is recommended to be installed prior to running GPE .",Method,Tool,Produce,"New Glycoproteomics Software, GlycoPep Evaluator, Generates Decoy Glycopeptides de Novo and Enables Accurate False Discovery Rate Analysis for Small Data Sets",https://pubs.acs.org/doi/pdf/10.1021/ac502176n
"ALICE , programmed in R and R - GUI , is the software with a user - friendly interface for an integrated genomic analysis of AF , LOH / LCSH , AI , and CNV / CNA . The software , reference databases , library files for APT , annotation files , test examples , and user manual can be downloaded from the ALICE homepage ( ). ALICE consists of three main components —“ Main Functions ” ( Additional file 11 ), “ Genome",Method,Tool,Produce,An integrated analysis tool for analyzing hybridization intensities and genotypes using new-generation population-optimized human arrays,https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-016-2478-8
All essential functionalities were integrated into the user - friendly interface of QCanvas . The simple and intuitive nature of this tool meets the practical needs of research scientists working on omics data who do not have expertise in bioinformatics approaches . The program is freely available with demo data and a step - by - step tutorial through the website ( ~ qcanvas ).,Method,Tool,Produce,MetaboAnalyst: a web server for metabolomic data analysis and interpretation,https://watermark.silverchair.com/gkp356.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAsgwggLEBgkqhkiG9w0BBwagggK1MIICsQIBADCCAqoGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMtWGXPkYLIwO-omplAgEQgIICezgs0fPQvDUUqx0b2uUp0lT27_qeBj5AFTipXkEg_hF9UdOFMgx9vh4EWmakdlM-OQMuafcgqT3_wKBGMBBv1ocnrhNp69ZmMrAZYwYe1nSr-6vqPQsY8S_Qq17IKL_izKxHvucCccuOpx-4xnKXkqfdJTk-45_B9ew9udEQoHxOMWRYylAzXRyUgS35ltUiuvRIqznaubYZfwJ3fVv1ZFypG9A1p9HA3qgamCP3iH3DU9H8xScvO-NTYYoH_rTtl0PYMUJn5lFIMrHxPR_KxSbK709r05nAw-88cZVYVRuGqb5s_tYT7-ubBI4b-o4bCt3_iGirmJjO-KlNR60SEHAx8Ty5iaXmqt74VyZa8S7VQXVpnhB-SRsKgChdEQAtxLA362ofJQLze2SC7wMvHGAGN68xeGA1anqnSOW5VoCjqBgt6nB5wcb0hwlrCCBzDM5k66k40Z9ZXHHn6HctZFyeV3L3RdQkow35DDFYhniaw719PlkF0Ntwqw9wJX7RFDGylQ2Y3qsTme8ITsmrXwBPQbpxJkuPlfDyNQMTiI5rIRfosIWocPNyYH9lGN_dJJ0o7qo38P_7o9xgA5GdSEao7JYQaUPSWwP6uJiLxh7HfVh_WHW9pLInguylXTrpd14OiGg87bYc_Ct5tea4hMcznr75OIIWs3yGNyK3HwKkhUL3IC4L5rzrtUgxyRt5QarJOtpKfsPuVeZhSZUKIPw6K_bLKYsBiL-uO4lgaTAsRD3HIJwTd32gop1xuaVzfjKO935mhcd2kVnWcIb3yel59doV0IsFPpL-GmOcYEuHTDRkOx2m35aqapqDiKtXxXveBf9qhUcibcMF
"There are two ways to convert data from another format and create an SPM M / EEG dataset . The first is geared towards EEG and MEG datasets stored in their native formats or in formats of other analysis packages ( e . g ., EEGLAB ). This conversion facility is based on “ fileio ” module ( see ), which is shared between SPM8 , FieldTrip and EEGLAB toolboxes and jointly developed by the users of these toolboxes . At the moment , most common EEG and MEG data formats are supported . For some formats , it might be necessary to install additional MATLAB toolboxes ( there is an error message if these toolboxes are missing ).",Method,Tool,Produce,Academic Software Applications for Electromagnetic Brain Mapping Using MEG and EEG,https://downloads.hindawi.com/journals/specialissues/138743.pdf
"Availability of data and materials The datasets supporting the conclusions of this article are available in the NCBI Gene Expression Omnibus repository [ NCBI GEO : GSE68983 ]. In addition , all data analysis performed here , including raw data , processed data , software tools , and analysis scripts , has been reproduced in a publically accessible Linux virtual machine . See for details . The following publically available data sets were analyzed in the current study : Dl / Twi / Sna regions [ 19 ] obtained from http :// younglab . wi . mit . edu / dorsal / Dorsal_network_targets . txt , modENCODE cold / warm / hot transcription factor binding regions Dataset S8 [ 71 ] obtained from http :// data . modencode . org / publications / files / fly / DataS8 . gff , and Vienna Tiles and anatomical annotations from Additional file 2 : Table S1 [ 39 ].",Method,Tool,Produce,Genome-wide identification of Drosophila dorso-ventral enhancers by differential histone acetylation analysis,https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1057-2
Funding Publication charges for this article have been funded by Case Western Reserve University institutional funding to T . L . The funding body played no role in study design or conclusions . Availability of data and materials The MitoDel tool can be downloaded at _CITE_,Method,Tool,Produce,Selected articles from the 12th International Symposium on Bioinformatics Research and Applications (ISBRA 2016): bioinformatics,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-017-1821-7
"Additionally , putative PPI data can be filtered using functional information or correlation to large scale protein interaction networks . However , usually data analysis programs aim to filter the experimental data either using control experiments or by integration of functional information . The software PIPINO ( Protein - Protein Interaction Optimizer , ) is a novel attempt to integrate and combine the strengths of both approaches . PIPINO allows standardizing the data analysis process and offers a semiautomatic analysis pipeline . Beside various statistical methods for evaluating the data the software is capable of functionally annotating and enriching / filtering data entries with additional information .",Method,Tool,Produce,VarWalker: Personalized Mutation Network Analysis of Putative Cancer Genes from Next-Generation Sequencing Data,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003460
"Lexique Pro , an excellent free tool by SIL International ( http :// www . lexiquepro . com /) is smaller , but there are differences in that Lexique Pro is a Windows - only closed - source program whose native MDF ( Multi - Dictionary - Formatter ) format is not as flexible as XML and therefore cannot be processed by the many tools that handle XML and TEI in particular . Consequently , the perspectives for re - use of Lexique Pro dictionaries in computational linguistic applications are much smaller . To our knowledge , Lexique Pro does not make it possible for users to query words straight off web pages , which can be done thanks to dict , a Firefox add - on ( ). It admittedly has other advantages that make it a serious alternative . 7 The ideal solution would be to have an editing front - end such as Lexique Pro coupled with the openness and modifiability of the data offered by FreeDict . Indeed , there are plans for creating a converter from the new LIFT interchange standard ( http :// code . google . com / p / lift - standard /) that the beta versions of Lexique Pro can read 7 We do not discuss professional commercial dictionary writing systems such as TshwaneLex ( http :// tshwanedje . com / tshwanelex /) because , despite the academic discounts , they may be out of range for the average developer .",Method,Tool,Use,A repository of free lexical resources for African languages: the project and the method,https://aclanthology.org/W09-0713.pdf
"On the basis of functions such as these , it is possible to construct the DAG shown in Fig . 1 . 3 The unidirectional edges between the various 2A completion may be thought of as the semantic equivalent of an utterance , an entity as the semantic equivalent of a noun , and an action as the semantic equivalent of a verb . 3The DAGs shown here were constructed with yEd ( about . html ), which generates a GraphML representation for each graph . For simplicity , we have ignored representation of tense and aspect in these examples , although the formalism permits this .",Method,Tool,Use,Time after Time: Representing Time in Literary Texts,https://aclanthology.org/W14-0904.pdf
"In the preliminary experiment , 27 , 239 Thai utterances with a mix of sentences and phrases from a general domain corpus are tested . The input was word - segmented by JwordSeg ( ) and approved by linguists . In the test corpus , the longest utterance contains seventeen words , and the shortest utterance contains two words .",Method,Tool,Use,A Syntactic Resource for Thai: CG Treebank,https://aclanthology.org/W09-3414.pdf
"A more useful feature would be to label whether a pronoun refers to an entity in the previous questions or in the current question . However , the performances of currently available tools for anaphora resolution are quite limited for our task . The tools we tried , including GATE ( Cunningham et al ., 2002 ), LingPipe ( ) and JavaRAP ( Qiu et al ., 2004 ), tend to use the nearest noun phrase as the referents for pronouns . While in the TREC questions , pronouns tend to refer to the topic words ( focus ). As a result , unsupervised anaphora resolution introduced more noise than useful information .",Method,Tool,Use,A Data Driven Approach to Relevancy Recognition for Contextual Question Answering,https://aclanthology.org/W06-3005.pdf
"For each mention , its head and extension were considered . The extension was learned by using the mention annotation provided in the training set ( 13th column ) whereas the head annotation was learned by exploiting the information produced by MaltParser ( Nivre et al ., 2007 ). In addition to the features extracted from the training set , such as prefixes and suffixes ( 1 - 4 characters ) and orthographic information ( capitalization and hyphenation ), a number of features extracted by using external resources were used : mentions recognized by TextPro ( ), gazetteers of generic proper nouns extracted from the Italian phone - book and Wikipedia , and other features derived from WordNet . Each of these features was extracted in a local context of f2 words .",Method,Tool,Use,BART: A Multilingual Anaphora Resolution System,https://aclanthology.org/S10-1021.pdf
"[ The ginger ] stops constipation . Pechsiri and Kawtrakul ( 2007 ), proposed verb - pair rules learned by two different machine learning techniques ( NB and SVM ) to extract causality with multiple EDUs of a causative unit and multiple EDUs of an effect unit with the problems of the discourse marker ambiguity and the implicit discourse marker . This verb - pair rule has been represented by the following equation ( 1 ) ( Pechsiri and Kawtrakul , 2007 ) where Vc is the causative verb concept set , Ve is the effect verb concept set , C is the Boolean variables of causality and non - causality , and a causative verb concept ( vc , where vcEVj and an effect verb concept ( ve , where veEVe ) are referred to WordNet ( ) and the predefined plant disease information from Department of Agriculture ( http :// www . doa . go . th /). CausalityFunction : Vc A Ve 4 C ( 1 ) They also proposed using Vc and Ve to solve the boundary of the causative unit and using the Centering theory along with Ve to solve the boundary of the effect unit . The outcomes of their research were the verb - pair rule , Vc , Ve , and the multiple EDUs of causality ( extracted from textual data ) was at their highest precision of 89 % and their highest recall of 76 %.",Method,Tool,Use,Know-Why Extraction from Textual Data for Supporting What Question,https://aclanthology.org/W08-1603.pdf
"More specifically , for a given source si and another sentence σ , we define LDA ( σ | si ) as follows ( d = si ), where w1 , ... , w | a | are now the words of σ , ignoring stop - words . 16The document - specific parameters of the first multinomial distribution are drawn from a Dirichlet distribution . 17We use MALLET ( ), with Gibbs sampling ( Griffiths and Steyvers , 2004 ). We set K = 800 , having first experimented with K = 200 , 400 , 600 , 800 , 1000 . 18We trained the LDA model on approximately 106 , 000 articles from the TIPSTER and AQUAINT corpora .",Method,Tool,Use,A New Sentence Compression Dataset and Its Use in an Abstractive Generate-and-Rank Sentence Compressor,https://aclanthology.org/W11-2701.pdf
"The latter makes this extraction methodology suitable for inflecting languages ( Russian in our case ) where frequencies of ngrams are low . Porting the NP extractor from English to Russian consisted in substituting English stop lexicons of the tool with the Russian equivalents . We did this by translating each of the English stop lists into Russian using a free online system PROMT ( ) followed by manual brush - up . The NP extractor does not rely on a preconstructed corpus , works on small texts , does not miss low frequency units and can reliably extract all NPs from an input text . We excluded a lemmatizer from the original extraction algorithm and kept all extracted Russian NPs in their textual forms .",Method,Tool,Use,On Integrating Hybrid And Rule-Based Components For Patent MT With Several Levels Of Output,https://aclanthology.org/2013.mtsummit-wpt.1.pdf
"We have provided a qualitative analysis of the process and results of ZI based on our handannotated sample , with a view to strengthening the basis for the annotation scheme . We are now starting to use our sample as training data for machine learning , as well as creating more data in a systematic way , toward automatic annotation . We are also considering to use our ontology management tool ( Open Ontology Forge , ex . htm ) for these purposes ; 1 ) to define zone classes as ontology classes ; zone annotation is then expected to be a variant of named entity annotation , which we are familiar with , and 2 ) to link between expressions referring to results ( e . g . these results / our results ) and their antecedent ( i . e . the RSL zone providing a concrete description of the experimental results ), using the coreference tool .",Method,Tool,Use,Zone Identification in Biology Articles as a Basis for Information Extraction,https://aclanthology.org/W04-1205.pdf
"In this set of experiments , we investigate the influence of the text normalization strategies presented in section 3 on parsing and more specifically on our parse revision strategy . Thus , we first apply a partial normalization , using only the basic text normal11_CITE_ ization . For the full normalization , we combine the basic text normalization with the spell checker . For these experiments , we use the restricted APS reviser and the EWT treebank for training and testing .",Method,Tool,Use,Does Size Matter? Text and Grammar Revision for Parsing Social Media Data,https://aclanthology.org/W13-1101.pdf
"We use a CRF ++ based POS tagger for Hi , which is freely available from For En , we use the Twitter POS tagger ( Owoputi et al ., 2013 ). It also has an inbuilt tokenizer and can work directly on unnormalized text .",Method,Tool,Use,POS Tagging of English-Hindi Code-Mixed Social Media Content,https://aclanthology.org/D14-1105.pdf
"All the documents are stemmed and all stopwords are removed with the SnowBall Stemmer ( ) for the Russian language . As it was mentioned above , this algorithm is aimed at providing word sense discrimination and non - literal usages detection simultaneously . So far we have paid attention only to the non - literal usages detection aspects .",Method,Tool,Use,A Framework for Figurative Language Detection Based on Sense Differentiation,https://aclanthology.org/P10-3012.pdf
"In this paper , we introduce a voice - based search system that allows users to specify search requests in a single natural language utterance . The output of ASR is then parsed by a query parser into three fields : LocationTerm , SearchTerm , and Filler . We use a local search engine , , which accepts the SearchTerm and LocationTerm as two query fields and returns the search results from a business listings database . We present two methods for parsing the voice query into different fields with particular emphasis on exploiting the ASR output beyond the 1 - best hypothesis . We demonstrate that by parsing word confusion networks , the accuracy of the query parser can be improved .",Method,Tool,Use,Query parsing for voice-enabled mobile local search,https://ieeexplore.ieee.org/abstract/document/4960699
"In human evaluation , people judge the adequacy and the fluency of each translation . Denoual and Lepage ( 2005 ) pointed out that BLEU assumes word boundaries , which is ambiguous in Japanese and Chinese . Here , we assume the word boundaries given by ChaSen , one of the standard morphological analyzers ( ) following Fujii et al . ( 2008 ) In JE translation , most Statistical Machine Translation ( SMT ) systems translate the Japanese sentence ( J0 ) kare wa sono hon wo yonda node sekaishi ni kyoumi ga atta which means",Method,Tool,Use,Automatic Evaluation of Translation Quality for Distant Language Pairs,https://aclanthology.org/D10-1092.pdf
"After we had obtained the extracted verb features , we then determined the probability of causal and non causal from the occurrences of the cartesian products of three verb feature concepts , shown in Table2 , by using Weka which is a software tool for machine learning ( _CITE_",Method,Tool,Use,Know-Why Extraction from Textual Data for Supporting What Question,https://aclanthology.org/W08-1603.pdf
"Our initial Talking Head was based around the Stelarc Prosthetic Head which combines multiple off - the - shelf components : keyboard input to a chatbot ( AliceBot ) is linked to speech synthesis ( IBM ViaVoice ) and 3D face rendering ( Eyematic ). More recently we have adopted Head X5 which is capable of generating a continuous , synchronized , optionally subtitled audiovisual speech stream in many different languages , with the ability to switch and modify voices and morph different faces at the same time as interacting with the user . The system is designed to be able to use different speech and face technologies , and we in general use Microsoft ’ s SAPI for speech recognition and generation plus the FaceGen face generation technology . We have been predominantly exploring the application of our Talking Head as a virtual tutor of various subject areas . Initially our focus was language teaching / learning , but more recently demand for assistance with social teaching and assistant / companion applications has redirected our efforts .",Method,Tool,Use,MANA for the Ageing,https://aclanthology.org/W10-2702.pdf
"The system obtained an average precision of 77 % and an average recall of 35 . 1 % for all four drugs . To the best of our knowledge , the system described in ( Segura - Bedmar et al ., 2014 ) is the only one that has dealt with the detection of drugs and their effects from Spanish social media streams . The system used the Textalytics tool , which follows a dictionary - based approach to identify entities in texts . The dictionary was constructed based on the following resources : CIMA and MedDRA . CIMA is an online information center maintained by the Spanish Agency for Medicines and Health Products ( AEMPS ).",Method,Tool,Use,Exploring Spanish health social media for detecting drug effects,https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/1472-6947-15-S2-S6
"See Figure 4 for details . Our part - of - speech tagging data set is the standard data set from Wall Street Journal included in PennIII ( Marcus et al ., 1993 ). We use the standard splits and construct our data set in the following way , following Søgaard ( 2010 ): Each word in the data wi is associated with a feature vector xi = ( x _CITE_i , x i ) where x _CITE_i is the prediction on wi of a supervised partof - speech tagger , in our case SVMTool ( Gimenez and Marquez , 2004 ) trained on Sect . 0 – 18 , and x i is a prediction on wi from an unsupervised part - ofspeech tagger ( a cluster label ), in our case Unsupos ( Biemann , 2006 ) trained on the British National Corpus . We train a semi - supervised condensed nearest neighbor classifier on Sect .",Method,Tool,Use,Semisupervised condensed nearest neighbor for part-of-speech tagging,https://aclanthology.org/P11-2009.pdf
"First , word alignments in both directions are calculated . We used a multi - threaded version of the GIZA ++ tool ( Gao and Vogel , 2008 ). This speeds up the process and corrects an error of GIZA ++ that can appear with rare words . Phrases and lexical reorderings are extracted using the default settings of the Moses toolkit . The parameters of Moses were tuned on newstest2008 , using the ‘ new ’ MERT tool .",Method,Tool,Use,Investigations on Translation Model Adaptation Using Monolingual Data,https://hal.science/hal-00625481/
"These state charts model various subdialogues like question - answering , offer , threat , greetings , closings , etc . The DM also implements advanced features like topic - tracking and grounding ( Roque and Traum , 2009 ). The virtual human character de livers synthesized speech and corresponding nonverbal behavior , based on additional components of the ICT Virtual Human Toolkit . This work was sponsored by the U . S . Army Research , Development , and Engineering Command ( RDECOM ). The content does not necessarily reflect the position or the policy of the U . S . Government , and no official endorsement should be inferred .",Method,Tool,Use,Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning,https://www.researchgate.net/profile/Cosmin-Bejan/publication/221251392_Choice_of_Plausible_Alternatives_An_Evaluation_of_Commonsense_Causal_Reasoning/links/5c129b024585157ac1c05c6e/Choice-of-Plausible-Alternatives-An-Evaluation-of-Commonsense-Causal-Reasoning.pdf
"We construct 1000 clusters employing the Brown method on 112 million words from the North American New York Times corpus . We keep the top 20 most frequent words for each cluster as paraphrases . To generate LSA paraphrases , we used the Infomap software on a 34 million word collection of articles from the American News Text corpus . We used the default parameter settings : a 20 , 000 word vocabulary , the 1000 most frequent words ( minus a stoplist ) for features , a 15 word context window on either side of a word , a 100 feature reduced representation , and the 20 most similar words as paraphrases . While we experimented with several parameter settings for LSA and Brown methods , we do not claim that the selected settings are necessarily optimal .",Method,Tool,Use,Paraphrasing for Automatic Evaluation,https://aclanthology.org/N06-1058.pdf
"Surprisingly , there was not a significant change in our ROUGE scores over the three different summary lengths . This indicates that our system can create summaries of any length without losing its content . We also conduct manual evaluations utilizing a crowdsourcing tool . In this experiment , our system with 15 segments is compared with FUSION , human - authored summaries ( ABS ) and , humanannotated extractive summaries ( EXT ). After randomly selecting 10 meetings , 10 participants were selected for each meeting and given instructions to browse the transcription of the meeting so as to understand its gist .",Method,Tool,Use,A Template-based Abstractive Meeting Summarization: Leveraging Summary and Source Text Relationships,https://aclanthology.org/W14-4407.pdf
"It helps avoiding misunderstandings and giving them a sense of being involved and committed . Annotation tools Although there exists many annotation tools , few are actually available , free , downloadable and usable . Among those tools are Callisto , MMAX2 , Knowtator or Cadixe which was used in the reported experiment . The features and the annotation language expressivity must be adapted to the targeted annotation task : is it sufficient to type the textual segments or should they also be related ? is it possible / necessary to have concurrent or overlapping annotations ?",Method,Tool,Use,Towards a Methodology for Named Entities Annotation,https://hal.science/hal-00402453/
"Compared with its performance on CTB5 ( in Table 4 ), our Nonlocal & Cluster system also got 0 . 8 % improvement . All these results show that our approach can become more powerful when given more labeled training data . To better understand the linguistic behavior of our systems , we employed the berkeley - parseranalyser tool ( Kummerfeld et al ., 2013 ) to categorize the errors . Table 6 presents the average number of errors for each error type by our parsing systems . We can see that almost all the Worst numbers are produced by the Pipeline system .",Method,Tool,Use,Joint POS Tagging and Transition-based Constituent Parsing in Chinese with Non-local Features,https://aclanthology.org/P14-1069.pdf
"The algorithm parameters are tuned on the development set . In order to compare our approach with a nonsequential one , we perform the classification task also using Support Vector Machines ( Vapnik , 1998 ). We use YAMCHA , a tool developed for chunking tasks , in which SVMs are easily combined with different context window sizes and dynamic features ( Kudo and Matsumoto , 2001 ). Since this work is only a preliminary step towards the automatic identification and extraction of biographical information from Wikipedia , we first experiment with the simplest approach . Therefore , we consider a small set of shallow features extracted only from section titles , and we ignore the content of the sections .",Method,Tool,Use,Recognizing Biographical Sections in Wikipedia,https://cris.fbk.eu/handle/11582/301635
"First , we propose how to reduce paraphrase generation costs by early exclusion of low - accuracy crowdworkers . Second , we compare two HIT designs for evaluating phrase pairs on a continuous semantic similarity scale . In order to evaluate our crowdsourcing strategies , we conduct our own experiments via the CROWDFLOWER platform . The rest of the paper is structured as follows . Section 2 first gives an overview of related work and lines out current approaches .",Method,Tool,Use,Leveraging Crowdsourcing for Paraphrase Recognition,https://aclanthology.org/W13-2325.pdf
"Two vectors of features are used , one where the seed set is the subjective seed set , and one where it is the objective seed set . In summary , we use the following features ( here , SS is the subjective seed set and OS is the objective one ). We perform 10 - fold cross validation experiments on several data sets , using SVM light ( Joachims , 1999 ) under its default settings . Based on our random sampling of WordNet , it appears that WordNet nouns are highly skewed toward objective senses . ( Esuli and Sebastiani , 2007 ) argue that random sampling from WordNet would yield a corpus mostly consisting of objective ( neutral ) senses , which would be “ pretty useless as a benchmark for testing derived lexical resources for opinion mining [ p . 428 ].” So , they use a mixture of subjective and objective senses in their data set .",Method,Tool,Use,Integrating Knowledge for Subjectivity Sense Labeling,https://aclanthology.org/N09-1002.pdf
"Specifically , we take the PCFG encoding of the LDA topic model described above , but modify it so that the Topici nodes generate sequences of words rather than single words . Then we adapt each of the Topici nonterminals , which means that we learn the probability of each of the sequences of words it can expand to . In order to demonstrate that this model works , we implemented this using the publicallyavailable adaptor grammar inference software , and ran it on the NIPS corpus ( composed of published NIPS abstracts ), which has previously been used for studying collocation - based topic models ( Griffiths et al ., 2007 ). Because there is no generally accepted evaluation for collocation - finding , we merely present some of the sample analyses found by our adaptor grammar . We ran our adaptor grammar with ` = 20 topics ( i . e ., 20 distinct Topici nonterminals ).",Method,Tool,Use,"PCFGs, Topic Models, Adaptor Grammars and Learning Topical Collocations and the Structure of Proper Names",https://aclanthology.org/P10-1117.pdf
"Currently , there are 109 composers in this category . We evaluated manually the matching accuracy for the articles in this category , obtaining 95 . 5 % and 89 . 1 % matching accuracy for the 15th edition and 11th edition respectively , with the lower matching accuracy for 11th edition mainly caused by segmentation errors . We used Web - based Analysis and Visualization Environment ( WEAVE ) to visualize and analyze the relative importance , rank , and its change over time for the historical figures in this category . Figure 3 illustrates the change in importance . The legend on the left lists the composers alphabetically .",Method,Tool,Use,Catching the Red Priest: Using Historical Editions of Encyclopaedia Britannica to Track the Evolution of Reputations,https://aclanthology.org/W15-3701.pdf
"Since the output is generated via templates , other formats could also be generated to feed into alternate tools . In addition to generating existing XML formats it is also useful to generate data in a form that is easily consumed by custom applications . JSON ( Javascript Object Notation ) is a data format that is frequently used to transport data in modern web applications and is easily parsed by libraries in many target languages . The DADA JSON interface will deliver descriptions of any kind of object in the data store in a way that makes it easy to implement clients that present interactive displays of the data . As a demonstration of the web based API allowing remote clients to read annotation data from the server , we have implemented a Javascript based browser for annotation data that is able to show data aligned with the source video data .",Method,Tool,Use,Ingesting the Auslan Corpus into the DADA Annotation Store,https://aclanthology.org/W09-3028.pdf
"The disambiguated items with high confidence correspond to more than 50 % of all the bank & apos ; bank & apos ; number & apos ; number & apos ; hood & apos ; hood & apos ; content words . As a result of the disambiguation step , we obtain sense - annotated data comprising around one billion tagged words with at least five occurrences and 2 . 5 million unique word senses . The disambiguated text is processed with the Word2vec ( Mikolov et al ., 2013a ) toolkit . We applied Word2vec to produce continuous representations of word senses based on the distributional information obtained from the annotated corpus . For each target word sense , a representation is computed by maximizing the log likelihood of the word sense with respect to its context .",Method,Tool,Use,SENSEMBED: Learning Sense Embeddings for Word and Relational Similarity,https://aclanthology.org/P15-1010.pdf
"The proposed lexical word splitter was implemented on the CRF model toolkit released with the Stanford segmenter ( Tseng et al ., 2005 ). The regularity parameters Sk are set to be 3 , the same as the Stanford segmenter , because no significant performance improvements were observed by tuning that parameter . To extract features for the word splitter , the Stanford named entity recognizer ( Finkel et al ., 2005 ) was employed to obtain the tags of named entities . Word frequencies were caculated from the source side of SMT training corpus . The character - level unsupervised alignment was conducted using GIZA ++ ( Och and Ney , 2003 ) .",Method,Tool,Use,Refining Word Segmentation Using a Manually Aligned Corpus for Statistical Machine Translation,https://aclanthology.org/D14-1173.pdf
"It is also possible to view the definitions that originated the path . FrameNet ( Baker et al ., 1998 ) is a manually built knowledge base structured on semantic frames that describe objects , states or events . There are several means for exploring FrameNet easily , including FrameSQL ( Sato , 2003 ) , which allows searching for frames , lexical units and relations in an integrated interface , and FrameGrapher , a graphical interface for the visualization of frame relations . For each frame , in both interfaces , a textual definition , annotated sentences of the frame elements , lists of the frame relations , and lists with the lexical units in the frame are provided . ReVerb ( Fader et al ., 2011 ) is a Web - scale information extraction system that automatically acquires binary relations from text .",Method,Tool,Use,Folheador: browsing through Portuguese semantic relations,https://aclanthology.org/E12-2008.pdf
"The development corpus and test corpus were taken from the evaluation dataset in IWSLT 2006 ( 489 tuning and 500 test sentences with 7 references ). The EUROPARL model was trained using the EUROPARL corpora with approximately 1 . 3M sentence pairs , leaving out 1K sentences for tuning and another 1K sentences for tests . In the IWSLT experiment , word alignments were generated using an HMM model ( Vogel et al ., 1996 ), with symmetric posterior constraints ( V . Grac ¸ a et al ., 2010 ), using the Geppetto toolkit . This setup was used in the official evaluation in ( Ling et al ., 2010 ). For the EUROPARL experiment the word alignments were generated using IBM model 4 .",Method,Tool,Use,Entropy-based Pruning for Phrase-based Machine Translation,https://aclanthology.org/D12-1088.pdf
"Table 1 provides a summary of this corpus . We use mate - tools to perform morphological analysis and parse German sentences ( Bohnet , 2010 ). Then MaltParser converts a parse result into a projective dependency tree ( Nivre and Nilsson , 2005 ). In this paper , we mainly compare our system ( DGST ) with HPB in Moses ( Koehn et al ., 2007 ). We implement our model in Moses and take the same settings as Moses HPB in all experiments .",Method,Tool,Use,Dependency graph-to-string translation,https://doras.dcu.ie/23335/
"For our goal , it is essential to normalize nouns to their singular form . This task is non - trivial , because there are numerous words with irregular plural forms and there exist even word forms that can be either the singular form of one word or the plural form of another . By collecting these exceptions systematically from WordNet , we were able to stem most of them correctly with our Plural - toSingular Stemmer ( PlingStemmer ). For the nongrammatical files , we provide a pseudo - parsing , which links each two adjacent items by an artificial connector . As a result , the uniform output of the preprocessing is a sequence of linkages , which constitutes the input for the core algorithm .",Method,Tool,Use,LEILA: Learning to Extract Information by Linguistic Analysis,https://aclanthology.org/W06-0503.pdf
"The corpus is a collection of 30 , 033 sentence pairs and consists of dialogs in travel situations ( 10 , 061 ) and parts of the BTEC corpus ( 19 , 972 ). Details about the provided corpus are described in ( Paul , 2009 ). We used the Stanford Parser to obtain word - level dependency structures of Chinese sentences , and GIZA ++ to obtain word alignments of the biligual corpus . We extracted the SCFG - MWU from the biligual corpus with word alignment . In order to investigate the coverage of the extracted rule , we counted the number of the recovered sentences , i . e .",Method,Tool,Use,Multi-Word Unit Dependency Forest-based Translation Rule Extraction,https://aclanthology.org/W11-1005.pdf
"First , training data are linguistically annotated . In order to achieve robustness the same tools have been used to linguistically annotate both languages . The SVMTool has been used for PoS - tagging ( Gim ´ enez and M ` arquez , 2004 ). The Freeling package ( Carreras et al ., 2004 ) has been used for lemmatizing . Finally , the Phreco software ( Carreras et al ., 2005 ) has been used for shallow parsing .",Method,Tool,Use,The LDV-COMBO system for SMT,https://aclanthology.org/W06-3126.pdf
"The data set consists of 100 files taken from the Chinese Treebank ( Xue et al ., 2005 ). The source of these files is Xinhua newswire . The annotation is carried out within the confines of the Brandeis Annotation Tool ( BAT ) ( Verhagen , 2010 ). Table 1 reports the inter - annotator agreement of temporal annotation , both between the two annotators ( A and B ) and between each annotator and the judge ( J ), over a training period of ten weeks . Each week , 10 files are assigned , averaging about 315 event pairs for annotation .",Method,Tool,Use,Discourse-constrained Temporal Annotation,https://aclanthology.org/W11-0420.pdf
"Development and test sets are automatically tagged by the tagger trained on the training set . We use the training data set to train a supertagger of each model using Conditional Random Fields ( CRF ) and the test data set to evaluate the accuracies . We use version 0 . 12 of CRFsuite for our CRF implementation . First - order transitions , and word / POS of uni , bi and trigrams in a 7 - word window surrounding the target word are used as features . Table 3 shows the result of the supertagging accuracies .",Method,Tool,Use,Improving Dependency Parsers with Supertags,https://aclanthology.org/E14-4030.pdf
"Therefore , there is no forward jump from hCode , codei to h .,. i , but a monotone step to hein , εi followed by h .,. i . As the JTR sequence gK 1 is a unique interpretation of a bilingual sentence pair and its alignment , the probability p ( f1J , eI1 , bI1 ) can be computed as : Within this work , we first estimate the Viterbi alignment for the bilingual training data using GIZA ++ ( Och and Ney , 2003 ). Secondly , the conversion presented in Algorithm 1 is applied to obtain the JTR sequences , on which we estimate an n - gram model with modified Kneser - Ney smoothing as described in ( Chen and Goodman , 1998 ) using the KenLM toolkit ( Heafield et al ., 2013 ). tokens gk corresponding to Figure 2 . The right side shows the source and target tokens sk and tk obtained from the JTR tokens gk .",Method,Tool,Use,A Comparison between Count and Neural Network Models Based on Joint Translation and Reordering Sequences,https://aclanthology.org/D15-1165.pdf
"00Equation 3 does not require that a symbol represent the entire right - hand side of each non - lexical rule , but does ensure that each right - hand side se Finally , Equation 5 ensures that if a pair is used , each 2 3 4 5 6 7 8 9 10 + member of the pair is included . This program can be optimized with an off - the - shelf ILP solver . Figure 4 shows the number of intermediate grammar symbols needed for the four binarization policies described above for a short sentence . Our ILP solver could only find optimal solutions for very short sentences ( which have small grammars after relativization ). Because greedy requires very little time to compute and generates symbol counts that are close to optimal when both can be computed , we use it for our remaining experiments .",Method,Tool,Use,Efficient Parsing for Transducer Grammars,https://aclanthology.org/N09-1026.pdf
"This discriminative module can flexibly incorporate extra features and it is implemented with the ME package given by Zhang Le . All training experiments are done with Gaussian prior 1 . 0 and 200 iterations . The character - based generative module is a character - tag - pair - based trigram model ( Wang et al ., 2009 ) and can be expressed as below : In our experiments , SRI Language Modeling Toolkit ( Stolcke , 2002 ) is used to train the generative trigram model with modified Kneser - Ney smoothing ( Chen and Goodman , 1998 ). The character - based joint model combines the above discriminative module and the generative module with log - linear interpolation as follows : Where the parameter α ( 0 . 0 ≤ α ≤ 1 . 0 ) is the weight for the generative model . Score ( tk ) will be directly used during searching the best sequence .",Method,Tool,Use,A Character-Based Joint Model for CIPS-SIGHAN Word Segmentation Bakeoff 2010,https://aclanthology.org/W10-4133.pdf
"Then each bookmarks is represented as a feature vector whose each column value is the number of times that the word occurred in the document plus a constant multiple of the times it occurs in selected text , tags / labels ( constant multiplied to give higher weight to the selected text , tags / labels where this constant multiple is found by trial and error ). All the feature vectors are stored in the database . Porter stemmer is used for stemming the words . To make the system suitable for a online application , every activity like generating feature vector , training the classifier is done offline . To be clear and precise , when a user bookmarks a web page with selected text , tags / labels , then bookmarked content ( web page with selected text , tags / labels ) are stored in the database .",Method,Tool,Use,Content Bookmarking and Recommendation,https://aclanthology.org/W12-5809.pdf
"We downloaded the dump dated February 27 , 2012 and extracted the textual contents using the wikipedia2text tool . The final plaintext file contains approximately 10 million words . We extracted word n - grams ( n ranging from 1 to 3 ) and their frequencies from this corpus thanks to the Text - NSP Perl module and its count . pl program , which produces the list of n - grams of a document , with their frequencies . Table 1 gives the number of n - grams produced . Some of these n - grams are invalid , and result from problems when extracting plain text from Wikipedia , such as “ 27 | ufc 1 ”, which corresponds to wiki syntax .",Method,Tool,Use,ANNLOR: A Naïve Notation-system for Lexical Outputs Ranking,https://hal.science/hal-00790866/
"One of the most successful approaches in the last years is the supervised learning from examples , in which statistical or Machine Learning classification models are induced from semantically annotated corpora ( M ` arquez et al ., 2006 ). Generally , supervised systems have obtained better results than the unsupervised ones , as shown by experimental work and international evaluation exercises such This paper has been supported by the European Union under the projects QALL - ME ( FP6 IST - 033860 ) and KYOTO ( FP7 ICT - 211423 ), and the Spanish Government under the project Text - Mess ( TIN2006 - 15265 - C06 - 01 ) and KNOW ( TIN2006 - 15049 - C03 - 01 ) as Senseval . These annotated corpora are usually manually tagged by lexicographers with word senses taken from a particular lexical semantic resource – most commonly WordNet ( WN ) ( Fellbaum , 1998 ). WN has been widely criticized for being a sense repository that often provides too fine – grained sense distinctions for higher level applications like Machine Translation or Question & Answering . In fact , WSD at this level of granularity has resisted all attempts of inferring robust broadcoverage models .",Method,Tool,Use,An Empirical Study on Class-based Word Sense Disambiguation,https://aclanthology.org/E09-1045.pdf
"Next , we used our Scasim measure to calculate the pair - wise similarities of all these regression patterns . This can be done with a function called Scasim which is freely available from the authors . This function takes a data frame ( basically a table ) as input which contains , chronologically ordered , a line for every fixation in the data set . One column identifies the trial to which a fixation belongs , other columns specify the x and y coordinates and the duration of a fixation . The resulting matrix of similarity scores was then used to fit a map of scanpath space , i . e ., a n - dimensional vector space with a vector for each regressive scanpath ( see fig .",Method,Tool,Use,Scanpaths in reading are informative about sentence processing,https://aclanthology.org/W12-4904.pdf
"We used gold - standard ( manually annotated ) morphemes , named entities , dependency structures and coreference relations to focus on the A / R detection and the zero reference resolution . We used SVMrank for the learning - to - rank method of the A / R detection and the PAS analysis . The categories of words are given by the morphological analyzer JUMAN . Named entities and predicate features ( e . g ., honorific expressions , modality ) are given by the syntactic parser KNP . We show the results of the author and reader mention detection in Table 6 and Table 7 .",Method,Tool,Use,Japanese Zero Reference Resolution Considering Exophora and Author/Reader Mentions,"Named entities and predicate features ( e . g ., honorific expressions , modality ) are given by the syntactic parser KNP "
"We conclude by summarizing plans for further development of our prototype . The initial input to the SurfShop system consists of a product database and a product ontology with node labels . All products were indexed for fast retrieval by the application . A chart of application components is presented in Figure1 . Raw product descriptions from our data would constitute a large corpus including meta - data such as shipping or manufacturer information , which are not relevant to our task .",Method,Tool,Use,SurfShop: combing a product ontology with topic model results for online window-shopping.,https://aclanthology.org/N12-3004.pdf
"We define a set of token and semantic features to train the CRF model . Token features : The word , the part - of - speech tag ( pos - tags ) and the lemma ; two tokens after and two tokens before the word , their lemmas and their pos - tags . We used StanfordTagger to obtain the words of clinical texts as well as their lemmas and their part - of - speech tags . StanfordTagger recognizes the word 1 / word 2 token as one word . Since , many UMLS terms contain either the word 1 or the word 2 , we separate the word 1 / word 2 phrase into three words : word 1 , / and word 2 .",Method,Tool,Use,A Part-of-Speech tagger for Irish using finite state morphology and constraint grammar disambiguation,https://doras.dcu.ie/16367/
"However , due to the extreme level of variation of the topics in these corpora , we applied a filtering algorithm to select a subset of the corpora . Our approach to make the text similar involved reducing the corora based on matching Named Entities . Named Entities of English and Hindi corpus were listed using LingPipe and a Hindi NER system built at IIT Kharagpur ( Saha et al ., 1999 ). The listed Named Entities of the two corpora were compared to find the matching Named Entities . Named Entities in Hindi Unicode were converted to iTRANS format and matched with English Named Entities using edit distance .",Method,Tool,Use,Co-occurrence Graph Based Iterative Bilingual Lexicon Extraction From Comparable Corpora,https://aclanthology.org/W10-4007.pdf
"Since the classification accuracies deceased to be quite low for source spans with more than 10 words , only { C1 , ..., C10 } were integrated into the HPB translation system . For each translation task , the recent version of Moses HPB decoder ( Koehn et al ., 2007 ) with the training scripts was used as the baseline ( Base ). We used the default parameters for Moses , and a 5 - gram language model was trained on the target side of the training corpus by IRST LM Toolkit with improved Kneser - Ney smoothing . { C1 ,..., C10 } were integrated into the baseline with different weights , which were tuned by MERT ( Och , 2003 ) together with other feature weights ( language model , word penalty ,...) under the log - linear framework ( Och and Ney , 2002 ). represents a significant difference at the p & lt ; 0 . 01 level and - represents a significant difference at the p & lt ; 0 . 05 level against the BLM .",Method,Tool,Use,Learning Hierarchical Translation Spans,https://aclanthology.org/D14-1022.pdf
"The list of modals and auxilliaries is deterministic . Syntactic Chunk ( CHUNK ): This feature explicitly models the syntactic phrases in which our tokens occur . The possible phrases are shallow syntactic representations that we obtain from the TreeTagger chunker : ADJC ( Adjective Chunk ), ADVC ( Adverbial Chunk ), CONJC ( Conjunctional Chunk ), INTJ ( Interjunctional Chunk ), LST ( numbers 1 , 2 , 3 etc ), NC ( Noun Chunk ), PC ( Prepositional Chunk ), PRT ( off , out , up etc ), VC ( Verb Chunk ). Since the data is very small , we tested our automatic annotation using 5 fold cross validation where 10 % of the data is set aside as development data , then 70 % is used for training and 20 % for testing . The reported results are averaged over the 5 folds for the Test data for each of our experimental conditions .",Method,Tool,Use,Committed Belief Annotation and Tagging,https://aclanthology.org/W09-3012.pdf
"The dataset is composed of two test sets , A and B . They both contain the same instances , but the test B was processed with a Named Entity Recogniser ( NER ) We used the training set to learn probabilities and the corresponding machine learning models . We tested our methods with the development set using the Weka GUI ( Witten and Frank , 2005 ). We built a Java application to predict documents in the test set by using the models previously learned with Weka . In the following sections we explain the specific approach for both open and close submissions .",Method,Tool,Use,NLEL UPV Autoritas participation at Discrimination between Similar Languages (DSL) 2015 Shared Task,https://aclanthology.org/W15-5409.pdf
"Novel research directions we investigated include : neural network language models and bilingual neural network language models , a comprehensive use of word classes , and sparse lexicalized reordering features . The Edinburgh / JHU phrase - based translation systems for our participation in the WMT 2015 shared translation task are based on the open source Moses toolkit ( Koehn et al ., 2007 ). We built upon Edinburgh ’ s strong baselines from WMT submissions in previous years ( Durrani et al ., 2014a ) as well as our recent research within the framework of other evaluation campaigns and projects such as IWSLT and EU - BRIDGE ( Birch et al ., 2014 ; Freitag et al ., 2014a ; Freitag et al ., 2014b ). We first discuss novel features that we integrated into our systems for the 2015 Edinburgh / JHU submission . Next we give a general system overview with details on our training pipeline and decoder configuration .",Method,Tool,Use,The Edinburgh/JHU Phrase-based Machine Translation Systems for WMT 2015,https://aclanthology.org/W15-3013.pdf
"During fold partition , all posts that are in the same post sequence are assigned to the same fold . All reason and stance classifiers are domain - specific , meaning that each of them is trained on sentences / posts from exactly one domain and is applied to classify sentences / posts from the same domain . We use the Stanford maximum entropy classifier for classification and solve ILP programs using lpsolve . Results are shown in Table 3 . Each row corresponds to one of our seven RC systems , showing its SC accuracy as well as its sentence - and postlevel RC F - scores for each domain .",Method,Tool,Use,Why are You Taking this Stance? Identifying and Classifying Reasons in Ideological Debates,https://aclanthology.org/D14-1083.pdf
"We performed feature selection using the metric Chisquare , to select the top 500 features to represent documents . Since tweets are very short we incorporated a binary representation for BoW instead of term frequency . For classification we used a multiclass SVM classifier and all the experiments were conducted using the data mining software Weka . We used standard metrics such as Precision , Recall and F - measure to compare the performance of the different algorithms . In the following section we analyse the experimental results for TF - lex ( Sec 4 . 1 ), EMallclass - lex ( Sec 4 . 2 . 2 ), EMclass - corpuslex ( Sec 4 . 2 . 3 ), PMI - lex ( Mohammad , 2012a ), WNA - lex ( Strapparava and Valitutti , 2004 ), NRClex ( Saif M . Mohammad , 2013 ) and BoW in an emotion classification task .",Method,Tool,Use,Generating a Word-Emotion Lexicon from #Emotional Tweets,https://aclanthology.org/S14-1002.pdf
"We train our model on a dataset with ˜ 1 . 5M sentence pairs from the LDC dataset . We use the 2002 NIST MT evaluation test data ( 878 sentence pairs ) as the development data , and the 2003 , 2004 , 2005 , 2006 - news NIST MT evaluation test data ( 919 , 1788 , 1082 , and 616 sentence pairs , respectively ) as the test data . To find heads , we parse the source sentences with the Berkeley Parser ( Petrov and Klein , 2007 ) trained on Chinese TreeBank 6 . 0 and use the Penn2Malt toolkit to obtain ( unlabeled ) dependency structures . We obtain the word alignments by running GIZA ++ ( Och and Ney , 2000 ) on the corpus in both directions and applying “ grow - diag - final - and ” refinement ( Koehn et al ., 2003 ). We use the SRI language modeling toolkit to train a 5 - gram language model on the Xinhua portion of the Gigaword corpus and standard MERT ( Och , 2003 ) to tune the feature weights on the development data .",Method,Tool,Use,Using Syntactic Head Information in Hierarchical Phrase-Based Translation,https://aclanthology.org/W12-3128.pdf
"Discourse Topic is an under - theorized notion in linguistic theory : not all linguists agree that the notion of Discourse Topic is required in discourse analysis at all ( cf . Asher , 2004 ). For our purposes , however , we formulated a set of patterns for identifying Discourse Topics on the basis of the output of the CMU Link Parser the system uses . Paradigmatically , we counted ordinary subjects of the first sentence of a passage as expressive of the Discourse Topic . So , if we found an expression of the topic there , either in full or reduced form , we took that as an instance of the topic appearing as Discourse Topic in that passage and ranked that passage highly .",Method,Tool,Use,Lycos Retriever: An Information Fusion Engine,https://aclanthology.org/N06-2045.pdf
"The topic model infers the topic distribution features of each excerpt and the RF classifier predicts the section ( s1 , s2 , etc .) of the excerpt . All web automation tasks are performed using HTMLUnit . In the second stage , our ILP based summarization approach synthesizes information from multiple excerpts assigned to a section and presents the most informative and linguistically well - formed summary as the corresponding content for each section . A wordgraph is constructed that generates several sentences ; only a few of the sentences are retained based on the ILP solution .",Method,Tool,Use,WikiKreator: Improving Wikipedia Stubs Automatically,https://aclanthology.org/P15-1084.pdf
"Besides the common features used in traditional Named Entity Recognition ( NER ) systems , we also utilize extensive external resources to build various name lists and word clusters . Following the traditional BIO scheme used in sequential labeling , we assign a label for each word in the sentence , where “ B - TERM ” indicates the start of an aspect term , “ I - TERM ” indicates the continuation of an aspect term , and “ O ” indicates not an aspect term . All sentences are tokenized and parsed using the Stanford Parser . The parsing information is used to extract various syntactic features ( e . g . POS , head word , dependency relation ) described in the next section .",Method,Tool,Use,DLIREC: Aspect Term Extraction and Term Polarity Classification System,https://aclanthology.org/S14-2038.pdf
"However , context models , user models or plan based mechanisms could also be used for this purpose . During the activation , the appropriate dialogue description is translated into internal data structures appropriate for the dialogue management in SesaME . This process is performed through JAXB which provides a fast way to create a twoway mapping between XML documents and Java objects ( Pakucs , 2002 ). During the dialogue management , the generated internal data structures are used for frame - based dialogue management . The actual dialogue management process does not follow the VoiceXML specifications .",Method,Tool,Use,SesaME: A Framework for Personalised and Adaptive Speech Interfaces,https://aclanthology.org/W03-2713.pdf
"We also collected article titles from Project Gutenberg for segmentation and evaluation . We use the 15th edition gender metadata to identify and extract articles about people from the current edition . In order to identify people articles in the historical editions , we use the Stanford CoreNLP named entity recognizer ( NER ) with pre - trained models , on the first sentence of the article . The common format of a person name is “ last name , first name ” in the 9th and 11th edition and “ last name ( first name )” in the 3rd edition . The first token always serves as the article title and is prone to OCR errors , since it is usually all - capitalized , and in some editions , uses a special font .",Method,Tool,Use,Catching the Red Priest: Using Historical Editions of Encyclopaedia Britannica to Track the Evolution of Reputations,https://aclanthology.org/W15-3701.pdf
"Features of the first group are only given as examples . We then applied machine learning in order to build an automatic classifier for detecting nonreferential instances of it , given a vector of features as described above . We used JRip , the WEKA reimplementation of Ripper ( Cohen , 1995 ). All following figures were obtained by means of ten - fold cross - validation . Table 3 contains all results discussed in what follows .",Method,Tool,Use,Automatic Detection of Nonreferential It in Spoken Multi-Party Dialog,https://aclanthology.org/E06-1007.pdf
"In this task we followed the tagging schema of “ Specification for Corpus Processing at Peking University ” in the design of our model . In this word , under the assumption that a segmentation system for general text is already good , for a special domain we only need to do some modification to make the segmentation result better . The main frame of this system is using ICTCLAS as the segmentation tool . Based on it result , we do a group of preprocessing and postprocessing to get a better result . After analyzed the 500 sentences train corpora , we found that there are some rules in the segmentation that it is very difficult to use other approaches to recognize them .",Method,Tool,Use,CRFs-Based Chinese Word Segmentation for Micro-Blog with SmallScale Data,https://aclanthology.org/W12-6310.pdf
"– Subclauses : The mean number of subclauses in each sentence , normalized by sentence length in words . The mean subclause length in words . Subclauses are labeled as “ SBAR ” in the parser tree generated by a commonly used NLP tool , Stanford Core NLP ( Klein and Manning , 2003 ), which is an integrated suite of natural language processing tools for English in Java , including part - of - speech tagging , parsing , co - reference , etc .. – Sentence level : The sum of the depth of all nodes in a parser tree generated by Stanford Core NLP . The height of the parser tree is also incorpo rated into the feature set . – Mode , preposition , comma : The number of modes , prepositions and commas in each sentence respectively , normalized by sentence length in words .",Method,Tool,Use,Automated Essay Scoring by Maximizing Human-machine Agreement,https://aclanthology.org/D13-1180.pdf
"The linear interpolation coefficients are grouped into equivalence classes ( tied ) based on the range into which the count falls ; the count ranges for each equivalence class , “ buckets ,” are set such that a statistically sufficient number of events fall within that range . In our experiments , we set the count ranges to be the intervals of 2i , i = 0 , 1 , · · · , 10 ( i . e ., 0 , 1 , 2 , 4 , 8 , 16 , 32 , 64 , 128 , 256 , 512 , 1024 , and ∞). These “ tied ” interpolation weights are determined by the maximum likelihood estimate from cross - validation data through the EM algorithm ( Dempster , Laird , and Rubin 1977 ) where we use a public available parser in the openNLP software to parse sentences in cross - validation data , and we run LSA to extract N most likely topics for each document in cross - validation data , then we gather joint counts for each model component , WORDPREDICTOR , TAGGER , CONSTRUCTOR used to determine interpolation weights . In the M - step , assuming that the count ranges and the corresponding interpolation values for each order are kept fixed to their initial values , the only parameters to be re - estimated using the EM algorithm are the maximal order counts for each model component . The interpolation scheme outlined here is then used to obtain a smooth probability estimate for each model component .",Method,Tool,Use,Structured language modeling,https://www.sciencedirect.com/science/article/abs/pii/S0885230800901475
"The system is domain - independent , using a primary task description vocabulary and training data to learn the task , but domain resources can be incorporated as additional features when available , as described here . The approach can be broken down into 4 components : an automated annotation pipeline to provide the basis for features , classification - based trigger identification and argument identification components , and a post - processing component to apply semantic constraints . The UIMA framework is used to integrate the components into a pipeline architecture . A definition of the events to be extracted is used to define candidates for classification and post - process the results of the classification . First a list of domain - specific entity classes is given .",Method,Tool,Use,Complex Biological Event Extraction from Full Text using Signatures of Linguistic and Semantic Features,https://aclanthology.org/W11-1818.pdf
"We use Python 2 . 7 ’ s multiprocessing module in all experiments . We base our experiments on our dynamic programming incremental dependency parser ( Huang and Sagae , 2010 ). Following Huang et al . ( 2012 ), we use max - violation update and beam size b = 8 . We evaluate on the standard Penn Treebank ( PTB ) using the standard split : Sections 02 - 21 for training , and Section 22 as the held - out set ( which is indeed the test - set in this setting , following McDonald et al .",Method,Tool,Use,Minibatch and Parallelization for Online Large Margin Structured Learning,https://aclanthology.org/N13-1038.pdf
"As a post - processing , in the En2Es direction we used a POS target language model as a feature ( instead of the target language model based on classes ) that allowed to recover the segmentations ( de Gispert , 2006 ). Language Model Interpolation . In other to better adapt the system to the out - of - domain condition , the target language model feature was built by combining two 5 - gram target language models ( using SRILM ). One was trained from the EuroParl training data set , and the other from the available , but much smaller , newscommentary data set . The combination weights for the EuroParl and news - commentary language models were empirically adjusted by following a minimum perplexity criterion .",Method,Tool,Use,Ngram-based statistical machine translation enhanced with multiple weighted reordering hypotheses,https://aclanthology.org/W07-0720.pdf
"A classification based approach and a dictionary based approach are employed to calculate the accuracy of the queries translated . 400 sentences with their corresponding translations ( English - Hindi ) have been used as test set to evaluate the performance of the query formation . The sentence pairs are provided by FIRE . These sentences contain all types of words ( Named entities , Verbs etc ) and will be referred to as samples . The English language sentences are used as queries and are translated to Hindi using the approach described .",Method,Tool,Use,Language-Independent Context Aware Query Translation using Wikipedia,https://aclanthology.org/W11-1219.pdf
"These results are obtained using 10 - folds cross validation (* Recall has been inherited from the definition classification task , since no indication has been reported in their contribution ). In this section we present the evaluation of our technique on both the tasks of classifying definitional sentences and extracting hypernym relations . Notice that our approach is susceptible from the errors given by the POS - tagger and the syntactic parser . In spite of this , our approach demonstrates how syntax can be more robust for identifying semantic relations . Our approach does not make use of the full parse tree , and we are not dependent on a complete and correct result of the parser .",Method,Tool,Use,Extracting Definitions and Hypernym Relations relying on Syntactic Dependencies and Support Vector Machines,https://iris.unito.it/bitstream/2318/1690948/1/P13-2095.pdf
"We divided them evenly and randomly into two parts and use one half for a training set and the other for a test set . In experiments described in section 4 . 4 and 4 . 5 , we used other portion of the corpus to scale experiments . For tokenization and pos - tagging , we used MeCab to Japanese texts and SS Tagger to English texts . Because SS Tagger doesn ’ t act as lemmatizer , we used morphstr () function in WordNet library . Figure 3 shows the results of experiments on several conditions .",Method,Tool,Use,A fast and accurate method for detecting English-Japanese parallel texts,https://aclanthology.org/W06-1008.pdf
"For aspects , however , there is not a pre - defined set . We observe that these topic aspects are usually named entities or noun phrases frequently mentioned . We therefore use the OpenNLP toolkit to perform chunking and obtain noun phrases and the Standford NER tagger to identify named entities from the posts . Some of the candidate aspect phrases identified above actually refer to the same actual aspect , e . g . “ Obama voter ,” “ Obama voters ” and “ the Obama voter .” We remove stop words from each candidate phrase and use the WordNet by Miller ( 1995 ) to obtain the lemma of each word such that we can normalize the candidate aspect phases to some extent .",Method,Tool,Use,Mining User Relations from Online Discussions using Sentiment Analysis and Probabilistic Matrix Factorization,https://ink.library.smu.edu.sg/sis_research/1891/
"Thus , we build a sentiment classifier that takes a node as input and outputs a positive and a negative score . It is built from widely - used , freely available resources : the OpinionFinder ( Wilson et al ., 2005 ) and General Inquirer ( Stone et al ., 1966 ) lexicons and the OpinionFinder system . We also use a new Opinion Extraction system ( Johansson and Moschitti , 2013 ) that shows better performance than previous work on fine - grained sentiment analysis , and a new automatically developed connotation lexicon ( Feng et al ., 2013 ). We implement a weighted voting method among these various sentiment resources . After that , for nodes that have not yet been assigned polar values ( positive or negative ), we implement a simple local discourse heuristic to try to assign them polar values .",Method,Tool,Use,Sentiment Propagation via Implicature Constraints,https://aclanthology.org/E14-1040.pdf
"It is a common practice in the Hindi community to use the characters zF [ k ], a [ kʰ ], wr [ g ], ur [ ʤ ], � [ ɖ ], - a [ ɖʰ ] and w [ p ] instead of the characters zF [ q ], w [ x ], ar [ ɣ ], 7 [ z ], , [ ɽ ], -,� [ ɽʰ ] and ? F [ f ] respectively , due to their shape similarities . In Test Set 2 , the extracted Hindi sentences were edited and corrected for these typographical errors . Then , we translated the extracted Hindi sentences into Urdu by using an online Hindi – Urdu transliteration system . These translated Urdu sentences were post - edited to remove errors , and all necessary diacritical marks were introduced in the Urdu text . Diacritical marks are vital for Urdu to Hindi transliteration , but they are sparingly used by people in writing .",Method,Tool,Use,Urdu Hindi Machine Transliteration using SMT,https://aclanthology.org/W13-4706.pdf
"Although the general ways are essentially the same for English and Chinese , the implementation details are different . It is also nontrivial to optimize these methods for Chinese NLP tasks . There are also some toolkits to be used for NLP , such as Stanford CoreNLP , Apache OpenNLP , Curator and NLTK . But these toolkits are developed mainly for English and not optimized for Chinese . In order to customize an optimized system for Chinese language process , we implement an open source toolkit , FudanNLPS , which is written in Java .",Method,Tool,Use,FudanNLP: A Toolkit for Chinese Natural Language Processing,https://aclanthology.org/P13-4009.pdf
"The weights associated to feature functions are optimally combined using a discriminative training framework ( Och , 2003 ) ( Minimum Error Rate Training ( ME RT ), see details in Section 5 . 4 ), using the provided newstest2009 data as development set . om agiven word - aligned pair of sentences ( top ). 310 a word - aligned corpus ( using MGIZA ++ with default settings ) in such a way that a unique segmentation of the bilingual corpus is achieved , allowing to estimate the n - gram model . Figure 1 presents a simple example illustrating the unique tuple segmentation for The resulting sequence of tuples is further refined to avoid NULL words in the source side of the tuples ( 2 ). Once the whole bilingual training data is segmented into tuples , n - gram language model probabilities can be estimated .",Method,Tool,Use,Improving Reordering with Linguistically Informed Bilingual n-grams,https://aclanthology.org/C10-2023.pdf
"Thus , we designed the process to be gated by cost , and keeping the costs low was a high priority . Crowd - sourcing seemed particularly appropriate , given the nature of the task , so we opted to use Amazon Mechanical Turk ( AMT ). With over 500 , 000 workers , it provides the work force required to both achieve scalability and , equally importantly , to provide diversity in the stories and types of questions . We restricted our task to AMT workers ( workers ) residing in the United States . The average worker is 36 years old , more educated than the United States population in general ( Paolacci et al ., 2010 ), and the majority of workers are female .",Method,Tool,Use,MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text,https://aclanthology.org/D13-1020.pdf
"Table 1 shows the feature templates used in our experiments and we call the features in the bottom two rows “ non - local ” features . We conducted experiments for NTCIR - 9 and 10 patent data using a Japanese - English language pair . Mecab was used for the Japanese morphological analysis . The data are summarized in Table 2 . We used Enju ( Miyao and Tsujii , 2008 ) for parsing the English training data and converted parse trees into HFE trees by a head - finalization scheme .",Method,Tool,Use,Shift-Reduce Word Reordering for Machine Translation,https://aclanthology.org/D13-1139.pdf
"This mismatch will be interpreted in view of our translation - oriented research . In the following subsection we will see how these two phenomena can be retrieved automatically . Since the multi - dimensional annotation and alignment is realised in XML , the queries are posed using XQuery . This query language is particularly suited to retrieve information from different sources like for instance individual annotation and alignment files . The use for multilayer annotation is shown in ( Teich et al .",Method,Tool,Use,Multi-dimensional Annotation and Alignment in an English-German Translation Corpus,https://aclanthology.org/W06-2705.pdf
"PCFG parsing features were generated on the output of the Berkeley Parser ( Petrov and Klein , 2007 ), trained over an English and a Spanish treebank ( Mariona Taul ´ e and Recasens , 2008 ). Ngram features have been generated with the SRILM toolkit ( Stolcke , 2002 ). The Acrolinx IQ was used to parse the source side , whereas the Language Tool was applied on both sides . The feature selection and learning algorithms were implemented with the Orange ( Demˇsar et al ., 2004 ) and Weka ( Hall et al ., 2009 ) toolkits . The methods explained in the previous section provide a wide range of experiment parameters .",Method,Tool,Use,Quality Estimation for Machine Translation output using linguistic analysis and decoding features,https://aclanthology.org/W12-3108.pdf
"Its support is 66 . 7 % and its confidence is 100 %. As another example , LSP p2 Generating Sequence Database . We generate the database by applying Part - Of - Speech ( POS ) tagger to tag each training sentence while keeping function words and time words . After the processing , each sentence together with its label becomes a database tuple . The function words and POS tags play important roles in both grammars and sentence structures .",Method,Tool,Use,Detecting Erroneous Sentences using Automatically Mined Sequential Patterns,https://aclanthology.org/P07-1011.pdf
"We worked with their unigram model ( Purandare and Pedersen , 2004 ) to cluster the web pages using the text content between the title tags . Our web people clustering approach is presented in Figure 1 and consists of the following steps : away , the javascript code is eliminated , the non closed WePS tags are repaired , the missing begin / end body tags are included and then the content between the title , the body and the anchor tags is extracted . • name matching : the location , person and organization names in the body texts are identified with the GATE system ( Cunningham , 2005 ). Each named entity of a document is matched with its corresponding named entity category from the rest of the web pages . This information is used to calculate the social semantic similarity of the person , the location and the organization names .",Method,Tool,Use,UA-ZSA: Web Page Clustering on the basis of Name Disambiguation,https://aclanthology.org/S07-1073.pdf
"They argue that information extraction techniques can be used to mine large text datasets for relevant information , such as relations between specific types of entities . Inspired in the previews works the system we propose makes use of machine learning methods too , using some of the common features described above , such as the n - grams and keywords and co - occurrences , but we also add some semantic information to enrich those features . As it has been mentioned before , the system was developed to detect and classify drugs in biomedical texts , so the process is performed in two main phases : Both phases are determined by the following stages , described in Figure 1 : Given a biomedical sentence , the system obtains the lemmas and POS - tag of every token of the sentence , by means of Freeling tool . After that , it is able to generate candidates according to certain parameters ( see section 3 . 3 ). Then , all the generated candidates are processed to extract the features needed for the learning methods , in order to determine which candidates are drugs .",Method,Tool,Use,UMCC_DLSI: Semantic and Lexical features for detection and classification Drugs in biomedical texts,https://aclanthology.org/S13-2106.pdf
"For word pairs , we extract the ordered pairs of words that occur in the same sentence , and similarly for POS pairs . To derive VIN features , we take each word bigram w1 , w2 and further represent it as two patterns p1 , w2 and w1 , p2 each consisting of a word and a POS tag . In all of our experiments , we train logistic regression classifiers using the liblinear toolkit . This choice was partly motivated by our earlier summarization research , where logistic regression classifiers were compared alongside support vector machines . The two types of classifier yielded very similar results , with logistic regression classifiers being much faster to train .",Method,Tool,Use,Domain Adaptation to Summarize Human Conversations,https://aclanthology.org/W10-2603.pdf
"However , when this happens , the propositions grouped together in the RS must remain consecutive in the TS ; solutions in which p3 comes in between p1 and p2 are prohibited . Our procedure for generating candidate solutions is based on a technique for formulating text structuring as a constraint satisfaction problem ( CSP ) ( van Hentenryck , 1989 ), using the ECLIPSE logic programming environment . In general , a CSP is characterized by the following elements : A solution assigns to each variable Vi a value from its domain Di while respecting all constraints . For instance each node of the rhetorical structure is annotated with a TEXT – LEVEL variable with the domain 0 ... Lmax and an ORDER variable with the domain 1 ... N , where N is the number of sisters . Depending on the constraints , there may be multiple solutions , or there may be no solution at all .",Method,Tool,Use,Optimizing Referential Coherence in Text Generation,https://direct.mit.edu/coli/article/30/4/401/1865/Optimizing-Referential-Coherence-in-Text
"PARSEVAL results on the development and test set are presented in Tables 5 and 6 . We see that the reranked models outperform the generative baseline model in terms of F1 , and that the reranked model that uses extra - sentential context outperforms the version that does not use extra - sentential context in the development set , but not in the test set . Using Bikel ’ s randomized parsing evaluation comparator , we find that both reranking models outperform the baseline generative model to statistical significance for recall and precision . The context - ignorant reranker outperforms the context - aware reranker on recall ( p & lt ; 0 . 01 ), but not on precision ( p = 0 . 42 ). However , the context - aware model has the highest exact match scores in both the development and the test set .",Method,Tool,Use,Utilizing Extra-sentential Context for Parsing,https://aclanthology.org/D10-1003.pdf
"First , we prepared source text in the four languages from Wikipedia dumps following ( Baroni et al ., 2014 ). We extracted plain text from the XML dumps by using wp2txt . Since words are concatenated in Japanese and Chinese , we used MeCab and Stanford Word Segmenter to tokenize the text . Since inflection occurs in English , Spanish , and Japanese , we used Stanford POS tagger , Pattern , and MeCab to lemmatize the text . Next , we induced count - based word vectors from the obtained text .",Method,Tool,Use,Accurate Cross-lingual Projection between Count-based Word Vectors by Exploiting Translatable Context Pairs,https://aclanthology.org/K15-1030.pdf
"The hypotheses for our experiments is that the selection of high - quality dependency trees is a crucial precondition for the successful use of selftraining in dependency parsing . Therefore , we explore a confidence - based method to select highquality dependency trees from newly parsed sentences . Our self - training approach consists of a single iteration with the following steps : We use the freely available Mate tools to implement the self - training approach . This tool set contains a part - of - speech ( PoS ) tagger , morphologic tagger , lemmatizer , graph - based parser and an arc - standard transition - based parser . The arcstandard transition - based parser has the option to use a graph - based model to rescore the beam which seems to be a sort - of reranking ( Bohnet and Kuhn , 2012 ).",Method,Tool,Use,Domain Adaptation for Dependency Parsing via Self-training,https://aclanthology.org/W15-2201.pdf
"Earlier work on Turkish indicates that starting with default Moses parameters and applying MERT to the resulting model does not even come close to the performance of the model with those two specific parameters set as such ( distortion limit - 1 and distortion weight 0 . 1 ), most likely because the default parameters do not encourage the range of distortions that are needed to deal with the constituent order differences . Earlier work on Turkish also shows that even when the weight - d parameter is initialized with this specific value , the space explored for distortion weight and other parameters do not produce any improvements on the test set , even though MERT claims there are improvements on the tune set . The other practical reasons for not using MERT were the following : at the time we performed this work , the discussion thread at indicated that MERT was not tested on multiple factors . The discussion thread at http :// www . mail - archive . com / moses - support @ mit . edu / msg00262 . html claimed that MERT does not help very much with factored models . With these observations , we opted not to experiment with MERT with the multiple factor approach we employed , given that it would be risky and time consuming to run MERT needed for 10 different models and then not necessarily see any ( consistent ) improvements .",Supplement,Document,Introduce,Raúl Reina,https://www.researchgate.net/publication/220873756_Syntax-to-Morphology_Mapping_in_Factored_Phrase-Based_Statistical_Machine_Translation_from_English_to_Turkish
"Engelhardt , Bailey , and Ferreira ( 2006 ) found that subjects rated 5 This term is more commonly used in biology where it refers to a laboratory measurement of biological activity within the body that indirectly indicates the effect of treatment on disease state . For example , CD4 cell counts and viral load are examples of surrogate markers in HIV infection . ( ).",Supplement,Document,Introduce,Do speakers and listeners observe the Gricean Maxim of Quantity?,https://ferreiralab.faculty.ucdavis.edu/wp-content/uploads/sites/222/2015/05/Engelhardt-et-al.-2006_GriceanMaximQuantity_JML.pdf
"In Canada , the Canadian Legal Information Institute project ( CANLII ) aims at gathering legislative and judicial texts , as well as legal commentaries , from federal , provincial and territorial jurisdictions in order to make primary sources of Canadian law accessible for free on the Internet ( ). The large volume of legal information in electronic form creates a need for the creation and production of powerful computational tools in order to extract relevant information in a condensed form . But why are we interested in the processing of previous legal decisions and in their summaries ?",Supplement,Document,Introduce,"Letsum, an automatic legal text summarizing system",https://www.researchgate.net/publication/228980166_Letsum_an_automatic_legal_text_summarizing_system
"Unfortunately , the results for ME and TBL when training on one million words cannot be reported in this paper . The learning algorithms will still be occupied after the deadline for the final version of this manuscript . The results will be published on the author ' s web page as soon as the learners have finished their struggle . The total error rate , i . e . the percentage of erroneous tags , is shown in Figure 2 for each classifier .",Supplement,Document,Introduce,"Team-based learning: design, facilitation and participation",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7712595/
"The unsatisfying results for the speaking head are based hypothetically on the missing facial expression and on its location within the spelling game . Compared to the virtual language teacher Ville , which was developed specifically for educational purposes , the SitePal ' s talking head seems to have a rather entertaining function . The expressive lip movement that is 1Full questionnaire form can be downloaded from 112 that the words in the Kelly - list are too advanced for the intermediate level . Some of the advanced participants find the word level not challenging enough as the target words are displayed quickly before they are pronounced . This kind of spelling tip needs to be adapted to the proficiency level .",Supplement,Document,Introduce,Lark Trills for Language Drills: Text-to-speech technology for language learners,https://aclanthology.org/W15-0613.pdf
"Reitter , D . ( 2002 ), Rhetorical theory in LaTeX with the ` rse package , Technical report , Reitter , D . ( to appear ), Complex signals for rhetorics : On rhetorical analysis with richfeature support vector models , in ' in Proceedings of the GLDV conference 2003 '. Schilder , F . ( 2002 ), ' Robust discourse parsing via discourse markers , topicality and position ', Natural Language Engineering 8 ( 2 / 3 ).",Supplement,Document,Introduce,Rhetorical theory in LaTeX with the rst package,https://www.researchgate.net/publication/2538132_Rhetorical_theory_in_LaTeX_with_the_rst_package
"The different classes ( types in Freebase ) have different properties . Although the Freebase types are not strict in inheriting properties , some types are still not mutually compatible ( intuitively ). For example , due to this misclassification , the instance of the United States of America ( ) is not only an instance of the types Country , Location but also of Food . We believe that such knowledge has to be represented in a different way . It is important to note that correcting such cases of instances classification to many disjoint types ( classes ) is outside the scope of the current version of FactForge .",Supplement,Document,Introduce,Accessing Linked Open Data via A Common Ontology*,https://aclanthology.org/W15-5506.pdf
"The corpora are detailed in Table 1 . Links to descriptions of the corpora can be found at bakeoff_instr . html ; publications on specific corpora are ( Huang et al ., 1997 ) ( Academia Sinica ), ( Xia , 1999 ) ( Chinese Treebank ); the Beijing University standard is very similar to that outlined in ( GB / T 13715 – 92 , 1993 ). Table 1 lists the abbreviations for the four corpora that will be used throughout this paper . The suffixes “ o ” and “ c ” will be used to denote open and closed tracks , respectively : Thus “ ASo , c ” denotes the Academia Sinica corpus , both open and closed tracks ; and “ PKc ” denotes the Beijing University corpus , closed track .",Supplement,Document,Introduce,The First International Chinese Word Segmentation Bakeoff,https://aclanthology.org/W03-1719.pdf
"The sarcasm is ambiguous because of a likely hyperbole in the first sentence , and because 1We use irony and sarcasm interchangeably in this paper , as has been done in past work . Sarcasm has an element of criticism , while irony may not . 2_CITE_ sentiment associated with ‘ four hours cooking ’ depends on how much the author / speaker likes cooking . Such sarcasm is difficult to judge for humans as well as an automatic sarcasm detection approach . Essentially , we need more context related to the author of these sentences to identify sarcasm within them .",Supplement,Document,Introduce,Your Sentiment Precedes You: Using an author’s historical tweets to predict sarcasm,https://aclanthology.org/W15-2905.pdf
"( 2008 ) proposed two different methods to extract term translations based on the observation that authors of many bilingual web pages , especially those whose primary language is Chinese , Japanese or Korean , sometimes annotate terms with their English translations inside a pair of parentheses , like “ c1c2 ... cn ( e1 e2 ... em )” ( c1c2 ... cn is a primary language term and e1 e2 ... em is its English translation ). Actually , in addition to the parenthesis pattern , there is another interesting phenomenon that in many bilingual web pages bilingual data appear collectively and follow similar surface patterns . Figure 1 shows an excerpt of a page which introduces different kinds of dogs . The page provides a list of dog names in both English and Chinese . Note that those bilingual names do not follow the parenthesis pattern .",Supplement,Document,Introduce,Automatic Mining of Internet Translation Reference Knowledge Based on Multiple Search Engines,https://www.iaeng.org/publication/WCECS2014/WCECS2014_pp428-433.pdf
"The connection to the sense modalities of the words might not be mutually exclusive , that is to say a word can be associated with more than one sense . For instance , the adjective sweet could be associated with both taste and smell . The description of one kind of sense impression by using words that normally describe another is commonly referred to as linguistic synaesthesia . As an example , we can consider the slogans “ The taste of a paradise ” where the sense of sight is combined with the sense of taste or “ Hear the big picture ” where sight and hearing are merged . Synaesthesia strengthens creative thinking and it is commonly exploited as an imagination boosting tool in advertisement slogans ( Pricken , 2008 ).",Supplement,Document,Introduce,Exploring Sensorial Features for Metaphor Identification,https://aclanthology.org/W15-1404.pdf
"Otherwise , we may alter the coherence of the text and decrease its readability . This leaves us with 19 simplification rules . To apply them , the candidate structures for simplification first need to be detected using regular expressions , via Tregex ( Levy and Andrew , 2006 ) that allows the retrieval of elements and relationships in a parse tree . In a second step , syntactic trees in which a structure requires simplification are modified according a set of operations implemented through Tsurgeon . The operations to perform depend on the type of rules : 1 .",Supplement,Document,Introduce,Syntactic Sentence Simplification for French,https://hal.science/hal-00955176v1/document
"For each emotion class , the judge extracted expressions that reflect the emotion , and then made pairs that were conceptually equivalent . It was not feasible to ask a second judge to do the same task , because the process is time - consuming and tedious . In Information Retrieval , Precision and Recall are defined in terms of a set of retrieved documents and a set of relevant documents . In the following sections we describe how we compute the Precision and Recall for our algorithm compared to the manually extracted paraphrases . From the paraphrases that were extracted by the algorithm from the same texts , we counted how many of them were also extracted by the human judge .",Supplement,Document,Introduce,Emotions Extracted from Text vs. True Emotions–An Empirical Evaluation in SE Context,https://ieeexplore.ieee.org/document/8952437
"It is available as a free software project , thus enabling its practical re - use in other systems . Some research is also underway to explore the reverse direction , i . e . from XML schema to ontology content . The motivation for that is twofold : firstly to enable reasoning about XML content for DAML - enabled software and secondly to create DAML content from XML in a quick and automated fashion . The main objective of our approach is , however , to bring semantics to XML documents , i . e ., derive appropriate interface specifications from the given domain model , thereby enabling highquality reasoning immediately on the XMLS level .",Supplement,Document,Introduce,Towards the Semantic Web: Ontology‐driven Knowledge Management,https://onlinelibrary.wiley.com/doi/book/10.1002/0470858060
"Links between aligned words in the sentence pairs are then classified as positive or negative based on their scores , a technique which has previously been applied to extract paraphrase fragments from non - parallel bilingual corpora and has been shown to improve a state of the art machine translation system ( Munteanu and Marcu , 2006 ). Word pairs containing punctuation or stop words are excluded from the alignment prior to scoring . Afterwards , the alignment is refined by removing all negatively - scored word pairs , such that only very strong alignments survive . We then smooth the alignment by recomputing scores for each word , averaging over a window of five words . In this way we often capture context words that are left out of the alignment process ( e . g .",Supplement,Document,Introduce,Paraphrase Detection for Short Answer Scoring,https://aclanthology.org/W14-3505.pdf
"This paper deal with Arabic language and its variants for the analysis of social media and the collaborative construction of linguistic tools , such as lexical dictionaries and grammars and their exploitation in NLP applications , such as translation technologies . Basically , Arabic is considered as morphologically rich and complex language , which presents significant challenges for NLP and its applications . It is the official language in 22 countries spoken by more than 350 million people around the world . Moreover , Arabic language exists in a state of diglossia where the standard form of the language , Modern Standard Arabic ( MSA ) and the regional dialects ( AD ) live side - by - side and are closely related ( Elfardy and Diab , 2013 ). Arabic has more than 22 variants , refereed a as dialects ; some countries share the same dialects , while many dialects may exist alongside MSA within the same Arab country .",Supplement,Document,Introduce,Automatic Identification of Arabic Language Varieties and Dialects in Social Media,https://aclanthology.org/W14-5904.pdf
"Then , for each domain we produced two kinds of gold standard taxonomies . WordNet taxonomy Concepts and relationships in the WordNet hypernym - hyponym hierarchy rooted on the corresponding root concept . Combined taxonomy Domain - specific terms and relations from well - known , publicly available , tax onomies other than WordNet : CheBI for Chemicals , “ The Google product taxonomy ” for Foods , the “ Material Handling Equipment ” taxonomy for Equipment , and the “ Taxonomy of Fields and their Subfields ” for Science . Hypernym - hyponym relationships were also gathered from a general purpose resource , the Wikipedia Bitaxonomy ( WiBi ) ( Flati et al ., 2014 ), using a semi - automatic approach . For each domain we first manually identified domain sub - hierarchies from WiBi ( W ); Second we automatically searched for the terms of W in common with the corresponding gold standard G . For each common term t we added in G the taxonomy rooted on t from W . Table 1 shows the resulting number of vertices JV J , i . e ., the number of terms given to the participants , and the number of edges JEJ of the produced gold standard taxonomies for the four target domains .",Supplement,Document,Introduce,"ExTaSem! Extending, Taxonomizing and Semantifying Domain Terminologies",https://ojs.aaai.org/index.php/AAAI/article/view/10330
"We also discuss NLP - related applications that support the linguistic analysis of texts -- typically in the context of developing readability measures -- which continues to be a prominent area of research ; other research supports student tools allowing direct interaction with language forms ( Section 2 . 2 ). Language Demands on ELLs . The English Language Arts Common Core State Standards ( Standards ) ( NGA Center & CCSSO , 2010 ) has now been adopted by 46 states and is a trend - setter in U . S . education . The Standards emphasize the need for all learners ( including ELLs ) to read progressively more complex texts across multiple genres in the content areas , preparing learners for college and careers . To accomplish this , learners must have familiarity with numerous linguistic features related to vocabulary , English language structures , and a variety of text structures ( discourse ).",Supplement,Document,Introduce,From Teacher Professional Development to the Classroom: How NLP Technology Can Enhance Teachers' Linguistic Awareness to Support Curriculum Development for English Language Learners,https://sci-hubtw.hkvisa.net/10.2190/ec.51.1.f
"ROUGE scores , based on n - gram overlap between human abstracts and automatic extracts , were also calculated for comparison [ 5 ]. ROUGE2 , based on bigram overlap , is considered the most stable as far as correlating with human judgments , and this was therefore our ROUGE metric of interest . ROUGE - SU4 , which evaluates bigrams with intervening material between the two elements of the bigram , has recently been shown in the context of the Document Understanding Conference ( DUC ) to bring no significant additional information as compared with ROUGE - 2 . Results from [ 4 ] and from DUC 2005 also show that ROUGE does not always correlate well with human judgments . It is therefore included in this research in the hope of further determining how reliable the ROUGE metric is for our domain of meeting summarization .",Supplement,Document,Introduce,Incorporating Speaker and Discourse Features into Speech Summarization,https://aclanthology.org/N06-1047.pdf
"However , suppose that we express the same English meaning in the following way : Chief of Mali defense wants more weapons . Then BING produces a much better translation : Chef d ’ état - major de la défense du Mali veut plus d ’ armes . The fact that the formulation of the source can strongly influence the quality of the translation has long been known , and there have been studies indicating that adherence to so - called “ Controlled Language ” guidelines , such as Simplified Technical English can reduce the MT post - edition effort . However , as one such study ( O ’ Brien , 2006 ) notes , it is unfortunately not sufficient to just “ apply the rules [ i . e . guidelines ] and press Translate .",Supplement,Document,Introduce,SORT: An Interactive Source-Rewriting Tool for Improved Translation,https://aclanthology.org/P13-4015.pdf
"This model included a list of “ objective ” error types , graded by their severity and pre - assigned penalty points . The SAE J2450 standard , from the automotive service , also became popular . What became clear from these first efforts was that no one - fits - all evaluation scheme is possible for MT . Each player within the translation workflow , from developers to vendors and clients , has its own needs and the information they expect from the evaluations is different . After LISA ceased operations , two major efforts emerged : TAUS presented its Dynamic Quality Framework ( DQF ) and the QTLaunchPad project developed the Multidimensional Quality Metrics ( MQM ).",Supplement,Document,Introduce,Multidimensional Quality Metrics (MQM): A Framework for Declaring and Describing Translation Quality Metrics,https://ddd.uab.cat/pub/tradumatica/tradumatica_a2014n12/tradumatica_a2014n12p455.pdf
"However they are located in different places , have been developed using different standards ( if any ) and in many cases are not well documented . High fragmentation and a lack of unified access to language resources are the key obstacles to European innovation potential in language technology ( LT ) development and research . To address these issues the European Commission has dedicated specific activities in its FP7 R & D and ICT - PSP programmes . The overall objective is to ease and speed up the provision of online services centred around computerbased translation and cross - lingual information access and delivery . The focus is on assembling , linking across languages , and making widely available the basic language resources used by developers , professionals and researchers to build specific products and applications .",Supplement,Document,Introduce,META-NORD: Baltic and Nordic Branch of the European Open Linguistic Infrastructure,https://d1wqtxts1xzle7.cloudfront.net/30196343/proceedings_vol13-libre.pdf?1390880284=&response-content-disposition=inline%3B+filename%3DMETA_NORD_Baltic_and_Nordic_Branch_of_th.pdf&Expires=1686168969&Signature=HcmD-~06J8Bcv4Q7aVl58RmsRJem9C46rXNdB9tbDrUGLM1rMQcqOA9x3uvNPrKNJEzxpzUvt21mF2ZAr5jLxCUdumpdshQMhO7E4HZB4RlOtJQQpm-2fR4OTYBvkhi1bbSyhwto6LZRMH2~bEoy3nwMzJYHq7lPS31IzqoHw6EQ9HiiufQWbH3HMN1dZSX536z33iYKnPuj08k1cqciNGrOHZKsez7hIIjnZB05ZQoCwhcmSMHes1AYrPBOLmpFDW49shkMjtSkkbCb5bE8uEqDLpnyXYxNYPoWqFBeBL~tuO96ZRl6QIakZCpA1~dWqPvZgz0aMrazZwfwg6xkiA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA#page=24
"However , these small snippets of text have several liguistic peculiarities that can be employed to improve the sentiment classification performance . We describe these peculiarities below : However , users tweet in more than 80 languages . The information it contains can be useful to obtain information and updates about , for example , crisis events , in real time . In order to benefit from this , however , a system processing these texts has to be easily adaptable to other languages and it has to work in near real time . Bearing this in mind , the main contributions we bring in this paper are : 1 .",Supplement,Document,Introduce,Sentiment Analysis in Social Media Texts,https://aclanthology.org/W13-1617.pdf
"2004 ), ( b ) its recurring elements ( semantic primitives ( Schank , 1975 ; Wierbicka , 1996 ) or ( c ) its role in discourse : words are grouped by domain , ( see Roget ' s Thesaurus , Roget , 1852 ). Unlike linguists , psychologists are more interested in word relations . Gathering typically related terms ( x evoking y ) they ' ve built association lists ( Deese , 1965 ; Schvaneveldt , 1989 ). Such lists are nowadays freely available in different languages : Dutch , English ( , ), French , German , Japanese , and Russian . The Edinburgh Associative Thesaurus is particularly interesting , in as it shows not only the words evoked (' red ', ' flower ', etc .) in response to a given stimulus (' rose '), but also the causes ( primes ) of this input .",Supplement,Document,Introduce,Automatic index creation to support navigation in lexical graphs encoding part_of relations,https://aclanthology.org/W12-5104.pdf
"For example , functionality specification before implementation was described for CGAL and is typical of large projects but would have been cumbersome for Moses . Secondly , the aims of Moses and these projects are different . The goal of the CGAL project is to ‘ make ... computational geometry available for industrial application ’ . Both CGAL and DCMTK are used extensively in commercial applications . Therefore , issues such robustness , cross - platform compatibility and easeof - use are predominant for these projects .",Supplement,Document,Introduce,Design of the Moses Decoder for Statistical Machine Translation,https://aclanthology.org/W08-0510.pdf
"), which can be instantiated in different ways depending on the annotator ❑ s approach and goals . We have implemented both the abstract model and various instantiations using XML schemas ( Thompson , et al ., 2000 ), the Resource Definition Framework ( RDF ) ( Lassila and Swick , 2000 ) and RDF schemas ( Brickley and Guha , 2000 ), which enable description and definition of abstract data models together with means to interpret , via the model , information encoded according to different conventions . The results have been incorporated into XCES ( Ide , et al ., 2000a ), part of the EAGLES Guidelines developed by the Expert Advisory Group on Language Engineering Standards ( EAGLES ) . The XCES provides a ready - made , standard encoding format together with a data architecture designed specifically for linguistically annotated corpora . In this paper we provide an overview of our representation framework and demonstrate its applicability to syntactic annotation .",Supplement,Document,Introduce,A Common Framework for Syntactic Annotation,https://aclanthology.org/P01-1040.pdf
"Electronic career guidance is , thus , a supplement to career guidance by human experts , helping young people to decide which profession to choose . The goal is to automatically compute a ranked list of professions according to the user ’ s interests . A current system employed by the German Federal Labour Office ( GFLO ) in their automatic career guidance front - end is based on vocational trainings , manually annotated using a tagset of 41 keywords . The user must select appropriate keywords according to her interests . In reply , the system consults a knowledge base with professions manually annotated with the keywords by career guidance experts .",Supplement,Document,Introduce,What to be? - Electronic Career Guidance Based on Semantic Relatedness,https://aclanthology.org/P07-1130.pdf
"Figure 2 gives one view of the type of information extracted by the collection of learned category and relation classifiers . Note the initial seed examples provided to CBL did not include information about either company or any of these relation instances . To estimate the capacity of our algorithm to contribute additional facts to publicly available semantic resources , we compared the complete lists of instances promoted during the Full 15 iteration run for certain categories to corresponding lists in the Freebase database ( Metaweb Technologies , 2009 ). Excluding the categories that did not have a directly corresponding Freebase list , we computed for each category : Precision x | CBLInstances |− | Matches |, where Precision is the estimated precision from our random sample of 30 instances , | CBLInstances | is the total number of instances promoted for that category , and | Matches | is the number of promoted instances that had an exact match in Freebase . While exact matches may underestimate the number of matches , it should be noted that rather than make definitive claims , our intent here is simply to give rough estimates , which are shown in Table 3 .",Supplement,Document,Introduce,Coupling Semi-Supervised Learning of Categories and Relations,https://aclanthology.org/W09-2201.pdf
"The reliable processing of temporal information is an important step in many NLP applications , such as information extraction , question answering , and document summarisation . Consequently , the tasks of identifying and assigning values to temporal expressions have recently received significant attention , resulting in the creation of mature corpus annotation guidelines ( e . g . TIMEX2 and TimeML ), publicly However , existing corpora have their limitations . In particular , the documents in these corpora tend to be limited in length and , in consequence , discourse structure . This impacts on the number , range and variety of temporal expressions they contain .",Supplement,Document,Introduce,WikiWars: A New Corpus for Research on Temporal Expressions,https://aclanthology.org/D10-1089.pdf
"Semantic textual similarity relates to textual entailment ( Dagan et al ., 2005 ), lexical substitution ( McCarthy and Navigli , 2009 ) and paraphrasing ( Hirst , 2003 ). The key issue for semantic textual similarity is that the task is to determine similarity , where similarity is cast as meaning equivalence . In textual entailment the relation under question is the more specific relation of entailment , where the meaning of one sentence is entailed by another and a system needs to determine the direction of the entailment . Lexical substitution relates to semantic textual similarity though the task involves a lemma in the context of a sentence , candidate substitutes are not provided , and the relation at question in the task is one of substitutability . Paraphrase recognition is a highly related task , for example using comparable corpora ( Barzilay and Elhadad , 2003 ), and it is likely that semantic textual similarity measures might be useful for ranking candidates in paraphrase acquisition .",Supplement,Document,Introduce,"DSS: Text Similarity Using Lexical Alignments of Form, Distributional Semantics and Grammatical Relations",https://aclanthology.org/S12-1081.pdf
"Reliable inference from the observed number of spikes about the underlying firing rate of a neuronal response , however , requires a sufficiently long time interval , while integration times of neurons in vivo [ 3 ] as well as reaction times of humans or animals when performing classification tasks [ 4 , 5 ] are known to be rather short . Therefore , it is important to understand , how neural rate coding is affected by a limited time window available for decoding . While rate codes are usually characterized by tuning functions relating the intensity of the * neuronal response to a particular stimulus parameter , the question , how relevant the idea of analogc",Supplement,Document,Introduce,Binary Tuning is Optimal for Neural Rate Coding with High Temporal Resolution,https://proceedings.neurips.cc/paper_files/paper/2002/file/e45823afe1e5120cec11fc4c379a0c67-Paper.pdf
"Each image is first segmented into 800 “ superpixels ”, which are local , coherent and preserve most of the structure necessary for segmentation at the scale of interest [ 19 ]. The software used for over - segmentation is discussed in [ 17 ] and is available online ( http :// www . cs . sfu . ca /∼ mori / research / superpixels /). Each superpixel is represented by both color and texture descriptors , based on the local RGB , hue [ 25 ] feature vectors and also the output of maximum response ( MR ) filter banks [ 22 ] ( ). We discretize these features using a codebook of size 64 ( other codebook sizes gave similar performance ), and then calculate the distribution [ 1 ] for each feature within each superpixel as visual words [ 3 , 6 , 10 , 11 , 20 , 23 , 24 ]. Since each superpixel is represented by three visual words , the mixture atoms θ ∗ j are three multinomial distributions { Mult ( Θ ∗ 1j ) (& Mult ( Θ ∗ 2j ) (& Mult ( Θ ∗ 3j )} for j / = 1 , · · , J .",Supplement,Document,Introduce,"A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation",https://proceedings.neurips.cc/paper_files/paper/2009/file/f85454e8279be180185cac7d243c5eb3-Paper.pdf
"This work was supported by NSF CCF - 0830780 , CCF - 0917274 , DMS0915228 , and IIS - 1117965 at UTA ; and by NSF IIS - 1117335 , NIH R01 LM011360 , UL1 RR025761 , U01 AG024904 , RC2 AG036535 , R01 AG19771 , and P30 AG10133 - 18S1 at IU . Data used in the work were obtained from the ADNI database . ADNI funding information is available at to apply / ADNI DSP Policy . pdf .",Supplement,Document,Introduce,High-Order Multi-Task Feature Learning to Identify Longitudinal Phenotypic Markers for Alzheimer’s Disease Progression Prediction,https://proceedings.neurips.cc/paper_files/paper/2012/file/85fc37b18c57097425b52fc7afbb6969-Paper.pdf
"There exists a very large literature on neural circuits for translation - invariant pattern recognition see http :// www . cnl . salk . edurwiskott / Bibliographiesfinvariances . htrnl . Unfortunately there exists substantial disagreement regarding the interpretation of existing approaches see Virtually all positive results are based on computer simulations of small circuits , or on learning algorithms for concrete neural networks with a fixed input size n on the order of 20 or 30 , without an analysis how the required number of gates and the area or volume occupied by wires scale up with the input size . The computational performance of these networks is often reported in an anecdotical manner .",Supplement,Document,Introduce,"Computational Neuroscience: Trends in Research, 1998",https://books.google.com.vn/books?hl=en&lr=&id=0jnSBwAAQBAJ&oi=fnd&pg=PA497&dq=Computational+Neurobiology+Laboratory+at+the+Salk+Institute+for+Biological+Studies&ots=ctlqyJbPmd&sig=gKWJzJCYQDevenB9LYYUcwUSijg&redir_esc=y#v=onepage&q=on%20the%20order%20of%2020%20or%2030&f=false
"The methods follow , e . g ., example 3 . 2 . 12 of [ 5 ] — basically , a generalization of the classical theorem on the asymptotic distribution of the maximum likelihood estimator in regular parametric families . Again , see the longer draft at , liam for the precise definition of the approximation error and the full expression for a ( k0 ). We have developed an algorithm for the computation of argmaxvMN ( V ), and numerical results show that 1 : 4 can be competitive with spike - triggered average or covariance techniques even in cases in which \- kcoRR ) are zero . We present a brief application of Ko in section 4 .",Supplement,Document,Introduce,Convergence Properties of Some Spike-Triggered Analysis Techniques,https://proceedings.neurips.cc/paper_files/paper/2002/file/4aecfbe5d21e3f7912bf8eb29124423a-Paper.pdf
"∗ Data used in preparation of this article were obtained from the Alzheimer ’ s Disease Neuroimaging Initiative ( ADNI ) database ( adni . loni . ucla . edu ). As such , the investigators within the ADNI contributed to the design and implementation of ADNI and / or provided data but did not participate in analysis or writing of this report . A complete listing of ADNI investigators can be found at : to apply / ADNI Acknowledgement List . pdf .",Supplement,Document,Introduce,Alzheimer's Disease Neuroimaging Initiative (ADNI),https://n.neurology.org/content/74/3/201.short
"We analyze the link between “ Vote ” and “ PChange ”. Though the marginal correlation between them ( without X ) is only 0 . 0389 , which is the second lowest absolute pairwise correlation , the link is firstly recovered by SLasso . It has been suggested that there is indeed a connection . This shows that after taking features into account , the dependence structure of response variables may change and hidden relations could be discovered . The main factors in this case are “ percentage of housing unit change ” ( X1 ) and “ population percentage of people over 65 ” ( X2 ).",Supplement,Document,Introduce,Learning Higher-Order Graph Structure with Features by Structure Penalty,https://proceedings.neurips.cc/paper_files/paper/2011/file/0336dcbab05b9d5ad24f4333c7658a0e-Paper.pdf
"A single wrong correspondence between two consecutive frames may reduce the electrode ’ s score dramatically , while being unnoticed by the single frame score . In most cases the algorithm gives reasonably evolving clustering , even when it disagrees with the manual solution . Examples can be seen at the authors ’ web site . Low matching scores between the manual and the automatic clustering may result from inherent ambiguity in the data . As a preliminary assessment of this hypothesis we obtained a second , independent , manual clustering for the data set for which we got the lowest match scores .",Supplement,Document,Introduce,Spike Sorting: Bayesian Clustering of Non-Stationary Data,https://proceedings.neurips.cc/paper_files/paper/2004/file/b5baa9c23ac3e015ad287b17a3d4afa3-Paper.pdf
"We define a concept graph as a rooted , directed graph where the nodes represent thematic units ( called concepts ) and the edges represent relationships between concepts . Concept graphs are useful for summarizing document collections and providing a visualization of the thematic content and structure of large document sets - a task that is difficult to accomplish using only keyword search . An example of a concept graph is Wikipedia ’ s category graph . Figure 1 shows a small portion of the Wikipedia category graph rooted at the category MACHINE LEARNING . From the graph we can quickly infer that the collection of machine learning articles in Wikipedia focuses primarily on evolutionary algorithms and Markov models with less emphasis on other aspects of machine learning such as Bayesian networks and kernel methods .",Supplement,Document,Introduce,Learning Concept Graphs from Text with Stick-Breaking Priors,https://proceedings.neurips.cc/paper_files/paper/2010/file/6c8dba7d0df1c4a79dd07646be9a26c8-Paper.pdf
"Social media and social networking sites are increasingly used by people to express their opinions , give their “ hot takes ”, on the latest breaking news , political issues , sports events , and new products . As a consequence , there has been an increasing interest on leveraging social media and social networking sites to sense and forecast opinions , as well as understand opinion dynamics . For example , political parties routinely use social media to sense people ’ s opinion about their political discourse ; quantitative investment firms measure investor sentiment and trade using social media [ 18 ]; and , corporations leverage brand sentiment , estimated from users ’ posts , likes and shares in social media and social networking sites , to design their marketing campaigns . In this context , multiple methods for sensing opinions , typically based on sentiment analysis [ 21 ], have been proposed in recent years . However , methods for accurately forecasting opinions are still scarce [ 7 , 8 , 19 ], despite the extensive literature on theoretical models of opinion dynamics [ 6 , 9 ].",Supplement,Document,Introduce,Learning and Forecasting Opinion Dynamics in Social Networks,https://proceedings.neurips.cc/paper_files/paper/2016/file/f340f1b1f65b6df5b5e3f94d95b11daf-Paper.pdf
"Of the players that did not fold , the player with the highest ranked poker hand wins all of the bets . Full rules can be found on - line . We focus on the Limit Hold ’ em variant that fixes the bet sizes and the number of bets allowed per round . We denote the players ’ actions as f ( fold ), c ( check or call ), and r ( bet or raise ). Leduc Hold ’ em [ 10 ] ( or simply Leduc ) is a smaller version of Hold ’ em , played with a six card deck consisting of two Jacks , two Queens , and two Kings with only two betting rounds , pre - flop and flop .",Supplement,Document,Introduce,On Strategy Stitching in Large Extensive Form Multiplayer Games,https://proceedings.neurips.cc/paper_files/paper/2011/file/812b4ba287f5ee0bc9d43bbf5bbe87fb-Paper.pdf
"Social media and social networking sites are increasingly used by people to express their opinions , give their “ hot takes ”, on the latest breaking news , political issues , sports events , and new products . As a consequence , there has been an increasing interest on leveraging social media and social networking sites to sense and forecast opinions , as well as understand opinion dynamics . For example , political parties routinely use social media to sense people ’ s opinion about their political discourse ; quantitative investment firms measure investor sentiment and trade using social media [ 18 ]; and , corporations leverage brand sentiment , estimated from users ’ posts , likes and shares in social media and social networking sites , to design their marketing campaigns . In this context , multiple methods for sensing opinions , typically based on sentiment analysis [ 21 ], have been proposed in recent years . However , methods for accurately forecasting opinions are still scarce [ 7 , 8 , 19 ], despite the extensive literature on theoretical models of opinion dynamics [ 6 , 9 ].",Supplement,Document,Introduce,Modeling Opinion Dynamics in Diffusion Networks,https://www.researchgate.net/profile/Isabel-Valera/publication/278733707_Modeling_Opinion_Dynamics_in_Diffusion_Networks/links/5758521b08aec913749f0262/Modeling-Opinion-Dynamics-in-Diffusion-Networks.pdf
"Supporting information : this article has supporting information at journals . iucr . org / d Acta Cryst . ( 2018 ). D74 , 441 – 449 441 research papers images can be collected via the rotation method , where integrated Bragg intensities are experimentally obtained . At cryogenic temperatures , small - wedge ( 5 – 10 °) data collection can be a good compromise to obtain strong diffraction signals under tolerable doses , and tens to hundreds of data sets are usually sufficient to obtain a high - resolution structure . Efficient data collection can be achieved and easily automated when multiple microcrystals are held in a sample holder .",Supplement,Document,Introduce,KAMO: towards automated data processing for microcrystals,https://journals.iucr.org/d/issues/2018/05/00/wa5117/wa5117sup1.pdf
"Use of the Web Ontology Language ( OWL ) OBI is developed using the OWL 2 Web Ontology Language ( http :// www . w3 . org / TR / owl2 - overview /) as this provides richer semantic support than OBO format ( http :// www . geneontology . org / GO . format . obo - 1_2 . shtml )— the other commonly used alternative in the biomedical domain . The metadata scheme is implemented as OWL annotation properties . The OWL 2 Web Ontology Language ( ) is a W3C standard for the representation of ontologies within the larger framework of the semantic web . OWL builds on the Resource Description Framework ( RDF ; http :// www . w3 . org / TR / rdf - primer /) standard in which data is represented by sets of subject - predicate - object statements (“ triples ”) that form a directed graph . Subjects and predicates are named using Internationalized Resource Identifiers ( IRIs ; https :// tools . ietf . org / html / rfc3987 ), while the object position can be filled by an IRI or a literal value ( e . g .",Supplement,Document,Introduce,The Ontology for Biomedical Investigations,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0154556
"The DC elements ‘ dc : coverage ’ and ‘ dc : subject ’ have a high topical overlap ( ); for instance , subject elements often contain location names such as countries . The usage of the ‘ coverage ’ element – intended to denote spatial and temporal applicability – is very diverse and ranges from standardized dates with milliseconds granularity to relative - time indications such as ‘ Early Middle Ages ’, and can contain both instants and time ranges . We addressed this semantic problem by introducing a set of experimental , non - validated fields whose content is the result of a named entity recognition and geocoding .",Supplement,Document,Introduce,A data discovery index for the social sciences,https://www.nature.com/articles/sdata201864
Supplementary Information accompanies this paper at Competing interests : The authors declare no competing financial interests . Reprints and permission information is available online at http :// npg . nature . com / reprintsandpermissions / Publisher ' s note : Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations .,Supplement,Document,Introduce,A data discovery index for the social sciences,https://sci-hubtw.hkvisa.net/10.1038/sdata.2018.64
"_CITE_ section Materials and methods ) used in CePa , the most influential genes were the nodes with the highest betweenness centrality .",Supplement,Document,Introduce,A critical comparison of topology-based pathway analysis methods,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0191154
"PLOS ONE | https :// doi . org / 10 . 1371 / journal . pone . 0198189 May 24 , 2018 13 / 24 A time series of urban extent in China using NTL data Fig 5 . Offset in the extracted urban extents of Beijing in 2008 and 2009 . ( a ) The result for 2008 is superimposed on the result for 2009 ; ( b ) The result for 2009 is superimposed on the result for 2008 . The spatial distribution of the urban sprawl pattern displays some aggregation , which is approximately distributed in the eastern , central and western areas ( Fig 8 ). De - urbanization and Constant Urban Activity do not exit or have not appeared in China . Only three patterns of urban growth are shown on the map .",Supplement,Document,Introduce,A time series of urban extent in China using DSMP/OLS nighttime light data,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198189
"Session 4 : Private - public partnership for the development of new tools for arbovirus vector control The session aimed at discussing the challenge of insecticide resistance in the context of developing new effective tools for insect vector control from the insecticide manufacturer ’ s perspective . Representatives of the agrochemical sector ( 28 companies were represented ), Innovative vector Control Consortium ( IVCC ) and Insecticide Resistance Action Committee ( IRAC ) attended the workshop to present efficacy data and share their experience of vector control and resistance management . Mr . John Lucas ( Sumitomo Chemical Co ., UK ) provided an overview of the Insecticide Resistance Action Committee ( IRAC ) that was formed in 1984 to provide a coordinated industry approach to counter the development of resistance in pests and mites ( ). The challenge of insecticide resistance in insects that impact public health comes from the limited arsenal of new chemistries . This has been exacerbated by a major decline in the number of companies actively involved in insecticide development .",Supplement,Document,Introduce,"International workshop on insecticide resistance in vectors of arboviruses, December 2016, Rio de Janeiro, Brazil",https://link.springer.com/article/10.1186/s13071-017-2224-3
"Shorter and longer exposures are presented in S7 Fig . The table lists the description of all genes analyzed . from HU - block , but not 6 . 5h after release ( Fig 8B , S7 Fig ). No other genes in the cluster were activated to the same extent at either of the two time - points . In the chromosome 32 cluster that was analyzed CYC9 was transcriptionally activated only at 6 . 5h after release , and none of the other genes in the cluster were activated to the same extent at either time - point .",Supplement,Document,Introduce,Cell cycle stage-specific transcriptional activation of cyclins mediated by HAT2-dependent H4K10 acetylation of promoters in Leishmania donovani,https://journals.plos.org/plospathogens/article?id=10.1371/journal.ppat.1006615
"_CITE_ Figure 43 , Appendix 11 Opisthostoma kitteli Maassen , 2002 : 176 , figures 35 & 36 ( original description ). Type material . Holotype : RMNH 92942 ( 1 ) ( seen ).",Supplement,Document,Introduce,The Evolution of Shell Form in Tropical Terrestrial Microsnails,https://scholarlypublications.universiteitleiden.nl/access/item%3A2922542/view
"We thank Sonja Hopf from the Evolutionary and Functional Genomics group ( LMU Munich ) for valuable biological feedback . The work presented here was partially funded by the German Federal Ministry of Economy and Technology ( BMWi ) under the THESEUS project . Page 12 of 14 ( page number not for citation purposes ) BMC Bioinformatics 2008 , 9 : 207 _CITE_",Supplement,Document,Introduce,Extraction of semantic biomedical relations from text using conditional random fields,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-207
"We also determined Bonnet et al . eLife 2018 ; 7 : e32937 . DOI : 41 of 49 Research article Developmental Biology numerically the confidence regions for the distributions of fates that can yield fN f 2 . 5 %, fN f 5 % and f � f 10 %. In the end , we also report the distribution of fates that was actually measured in each condition , and check in which confidence interval it is ( Ventral zone : Appendix 4 — figure 2 , Appendix 4 — figure 3 , Appendix 4 — figure 4 , Dorsal zone : Appendix 4 — figure 5 , Appendix 4 — figure 6 , Appendix 4 — figure 7 ). Appendix 4 — figure 2 .",Supplement,Document,Introduce,Neurogenic decisions require a cell cycle independent function of the CDC25B phosphatase,https://elifesciences.org/articles/32937
"_CITE_ Figure 44 , Appendix 14 Opisthostoma charasense Tomlin , 1948 : 225 , Plate 2 - figure 4 ( original description ). Opisthostoma charasense Tomlin , van Benthem Jutting ( 1952 : 42 ). Type material .",Supplement,Document,Introduce,"A cybertaxonomic revision of the micro-landsnail genus Plectostoma Adam (Mollusca, Caenogastropoda, Diplommatinidae), from Peninsular Malaysia, Sumatra and Indochina",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3974427/
( 7Z ) S11 Dataset . VTK file for the distribution of actomyosin prestress colour - coded in Fig 5a . The VTK file format is described on ( 7Z ) S12 Dataset . VTK file for velocity shown as arrows in Fig 5a .,Supplement,Document,Introduce,Geometry can provide long-range mechanical guidance for embryogenesis,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005443
"In May 2011 , federal regulations prohibited vessels from approaching whales within 200 yards ( 183 m ) of whales , or positioning themselves within 400 yards ( 366 m ) of the path of a whale [ 34 ]. Research vessels operating under permit are exempt from federal regulations . An additional guideline recommends that vessels do not travel at speeds faster than 7 knots ( 13 kph ) within 400 yd ( 366 m ) of a whale ( ). These regulations apply only in U . S . waters . In Canada , whale watching is only subjected to the less stringent voluntary guideline of a 100 m minimum approach distance .",Supplement,Document,Introduce,The Relationship between Vessel Traffic and Noise Levels Received by Killer Whales (Orcinus orca),https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140119https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140119
family The full scientific name of the family in which the taxon is classified ( http :// rs . tdwg . org / dwc / terms / family ). familyNameId An identifier for the family name . genus The full scientific name of the genus in which the taxon is classified ( ). subgenus The full scientific name of the subgenus in which the taxon is classified . Values include the genus to avoid homonym confusion ( http :// rs . tdwg . org / dwc / terms / subgenus ).,Supplement,Document,Introduce,Fauna Europaea: Gastrotricha,https://bdj.pensoft.net/articles.php?id=5800
"from data from ten CCD panels , background subtraction , and extraction of diffraction patterns suitable for the subsequent processing and analysis ( Fig . 3 ). In every raster scan , diffraction patterns from the data acquisition system of the MPCCD detectors are converted to a single file in HDF5 format ( ), which contains all diffraction patterns by X - ray pulses provided during the scan . First , TAMON reconstructs image data from the eight panels of the MPCCD - Octal detector and the two from the MPCCD - Dual into a single file using the geometrical parameters describing the relative positions and orientations of the detector panels ( Kameshima , 2012 ). The positional and angular accuracies of parameters are approximately 25 µm and 1 mrad , respectively .",Supplement,Document,Introduce,Data processing software suite SITENNO for coherent X-ray diffraction imaging using the X-ray free-electron laser SACLA,https://journals.iucr.org/s/issues/2014/03/00/gb5018/index.html
"aMatlab Publishing Markup refers to specific keys such as %% or _ _ which allows not only inserting comments into your Matlab code , but also format it for then publish the code automatically into an executable and readable format , see bWhen uploading data to OpenfMRI you need to ensure the structural data are defaced appropriately – the website also offers to use their own defacing tool , see https :// github . com / poldrack / openfmri / tree / master / pipeline / facemask . cThanks to Dorothy Bishop for pointing to this .",Supplement,Document,Introduce,Improving data availability for brain image biobanking in healthy subjects: Practice-based suggestions from an international multidisciplinary working group,https://sci-hub.hkvisa.net/10.1016/j.neuroimage.2017.02.030
"_CITE_ experiments and samples in an intuitive way . Although properties for different sample and experiment types have to be defined in advance , all types are connected to an XML - based property in our data model implementation , which offers the possibility to extend the amount of metadata that should be stored with entities in a generic manner . These XML properties can be controlled by providing XML schemata that are used to present users with a robust option to record a diverse set of meta information as found in modern biomedical experiments .",Supplement,Document,Introduce,These XML properties can be controlled by providing XML schemata that are used to present users with a robust option to record a divers,https://books.google.com.vn/books?hl=en&lr=&id=Zilck1_0c5QC&oi=fnd&pg=PT7&dq=These+XML+properties+can+be+controlled+by+providing+XML+schemata+that+are+used+to+present+users+with+a+robust+option+to+record+a+divers&ots=JIyL1XCUIY&sig=nwofyA0yqWN5YSneEvWBFwuUUu4&redir_esc=y#v=onepage&q&f=false
"The Facility Profile is completed by each facility that provides dialysis to ESKD patients on December 31st of each year . CORR publishes an Annual Data Report that provides the latest data on dialysis , organ transplants , waiting list and donors . The latest report issued in 2014 , reports on data from 2003 – 2012 and is available on CIHI ’ s website ( ). The Center - Specific Reports on Clinical Measures reports are new series of reports , released in 2014 , designed for dialysis centres and derived primarily from the clinical measures captured in the annual follow - up survey . This includes patient demographics , comorbidities , and laboratory and clinic indicator comparisons for the center , the province and Canada .",Supplement,Document,Introduce,The Relationship between Vessel Traffic and Noise Levels Received by Killer Whales (Orcinus orca),https://journals.sagepub.com/doi/pdf/10.1186/s40697-014-0026-5
_CITE_ Medical and Health Sciences . The sample sizes for some of the disciplines were rather small ( n < 40 ).,Supplement,Document,Introduce,Characterising and justifying sample size sufficiency in interview-based studies: systematic analysis of qualitative health research over a 15-year period,https://link.springer.com/article/10.1186/s12874-018-0594-7
The average time cost for each 5 × WGS analysis was 2 . 39 min and the average expenditure was $ 3 . 62 . Table 10 describes time cost details in this case . GT - WGS is the champion solution of the WGS time optimization problem on the Wind and Cloud challenge held by the GCTA committee ( see for the news report ). This success can be attributed to : ( 1 ) GT - WGS always tries to get the lowest price via spot instances ;,Supplement,Document,Introduce,GT-WGS: An efficient and economic tool for large-scale WGS analyses based on the AWS cloud service,https://www.researchgate.net/publication/322606613_GT-WGS_An_efficient_and_economic_tool_for_large-scale_WGS_analyses_based_on_the_AWS_cloud_service
"One such receptor is the aryl hydrocarbon receptor ( AHR ). The AHR is the only ligand - activated member of the Per - ARNT - Sim ( bHLH / PAS ) family of transcription factors , all of which play important roles as environmental - and physiological stress - sensing proteins [ 8 ]. The AHR has been best studied for its ability to be activated by dioxins , polychlorinated biphenyls , and polycyclic aromatic hydrocarbons [ 9 ], all of which are high priority chemicals on the U . S . Agency for Toxic Substances and Disease Registry list of pollutants of greatest concern to human health ( ). Ligand - bound AHR induces P450 enzymes such as CYP1B1 and CYP1A1 , which are capable of generating mutagenic intermediates . However , more recent work suggests that the AHR , which is expressed at aberrantly high levels and is chronically active in several cancers , plays an ongoing role in tumor progression by enhancing tumor invasion and migration [ 10 – 15 ].",Supplement,Document,Introduce,The dioxin (aryl hydrocarbon) receptor as a model for adaptive responses of bHLH/PAS transcription factors,https://www.sciencedirect.com/science/article/pii/S001457930700381X/pdf?crasolve=1&r=7d3c66a3fde018f8&ts=1686177669769&rtype=https&vrr=UKN&redir=UKN&redir_fr=UKN&redir_arc=UKN&vhash=UKN&host=d3d3LnNjaWVuY2VkaXJlY3QuY29t&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&rh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&re=X2JsYW5rXw%3D%3D&ns_h=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ns_e=X2JsYW5rXw%3D%3D&iv=ec6c18d36d0bfda19acb555ca1c794fa&token=32646230616533643932383666393365343730626138666133623734376465303161613038373232313433646639386139663538643034623032326239666366323564613237343465333638363139326161656465663a346663356532383564616634333734616666393532636532&text=76bf871390b505eebeeb413836a0e2fb2f3cba1d2e5ef0184f355f068eaaf54eb842e0961f39f521830ce550e0df0b04e57d57de9f00eb1553abf8bc3498274d30295a187fe060b6807c4d011e85dd5f6a6eeeee8dfb1227faba2b603268aef997b6a61d70392bc99fd7d490d5f2842cff531d4b46038f1fe43b986dbf5316b25d01db7755dfdf1830bec3d0611e29c19ec95242394e796575cb0245c9488cb308467f9938f5e9eb371fc8870ee447a517b30dda9fbdb6bb645ae5be7f78c567089d356c6a59b79662b1e72ec4a1930c471b916d20a8654d98260e9e2aead15676b15b7b970abb9dbb7613677e3bab2ed5b1f89760bd1dc1049a8e1372ef16346ee98827e839e1208b98129ce78e4dcaa51726da692c5e3f2354ca31fe654194ce6e345022a9463c83de81c02e9b20fd&original=3f
"Over 60 , 000 SmartMesh networks have been deployed so far . One vendor alone , Emerson , claims over 31 , 900 networks , with cumulated node operating hours above 9 billion ( http :// www . emerson . com / en - us / expertise / automation / industrial - internet - things / pervasive - sensing - solutions / wireless - technology ). While SmartMesh IP was designed for industrial applications , it has been used in numerous other spaces , including smart buildings ( ), smart cities ( http :// www . linear . com / docs / 41387 ) and smart agriculture [ 53 ]. SmartMesh IP is a proven technology ; we chose to use it because our system operates well within the limits of a SmartMesh IP network . For example , SmartMesh IP network as a whole cannot generate more than 36 packets per second , with each packet carrying at most 90 bytes of application payload .",Supplement,Document,Introduce,Real-Time Alpine Measurement System Using Wireless Sensor Networks,"SmartMesh networks have been deployed so far . One vendor alone , Emerson , claims over 31 , 900 networks , with cumulated node operating hours above 9 billion"
"Andreas Drakos , Dear George , thank you very much for your comments . The main concept of the agINFRA project was to re - use main infrastructure elements , connect with existing generic solutions and create something specified for the agricultural research domain . While in this article we tried to summarize the work of agINFRA , the specific aspects of each element has been presented in the numerous publications made from the partners ( they can all be found at ). Page 10 of 11 F1000Research 2015 , 4 : 127 Last updated : 21 AUG 2015 The agINFRA vision was to improve research collaboration and data exchange , but during the lifetime of the project , this had to be limited in creating the necessary building blocks ( e - infrastructure ) for services to built upon ( as for example the new AGRIS ). Hopefully this effort will continue and in the future we will be able to present a number of different end - user services specialized for the agricultural research community .",Supplement,Document,Introduce,"agINFRA: a research data hub for agriculture, food and the environment",https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=0eaf03a8e09dcb566c1c3fc758b9902df93a442b
"Combining all edges ( SR + LM + SB ) does not influence the results any more , but in any case the hybrid configuration achieves the best overall recall ( 0 . 87 ). In conclusion , our experiments on all four datasets consistently demonstrate that combining Dijkstra - WSA with a similarity - based approach as a back - off yields the strongest performance . The results of these best alignments will be made freely available to the research community on our website ( ).",Supplement,Document,Produce,Dijkstra-WSA: A Graph-Based Approach to Word Sense Alignment,https://direct.mit.edu/tacl/article-abstract/doi/10.1162/tacl_a_00217/43228
"However , in contrast to our implementation and that of Shafran et al ( 2011 ), no expansion into an WFST with aligned input / output is described . Lexicographic semirings , used for PoS tagging disambiguation ( Shafran et al ., 2011 ), have been also shown to be useful in other tasks ( Sproat et al ., 2014 ), such as optimized epsilon encoding for backoff language models ( Roark et al ., 2011 ), and hierarchical phrase - based decoding with Pushdown Automata ( Allauzen et al ., 2014 ). The tools for disambiguation and WFST composition with bilingual models , along with a tutorial to replicate Section 4 . 2 , are all available at _CITE_",Supplement,Document,Produce,Transducer Disambiguation with Sparse Topological Features,https://aclanthology.org/D15-1273.pdf
"Examples of the use of JSrealB , and a webbased development environment are available at : jsrealb - bilingual - text - realiser The javascript code of the realizer , the lexicon and tables are made available to the NLG community at : https :// github . com / rali - udem / JSrealB",Supplement,Document,Produce,JSrealB: A bilingual text realizer for web programming,https://aclanthology.org/W15-4719.pdf
"For the English and Swedish data sets , we obtained approval from the University of Pittsburgh IRB and the Regional Ethical Review Board in Stockholm ( Etikpr ¨ ovningsn ¨ amnden i Stockholm ). The study is part of the Interlock project , funded by the Stockholm University Academic Initiative and partially funded by NLM Fellowship 5T15LM007059 . Lexicons and probabilities will be made available and updated on the iDASH NLP ecosystem under Resources : _CITE_",Supplement,Document,Produce,Medical diagnosis lost in translation – Analysis of uncertainty and negation expressions in English and Swedish clinical texts,https://aclanthology.org/W12-2407.pdf
"Its output is a ( time - varying ) 3d model that can be displayed by Partiview , an external data viewer . Future plans include adding more scalable embedding algorithms , and allowing other output formats . Ndaona , documentation , and examples of models created with it , can be found at _CITE_",Supplement,Document,Produce,Automating the Creation of Interactive Glyph-supplemented Scatterplots for Visualizing Algorithm Results,https://aclanthology.org/N06-4008.pdf
"Systems that can produce an appropriate semantic representation for a TTS are not many at an international level but they can be traced from the results of a Shared Task organized by members of SigSem and are listed here below in the corresponding webpage _2008_shared_task : _comparing_semantic_repre sentations ( see Bos & Delmonte , 2008 ). State of the art semantic systems are based on different theories and representations , but the final aim of the workshop was reaching a consensus on what constituted a reasonably complete semantic representation . Semantics in our case not only refers to predicate - argument structure , negation scope , quantified structures , anaphora resolution and other similar items , it refers essentially to a propositional level analysis .",Supplement,Document,Produce,Semantics and Discourse Processing for Expressive TTS,https://aclanthology.org/W15-2704.pdf
"digestive endoscopy ). The data are thus homogeneous , and is about 25 0 pages long ( 15 0 , 000 + words ). Most of these practice guidelines are publicly available at : or http :// affsaps . sante . fr . Similar documents have been published in English and other languages ; the GEM DTD is languageindependent .",Supplement,Document,Produce,Automatically Restructuring Practice Guidelines using the GEM DTD,https://arxiv.org/pdf/0706.1137.pdf
"Analysis scripts and primary data and results files are available for download from When no target segment is found by the algorithm for the speech of one caregiver , this results in missing data , as no recall , purity , or collocation can be calculated in these conditions . Therefore , we excluded from inspection all settings of the similarity threshold that resulted in missing data prior to carrying out statistical analyses .",Supplement,Document,Produce,Motif discovery in infant- and adult-directed speech,https://aclanthology.org/W15-2413.pdf
"§ Please note that the analysis is based on a single native ‡ The standard deviation was 29 . 8 ( 9 . 3 %). speaker , thus we need further analysis by multiple subjects . ( ). The native speaker largely agreed with our gen † eration , determining correct choices ( type I ). The",Supplement,Document,Produce,Measuring Non-native Speakers’ Proficiency of English by Using a Test with Automatically-Generated Fill-in-the-Blank Questions,https://aclanthology.org/W05-0210.pdf
"Qualitative analysis of these word clusters yields insights about NLP and linguistic phenomena in this genre . Additionally , we contribute the first POS annotation guidelines for such text and release a new dataset of English language tweets annotated using these guidelines . Tagging software , annotation guidelines , and large - scale word clusters are available at : This paper describes release 0 . 3 of the “ CMU Twitter Part - of - Speech Tagger ” and annotated data .",Supplement,Document,Produce,Improved Part-of-Speech Tagging for Online Conversational Text with Word Clusters,https://aclanthology.org/N13-1039.pdf
"Furthermore , the optimal personality of the system is likely to be application - dependent ; it would thus be useful to evaluate how the user ’ s and the system ’ s personality affect task performance in different applications . The PERSONAGE language generator is available for download at http :// mi . eng . cam . ac . uk /∼ farm2 / personage , as well as the personality - annotated corpus collected for our experiments . An on - line demonstrator and a tutorial for customizing PERSONAGE for a new domain can be found at _CITE_",Supplement,Document,Produce,Controlling User Perceptions of Linguistic Style: Trainable Generation of Personality Traits,https://direct.mit.edu/coli/article/37/3/455/2108/Controlling-User-Perceptions-of-Linguistic-Style
Table 3 shows the performance of our Ngrambased system using the SMR technique . First row is the WMT07 baseline system which can be reproduced following the instructions in This baseline system uses a non - monotonic search . Second row shows the results of the Ngram - based system presented in section 2 using the weighted reordering graph trained with the best configuration found in the above section ( 200 statistical classes and an Ngram of length 5 ).,Supplement,Document,Produce,Analysis of statistical and morphological classes to generate weighted reordering hypotheses on a Statistical Machine Translation system,https://aclanthology.org/W07-0721.pdf
"This bakeoff followed a strict set of guidelines and a rigid timetable . The detailed instructions for the bakeoff can be found at The training material of simplified Chinese word segmentation was available starting April 1 , the training material of traditional Chinese word segmentation was available April 23 , testing material was available June 9 , and the results had to be returned to the organizer by email by June 11 no later than 18 : 00 Beijing time . The participating groups (“ sites ”) of CIPSSIGHAN CLP 2010 Bakeoff registered by email .",Supplement,Document,Produce,The CIPS-SIGHAN CLP 2010 Chinese Word Segmentation Bakeoff,https://aclanthology.org/W10-4126.pdf
The toolkit has been hosted and developed under sourceforge . net since inception . Moses has an active research community and has reached over 1000 downloads as of 1st March 2007 . The main online presence is at where many sources of information about the project can be found . Moses was the subject of this year ’ s Johns Hopkins University Workshop on Machine Translation ( Koehn et al . 2006 ).,Supplement,Document,Produce,Moses: Open Source Toolkit for Statistical Machine Translation,https://aclanthology.org/P07-2045.pdf
"Given our 72 animals and 54 features , we ask a human annotator to mark each animal - feature pair with a ‘ probability ’, expressed as a quantifier . Possible values are no , few , some , most , all . The guidelines for the annotation task can be seen at iwcs13 - annot . pdf .",Supplement,Document,Produce,"What is in a text, what isn’t, and what this has to do with lexical",https://aclanthology.org/W13-0204.pdf
"To evaluate the results , two native Romanian speakers labeled the system outputs as being “ DE ”, “ not DE ” or “ Hard ( to decide )”. The labeling protocol , which was somewhat complex to prevent bias , is described in the externallyavailable appendices (§ 7 . 1 ). The complete system output and annotations are publicly available at : _CITE_",Supplement,Document,Produce,Don't 'have a clue'? Unsupervised co-learning of downward-entailing operators,https://arxiv.org/abs/1008.3169
"The backbone of the LOGON prototype implements a relatively conventional architecture , orgaPhis demonstration reflects the work of a large group of people whose contributions we gratefully acknowledge . Please see ‘ for background .",Supplement,Document,Produce,Som ˚a kapp-ete med trollet?,https://aclanthology.org/2004.tmi-1.2.pdf
"We now turn to the question of learning rules which reflect real - world relationships . Because of space constraints , we are unable to reproduce actual output from the system , but examples can be seen at As illustration , we consider here the classifiers produced for the feature aquatic a . The baseline classifier ( the one learnt from distributional data only ) does use distributional features that are associated with water ( mediterranean a , in p ()+ water n ), but overall , the decision tree is rather far from the way we might expect a human to attribute the feature aquatic a to an animal species , and mostly includes seemingly irrelevant features such as variant of or again fascinating .",Supplement,Document,Produce,"What is in a text, what isn’t, and what this has to do with lexical semantics",https://aclanthology.org/W13-0204.pdf
 . We show the effectiveness of the method by computing the accuracy of prediction and also by means of perceptual evaluations . The synthesized multilingual wave files are available for download at _CITE_,Supplement,Document,Produce,Is word-to-phone mapping better than phone-phone mapping for handling English words?,https://aclanthology.org/P13-2035.pdf
"The semantic zone most frequently refers to ontological concepts , either directly or with property - based modifications , but can also describe word meaning extra - ontologically , for example , in terms of modality , aspect , time , etc . The current English lexicon contains approximately 25 , 000 senses , including most closed - class items and many of the most frequent and polysemous verbs , as targeted by corpus analysis . ( An extensive description of the lexicon , formatted as a tutorial , can be found at )",Supplement,Document,Produce,Finite-state description of Vietnamese reduplication,https://inria.hal.science/inria-00421099/
"In the aftermath , Chinese media accused Western media of “ softpedaling the attack and failing to state clearly that it was an act of terrorism ”. In particular , regarding the statement by the US embassy that referred to this incident as the “ terrible and senseless act of violence in Kunming ”, a Weibo user posted “ If you say that the Kunming attack is a ‘ terrible and senseless act of violence ’, then the 9 / 11 attack can be called a ‘ regrettable traffic incident ”’. This example is striking but not an isolated case , for settings in which one party is trying to convince another are pervasive ; scenarios range from court trials to conference submissions . Since the strength and scope of an argument can be a crucial factor in its success , it is important to understand the effects of statement strength in communication . A first step towards addressing this question is to be able to distinguish between strong and weak statements .",Supplement,Document,Produce,A Corpus of Sentence-level Revisions in Academic Writing: A Step towards Understanding Statement Strength in Communication,https://arxiv.org/abs/1405.1439
"These heuristics handled the alignment of named entities ( e . g ., George Bush ) and definite descriptions ( e . g ., the president ), tenses ( e . g ., had been and shall be ), noun phrases with mismatching determiners ( e . g ., a man and the man ), verb complexes ( e . g ., was developed and had been developed ), phrasal verbs ( e . g ., take up and accept ), genitives ( e . g ., Bush ’ s infrequent speeches and the infrequent speeches by Bush ), pronouns , repetitions , typographic errors , and approximate correspondences . For more details , we refer the interested reader to our annotation guidelines . Figure 1 shows the alignment for two sentence pairs from the MTC corpus . The first pair ( Australia is concerned with the issue of carbon dioxide emissions . & lt ;- 4 The problem of greenhouse gases has attracted Australia ’ s attention .)",Supplement,Document,Produce,Constructing Corpora for the Development and Evaluation of Paraphrase Systems,https://direct.mit.edu/coli/article-abstract/34/4/597/2001
"She has been waiting for him for 20 years . The reduplication scanner will be integrated to vnTokenizer - an open source and highly accurate tokenizer for Vietnamese texts ( Le et al ., 2008 ). The software and related resources will be distributed under the GNU General Public Lisence and it will be soon available online . We have presented for the first time a computational model for the reduplication of the Vietnamese language . We show that a large class of reduplicative words can be modeled effectively by sequential finite - state string - to - string transducers .",Supplement,Document,Produce,Finite-state description of Vietnamese reduplication,https://hal.inria.fr/inria-00421099/
"( 2011 ) argue that it is harder to distinguish sarcastic from non - sarcastic messages where the nonsarcastic messages contain sentiment . Our results support this argument ( 97 % F1 measure for the best result for S vs . L , compared to 84 % F1 for the best result for S vs . Laent ; Section 4 ). To collect a set of target words that can have either literal or sarcastic meaning depending on context , we propose a two step approach : 1 ) a crowdsourcing task to collect a parallel dataset of sarcastic utterances and their re - phrasings that convey the authors ’ intended meaning ; and 2 ) unsupervised alignment techniques to detect semantically opposite words / phrases . Crowdsourcing Task . Given a sarcastic message ( SM ), Turkers were asked to re - phrase the message so that the new message is likely to express the author ’ s intended meaning ( IM ).",Supplement,Document,Produce,Sarcastic or Not: Word Embeddings to Predict the Literal or Sarcastic Meaning of Words,https://aclanthology.org/D15-1116.pdf
"Each label candidate was rated in this way by at least 10 annotators , and ratings from annotators who passed the filter were combined by averaging them . A sample of topics , label candidates , and the average rating is presented in Table 1 . Finally , we train the regression model over all the described features , using the human rating - based ranking . In this section we present our experimental results for the topic labelling task , based on both the unsupervised and supervised methods , and the methodology of Mei et al . ( 2007 ), which we denote MSZ for the remainder of the paper .",Supplement,Document,Produce,Automatic Labelling of Topic Models,https://aclanthology.org/P11-1154.pdf
"2013 . The DDI Corpus : an annotated corpus with pharmacological substances and drug - drug interactions , submitted to BioInformatics more detailed description , the reader is directed to our annotation guidelines . For evaluation , a part of the DDI corpus consisting of 52 documents from DrugBank and 58 MedLine abstracts , is provided with the gold annotation hidden . The goal for participating systems is to recreate the gold annotation . Each participant system must output an ASCII list of reported entities , one per line , and formatted as : IdSentence | startOffset - endOffset | text | type Thus , for each recognized entity , each line must contain the id of the sentence where this entity appears , the position of the first character and the one of the last character of the entity in the sentence , the text of the entity , and its type .",Supplement,Document,Produce,SemEval-2013 Task 9 : Extraction of Drug-Drug Interactions from Biomedical Texts (DDIExtraction 2013),https://e-archivo.uc3m.es/handle/10016/20455
"[ foot ] 9 [ foot ] http :// trac . loria . fr /- semconst More information about the requirements and installation procedure is available at http :// trac . loria . fr /- semtag . Note that this toolbox is made of two main components : the GenI [ foot ] 8 [ foot ] system and the SemConst [ foot ] 9 [ foot ] system , which respectively performs generation and parsing from common linguistic resources . The first is written in Haskell ( except the XMG part written in Oz ) and is multi - platform ( Linux , Windows , Mac OS ).",Supplement,Document,Produce,"SemTAG, the LORIA toolbox for TAG-based Parsing and Generation",https://inria.hal.science/inria-00083555/
"The final filtered version of hrWaC contains 51M sentences and 1 . 2B tokens . The corpus is freely available for download , along with a more detailed description of the preprocessing steps . Tagging , lemmatization , and parsing . For morphosyntactic ( MSD ) tagging , lemmatization , and dependency parsing of hrWaC , we use freely available tools with models trained on the new SETimes Corpus of Croatian ( SETIMES . HR ), based on the Croatian part of the SETimes parallel corpus . SETIMES . HR and the derived tools are prototypes racy that are about to be released as parts of another work .",Supplement,Document,Produce,Lemmatization and Morphosyntactic Tagging of Croatian and Serbian,https://aclanthology.org/W13-2408.pdf
"Given six datasets in Catalan , Dutch , English , German , Italian , and Spanish , the task we present involved automatically detecting full coreference chains — composed of named entities ( NEs ), pronouns , and full noun phrases — in four different scenarios . For more information , the reader is referred to the task website . The rest of the paper is organized as follows . Section 2 presents the corpora from which the task datasets were extracted , and the automatic tools used to preprocess them . In Section 3 , we describe the task by providing information about the data format , evaluation settings , and evaluation metrics .",Supplement,Document,Produce,SemEval-2010 Task 1: Coreference Resolution in Multiple Languages,https://aclanthology.org/S10-1001.pdf
"For instance , one can search for verbs which have their subject in the partitive case , unless that subject has a numeral modifier , and unless the verb is governed by the clausal complement relation . In addition to the constraints on the syntactic structure , any combination of normal and negated constraints on the morphology of the words is possible . The full description of the query system capabilities is , however , out of scope of this paper , and we refer the interested reader to the online documentation . In addition to a scriptable , command - line utility meant for gathering data for further processing , the query system also has an online interface which allows the results to be visualized and inspected in real time ( Figure 3 ). In Section 5 we will demonstrate several real use - cases where this query system was used to obtain material for linguistic research from the parsebank .",Supplement,Document,Produce,Towards Universal Web Parsebanks,https://aclanthology.org/W15-2124.pdf
"the United Nations is referred to as FN ). The major Danish political parties were also added to this gazetteer . For person names , we build lists of both notable people , and also populated GATE ’ s first and last name lists with common choices in Denmark . We include temporal annotation for Danish in this pipeline , making DKIE the first temporal annotation tool for Danish . We follow the TimeML temporal annotation standard ( Pustejovsky et al ., 2004 ), completing just the TIMEX3 part .",Supplement,Document,Produce,DKIE: Open Source Information Extraction for Danish,https://aclanthology.org/E14-2016.pdf
"Our parser consistently outperforms the Turbo and MST parsers across 14 different languages . We also obtain the best published UAS results on 5 languages . Finding an expressive representation of input sentences is crucial for accurate parsing . Syntactic relations manifest themselves in a broad range of surface indicators , ranging from morphological to lexical , including positional and part - of - speech ( POS ) tagging features . Traditionally , parsing research has focused on modeling the direct connection between the features and the predicted syntactic relations such as head - modifier ( arc ) relations in dependency parsing .",Supplement,Document,Produce,Low-Rank Tensors for Scoring Dependency Structures,https://aclanthology.org/P14-1130.pdf
"We have performed some preliminary evaluations of semantic precision using unsupervised AQBC , and we have found it to work very well for retrieving semantic neighbors for extremely high - dimensional sparse data ( like the 20 Newsgroups dataset ), while ITQ currently works better for lower - dimensional , denser data . In the future , we plan to investigate how to improve the semantic precision of AQBC using either unsupervised or supervised learning . Additional resources and code are available at Acknowledgments . We thank Henry A . Rowley and Ruiqi Guo for helpful discussions , and the reviewers for helpful suggestions . Gong and Lazebnik were supported in part by NSF grants IIS 0916829 and IIS 1228082 , and the DARPA Computer Science Study Group ( D12AP00305 ).",Supplement,Document,Produce,Angular Quantization-based Binary Codes for Fast Similarity Search,https://proceedings.neurips.cc/paper/2012/hash/f5deaeeae1538fb6c45901d524ee2f98-Abstract.html
"prediction appearing in computational biology , where our method obtains less than a half of the error rate of the best competing HMM - based method . Our predictions are available at Wormbase : Additional data and results are available at the project ’ s website http :// www . fml . mpg . de / raetsch / projects / msplicer . Acknowledgments We thank K .- R . M ¨ uller , B . Sch ¨ olkopf , E . Georgii , A . Zien , G . Schweikert and G . Zeller for inspiring discussions .",Supplement,Document,Produce,Large Scale Hidden Semi-Markov SVMs,https://proceedings.neurips.cc/paper/2006/hash/faa453efde4ac6a36849ba381feb9e87-Abstract.html
"We now present empirical results on byte - prediction tasks and partially - observable RL . Our code and instructions for its use is publicly available at : Byte Prediction We compare the performance of D2 - CTW against CTW on the 18 - file variant of the Calgary Corpus [ 3 ], a benchmark of text and binary data files . For each file , we ask the algorithms to predict the next byte given the preceding data , such that | E |= 256 across all files .",Supplement,Document,Produce,"Reinforcement learning (RL) in partially observable settings is challenging because the agent’s observations are not Markov. Recently proposed methods can learn variable-order Markov models of the underlying process but have steep memory requirements and are sensitive to aliasing between observation histories due to sensor noise. This paper proposes dynamic-depth context tree weighting (D2-CTW), a model-learning method that addresses these limitations. D2-CTW dynamically expands a suffix tree while ensuring that the size of the model, but not its depth, remains bounded. We show that D2-CTW approximately matches the performance of state-of-the-art alternatives at stochastic time-series prediction while using at least an order of magnitude less memory. We also apply D2-CTW to model-based RL, showing that, on tasks that require memory of past observations, D2-CTW can learn without prior knowledge of a good state representation, or even the length of history upon which such a representation should depend.",https://proceedings.neurips.cc/paper/2017/hash/c366c2c97d47b02b24c3ecade4c40a01-Abstract.html
"Principal component analysis ( PCA ) [ 1 , 5 ] seeks the best ( in an ` 2 - sense ) such low - rank representation of the given data matrix . It enjoys a number of optimality properties when the data are only mildly corrupted by small noise , and can be stably and efficiently computed via the singular value decomposition . ∗ For more information , see This work was partially supported by NSF IIS 08 - 49292 , NSF ECCS 07 - 01676 , and ONR N00014 - 09 - 1 - 0230 . One major shortcoming of classical PCA is its brittleness with respect to grossly corrupted or outlying observations [ 5 ].",Supplement,Document,Produce,Parsing façade with rank-one approximation,https://ieeexplore.ieee.org/abstract/document/6247867
"We want to design our experiment — choose p ( x ) — optimally in some sense . One natural idea would be to choose p ( x ) in such a way that we learn as much as possible about the underlying model , on average . Information theory thus suggests we choose p ( x ) to optimize the * A longer version of this paper , including proofs , has been submitted and is available at following objective function :",Supplement,Document,Produce,Asymptotic Theory of Information-Theoretic Experimental Design,https://ieeexplore.ieee.org/abstract/document/6788301
We chose the hyperparameter settings that produced the highest quality images . We note that we found no correlation between the activation of a neuron and the recognizability of its visualization . Our code and parameters are available at _CITE_,Supplement,Document,Produce,Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,https://proceedings.neurips.cc/paper/2016/hash/5d79099fcdf499f12b79770834c0164a-Abstract.html
"This tool has applications in conditional and discriminative learning for latent variable models . For further results , extensions , etc . see : Hebaraibounds .",Supplement,Document,Produce,On Reversing Jensen's Inequality,https://proceedings.neurips.cc/paper/2000/hash/44a2e0804995faf8d2e3b084a1e2db1d-Abstract.html
"Similar ideas have seen application in a wide and somewhat scattered literature ; for a partial bibliography , see the longer draft of this paper at Somewhat surprisingly , we have not seen any applications of the information - theoretic objective function ( 1 ) to the design of neurophysiological experiments ( although see the abstract by [ 7 ], who seem to have independently implemented the same idea in a simulation study ). The primary goal of this paper is to elucidate the asymptotic behavior of the a posteriori density pN () when we choose x according to the recipe outlined above ; in particular , we want to compare the adaptive strategy to the more usual case , in which the stimuli are drawn i . i . d .",Supplement,Document,Produce,Design of Experiments via Information Theory,https://proceedings.neurips.cc/paper/2003/hash/5e6bd7a6970cd4325e587f02667f7f73-Abstract.html
"The posterior distribution of all model parameters has been computed using Gibbs sampling ; the detailed update equations are provided as supplemental material at The first 1000 Gibbs iterations were discarded as burn - in followed by 500 collection iterations . The truncation levels on the model are T = 20 , M = 10 , K = 30 , and the number of words in the vocabulary is V = 5249 . Hyperparameters were set as a = b = e = f = 10 − 6 , c = d = 1 , g = 103 , and h = 10 − 3 .",Supplement,Document,Produce,oint Analysis of Time-Evolving Binary Matrices and Associated Documents,https://proceedings.neurips.cc/paper/2010/hash/41ae36ecb9b3eee609d05b90c14222fb-Abstract.html
"where ✶ P ,,,,,, denotes Kronecker ’ s delta , and where we have used independence of δP , δ ,,,,,, and g . We refer the reader to for an illustration of the model . This generative model draws model discrepancies δ ` independently across IS . This is appropriate when IS are different in kind and share no relationship except that they model a common objective .",Supplement,Document,Produce,Multi-Information Source Optimization,https://proceedings.neurips.cc/paper/2017/hash/df1f1d20ee86704251795841e6a9405a-Abstract.html
"Once a suitable 0 is found , the correction step is taken and ( wc , zc ) becomes the new ( w , z ). The method is guaranteed to converge linearly to a solution w *, z * [ 11 , 9 ]. See the longer version of this paper at for details . By comparison , Exponentiated Gradient [ 4 ] has sublinear convergence rate guarantees , while Structured SMO [ 18 ] has none . The key step influencing the efficiency of the algorithm is the Euclidean projection onto the feasible sets W and Zi .",Supplement,Document,Produce,Structured Prediction via the Extragradient Method,https://proceedings.neurips.cc/paper/2005/hash/e465ae46b07058f4ab5e96b98f101756-Abstract.html
"In this section , we briefly outline the PF algorithm for generating samples from p ( dyi , t101 : t ). ( For details , please refer to our extended technical report at Assume that at time t - 1 we have N particles { y11_1 } 1 ' 11 distributed according to P ( dyi , t_1101 : t — i ) from which one can get the following empirical distribution approximation",Supplement,Document,Produce,Rao-Blackwellised Particle Filtering Data Augmentation,https://proceedings.neurips.cc/paper/2001/file/6f4920ea25403ec77bee9efce43ea25e-Paper.pdf
"Some other directions currently under investigation include ( i ) the use of Gaussian processes for classification problems by softmaxing the outputs of k regression surfaces ( for a k - class classification problem ), ( ii ) using non - stationary covariance functions , so that C ( x , x ') # C ( 1 x x ' I ) and ( iii ) using a covariance function containing a sum of two or more terms of the form given in line 1 of equation 3 . We hope to make our code for Gaussian process prediction publically available in the near future . Check for details .",Supplement,Document,Produce,Gaussian Processes for Regression,https://proceedings.neurips.cc/paper/1995/hash/7cce53cf90577442771720a370c3c723-Abstract.html
Availability . A web interface for AUTOBAYES is currently under development . More information is available at _CITE_,Supplement,Document,Produce,Automatic Derivation of Statistical Algorithms: The EM Family and Beyond,https://proceedings.neurips.cc/paper/2002/hash/0234c510bc6d908b28c70ff313743079-Abstract.html
"There are 2040 instances of flowers for training and 6149 for testing , mainly acquired from the web , with varying scales , resolutions , etc ., which are labeled into 102 categories . In [ 21 ], four relevant features are identified : Color , histogram of gradient orientations and the scale invariant feature transform , sampled on both the foreground region and its boundary . More information is available at For this type of dataset , state of the art performance has been achieved using a weighted linear combination of kernels ( one per feature ) in a support vector machine ( SVM ) classifier . A different set of weights is learned for each class .",Supplement,Document,Produce,Spike and Slab Variational Inference for Multi-Task and Multiple Kernel Learning,https://proceedings.neurips.cc/paper/2011/hash/b495ce63ede0f4efc9eec62cb947c162-Abstract.html
"( for adaptation to Huber hinge loss ) is provided as a supplementary material , and is also available on Whenever possible , we used warmstart approach , i . e ., when we trained a new solution , we used the closest solutions trained so far ( either approximate or optimal ones ) as the initial starting point of the optimizer . All the computations were conducted by using a single core of an HP workstation Z800 ( Xeon ( R ) CPU X5675 ( 3 . 07GHz ), 48GB MEM ).",Supplement,Document,Produce,Regularization Path of Cross-Validation Error Lower Bounds,https://proceedings.neurips.cc/paper/2015/hash/82b8a3434904411a9fdc43ca87cee70c-Abstract.html
"They lead to improved semi - supervised learning peformance and improved sample generation . We hope that some of them may form the basis for future work , providing formal guarantees of convergence . All code and hyperparameters may be found at _CITE_",Supplement,Document,Produce,Improved Techniques for Training GANs,https://proceedings.neurips.cc/paper/2016/hash/8a3363abe792db2d8761d6403605aeb7-Abstract.html
"The retraction mechanism is implemented by 3 resonators ( , Hz ) which connect the collision sensors ( CS ) to the neurons ( speed ) and ( steering angle ) with fixed weights ( reflex ). Each range finder ( RF ) is fed into a filter bank of 10 resonators with Hz where its output converges with variable weights on both the and - neuron . A more detailed technical description together with a set of movies can be found at : – movie 1 . ( b , d ) Parts of the motion trajectory for one trial in an arena of with three obstacles ( shaded ). Circles denote collisions .",Supplement,Document,Produce,Learning a Forward Model of a Reflex,https://proceedings.neurips.cc/paper/2002/hash/10907813b97e249163587e6246612e21-Abstract.html
"In this paper , we will try to shed more light on this topic . The motivation is twofold . First , the policy oscillation phenomenon is intimately connected to some aspects of the learning dynamics at the very heart of approximate dynamic An extended version of this paper is available at programming ; the lack of understanding in the former implies a lack of understanding in the latter . In the long run , this state might well be holding back important theoretical developments in the field .",Supplement,Document,Produce,Policy oscillation is overshooting,https://www.sciencedirect.com/science/article/abs/pii/S0893608014000033
The Inception score is used for assessing generations from GANs and is more appropriate for our scenario that traditional metrics such as PSNR or SSIM ( see appendix B for further discussion ). The curves show the mean scores of our generations decaying more gracefully than MCNet [ 33 ]. Further examples and generated movies may be viewed in appendix A and also at A natural concern with high capacity models is that they might be memorizing the training examples . We probe this in Fig .,Supplement,Document,Produce,Unsupervised Learning of Disentangled Representations from Video,https://proceedings.neurips.cc/paper/2017/hash/2d2ca7eedf739ef4c3800713ec482e1a-Abstract.html
"A learning algorithm could potentially learn a non - efficient code , for instance , but nonetheless describe the establishment of receptive fields seen in adult animals . Details of the algorithms , parameters , and fitting methods can be found in the supplementary information . Results from our grid searches are available at .",Supplement,Document,Produce,Unsupervised learning models of primary cortical receptive fields and receptive field plasticity,https://proceedings.neurips.cc/paper/2011/hash/e19347e1c3ca0c0b97de5fb3b690855a-Abstract.html
"The optimal firing rate response curve ( dotted line ) is asymptotically proportional to the cumulative probability distribution of inputs . The inset illustrates the typical timecourse of the dendritic voltage in the trained model . relationship at the soma , can be predicted from the theory of dynamical systems ( see for details ). The voltage and the conductances are nonlinearly coupled : the conductances affect the voltage , which , in turn , sets the conductances . Since the mutual information is a global property of the stimulus set , the learning rule for any one conductance would depend on the values of all other conductances , were it not for the nonlinear feedback loop between voltages and conductances .",Supplement,Document,Produce,Information Maximization in Single Neurons,https://proceedings.neurips.cc/paper/1998/hash/452bf208bf901322968557227b8f6efe-Abstract.html
"The heuristic computes the error for a given validation image at level k in the pyramid as Lk ( Ik ) = min { z ;}|| Gk ( zj , u ( Ik + 1 )) − hk || 2 where { zj } is a large set of noise vectors , drawn from pnozse ( z ). In other words , the heuristic is asking , are any of the generated residual images close to the ground truth ? Torch training and evaluation code , along with model specification files can be found at For all models , the noise vector zk is drawn from a uniform [- 1 , 1 ] distribution .",Supplement,Document,Produce,Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks Part of Advances in Neural Information Processing Systems 28 (NIPS 2015),https://proceedings.neurips.cc/paper/2015/hash/aa169b49b583a2b5af89203c2b78c67c-Abstract.html
"When the network is updated according to ( 1 ), then under certain conditions the network state becomes asymptotically independent of initial conditions . More precisely , if the network is started from two arbitrary states x ( 0 ), 31 ( 0 ) and is run with the same input sequence in both cases , the resulting state sequences x ( n ), x ( n ) converge to each other . If this condition holds , the reservoir network state will asymptotically depend only on the input history , and the network tained in a tutorial Mathematica notebook which can be fetched from is said to be an echo state network ( ESN ). A sufficient condition for the echo state property is contractivity of W . In practice it was found that a weaker condition suffices , namely , to ensure that the spectral radius Amax of W is less than unity .",Supplement,Document,Produce,Adaptive Nonlinear System Identification with Echo State Networks,https://proceedings.neurips.cc/paper/2002/hash/426f990b332ef8193a61cc90516c1245-Abstract.html
"For S2 , the difference between the treewidth seems negligible from the figure . This is due to the fact that the graph learned are actually sparse . Further experimental documentation is available , including how the score achieved by the algorithms evolve with time , are available from _CITE_",Supplement,Document,Produce,Learning Treewidth-Bounded Bayesian Networks with Thousands of Variables,https://proceedings.neurips.cc/paper/2016/hash/e2a2dcc36a08a345332c751b2f2e476c-Abstract.html
"When working with fully - connected models we use stochastic GRU - style state updates rather than the stochastic residual updates in Eq . 7 . Exhaustive descriptions of the modules can be found in our code at : These TD modules represent each conditional p ( zi | zi − 1 , ..., z0 ) in Eq . 1 using p ( zi | hti ).",Supplement,Document,Produce,"An Architecture for Deep, Hierarchical Generative Models - arXiv",https://arxiv.org/pdf/1612.04739.pdf
"where ( 2 ) approaches zero for an optimum result . Indeed , the main assumption in the original HA is that the R (`), B = 1 : S are noisy ‘ rotations ’ of a common template [ 1 , 9 ]. This paper provides a detailed description of HA methods in the supplementary materials ( ).",Supplement,Document,Produce,Deep Hyperalignment,https://www.researchgate.net/publication/320344387_Deep_Hyperalignment
"Through evolution , structure is more conserved than sequence , so that detecting even very subtle sequence similarities , or remote homology , is important for predicting function . The major methods for homology detection can be split into three basic groups : pairwise sequence comparison algorithms [ 1 , 2 ], generative models for protein families [ 3 , 4 ], and discriminative classifiers [ 5 , 6 , 7 ]. Popular sequence comparison methods such as BLAST * Supplemental information for the paper , including the data sets and Matlab source code can be found on this author ’ s web page at and Smith - Waterman are based on unsupervised alignment scores . Generative models such as profile hidden Markov models ( HMMs ) model positive examples of a protein family , but they can be trained iteratively using both positively labeled and unlabeled examples by pulling in close homologs and adding them to the positive set . A compromise between these methods is PSI - BLAST [ 8 ], which uses BLAST to iteratively build a probabilistic profile of a query sequence and obtain a more sensitive sequence comparison score .",Supplement,Document,Produce,Semi-supervised Protein Classification Using Cluster Kernels,https://proceedings.neurips.cc/paper/2003/hash/12ffb0968f2f56e51a59a6beb37b2859-Abstract.html
"Section 7 concludes the paper . Due to space limit , we omit all detailed proofs . A complete version of this work is available at _CITE_",Supplement,Document,Produce,Probability Estimates for Multi-Class Classification by Pairwise Coupling,https://proceedings.neurips.cc/paper/2003/hash/03e7ef47cee6fa4ae7567394b99912b7-Abstract.html
Experimental results and a discussion conclude the paper . Some proofs have been omitted due to space constraints . They can be found in an extended version of this paper ( available at_CITE_ ).,Supplement,Document,Produce,Kernel Machines and Boolean Functions,https://proceedings.neurips.cc/paper/2001/hash/d77f00766fd3be3f2189c843a6af3fb2-Abstract.html
"One would hope that extra structure should allow us to obtain more statistically efficient solutions . In this work , we focus on the case of bandable precision matrices , which capture ∗ Addison graduated from Yale in May 2017 . Up - to - date contact information may be found at _CITE_",Supplement,Document,Produce,Minimax Estimation of Bandable Precision Matrices,https://proceedings.neurips.cc/paper/2017/hash/070dbb6024b5ef93784428afc71f2146-Abstract.html
"Specifically , the translation that required adding more details to the image was usually harder ( e . g . night to day ). Additional results are available in Synthetic to real . In Figure 3 , we showed several example results achieved by applying the proposed framework to translate images between the synthetic images in the SYNTHIA dataset [ 23 ] and the real images in the Cityscape dataset [ 2 ].",Supplement,Document,Produce,Unsupervised Image-to-Image Translation Networks,https://proceedings.neurips.cc/paper_files/paper/2017/hash/dc6a6489640ca02b0d42dabeb8e46bb7-Abstract.html
"For the eigenspace representation , each target image region is resized to 32 × 32 patch , and the number of eigenvectors used in all experiments is set to 16 though fewer eigenvectors may also work well . Implemented in MATLAB with MEX , our algorithm runs at 4 frames per second on a standard computer with 200 particles . We present some tracking results in this section and more tracking results as well as videos can be found at _CITE_",Supplement,Document,Produce,Incremental Learning for Visual Tracking,https://proceedings.neurips.cc/paper/2004/hash/f21e255f89e0f258accbe4e984eef486-Abstract.html
"We also find that a low rank version is able to achieve approximately 23 × compression of the original data , with the optimal solution very close to the full rank optimum . Our method is a superior predictor to the existing regional model for visual system data , and the success of the low rank version suggests that this approach will be able to reveal whole - brain structural connectivity at unprecedented scale . All of our supplemental material and data processing and optimization code is available for download from : _CITE_",Supplement,Document,Produce,High resolution neural connectivity from incomplete tracing data using nonnegative spline regression,https://proceedings.neurips.cc/paper/2016/hash/f337d999d9ad116a7b4f3d409fcc6480-Abstract.html
"It is , therefore , interesting to see how the minimum degree of rate fluctuation depends on the non - Poissonian feature of spike trains . In this study , we investigate the extent to which the non - Poissonian feature of spike trains affects the encoding efficiency of rate fluctuations . In addition , we address the question of how the de ∗ tectability of rate fluctuations depends on the encoding efficiency . For this purpose , we introduce the Kullback - Leibler ( KL ) divergence to measure the encoding efficiency , and assume that spike sequences are generated by time - rescaled renewal processes . With the aid of analytical and numerical studies , we suggest that the lower bound of detectable rate fluctuations , below which the empirical Bayes decoder cannot detect the rate fluctuations , is uniquely determined by the KL divergence .",Supplement,Document,Produce,Coding efficiency and detectability of rate fluctuations with non-Poisson neuronal firing,https://proceedings.neurips.cc/paper_files/paper/2012/file/5fd0b37cd7dbbb00f97ba6ce92bf5add-Paper.pdf
"The system is scaleable to very large problems with very large weight arrays . Current research is aimed at showing that the system is scaleable , evaluating methods for the acceleration of the pre - and post processing tasks and considering greater integration of the elements of the processor through VLSI . For more details of the AURA project and the hardware described in this paper see _CITE_",Supplement,Document,Produce,A High Performance k-NN Classifier Using a Binary Correlation Matrix Memory,https://proceedings.neurips.cc/paper/1998/hash/fa1e9c965314ccd7810fb5ea838303e5-Abstract.html
"In future , it would be interesting to see how the proposed approach scales with more complex environments , diverse object collections , different manipulation skills and to other non - manipulation based tasks , such as navigation . Other directions for future investigation include the use of forward model for planning and developing better strategies for data collection than random interaction . Supplementary Materials : and videos can be found at Acknowledgement : We thank Alyosha Efros for inspiration and fruitful discussions throughout this work . The title of this paper is partly influenced by the term “ pokebot & quot ; that Alyosha has been using for several years .",Supplement,Document,Produce,Learning to Poke by Poking: Experiential Learning of Intuitive Physics,https://proceedings.neurips.cc/paper/2016/hash/c203d8a151612acf12457e4d67635a95-Abstract.html
"Qualitative Evaluation : Prediction video . The prediction videos of our models and baselines are available in the supplementary material and at the following website : Asseeninthe videos , the proposed models make qualitatively reasonable predictions over 30 – 500 steps depending on the game . In all games , the MLP baseline quickly diverges , and the naFf baseline fails to predict the controlled object .",Supplement,Document,Produce,Action-Conditional Video Prediction using Deep Networks in Atari Games,https://ar5iv.labs.arxiv.org/html/1507.08750
"We used a soft - max operation with an increasing temperature parameter to model the non - differentiable color channel selection at each point , which allowed us to train the pattern effectively . Finally , we demonstrated that our learned pattern enabled better reconstructions than past designs . An implementation of our method , along with trained models , data , and results , is available at our project page at Our results suggest that learning measurement strategies jointly with computational inference is both useful and possible . In particular , our approach can be used directly to learn other forms of optimized multiplexing patterns — e . g ., spatio - temporal multiplexing for video , viewpoint multiplexing in lightfield cameras , etc .",Supplement,Document,Produce,Learning Sensor Multiplexing Design through Back-propagation,https://arxiv.org/pdf/1605.07078.pdf
"The above joint analysis of text and votes was restricted to 1989 - 2008 , since the documents ( legislation ) were only available for those years . However , the dataset contains votes on all legislation from 1789 to the present , and we now analyze the vote data from 1789 - 1988 . Figure 5 shows snapshots in time of the latent space for voters and legislation , for the House of Representatives ( similar results have been computed for the Senate , and are omitted for brevity ; as supplemental material , at we present movies of how legislation and congressman evolve across all times , for both the House and Senate ). Five features were inferred , with the two highest - variance features chosen for the axes . The blue symbols denote Democratic legislators , or legislation sponsored by a Democrat , and the red points correspond to Republicans .",Supplement,Document,Produce,Joint Analysis of Time-Evolving Binary Matrices and Associated Documents,https://proceedings.neurips.cc/paper/2010/hash/41ae36ecb9b3eee609d05b90c14222fb-Abstract.html
"Outputs of the program , taking the form of posterior samples , are indicated by the return values . There is a finite set of sample and observe statements in a program source code , but the number of times each statement is called can vary between executions . We refer the reader to for more details .",Supplement,Document,Produce,Bayesian Optimization for Probabilistic Programs,https://proceedings.neurips.cc/paper/2016/hash/31fefc0e570cb3860f2a6d4b38c6490d-Abstract.html
"( iv ) Furthermore , with Precision - Recall - Gain curves it is possible to calibrate a model for Fp in the sense that the predicted score for any instance determines the value of p for which the instance is on the Fp decision boundary . ( v ) We give experimental evidence in Section 4 that this matters by demonstrating that the area under traditional Precision - Recall curves can easily favour models with lower expected F1 score than others . Proofs of the formal results are found in the Supplementary Material ; see also _CITE_",Supplement,Document,Produce,Precision-Recall-Gain Curves: PR Analysis Done Right,https://proceedings.neurips.cc/paper/2015/hash/33e8075e9970de0cfea955afd4644bb2-Abstract.html
"Kernel ridge regression was used to estimate the values of a *, k *, l * as to minimize Equation 12 for different user - specified LMA - Effort vectors ¯ e . The recovered parameter values were used to synthesize animations with the specified desired styles . Videos of these automatically generated motions as well as additional results can be viewed at . In order to test the generalization ability of our system , the target styles in this experiment were chosen to be considerably different from those in the training set . All of the synthesized sequences were visually inspected by LMA experts and , for the great majority , they were found to be consistent with the style target labels .",Supplement,Document,Produce,Learning Motion Style Synthesis from Perceptual Observations,https://proceedings.neurips.cc/paper/2006/hash/d4a897919a124958e699170b2b1dc8f2-Abstract.html
a squashing function ( exponential of the Digamma function ) before being normalized . We refer the reader to the original paper for more detail ( see also Publications . htm for a bug fix in the Digamma function implementation ).,Supplement,Document,Produce,Posterior vs Parameter Sparsity in Latent Variable Models,https://proceedings.neurips.cc/paper/2009/hash/8f1d43620bc6bb580df6e80b0dc05c48-Abstract.html
"Graph - based methods are amongst the most popular and aim to construct a graph connecting similar observations ; label information propagates through the graph from labelled to unlabelled nodes by finding the minimum energy ( MAP ) configuration ( Blum et al ., 2004 ; Zhu et al ., 2003 ). Graph - based approaches are sensitive to the graph structure and require eigen - analysis of the graph Laplacian , which limits the scale to which these methods can be applied – though efficient spectral methods are now available ( Fergus et al ., 2009 ). Neural network - based approaches combine unsupervised and supervised learning For an updated version of this paper , please see by training feed - forward classifiers with an additional penalty from an auto - encoder or other unsupervised embedding of the data ( Ranzato and Szummer , 2008 ; Weston et al ., 2012 ). The Manifold Tangent Classifier ( MTC ) ( Rifai et al ., 2011 ) trains contrastive auto - encoders ( CAEs ) to learn the manifold on which the data lies , followed by an instance of TangentProp to train a classifier that is approximately invariant to local perturbations along the manifold . The idea of manifold learning using graph - based methods has most recently been combined with kernel ( SVM ) methods in the Atlas RBF model ( Pitelis et al ., 2014 ) and provides amongst most competitive performance currently available .",Supplement,Document,Produce,Semi-supervised Learning with Deep Generative Models,https://proceedings.neurips.cc/paper/2014/hash/d523773c6b194f37b938d340d5d02232-Abstract.html
"Despite its limited size , through user study we show our algorithm is realizable in practice on high DoF manipulators . We hope this motivates researchers to build robotic systems capable of learning from non - expert users . For more details and video , please visit : _CITE_",Supplement,Document,Produce,Learning Trajectory Preferences for Manipulators via Iterative Improvement,https://proceedings.neurips.cc/paper/2013/hash/c058f544c737782deacefa532d9add4c-Abstract.html
"Together with the peak conductance values , the midpoint voltages VI and slopes s of these Boltzmann functions adapt to the statistics of stimuli . For simplicity , all time constants for the dendritic conductances are set to a constant 5 msec . For additional details and parameter values , see Hodgkin - Huxley models can exhibit complex behaviors on several timescales , such as firing patterns consisting of & quot ; bursts & quot ;— sequences of multiple spikes interspersed with periods of silence . We will , however , focus on models of regularly spiking cells that adapt to a sustained stimulus by spiking periodically .",Supplement,Document,Produce,Information Maximization in Single Neurons,https://proceedings.neurips.cc/paper/1998/hash/452bf208bf901322968557227b8f6efe-Abstract.html
"Due to space limitations , we omit proofs from this version of the paper . Complete proofs may be found in the extended version , which is available on the author ’ s Web page ( ). To prove ( a ), we show that when the search is at a node v whose least common ancestor with the target has height h , there is a high probability that v has a link into the sub - tree of height h − 1 containing the target . In this way , the search reaches the target in logarithmically many steps .",Supplement,Document,Produce,Small-World Phenomena and the Dynamics of Information,https://proceedings.neurips.cc/paper/2001/hash/52dbb0686f8bd0c0c757acf716e28ec0-Abstract.html
"This material includes the treatment of two additional problems : the NP - complete Maximum Cut Problem [ 11 ] and an NP - complete problem known as the multiprocessor document allocation problem ( MDAP ). Also in the full version of this paper is a substantially more thorough exposition of the material presented here . The reader is encouraged to refer to [ 10 ], available on the World Wide Web at , juelsi .",Supplement,Document,Produce,Stochastic Hillclimbing as a Baseline Method for Evaluating Genetic Algorithms,https://proceedings.neurips.cc/paper/1995/hash/36a1694bce9815b7e38a9dad05ad42e0-Abstract.html
"In this case , convergence with probability one ( w . p . 1 ) to a local optimum can be established for arbitrary differentiable policy classes under mild assumptions [ 22 , 13 , 19 ]. On the other hand , while the greedy value function approach is often considered to possess practical advantages in terms of convergence speed and representational flexibility , its behavior in the proximity of an optimum is currently not well understood . It is well known that interactively operated approximate hard - greedy An extended version of this paper with full proofs and additional background material is available at and http :// users . ics . aalto . fi / pwagner /. value function methods can fail to converge to any single policy and instead become trapped in sustained policy oscillation or policy chattering , which is currently a poorly understood phenomenon [ 6 , 7 ]. This applies to both non - optimistic and optimistic policy iteration ( value iteration being a special case of the latter ).",Supplement,Document,Produce,Optimistic policy iteration and natural actor-critic: A unifying view and a non-optimality result,https://proceedings.neurips.cc/paper/2013/hash/2dace78f80bc92e6d7493423d729448e-Abstract.html
"For the purposes of the example , the text to be processed is given inline . Our current implementation includes results from each step in a pipeline , where applicable , together with metadata describing the service applied in each step ( here , org . anc . lapps . stanford . SATokenizer : 1 . 4 . 0 ) and identified by an internally - defined type ( stanford ). The annotations include references to the objects defined in the WS - EV , in this example , Token ( defined at ) with ( inherited ) features id , start , end and specific feature string , defined at http :// vocab . lappsgrid . org / Token # id , http :// vocab . lappsgrid . org / Token # start , http :// vocab . lappsgrid . org / Token # end , and http :// vocab . lappsgrid . orgToken /# string , respectively . The web page defining these terms is shown in Figure 3 .",Supplement,Document,Use,The Language Application Grid Web Service Exchange Vocabulary,https://link.springer.com/chapter/10.1007/978-3-319-31468-6_2
"We use the data that were recorded and preprocessed by Mitchell et al . ( 2008 ), available for download in their supporting online material . Full details of the experimental protocol , data acquisition and preprocessing can be found in Mitchell et al . ( 2008 ) and the supporting material . Key points are that there were nine right - handed adult participants ( 5 female , age between 18 and 32 ).",Supplement,Document,Use,"Of words, eyes and brains: Correlating image-based distributional semantic models with neural representations of concepts",https://aclanthology.org/D13-1202.pdf
"We create a graph from a dictionary in the following way . The entries constituted the vertices . Edges between two vertices A and B were added if and only if B appears in A ’ s lemmatized definition as illustrated in Figure 4 . 1 We proceed in this way for each entry and obtained a graph of the dictionary . By extracting the subgraph composed only of verbs , the ’ neighborhood ’ we get for the verb ’ écorcer ’ is illustrated by Figure 4 . 1 . Then we render the graph symmetric and reflexive .",Supplement,Document,Use,"Toward a cognitive organization for electronic dictionaries, the case for semantic proxemy",https://hal.science/hal-00368888/
"In practice , it is no slower than running token - role filtering on its own . We extract dependency structures from the Penn Treebank using the head rules of Yamada and Matsumoto ( 2003 ). We divide the Treebank into train ( sections 2 – 21 ), development ( 22 ) and test ( 23 ). We part - of - speech tag our data using a perceptron tagger similar to the one described by Collins ( 2002 ). The training set is tagged with jack - knifing : the data is split into 10 folds and each fold is tagged by a system trained on the other 9 folds .",Supplement,Document,Use,Joint Training of Dependency Parsing Filters through Latent Support Vector Machines,https://aclanthology.org/P11-2035.pdf
"The examples are out of domain , so the language model doesn ’ t help us at all . So let ’ s try an in - domain example of newswire text . The following is almost the first text I found by searching Arabic Web pages for the Arabic for “ Google Machine Translation ,” simply because I had already read the English reference document , and I was pretty sure it would be out there somewhere . It is a human - authored Arabic translation of a recent Reuters story about the launching of Google Language Tools , taken from Al Jazeera : Here is the SMT translation , delivered in about the time it would take a native speaker to read the original : The German Franz Ouch which leads efforts Google translation computer feeds hundreds of millions of words of parallel texts such as Arabic , English , using documents of the United Nations and the European Union key sources . And how a new translation Ouch said that although the quality would not be complete That was a good in the previous translation mechanism , and that the correct translation mostly might be good enough for some tasks .",Supplement,Document,Use,Last words: On Becoming a Discipline,https://aclanthology.org/J08-1008.pdf
"2 , where the solid line represents training process and the dotted line represents testing process . The Korean analyzer at the center of the figure takes Korean texts as an input and generates several raw features as an output , such as results of morphological analysis , Part - Of - Speech ( POS ) tags , Named - Entity ( NE ) tags , and results of dependency parsing ( Lim et al ., 2006 ). The number of possible POS tags is 45 , which follows the definition of Sejong Treebank . The number of possible NE tags is 178 , where each of them belongs to one of 15 super NE tags . The generated raw features are used to define a set of features for machine - learning models and a set of hand - crafted rules .",Supplement,Document,Use,Temporal Information Extraction from Korean Texts,https://aclanthology.org/K15-1028.pdf
"The main difficulty encountered related to the distinction required between proper and common nouns , the morphological boundary between the two being unclear in those fields where common nouns are often reclassified as “ proper nouns ”, as is demonstrated by the presence of these names ( Tanabe et al ., 2005 ) notes that “ a more detailed definition of a gene / protein name , as well as additional annotation rules , could improve inter - annotator agreement and help solve some of the tagging inconsistencies ”. in nomenclatures ( small , acid - soluble spore protein A is an extreme case ) or acronymisation phenomena ( one finds for example across the outer membrane ( OM )). In those cases , annotators were instructed to refer to official lists , such as SwissProt , which requires a significant amount of time . Delimiting the boundaries of the elements to be annotated also raised many questions . One can thus choose to annotate nifh messenger RNA if it is considered that the mention of the state messenger RNA is part of the determination of the reference , or only nifh , if it is considered that the proper noun is enough to build the determination .",Supplement,Document,Use,Towards a Methodology for Named Entities Annotation,https://hal.science/hal-00402453v1/document
"In ( 8 ), both a literal ( triggered by “ arriving in ”) and a place - for - people reading ( triggered by “ leading critic ”) are invoked . We introduced the category mixed to deal with these cases . Using Gsearch ( Corley et al ., 2001 ), we randomly extracted 1000 occurrences of country names from the BNC , allowing any country name and its variants listed in the CIA factbook or WordNet ( Fellbaum , 1998 ) to occur . Each country name is surrounded by three sentences of context . The 1000 examples of our corpus have been independently annotated by two computational linguists , who are the authors of this paper .",Supplement,Document,Use,Syntactic Features and Word Similarity for Supervised Metonymy Resolution,https://aclanthology.org/P03-1008.pdf
"The improved run time for the linear algorithm also reflects the benefits of some improvements in our culling technique and a cleaner implementation permitted by the linear time algorithm . The quadratic code is simply too slow to run on the Wean Hall data . Log files for these runs are available from the DP - SLAM web page : The results show a significant practical advantage for the linear code , and vast improvement , both in terms of time and number of particles , for the hierarchical implementation .",Supplement,Document,Use,Hierarchical Linear/Constant Time SLAM Using Particle Filters for Dense Maps,https://proceedings.neurips.cc/paper_files/paper/2005/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf
"It can be made less restrictive , but this goes beyond the scope of this paper . Due to space limitations we have to omit the proof . It is found in a technical report , It can be made less restrictive , but this goes beyond the scope of this paper _CITE_",Supplement,Document,Use,seL4: formal verification of an OS kernel,https://dl.acm.org/doi/abs/10.1145/1629575.1629596
"EM - LDS was able to correct some of the deformation errors of EM - Gaussian . The average Z error for EM - LDS on the shark sequence after 100 EM iterations is 1 . 24 %. Videos of the shark reconstructions and the Matlab software used for these experiments are available from In highly - constrained cases — low - rank motion , no image noise , and no missing data ILSQ achieved reasonably good results . However , EM - Gaussian gave better results in nearly every case , and dramatically better results in underconstrained cases .",Supplement,Document,Use,Learning Non-Rigid 3D Shape from 2D Motion,https://proceedings.neurips.cc/paper_files/paper/2003/file/8db9264228dc48fbf47535e888c02ae0-Paper.pdf
"In section 4 . 3 , we learn human kernels to extrapolate on tasks which are difficult for Gaussian processes with standard kernels . In section 4 . 4 , we study model selection in human function learning . All human participants were recruited using Amazon ’ s mechanical turk and saw experimental materials provided at When we are considering stationary ground truth kernels , we use a spectral mixture for kernel learning ; otherwise , we use a non - parametric empirical estimate .",Supplement,Document,Use,Evaluating Amazon's Mechanical Turk as a Tool for Experimental Behavioral Research,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0057410
"a function of training steps . ( b ) The optimal resource appropriation policy for a single agent on this map . At convergence , the agent we study nearly learns this policy : ri : S x A1 x · · · x AN -+ R for player i . Finally , let us write Oi = { oi | s E S , oi = O ( s , i )} be the observation space of player i .",Supplement,Document,Use,A multi-agent reinforcement learning model of common-pool resource appropriation,https://proceedings.neurips.cc/paper_files/paper/2017/file/2b0f658cbffd284984fb11d90254081f-Paper.pdf
"Moreover , we show that analysis of the marginal distribution provides an indicator for the confidence in those predictions . Finally , we investigate the convergence rate and runtime performance of the algorithm in detail . For our evaluation dataset , we collected all Wikipedia articles that appeared in the featured list for a two week period in Oct . 2009 , thus obtaining 2460 documents . Of these , we considered a subset of 1717 documents assigned to the 7 most popular categories . After stemming and stop - word removal , we represented the text of each document as a tf / idf - weighted word vector .",Supplement,Document,Use,Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning,https://proceedings.neurips.cc/paper_files/paper/2010/file/459a4ddcb586f24efd9395aa7662bc7c-Paper.pdf
"Moreover , rotational invariance has been sought : ( i ) many data augmentation schemes have used rotated versions of images and ( ii ) models have been developed to learn this invariance , like the Spatial Transformer Networks [ 14 ]. Other explanations are the lack of experience on architecture design and the need to investigate better suited optimization or initialization strategies . The LeNet - 5 - like network architecture and the following hyper - parameters are borrowed from the TensorFlow MNIST tutorial : dropout probability of 0 . 5 , regularization weight of 5 x 10 − , initial learning rate of 0 . 03 , learning rate decay of 0 . 95 , momentum of 0 . 9 . Filters are of size 5 x 5 and graph filters have the same support of K = 25 . All models were trained for 20 epochs .",Supplement,Document,Use,Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering,https://proceedings.neurips.cc/paper_files/paper/2016/file/04df4d434d481c5bb723be1b6df1ee65-Paper.pdf
"It might be because we can better estimate the statistics of each sample . We apply our method to a CNN [ 26 ] for MNIST using one of the Tensorflow tutorials . The dataset has high testing accuracy , so most of the examples are too easy for the model after a few epochs . Selecting more difficult instances can accelerate learning or improve testing accuracy [ 18 , 29 , 13 ]. The results from SGD - SD and SGD - WD confirm this finding while selecting uncertain examples can give us a similar or larger boost .",Supplement,Document,Use,Active Bias: Training More Accurate Neural Networks by Emphasizing High Variance Samples,https://proceedings.neurips.cc/paper_files/paper/2017/file/2f37d10131f2a483a8dd005b3d14b0d9-Paper.pdf
"where each example may have more than one labels . Here , we maintained only a single label for each data point in order to apply standard multiclass classification . The maintained label was the first label appearing in each data entry in the repository files from which we obtained the data . Figure 3 displays convergence of the lower bounds ( and for the exact softmax cost ) for all methods . Recall , that the methods SOFT , OVE and BOUCHARD are non - stochastic and therefore their optimization can be carried out by standard gradient descent .",Supplement,Document,Use,One-vs-Each Approximation to Softmax for Scalable Estimation of Probabilities,https://proceedings.neurips.cc/paper_files/paper/2016/file/814a9c18f5abff398787c9cfcbf3d80c-Paper.pdf
"During data reduction , the SAS intensity data also should be placed on an absolute scale in units of cm - 1 by comparison with the incident beam flux or the scattering from pure H2O ( Orthaber et al ., 2000 ; Jacrot & Zaccai , 1981 ). Pure H2O is a readily accessible , universal standard whose scattering has been well characterized over a wide range of temperatures . Secondary standards are also available , such as glassy carbon ( see the new NIST Standard Reference Material 3600 ; Allen et al ., 2017 ). Absolute scaling enables the direct comparison of SAS data from different instruments , including X - ray and neutron sources , without arbitrary scaling and also enables the determination of M or V from I ( 0 ) without reference to the scattering from a reference protein . In the case of SANS , it has been routine to place the data on an absolute scale .",Supplement,Document,Use,2017 publication guidelines for structural modelling of small-angle scattering data from biomolecules in solution: an update,https://journals.iucr.org/d/issues/2017/09/00/jc5010/jc5010sup1.pdf
"We downloaded the combined annotation dependent depletion ( CADD ) score precalculated on 1000 Genome phase 3 variants from http :// cadd . gs . washington . edu / download / and used the scaled version ( PHRED - like score ). We downloaded the fitness consequence of functional annotation ( fitCons ) score integrated across the three ENCODE cell types from http :// compgen . cshl . edu / fitCons / 0downloads / tracks / current / i6 / scores /, and we used the highly significant scores ( P & lt ; 0 . 003 ) as defined by the authors . We obtained the contextual analysis of transcription factor occupancy ( CATO ) scores precalculated at 13 . 4 million single nucleotide polymorphisms ( SNPs ) overlapping with DNase Hypersensitivity Site from We mapped all scores to the 200 - bp windows used in this study and obtained the maximum score ( 0 if not available ) within each window . In the regression analysis , we used log (( x + 1e - 4 )/( 1 − x + 1e - 4 )) transformed scores as the response and we used the epigenetic states in the corresponding windows as dummy predictors .",Supplement,Document,Use,Accurate and reproducible functional maps in 127 human cell types via 2D genome segmentation,https://watermark.silverchair.com/gkx659.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAr4wggK6BgkqhkiG9w0BBwagggKrMIICpwIBADCCAqAGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMSLNpQ5FTGB1sNSe3AgEQgIICcak0GaGxfbJwNAfFZf0UUqcFtAF9pg2mYnHEnhkjqWIay42IvAVBl9TyUpWXg1Dfw3l_IPI8iu5JIzWHGf6wI_gaoHoVXEJpJhLbFsI_tibtIfJaQsiFz6oj45LDLt7UlWRrwtm5ULguVjwZ0eb0L9T6_KlbjvcmZjRdszzcGAlIElOqK4tuXK1xrMjbQVGMfyUDZOMI9HtOPZKnk5oN4wxqOd3uwx3crx-D2DSLBT-8DaEsIXvBGFhjhkHki0VmrxjHcKnUMfCJTqogAzCHx_wQHx3z19brz8DC7JCfaikIlYLmWLneALnbSifCuFtBe8raLLNm85-8huESPxVK46MGcFuVibDoobr8XDrZL1oELhxgPSBTIjHXgQzHIaMGeRybMLsZIXQXAqEB3A0CeJU47sSlcpde78Azw4BdwhT4iTxdL3FJ7CgCUVOZH2wZtbg5V2zg24O8x8jlnFFldGBJUCdU4eZ_6ecmPmeRoWRsb2k3znslLju_imDChRn4OsG9iYEMsutvwjxcqPS1MxDljoGzPUTFVCIHOIRKtkwRwYEmZIDp_nfOL-EMyFPKgFkkD5ZUQ9KQgnDoTPAaqCiBJEr1Ch7hfNZIjuTcDkimAI1Qvdh0XASNEvk7tFB3TZuhKrT-dT92fUK2P1OrKtlffu4wOO3E0D_fMUJwPjF-jk1bt00T5kJKR-eKC-JxJlfQDEppBJybZjOVN8kttyUqP76O-sj0jn5atxV8obEmDRsEAjEr1VdNRih3II66_NLpgvgMmTfTI3ILXQhahvTPkDyLNc4UQvTpD0DsgaoEl0pp3Sy1SaXrSU8WDImLGJ4
"family and kept the best likelihood value of each run for the LRT ( supplementary table S19 , Supplementary Material online ). The likelihood ratios were compared to a chisquare distribution with 1 degree of freedom as recommended in PAML user ’ s guide ( , last accessed April 24 , 2014 ).",Supplement,Document,Use,Contrasting Patterns of Nucleotide Substitution Rates Provide Insight into Dynamic Evolution of Plastid and Mitochondrial Genomes of Geranium,https://watermark.silverchair.com/evx124.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAArowggK2BgkqhkiG9w0BBwagggKnMIICowIBADCCApwGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMfW2fUeXCOo9lT9orAgEQgIICbWX_ErXzWniJxGBB3OLNn5Ea6-3m5RQP56vBKaHqCHDTVW6KjSjoRUlmIbqxVCr5FUkVGYm8Hrds06gr_aZxdohr56GQaSsW6fEC_5mc45SvqFSJZMLoeFUjj9w9Ep9pCz9oiwbYL5aOQOGPExn7yI2NWLM52hJMu17UlUqFutZtLaEJP_lbV9L4erhMPhnY9cor4IfgZnfVl9MXVgF_PDHgtaUN1FofGa4F_AbyCu6DUryGCIS7L9A-nX2IKKSAtfKreARjXkZrDUYJPCU8M2kq8O4iNazlEOnCGHNL7GvIWzFsPnCePlh0wEJL1KmSldEta17TovELqscJu2RGhv9FiSZ6oAIV4eMHyUzYNEV5TaJAKOa-xWsFJFIMmUj074FKHwakf4qxfjP8DPD5tyFKjzxB-4zu-qiZWYfNMAfD1OwfTkl0YW9v9Ds4BlwHtoQ--0KFzuDZ-lFTT8QPrssOFHDS3c_tl72ElvJRK31qlsbDjAh3s4mLPp4NjwUQ6Yh9nYMjb_GkKsZjPqdsPwgAPhMtQGQW_t51-wev0-6d-s21QfcyOPvdKkaQzqHfmyMKq9lhRbm1jLzBfRBaDDs8ewdNJssnWRA57ls-ajN7tKe0vBoOzBHSpxaBGexqdUxpN1rKf-nfidSfbqeRFmYkYVQlpKn3qv076ftoZLZUyPI_nFdhJdqqQKbyrXlnxTuN3X8fAdSVbaSu3R0ZofuttWYrqbGwkJ27kOfpyF-VmKtjCrqg5o04v-qYN-n71CxHZn8skrLAo3z4121gDviHDKr4PXsv2zYIhvK20yUIltYkjwmr4QrLJWTjyg
"Finally , the BNT toolbox can be downloaded from https :// code . google . com / p / bnt /. Instructions for installations as well as how to use the package is available in the website . The material from [ 1 ] has been made available in the Google drive folderview ? id = 0B7Kkv8wlhPU - T05wTTNodWNydjA & usp = sharing . This contains the individual files , contents of which are used in this manuscript . The drive and its contents can be accessed via the URLs mentioned earlier in the abstract .",Supplement,Document,Use,A pedagogical walkthrough of computational modeling and simulation of Wnt signaling pathway using static causal models in MATLAB,https://bsb-eurasipjournals.springeropen.com/articles/10.1186/s13637-016-0044-y
Previously reported mutational signatures were obtained from on 1 © 2018 The Authors . The Journal of Pathology published by John Wiley & Sons Ltd J Pathol 2018 ; 245 : 283 – 296 on behalf of Pathological Society of Great Britain and Ireland . www . pathsoc . org www . thejournalofpathology . com 286 D Temko et al June 2017 .,Supplement,Document,Use,"NOX2 in autoimmunity, tumor growth and metastasis†",https://pathsocjournals.onlinelibrary.wiley.com/doi/full/10.1002/path.5175
Comments are denoted by a #. Abbreviations for sequencing center and tissue source site are as follows : BCGSC — British Columbia Genome Sequencing Center ; Broad — The Broad Institute of MIT and Harvard ; Fox Chase — Fox Chase Cancer Center ; MSKCC — Memorial Sloan Kettering Cancer Center ; UCSF — University of California San Francisco ; UNC — University of North Carolina ; Wash Univ St . Louis — Washington University in St . Louis . This file is available at Dryad with the following link : ( GZ 259 kb ) Additional file 3 : Figure S2 . These histograms illustrate the variation in counts of bacterial taxa per sequencing run across cancer types .,Supplement,Document,Use,Distinguishing potential bacteria-tumor associations from contamination in a secondary data analysis of public cancer genome sequence data,https://microbiomejournal.biomedcentral.com/articles/10.1186/s40168-016-0224-8
"These various web interfaces enable users to extract human genetic polymorphism annotations with userfriendly search systems . Availability VarySysDB can be downloaded and freely accessed , with no restriction to academic users only , from http :// h - invitational . jp / varygene /. A help document is also available from _CITE_",Supplement,Document,Use,VarySysDB: a human genetic polymorphism database based on all H-InvDB transcripts,https://academic.oup.com/nar/article-pdf/37/suppl_1/D810/3291786/gkn798.pdf
"Data from each of the aforementioned survey rounds were included in this study , with many of the selected variables representing the same questions asked at multiple time points ( WLS survey rounds ). In addition , DNA saliva samples were provided by a subset of the WLS ( 4562 graduates ) and 77 single - nucleotide polymorphisms ( SNPs ) were genotyped for each of these participants in 2009 , providing genetic data for a subset of the WLS as well . Additional information about the WLS survey data and participants can be found elsewhere74 75 ( ). The WLS has enjoyed high response rates across multiple survey waves . The data for the current analyses come primarily from the 1993 , 2004 , and 2011 survey waves when the cohort was 53 , 64 and 71 years old , respectively .",Supplement,Document,Use,"Myocardial infarction in the Wisconsin Longitudinal Study: the interaction among environmental, health, social, behavioural and genetic factors",https://bmjopen.bmj.com/content/bmjopen/7/1/e011529.full.pdf
"This systematic review was registered with the International Prospective Register of Systematic Reviews ( PROSPERO ; Registration no . CRD42016035270 ; available from ), and was conducted and reported following the Preferred Reporting Items for Systematic Reviews and Meta - Analyses ( PRISMA ) statement [ 22 ]. Eligibility criteria The Population , Interventions , Comparisons , Outcomes , and Study design ( PICOS ) framework [ 23 ] was used to identify key study concepts in the research question , and to facilitate the search process . The Author ( s ) BMC Public Health 2017 , 17 ( Suppl 5 ): 868 Page 67 of 215",Supplement,Document,Use,Systematic review of the relationships between sedentary behaviour and health indicators in the early years (0–4 years),https://link.springer.com/article/10.1186/s12889-017-4849-8
"The final step is to populate Characteristics and Annotations . The project contains 198 samples , making the process of manual annotation very lengthy . To ease the process , we wrote an annotation file that can be imported directly within Djeen ( available from Djeen documentation page at ). However , it has to be formatted to be imported , especially to fit the sample database Ids . This is done by generating an empty annotation file by exporting current file annotation data using “ Files ”-> “ Save the file to annotation . txt ”, and editing “ annotation .",Supplement,Document,Use,Djeen (Database for Joomla!’s Extensible Engine): a research information management system for flexible multi-technology project administration,https://bmcresnotes.biomedcentral.com/articles/10.1186/1756-0500-6-223
"Ultimately , preservation of global health requires prioritization of and support for international collaboration . These and other principles were affirmed at the consultation ( Table 1 ) and codified into a consensus statement that was published on the WHO website immediately following the meeting ( http :// www . who . int / medicines / ebola - treatment / data - sharing_phe / en /). A more comprehensive set of principles and action items was made available in November 2015 , including the consensus statement made by the editorial staff of journals that attended the meeting ( ). The success of prior initiatives to accelerate timelines for reporting clinical trial results has helped build momentum for a broader data sharing agenda . As the quick and transparent dissemination of information is the bedrock of good science and public health practice , it is important that the current trends in data sharing carry over to all matters of acute public health need .",Supplement,Document,Use,Developing Global Norms for Sharing Data and Results during Public Health Emergencies,https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001935
"HOTAIR gene expression , copy number , DNA methylation and clinical data were downloaded from TCGA ; available from : , accessed 2017 ) [ 57 ]. TCGA Agilent ’ s G4502A 244K gene expression profiles from 572 GBMs , 27 grades II and III gliomas ( Supplementary Table 1 ), and 10 unmatched normal samples were analyzed , and “ level 3 ” values of HOTAIR ( probe A_32_P168442 ) and HOXA9 ( probe A_23_ P500998 ) were used . HOTAIR - high was considered when “ level 3 ” value & gt ; 0 , and HOXA9 - high when & gt ; 2 .",Supplement,Document,Use,The long non-coding RNA HOTAIR is transcriptionally activated by HOXA9 and is an independent prognostic marker in patients with malignant glioma,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5884661/
"We are also indebted to the numerous researchers worldwide who helped us by providing advice , data , and documentation , and by proofreading the multitagged Corpus and MultiTreebank . This COLING Workshop paper is an an abridged version of a full paper published in ICAME Journal , ( Atwell et al 2000 ); we are grateful for the Journal ’ s permission to present our findings to this complementary Workshop audience . To get the full ICAME Journal paper , see _CITE_",Supplement,Paper,Introduce,A comparative evaluation of modern English corpus grammatical annotation schemes,https://eprints.whiterose.ac.uk/81682/
"The overall home ranges estimated with a - LoCoHs and T - LoCoHs were very similar ( Fig 2 ), which was expected as T - LoCoH was developed as an extension of the location - based a - LoCoH [ 30 ]. The area estimates were also smaller than the GCM and BRB , which is supported by simulated LoCoH studies showing the hulls created essentially ‘ hug ’ the data [ 25 , 30 ]. However , this also means that the LoCoH PLOS ONE | March31 , 2017 14 / 23 Evaluating home range estimators using GPS collars methods are not as strong at modelling spatial uncertainty associated with GPS fixes [ 30 ]. They both perform most effectively with large data sets [ 76 ]; a - LoCoH has been shown to converge on the true range as sample size increases [ 25 ]. BRB appeared to show the best overall performance , producing high and robust AUC values , while not showing as much sensitivity to sample size or fix frequency as GCM , which had similarly high AUC values .",Supplement,Paper,Introduce,Evaluating methods for estimating home ranges using GPS collars: A comparison using proboscis monkeys (Nasalis larvatus),https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0174891
"This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( http :// creativecommons . org / licenses / by / 2 . 0 ), which permits unrestricted use , distribution , and reproduction in any medium , provided the original work is properly cited . Hofer er al . BMC Genomics 2011 , 12 : 262 Page 2 of 6 [ 11 ], the Atlas of Gene Expression in Mouse Aging Project ( AGEMAP ) [ 12 ], and the NetAge database [ 13 ]. However , to the best of our knowledge , there is no database which contains microarray gene expression data together with orthologous genes , ageing - related microarray miRNA expression data as well as data of follow - up experiments . We have therefore initiated the development of a database GiSAO . db ( Genes involved in senescence , apoptosis and oxidative stress ) to support ongoing and future studies in experimental ageing research .",Supplement,Paper,Introduce,GiSAO.db: a database for ageing research,https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-12-262
"Horev - Azaria et al . Particle and Fibre Toxicology 2013 , 10 : 32 Page 12 of 17 streptomycin ( Gibco , Invitrogen Corporation , Italy ). Cell preparations were maintained in standard cell culture conditions ( 37 ° C , 5 %, CO2 and 95 % humidity , HERAEUS incubator , Germany ) [ 25 ]. TK6 : TK6 cells are human lymphoblastoid cell line ( purchased from ATCC ).",Supplement,Paper,Introduce,Predictive Toxicology of cobalt ferrite nanoparticles: Comparative in-vitro study of different cellular models using methods of knowledge discovery from data,https://www.researchgate.net/publication/255793368_Predictive_Toxicology_of_cobalt_ferrite_nanoparticles_Comparative_in-vitro_study_of_different_cellular_models_using_methods_of_knowledge_discovery_from_data
"Murine hepatoma Hepa1 - 6 cells ( ACC 175 ) were obtained from the Leibnitz Institute DSMZ ( German Collection of Microorganisms and Cell Cultures , Braunschweig , Germany ). Cells were cultured in Dulbecco ’ s MEM with 4 . 5 g / l glucose ( Life Technologies ) complemented with 10 % heat - inactivated fetal calf serum ( PAN Biotech , Aidenbach , Germany ) at 37 ° C in a humidified atmosphere containing 95 % air and 5 % CO2 . PLOS Neglected Tropical Diseases | January 12 , 2018 4 / 25 B . pseudomallei benefits from changing host iron balance Generation and cultivation of primary murine macrophages Bone marrow - derived macrophages ( BMM ) were generated and cultivated in a serum - free cell culture system as recently described [ 34 ].",Supplement,Paper,Introduce,Burkholderia pseudomallei modulates host iron homeostasis to facilitate iron availability and intracellular survival,https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0006096
"YouTube is open access and also commonly used , yet automating data extraction and content analysis from videos is challenging . As a result , this digital data stream has primarily been evaluated with respect to its potential to spread misinformation or clinically useful material rather than as an epidemic surveillance or prediction tool [ 57 ]. Nevertheless , PLOS Neglected Tropical Diseases | November 30 , 2017 7 / 13 particular mention should be made of the study by Alasaad , who sought to evaluate the surveillance potential of Facebook and YouTube posts concerning probable leishmaniasis cases in Syria [ 12 ]. While this study had a very limited validation and the reference data set was difficult to reproduce ( Skype - calling individual clinicians in conflict zones with deteriorating public health infrastructure to confirm whether leishmaniasis had been seen in regions where YouTube and Facebook posts indicated disease ), the findings were nevertheless valuable for exploring a possible public health application of social media in a conflict zone . Limitations , challenges and future directions in the application of internet - based VBD biosurveillance The putative advantages of internet data for communicable disease surveillance are clear ; namely , these data are free , fast , and may offer valuable surveillance signals in regions with limited conventional surveillance infrastructure and rising internet access .",Supplement,Paper,Introduce,Internet-based biosurveillance methods for vector-borne diseases: Are they novel public health tools or just novelties?,https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0005871
"The skull from Gypsum Cave ( GCS ) can be distinguished from that of the francisci holotype ( fHS ) by its slightly larger size , and markedly longer and more slender rostrum , both Heintzman et al . eLife 2017 ; 6 : e29944 . DOI : 41 of 43 Research article Genomics and Evolutionary Biology absolutely and as a percentage of the skull length . The rostrum of the GCS is also absolutely narrower ; the fHS , despite being the smaller skull , is transversely broader at the i / 3 . The palatine foramina are positioned medial to the middle of the M2 in the GCS , whereas they are medial to the M2 - M3 junction in the fHS .",Supplement,Paper,Introduce,A new genus of horse from Pleistocene North America,https://elifesciences.org/articles/29944.pdf
"Supporting information : this article has supporting information at journals . iucr . org / d Acta Cryst . ( 2018 ). D74 , 441 – 449 441 research papers images can be collected via the rotation method , where integrated Bragg intensities are experimentally obtained . At cryogenic temperatures , small - wedge ( 5 – 10 °) data collection can be a good compromise to obtain strong diffraction signals under tolerable doses , and tens to hundreds of data sets are usually sufficient to obtain a high - resolution structure . Efficient data collection can be achieved and easily automated when multiple microcrystals are held in a sample holder .",Supplement,Paper,Introduce,KAMO: towards automated data processing for microcrystals,https://scripts.iucr.org/cgi-bin/paper?wa5117
"It may be noted that though both ReadDepth and CBS in iCopyDAV uses the same segmentation approach , the performance of CBS is better than ReadDepth for sequencing coverage & lt ; 40 × due to the difference in data pre - treatment approaches in two cases . From the comparison of recall and precision values of CBS and TVM in iCopyDAV with the three DoC - based tools , we observe higher recall with both TVM and CBS approaches for the detection of CNVs & lt ; 1 Kb , while for the detection of CNVs > 1 Kb all the DoC - based methods showed recall values approaching ‘ 1 ’ with increase in sequencing coverage ( S3 ( A ) Fig ). The precision ~ 1 with both CBS and TVM in the detection of small and large CNVs PLOS ONE | April 5 , 2018 16 / 37 iCopyDAV : Integrated platform for detection , annotation and visualization of copy number variations ( even at 5x sequencing coverage for TVM ), while precision values ( combined of small and large CNVs ) of ReadDepth , CNVnator , and Control - FREEC are — 0 . 71 , — 0 . 51 and — 0 . 26 , respectively , at 30x coverage ( S4 ( B ) Fig ). Also , it is observed that in case of ReadDepth and Control - FREEC , a reduction in precision is observed with increase in sequencing depth due to increase in the number of false positives . This clearly indicates the importance of appropriate normalization of read depth signals .",Supplement,Paper,Introduce,"iCopyDAV: Integrated platform for copy number variations—Detection, annotation and visualization",https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0195334
"( E ) Exemplar motifs of a tutor and three of his 65d pupils , each of which was injected with a different viral construct at 30d . These examples illustrate the percent similarity depicted in panel D . ( F ) Summary of the learning and variability phenotypes observed after virus injection . DOI : The following source data and figure supplement are available for figure 2 : Source data 1 . Contains the effect sizes for each syllable that are presented in ( C ). DOI : https :// doi . org / 10 . 7554 / eLife . 30649 . 010 Source data 2 .",Supplement,Paper,Introduce,FoxP2 isoforms delineate spatiotemporal transcriptional networks for vocal learning in the zebra finch,https://elifesciences.org/articles/30649
"It would be reasonable to assume that samples one , two and three all contain a similar number of transcripts for this gene . Patrick et al . BMCBioinformatics 2013 , 14 : 31 Page 3 of 10 were mapped ) [ 21 ] would be appropriate if isoforms were mutually exclusive . Unfortunately there is often evidence of multiple isoforms for a gene being present . If the abundance of these isoforms could be accurately estimated [ 21 ] it may be possible to estimate the rate of transcription by summing the FPKM of all isoforms of a gene .",Supplement,Paper,Introduce,Estimation of data-specific constitutive exons with RNA-Seq data,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3656776/
"Cognitive therapy approaches have been used effectively in treating PTSD following sexual or interpersonal violence [ 897 - 901 ], civilian trauma [ 902 - 908 ], and military trauma [ 909 - 914 ]. Katzman et al . BMC Psychiatry 2014 , 14 ( Suppl 1 ): S1 Page 34 of 83 Cognitive processing therapy ( CPT ) is an effective protocol that combines cognitive therapy and written accounts [ 899 - 901 , 910 - 913 ]; however , an analysis of the components found no differences in outcomes with either component alone or the combined protocol [ 899 ]. Prolonged exposure ( PE ) is a widely studied CBT approach . A meta - analysis of 13 RCTs concluded that PE therapy was more effective than wait - list or psychological placebo control conditions , and as effective as other active treatments ( e . g ., CBT , CPT , EMDR ) [ 69 ].",Supplement,Paper,Introduce,A randomized clinical trial to dismantle components of cognitive processing therapy for posttraumatic stress disorder in female victims of interpersonal violence.,https://psycnet.apa.org/record/2008-03290-007
"That ’ s clearly not a robust way ...( and the Medication Safety ) Thermometer for our organisation is brilliant ... it has slightly made our data collection better , I ’ d argue . P13 ( Nurse , EA ) Participants reported an initial lack of understanding about how data could be used for improvement , particularly in LA organisations , where data collection was initiated prior to gaining a full understanding of how it should be used . Some participants felt strongly that the PLOS ONE | February28 , 2018 6 / 19 An evaluation of the implementation of the Medication Safety Thermometer MedsST should not be used for pin - pointing individuals and for staff to have “ the finger pointed at them .” ( P3 , Clinical Auditor , LA ). Nonetheless , one pharmacist ( P2 , LA ) stated that MedsST data had been used for pin - pointing poor practice of nurses and subsequent performance management . Most nurses agreed with participant 2 that MedsST data should be used for monitoring performance of nurses and that practice cannot be completely “ blame - free ”, as certain “ stupid ” individuals could cause errors ; however , they also believed that errors are actually caused by system problems that need to be addressed by supporting individuals .",Supplement,Paper,Introduce,A qualitative interview study using normalisation process theory,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5830037/
"Importantly this analysis confirms the previous observations of Hmga binding to major satellites ( S8C Fig ). In summary , these findings reinforce our observation that Hmga proteins bind the genome preferentially at regions of higher AT content , which , as a consequence of genome evolution , tend to overlap with large , heterochromatic domains . As we do not detect a dependence of binding on sequence composition of the surrounding regions at the kilobase scale , Hmga1 - 2 PLOS Genetics | December 21 , 2017 11 / 36 Genome wide binding of HMGA proteins Fig 4 . Genomic distribution of Hmga - enriched regions and AT - rich DNA . ( A ) Average profiles of log2 enrichment values over DBD - mutant at LMR regulatory regions .",Supplement,Paper,Introduce,Binding of high mobility group A proteins to the mammalian genome occurs as a function of AT-content,https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1007102
"However , when there are no a priori reasons to spatially segment an assemblage , a method is needed to examine whether there is , nevertheless , spatial patterning in the data . To address this , a method for calculating and plotting nearest neighbor samples and , in effect , moving averages across an assemblage from a particular stratigraphic unit is presented . This method allows spatial patterning across an assemblage to be visualized in Benn PLOS ONE | January 2 , 2018 2 / 21 Statistical and graphical methods for analyzing site formation processes using artifact orientations space . When patterns are detected , the assemblage can then be spatially segmented and tested following the above mentioned techniques . Additionally , to further advance the analysis of artifact orientations , all of the software used in this paper to make the standard [ 1 ] and the newly presented statistical and graphical techniques are available in the Supplemental Information .",Supplement,Paper,Introduce,Additional statistical and graphical methods for analyzing site formation processes using artifact orientations,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5749765/
"_CITE_ study and reported from previous studies corresponded with minimum ASM estimates of 6 . 5 to 8 . 4 yr and mean ASM estimates ranging from 9 . 5 to 17 . 1 yr ( Table 2 ). Comparison of growth data back - calculated for Kemp ’ s ridleys stranded in the GOM ( n = 535 ) vs . the Atlantic [ 13 ] prior to 2000 , the time frame for which data from both regions were available , indicated that overall rates were similar , with the exception that growth was much faster in the GOM for turtles in the 20 cm SCL size class ( Table 3 ; Fig 3A ). Fitting Faben ’ s modified von Bertalanffy growth curve to bootstrapped pre - 2000 GOM data yielded k = 0 . 26 and L ,,, = 65 . 3 , contrasting with Atlantic values of k = 0 . 115 and L ,,, = 74 . 9 cm SCL for the same time period and emphasizing divergence in early growth rates ( Fig 3B ).",Supplement,Paper,Introduce,"Variability in age and size at maturation, reproductive longevity, and long-term growth dynamics for Kemp's ridley sea turtles in the Gulf of Mexico",https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0173999
"Each point in color represents the mean peak rate within the experimental group , i . e ., control , Ctx , Atx , and EGTA - AM . Paired ttest ( S3 Data ). Throughout the figure : concentration of a PLOS Biology | August 22 , 2017 6 / 32 Neuronal activity and oligodendrocyte precursor cells given drug is the same . The shown traces during drug application are taken from the time period when the drug effect on the amplitude of the evoked currents or rate of delayed currents was on the steady state . The numerical data used in D – O are included in S4 Data .",Supplement,Paper,Introduce,Different patterns of neuronal activity trigger distinct responses of oligodendrocyte precursor cells in the corpus callosum,https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2001993
"Bihrmann and Ersbøll InternationalJournal of Health Geographics 2015 , 14 : 1 Page 7 of 13 The variance parameter estimates were all reasonably similar , but with a slight tendency to either increase ( especially MAR0 OR = 1 / 3 and MAR1 OR = 1 / 3 ) or decrease ( especially MAR0 OR = 3 ) with more than 50 % missing data . Both the standard deviation of each parameter estimate , and the Root Median Squared Error ( RMeSE ) increased when the number of missing observations was increased , regardless of scenario . The median of the estimated range of influence within each simulation scenario ( Figure 1 ) ranged from 9 . 4 km ( SD 4 . 0 ) ( MAR1 OR = 1 / 3 , 75 %) to 14 . 8 km ( SD 19 . 3 ) ( MNAR OR = 3 , 75 %).",Supplement,Paper,Introduce,Estimating range of influence in case of missing spatial data: a simulation study on binary data,https://ij-healthgeographics.biomedcentral.com/articles/10.1186/1476-072X-14-1
"Data were analyzed by patient environment ( inpatient , outpatient , or homecare / hospice ), with homecare / hospice being applicable only to the clinical laboratory category because transfusions are not performed within that environment . Chi - square and t - tests were used to compare Whitehurst et al . Journal of Biomedical Semantics 2012 , 3 : 4 Page 6 of 10 categorical and continuous data , respectively . The Wilcoxon rank sum test was used to compare nonparametric data . All statistical analysis was performed using JMP Pro 9 . 0 ( SAS Corporation , Cary , NC , USA ).",Supplement,Paper,Introduce,Towards the creation of a flexible classification scheme for voluntarily reported transfusion and laboratory safety events,https://link.springer.com/article/10.1186/2041-1480-3-4
"Rankings of surgical innovation across specialties by cascade size and structural virality ( structural depth and width ) were found to correlate closely with the ranking by innovation value ( Spearman ’ s rank correlation coefficient = 0 . 758 ( p = 0 . 01 ), 0 . 782 ( p = 0 . 008 ), 0 . 624 PLOS ONE | August 25 , 2017 1 / 14 Networks of surgical innovation 2017 ). The funders had no role in the study design , ( p = 0 . 05 ), respectively ) which in turn matches the ranking based on real world big data from data collection and analysis , decision to publish , or the NIS ® ( Spearman ’ s coefficient = 0 . 673 ; p = 0 . 033 ). preparation of the manuscript .",Supplement,Paper,Introduce,Network analysis of surgical innovation: Measuring value and the virality of diffusion in robotic surgery,https://pubmed.ncbi.nlm.nih.gov/28841648/
"The present study demonstrates high intra - platform precision for all platforms . The majority of replicate CV median measurements for nCounter & apos ;, BioMark HDTM and OpenArray & apos ; were in the range between 5 - 15 % which was slightly higher than the CV values observed on the Affymetrix & apos ; Forreryd et al . BMC Genomics 2014 , 15 : 379 Page 12 of 17 platform . In contrast to the CV values observed on the Affymetrix ® platform , the distribution of replicate CV values varies between stimulations on evaluated platforms . The distribution of replicate CV values for a certain stimulation is however comparable across the evaluated platforms .",Supplement,Paper,Introduce,Evaluation of high throughput gene expression platforms using a genomic biomarker signature for prediction of skin sensitization,https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-379
"The effect of filtering using the age - based threshold was evaluated by comparing HRV indices before and after filtering of the edited data set and the unedited data set , respectively . Karlsson et al . BioMedical Engineering OnLine 2012 , 11 : 2 Page 4 of 12 _CITE_",Supplement,Paper,Introduce,Automatic filtering of outliers in RR intervals before analysis of heart rate variability in Holter recordings: a comparison with carefully edited data,https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-11-2
"This work has implications for researchers and those who use meta - analyses to help inform clinical and policy decisions . ( i ) Investigators should ensure a comprehensive systematic literature search to avoid or at least attenuate the effect of dissemination bias . Such searches can be PLOS ONE | April 25 , 2017 12 / 16 Study data not published in full text articles have unclear impact on meta - analyses results resource - intensive particularly when unpublished and grey literature data need to be identified . If the available resources do not permit comprehensive searches to identify unpublished or grey literature data , we strongly recommend ( at least ) a search in trial registries ( such as the ICTRP and ClinicalTrials . gov ) and websites of regulatory authorities which is less resourceintensive than searching for conference proceedings or dissertations , contacting experts , the industry and authors . When including unpublished or grey literature data sensitivity analyses should be carried out taking into account that this research may provide only preliminary results , is usually not peer reviewed and / or at higher risk of bias .",Supplement,Paper,Introduce,Systematic review finds that study data not published in full text articles have unclear impact on meta-analyses results in medical research,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0176210
"Ono et al . BMC Genomics 2014 , 15 : 1028 Page 7 of 15 ( See figure on previous page .) Figure 3 CCA results using the Gata3 dataset for the Th differentiation programmes . CCA was applied to the Gata3 dataset , using the microarray dataset that analysed Th1 , Th2 , Th17 , and iTreg ( the Th dataset ) as explanatory variables for the Th differentiation programmes .",Supplement,Paper,Introduce,Visualisation of the T cell differentiation programme by Canonical Correspondence Analysis of transcriptomes,https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-1028
"If I tell the doctor that I have fever he might give me the medicine ... then all that I am feeling will calm down [ Focus group discussion ( FGD ) 1 Tanzania respondent 5 ]. Allen et al . BMC Medical Research Methodology 2013 , 13 : 140 Page 7 of 13 Treatment use phraseology meanwhile revealed a hierarchy ; after ARVs or antimalarials , use of intermittent or over the counter substances ( such as painkillers or vitamins ) were mentioned , but qualified with ‘ only ’ or ‘ apart from ’. These perceptions of significance may intersect with the next factor shaping reporting behaviour : relevance to report . Relevance to report Participants appeared to delay reporting experiences that they perceived irrelevant , with the checklists helping them to decide what was necessary .",Supplement,Paper,Introduce,"How experiences become data: the process of eliciting adverse event, medical history and concomitant medication reports in antimalarial and antiretroviral interaction trials",https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-13-140
"Such a map rendering method produces visual discontinuities and conflicts at the tile borders , which may break the spatial distribution characteristics of features [ 49 ] and reduce the readability and applicability of the role in study design , data collection and analysis , decision to publish , or preparation of the manuscript . Competing interests : The authors have declared that no competing interests exist . PLOS ONE | May 5 , 2017 2 / 26 Tiled vector data model map [ 48 , 50 ]. Therefore , a critical issue for tiled vector E - maps is to join neighboring features with their symbol representation to maintain visual continuity and avoid visual conflicts . To eliminate visual breakage , this study proposes a tiled vector data model for the geographical features that define the additivity of map features and geographical features , partition vector geographical features , and implement map symbolizations to graphically match joined symbolized partitioned features without causing graphic conflicts and losses .",Supplement,Paper,Introduce,Tiled vector data model for the geographical features of symbolized maps,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0176387
"For each of the relation type dictionaries we define an active feature , if at least one keyword from the corresponding dictionary matches a word in the window size of 20 , i . e . - 10 and + 10 tokens away from the current token . Page 11 of 14 ( page number not for citation purposes ) BMC Bioinformatics 2008 , 9 : 207 _CITE_",Supplement,Paper,Introduce,Extraction of semantic biomedical relations from text using conditional random fields,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-207
"In fact , their findings suggest that uncertainty introduced via natural climate variability [ 62 ] should be explicitly included in future climate change assessments in addition to that introduced by the choice of GCM . Both studies also found that the relative contributions of the different uncertainty sources varied by species , likely a function of differences in the complexity of the climatic environment in which individual species reside . PLOS ONE | January 10 , 2018 17 / 23 Future species distributions in mountainous regions An interesting finding of our analysis is that the choice of conversion thresholds to convert probabilities to species presence contributed to only a small portion of variance in the future projections . Nenze ´ n and Arau ´ jo [ 60 ] found that the conversion threshold can induce a 1 . 7 to 9 . 9 - fold difference in the proportions of species projected to become threatened by climate change . Our results instead suggest that the choice of baseline climate dataset and GCM introduces more uncertainty to the climate change assessment than the choice of conversion threshold , although the differences between the two studies need to be interpreted cautiously as Nenze ´ n and Arau ´ jo [ 60 ] considered an overlapping , but not duplicative , set of potential uncertainty sources .",Supplement,Paper,Introduce,Uncertainty of future projections of species distributions in mountainous regions,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0189496
"Additionally , because the interviewees were drawn from the large proportion of the ADF population who provided responses to the Phase 1 questionnaire , the potential for sampling error was further reduced . Furthermore , the use of diagnostic interviews reduces the bias in response validity associated with self - report surveys . Citation : European Journal of Psychotraumatology 2014 , 5 : 23950 - 9 ( page number not for citation purpose )",Supplement,Paper,Introduce,The Australian Defence Force Mental Health Prevalence and Wellbeing Study: design and methods,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4138701/
"Each cluster had 3 CHWs , resulting in a total of 42 CHWs , and thus a corresponding number of reporting units , distributed across the study area . Parasitological assessments were conducted continuously from January 2011 to March 2013 in Luangwa and from April 2011 to March Hamainza et al . Malaria Journal 2014 , 13 : 489 Page 4 of 13 2013 in Nyimba district in all the selected clusters . All consenting households received monthly active visits from CHWs , which included parasitological surveys using RDTs detecting histidine - rich protein 2 antigen ( Malaria Pf cassette test , ICT Diagnostics ), coupled with registers designed in a pre - defined questionnaire format [ 10 ]. Consent for household participation was given by the head of the household and consent was obtained from individual study participants , or parents / guardians in the case of minors , for the RDT test .",Supplement,Paper,Introduce,Comparison of a mobile phone-based malaria reporting system with source participant register data for capturing spatial and temporal trends in epidemiological indicators of malaria transmission collected by community health workers in rural Zambia,https://malariajournal.biomedcentral.com/articles/10.1186/1475-2875-13-489
"In addition , for a direct comparison with the X - Ray based Kypho - Lordotic angle values presented in the literature [ 71 – 74 ] the sagittal plane spine angle values have also been assessed for the most reported anatomical regions ( T1 — T12 ) as well as T4 — T12 for kyphosis and T12 — L5 for lordosis . After computation , a graphical report summarizes and represents the 3D full skeleton reconstruction and the related computed quantitative parameters ( Fig 4 ). PLOS ONE | June 22 , 2017 10 / 31 Normative 3D posture and spine data in healthy young adults In this paper , the total number of computed quantitative biomechanical parameters has been limited to n = 25 as shown in Table 2 .",Supplement,Paper,Introduce,Normative 3D opto-electronic stereo-photogrammetric posture and spine morphology data in young healthy adult population,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5480974/
"Plotted are mean ± SD of mean values for each class of trait calculated across 100 posterior trees ( see S6 Data ). BM , Brownian motion ; MDI , morphological disparity index ; ML , maximum likelihood . PLOS Biology | https :// doi . org / 10 . 1371 / journal . pbio . 2003563 January 31 , 2018 8 / 23 Competition and evolution in a songbird radiation crypsis opposing the effects of sexual selection [ 31 ], S4 Table ). Although we did not find a direct negative relationship between evolutionary rate per se and evidence for competition ( S17 Fig ), there is a trend in the predicted direction , and together with estimates of disparity and divergence , our results are consistent with a model of evolution in which the impact of interspecific competition is negatively related to evolutionary rates : traits either evolve rapidly ( e . g ., under social selection ) and escape the effect of competition upon secondary contact , or they evolve slowly and thus are subject to the effect of interspecific competition in sympatry . We note that there are other possible reasons for why we did not detect a consistent effect of competition on traits involved in social interactions .",Supplement,Paper,Introduce,Contrasting impacts of competition on ecological and social trait evolution in songbirds,https://hal.science/hal-02408841/document
"It is , of course , nevertheless the case that the validity and integrity of data are ultimately linked to the sum of the integrity and validity of all data processes in the lineage of data creation . Recommendation 16 : GBIF should investigate innovative mechanisms for discovery and publishing of Moritz et al . BMC Bioinformatics 2011 , 12 ( Suppl 15 ): S1 Page 7 of 10 primary biodiversity data in multiple languages . GBIF should commission a position paper detailing such mechanisms for potential uptake by the community . Recommendation 17 : GBIF must institutionalize the ‘ biodiversity informatics potential ’ ( BIP ) Index to demonstrate the potential and urgency for nations to implement biodiversity informatics [ 61 ].",Supplement,Paper,Introduce,Towards mainstreaming of biodiversity data publishing: recommendations of the GBIF Data Publishing Framework Task Group,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-S15-S1
"where G0 denotes equilibrium shear modulus , S network stiffness , Γ the Gamma function , and n is a network specific exponent defining the power law slope . Unfortunately , this model was not sufficient to describe our data . First , it predicts a ratio between storage and loss PLOS ONE | April6 , 2018 12 / 22 Ultrasoft PDMS elastomers for mechanobiology module that is far from our observation . Second , it predicts a constant exponent n over the full range of frequencies . However , as can be clearly seen from our data , e . g .",Supplement,Paper,Introduce,"Chemically defined, ultrasoft PDMS elastomers with selectable elasticity for mechanobiology",https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0195180&type=printable
"Because of the ‘ digital ’ end - point measurement in dPCR , effects of PCR efficiencies are eliminated in the quantification . Moreover , with dPCR , it is possible to perform a direct absolute quantification of intact DNA copies in the PCR mix [ 49 , 53 ]. Similar as in the qPCR , several CF primers resulting in PLOS ONE | June 14 , 2018 11 / 17 Evaluation of bisulfite kit performance using dPCR amplicons of different lengths ( 88 to 414 bp ), were used to investigate the difference in fragmentation between the twelve kits . 2 µl DNA of all 60 bisulfite treated samples ( 1 : 2 diluted ) was added to the dPCR mix containing QX200 ddPCR EvaGreen Supermix ( 2x ) ( 186 – 4033 , Bio - Rad ) with 100 nM forward and reverse primers , in a final volume of 20 µl . PCR reactions consisted of initial denaturation at 95 ° C for 5 min , followed by 40 cycles of denaturation at 95 ° C for 30 sec and annealing / elongation at specific temperature ( S10 Table ) for 2 min , and ended with a signal stabilization at 4 ° C for 5 min and 95 ° C for 5 min .",Supplement,Paper,Introduce,Evaluation of bisulfite kits for DNA methylation profiling in terms of DNA fragmentation and DNA recovery using digital PCR,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0199091
"If each video is reviewed completely by two observers , nR nO will be 2 . 0 . Thus , the product nR nO reflects that observers may make repeated Trask et al . BMC Medical Research Methodology 2013 , 13 : 124 Page 4 of 14 observation of the same video frames , which is one way of improving precision of exposure estimations obtained by observation [ 7 ]. Substituting Eq . s ( 2 ) and ( 4 ) into Eq . ( 1 ) results in models specific to the observation method :",Supplement,Paper,Introduce,Data processing costs for three posture assessment methods,https://www.diva-portal.org/smash/get/diva2:690328/FULLTEXT01.pdf
"We further show that the effects of high larval population density persist through adulthood , as C . elegans larvae raised at high densities exhibit significantly reduced adult lifespan and respond differently to exogenous chemical signals compared to larvae raised at low densities , independent of density during adulthood . Our results demonstrate how inter - organismal signaling during development regulates reproductive maturation and longevity . PLOS Genetics | April 10 , 2017 1 / 21 Larval crowding accelerates C . elegans development and reduces lifespan",Supplement,Paper,Introduce,Larval crowding accelerates C. elegans development and reduces lifespan,https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006717
"Tibetan participants were recruited from two districts during spring and summer of year 2012 : 23 individuals are from Tsum region in Gorkha district and 30 individuals are from Upper Mustang region in Mustang district . All participants were born and raised in high altitude regions (& gt ; 3 , 000 m ). These 53 individuals are a subset of a bigger cohort recruited at the same time , and selected for PLOS ONE | April 27 , 2017 6 / 12 The population structure of Tibetans this study based on harboring negligible level of South Asian ancestry . Saliva samples were collected using OG - 500 Oragene saliva collection kits ( DNA Genotek , Inc ., Ottawa , ON , Canada ) and genomic DNA was extracted using PT - L2P reagents ( DNA Genotek , Inc ., Ottawa , ON , Canada ) following manufacturer ’ s protocol . Genome - wide genotyping experiments were performed at the Genomics facility at the University of Chicago , using both Illumina HumanCore v1 - 0 ( 298 , 931 markers ) and HumanOmniExpress - 24 v1 . 0 ( 716 , 503 markers ) arrays .",Supplement,Paper,Introduce,A longitudinal cline characterizes the genetic structure of human populations in the Tibetan plateau,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0175885
"Nurses at the 39 sites were instructed to apply the case definition to all presenting patients and to record and report demographic characteristics ( name , age , sex , place of residence ), symptom ( fever , rash , mucosal bleeding anorexia , arthralgia , abdominal pain , persistent vomiting , lethargy , fluid retention , liver enlargement , tourniquet test ), date of symptom onset , rapid diagnostic test result , and hospitalisation status data for patients that met the definition on a provided form . The first new sentinel sites began reporting data in epidemiological week 33 / 2016 with others contributing by epidemiological week 42 / 2016 . PLOS ONE | June 7 , 2018 8 / 15 Enhanced surveillance during a large dengue outbreak in Solomon Islands , 2016 - 17 Data were transferred from surveillance sites to the Honiara - based MHMS surveillance unit on a weekly basis by various means , including collection of reporting forms by MHMS staff ( number of surveillance sites = 17 , 44 %), hand delivery of forms to MHMS staff ( number of surveillance sites = 12 , 31 %), by email ( number of surveillance sites = 4 , 10 %), and verbally by telephone ( number of surveillance sites = 6 , 15 %). MHMS surveillance staff manually entered data received into an Excel ® database for analysis . The resulting information was presented in a weekly report sent to ~ 120 recipients including staff of national and provincial health services , other government departments , development partners and relevant SI - based non - government organisations .",Supplement,Paper,Introduce,"Experience from a large dengue outbreak in Solomon Islands, 2016-17",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5991673/
"Therefore , ADAPT is a very powerful approach to study longitudinal development of diseases and therapeutic interventions and uses experimental data to infer adaptations in the system [ 36 , 37 , 39 , 40 ]. In previous studies , ADAPT has been applied to study hepatic steatosis [ 37 , 39 ], and treatment of type 2 diabetes [ 40 ], but has not yet been applied to study the full metabolic complexity of MetS . PLOS Computational Biology | June 7 , 2018 2 / 19 In vivo and in silico dynamics of the development of Metabolic Syndrome Therefore , we aimed to design a computational , data - driven approach to study the longitudinal and progressive dynamics of the majority of metabolic alterations of MetS , i . e . obesity , glucose intolerance , insulin resistance and dyslipidemia . We employed a systems biology methodology that integrates three main concepts to infer metabolic adaptations during MetS development : i ) the long - term simulation method ADAPT , combined with ii ) a newly developed in silico MetS model that describes the metabolic processes involved in whole - body carbohydrate and lipid metabolism , and integrated with iii ) time - series data obtained from an in vivo MetS model .",Supplement,Paper,Introduce,In vivo and in silico dynamics of the development of Metabolic Syndrome,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006145
"Three steps were necessary in applying the propensity score method to the Medicare HOS data . First , self - comPage 4 of 12 ( page number not for citation purposes ) Health and Quality of Life Outcomes 2003 , 1 _CITE_",Supplement,Paper,Introduce,Utilization of the propensity score method: an exploratory comparison of proxy-completed to self-completed responses in the Medicare Health Outcomes Survey,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC222919/
"It is equal to Actual Mapped +( Expected Unmapped - Actual Unmapped ) while Reported correct is the total number of correctly mapped reads . Hatem et al . BMC Bioinformatics 2013 , 14 : 184 Page 22 of 25 the Human genome using ART . The maximum allowed error rate was 5 %, i . e ., 5 mismatches in that case . The results for this experiment are shown in Table 3 .",Supplement,Paper,Introduce,Benchmarking short sequence mapping tools,https://link.springer.com/article/10.1186/1471-2105-14-184
"( Notice that the gene annotations in the GPKB are not considered in such transitive relationship based annotation identification ; they are only used for comparison with the identification results .) Overall , we obtained a recall of 90 . 56 % ( 99 . 09 %, 48 . 65 %, 99 . 03 % and 99 . 97 % recall for the gene to pathway , gene to biological function , gene to transcript and gene Masseroli et al . BMC Genomics 2015 , 16 ( Suppl 6 ): S5 Page 7 of 16 Figure 3 GPKB Web interface : Search result page . The transferred new annotation of the Insulin - like growth factor 2 ( somatomedin A ) ( IGF2 ) human gene to the Insulin - like growth factor binding biological function is shown . ( Notice the external links on all IDs , the “ Show new transitive relationships only “ button and the “ Download “ icon .)",Supplement,Paper,Introduce,Detection of gene annotations and protein-protein interaction associated disorders through transitive relationships between integrated annotations,https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-16-S6-S5
"A change in the set of exporters of a product is thus necessary to cause the observed trajectories . The finding of Eq 5 suggests a scheme where most of the products are at their asymptotic market , with the logPRODY reflecting their Complexity . Their moving away from the asymptotic market is unpredictable and accompanied , on average , by a decrease of the competition PLOS ONE | May 17 , 2017 6 / 20 The complex dynamics of products and its asymptotic properties on the market for a given product . Their return to asymptotic market is instead much more regular and evident ( see Fig 1 panel a ) and corresponds to an increase in competition . This mechanism seems to be reliable enough that we can describe the motion on the plane with an equation that connects velocities to competition , and we can confidently say that vertical motion on the plane corresponds to shifts in the market composition .",Supplement,Paper,Introduce,The complex dynamics of products and its asymptotic properties,https://www.researchgate.net/publication/308807559_The_complex_dynamics_of_products_and_its_asymptotic_properties
"Then for each day of BC data we minimize the effects of rainfall by first calculating the residual : residual = yi — y Where yˆ is the predicted BC and yi is the observed BC for that day . We then subtracted the residual from our original BC data to get rainfall - adjusted BC concentration useful to compare variation between the biomass burning months and non - biomass burning months and general longer - term trends . PLOS ONE | May 8 , 2018 5 / 21 Hanoi , Vietnam air pollution",Supplement,Paper,Introduce,"Analysis of air pollution over Hanoi, Vietnam using multi-satellite and MERRA reanalysis datasets",https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196629
"Carreira et al . [ 35 ] compared a group provided with a thumb splint for 90 days to a group who only used the splint for evaluation . While the group who used the splint for 90 days showed superior results in terms of pain reduction ( significant large ES : - 1 . 1 ( 95 % CI - 1 . 90 to - 0 . 30 )), non - significant PLOS ONE | March 14 , 2018 11 / 42 Prosthetic and orthotic interventions : A systematic review small effect sizes were calculated for the remaining function and dexterity measures ( grip and pinch strength , upper limb dexterity and DASH ). The first of two studies which examined knee orthoses in individuals with osteoarthritis compared a knee brace group to a control group [ 58 ]. The knee brace group had superior pain reduction ( significant medium ES : - 0 . 75 ( 95 % CI - 1 . 16 to - 0 . 34 )) but no differences in KOOS and patellofemoral bone marrow lesion volume results .",Supplement,Paper,Introduce,A systematic review of randomised controlled trials assessing effectiveness of prosthetic and orthotic interventions,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0192094
"Behavioral National Sciences and Engineering Council ( NSERC ) to PPO . Competing interests : The authors have declared that no competing interests exist . PLOS ONE | March 1 , 2018 2 / 21 Social consistency and plasticity across changes in population density variation associated with animal personality and plasticity may be important for individuals to adapt to changes in population density [ 28 ]. For instance , at low local density , selection favoured fast exploring great tits , Parus major , while at high density , selection favoured slow exploring birds , presumably because temporal variation in local density selects for a range of personality types [ 4 ]. Elk , Cervus canadensis , are gregarious ungulates that exhibit sexual segregation outside of the breeding season [ 29 ].",Supplement,Paper,Introduce,Consistent individual differences and population plasticity in network-derived sociality: An experimental manipulation of density in a gregarious ungulate,https://pdfs.semanticscholar.org/19f0/4093a49a817a0cd1352fd82aeea1c21a27e4.pdf
"Chromatin occupies a major part of the nuclear space and requires a high level of organization . It is now evident that the higher level organization of the nucleus affects gene function ( Cremer et al ., 2006 ; Fraser and Bickmore , 2007 ; Meaburn et al ., 2007 ; de Wit and van Steensel , 2009 ; Nunez et al ., 2009 ). Chromosomes are positioned in preferred locations within the nucleus , so - called chromosome territories ( CTs ; Cremer and Cremer , 2001 ), which seem to correlate This article was published online ahead of print in MBoC in Press ( ) on September 8 , 2010 . Address correspondence to : Angus I . Lamond ( angus @ lifesci . dundee . ac . uk ).",Supplement,Paper,Introduce,High-Resolution Whole-Genome Sequencing Reveals That Specific Chromatin Domains from Most Human Chromosomes Associate with Nucleoli,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2965689/
"The genomic targets can be given by their extended genomic sequence or genomic coordinates . ( 2 ) Given a specified nucleotide sequence , CRISTA identifies all potential targets within it ( i . e ., those followed by ‘ NGG ’) and ranks these according to the predicted cleavage score . ( 3 ) Given an sgRNA and a specified genome ( currently 230 genome assemblies PLOS Computational Biology | October 16 , 2017 5 / 24 A machine learning approach for predicting CRISPR - Cas9 cleavage efficiencies are supported encompassing vertebrates , plants , yeast , insects , and deuterostomes [ 49 , 50 ]), CRISTA detects possible off - targets throughout the genome . As opposed to most currently available alternatives , the off - targets detected by CRISTA also include DNA / RNA bulges . A comprehensive detection of off - targets using the pairwise alignment approach described above is computationally demanding .",Supplement,Paper,Introduce,A machine learning approach for predicting CRISPR-Cas9 cleavage efficiencies and patterns underlying its mechanism of action,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005807
"[ 14 ] utilized the propensity score methodology in a nonrandomized study of amiodarone and mortality among acute myocardial infarction patients with atrial fibrillation . Patient characteristics that were associated with prescriptive use of amiodarone were incorporated into a regression analysis through the use of the propensity score methodology . Assessing the difference between proxy - completed and self - completed responses in survey research is analogous to nonrandomized treatment studies such as the two disPage 3 of 12 ( page number not for citation purposes ) Health and Quality of Life Outcomes 2003 , 1 cussed above . Proxy - completed responses can be conceptualized partly as the results of selection bias , and partly the result of true differences between proxy and selfrespondents . Generally , proxy respondents who answer survey items for the respondent occupy a specific role in the respondent ' s life such as a family member ( spouse , child ), friend , or professional caregiver .",Supplement,Paper,Introduce,Utilization of the propensity score method: an exploratory comparison of proxy-completed to self-completed responses in the Medicare Health Outcomes Survey,https://hqlo.biomedcentral.com/articles/10.1186/1477-7525-1-47
"[ 49 ] studied an experimental system in which apoptosis was chemically induced in dividing cells both in the thymus and the periphery . In otherwise healthy mice , they found that the subsequent approximately 50 % drop in naive T - cell numbers was equivalent to that incurred by thymectomy , but the same treatment in Tx mice had no impact on naive T - cell numbers over a 2 - wk period . These observations are consistent with the consensus that the thymus is the dominant source of naive T - cell production in mice PLOS Biology | April 11 , 2018 15 / 20 Naive T cells acquire homeostatic fitness as they age and that there is little or no increase in peripheral division to compensate for thymectomy [ 52 ]. Thomas - Vaslin et al . found that in healthy mice , naive T - cell numbers returned to normal levels within 10 wk of treatment .",Supplement,Paper,Introduce,Age is not just a number: Naive T cells increase their ability to persist in the circulation over time,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5894957/
"The evolutionary processes underlying the origin and maintenance of species diversity in tropical forests — some of the oldest and most diverse ecosystems on Earth — have long been a source of fascination and debate among biologists [ 1 , 2 ]. Although tropical forests are known to be species rich , precise estimates of their diversity , and variation across space , are difficult to obtain due to limitations of sampling and our ability to accurately circumscribe species . PLOS ONE | June 15 , 2018 1 / 20 Reconciling species diversity in Canarium funders had no role in study design , data collection and analysis , decision to publish , or preparation of the manuscript . Competing interests : The authors have declared that no competing interests exist . Refining these estimates is important , however , as it directly impacts a variety of fields that rely on species as units of analysis , including conservation , macroecology , and macroevolution [ 3 , 4 ].",Supplement,Paper,Introduce,"Reconciling species diversity in a tropical plant clade (Canarium, Burseraceae)",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6003679/
"A recent study indicated a higher incidence of melioidosis in Malaysia among children with thalassemia that significantly decreased with intravenous iron chelation therapy [ 25 ]. Consistent with these observations during human melioidosis , we established in a murine experimental model that FAC - derived iron supplementation tends to stimulate both systemic and hepatic iron load leading to higher bacterial numbers in organs as well as release of cytokines and MPO . On the other hand , the DFOmediated limitation of iron availability improves outcome of B . pseudomallei - infected mice as shown by reduced bacterial burden and inflammatory response . PLOS Neglected Tropical Diseases | January 12 , 2018 18 / 25 B . pseudomallei benefits from changing host iron balance Thus , it is reasonable to propose that manipulation of host iron metabolism or direct targeting of iron may represent a new therapeutic approach during melioidosis . In this context , Nifedipine , a calcium channel blocker , can induce Fpn expression , thus mobilizing tissue iron and improving host resistance to Salmonella [ 76 ]. Recent evidence further suggest that an inverse agonist of estrogen related receptor gamma ( ERRγ ) is able to ameliorate Salmonellainduced hypoferremia by reduction of ERRγ - mediated hepcidin expression in hepatocytes leading to a better control of infection [ 55 ].",Supplement,Paper,Introduce,Burkholderia pseudomallei modulates host iron homeostasis to facilitate iron availability and intracellular survival,https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0006096
"Also , it is not surprising that haplotype frequencies estimated from the multiallelic data set are found to be less accurate than those estimated from SNPs , given the more complex nature of the data . The RCI is a relative measure , and illustrates not so much the accuracy of the algorithm , rather the effect of additional missing data . The results displayed in Tables 2 and 4 show that the algorithm handles the increase in the proportion of unknown alleles equally well for both SNPs and multiallelic data , although it should be pointed out that the RCI measure Page 9 of 13 ( page number not for citation purposes ) BMC Bioinformatics 2004 , 5 : 188 hˆ gives no indication of the accuracy of the point estimates , and should generally be considered in tandem with a measure such as D ( h , ). Interestingly , the results for the hˆ multiallelic data set were achieved despite departure from Hardy - Weinberg equilibrium ( HWE ) at two of the seven loci ( see Methods section ). Although this technique relies on the assumption of HWE , Niu et al .",Supplement,Paper,Introduce,Haplotype frequency estimation error analysis in the presence of missing genotype data,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC544188/
"Other DNA sensor genes in the SLEmetaSig100 signature are key enzymes involved in breakdown of DNA including nucleases such as DNASE1 , DNASE1lL3 , TREX1 , and TREX2 . Importantly , a loss - of - function variant of DNASE1L3 causes a familial form of SLE . Mutations PLOS ONE | July 5 , 2018 11 / 16 Identification of a gene - expression predictor for diagnosis and personalized stratification of lupus patients in TREX1 are associated with familial chilblain lupus and are also associated with the inflammatory disorder Aicardi - Goutieres syndrome . The SLEmetasig100 emphasizes the importance of including DNA processing pathways , which may capture the contributions of proteostasis and ER stress to SLE pathogenesis . Lupus nephritis is a frequently seen complication in patients with SLE and is known to significantly reduce the survival of SLE patients .",Supplement,Paper,Introduce,Identification of a gene-expression predictor for diagnosis and personalized stratification of lupus patients,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198325
"Each dataset is expressed by a matrix X = { xi , j }, where i = 1 , ..., T and j = 1 , ..., F are for time and frequency , respectively . The entries , xi , j , are intensities corresponding to the level of vocalization . PLOS ONE | May 9 , 2018 3 / 26 Functional clustering of mouse USV data",Supplement,Paper,Introduce,Functional clustering of mouse ultrasonic vocalization data,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196834
"Ozer and Sezerman BMC Genomics 2015 , 16 ( Suppl 12 ): S7 Page 7 of 19 _CITE_",Supplement,Paper,Introduce,A novel analysis strategy for integrating methylation and expression data reveals core pathways for thyroid cancer aetiology,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=2267bfbf65b7f076b7d0e20f655ac650c9180eb8
"Merrill et al . Journal of Biomedical Semantics 2014 , 5 ( Suppl 1 ): S3 Page 6 of 12 public data , and whose SPARQL endpoint is publicly available ; the other which contains the entire data and is kept secure using an API key . The secure , administrative endpoint is used by R scripts ( described in the next section ) to access data for query and analysis by members who have access authorization . The other benefit of having decoupled stores is that we have the flexibility of optimizing the performance and scalability of each store independently from the other .",Supplement,Paper,Introduce,Semantic Web repositories for genomics data using the eXframe platform,https://www.researchgate.net/publication/264501183_Semantic_Web_repositories_for_genomics_data_using_the_eXframe_platform
"While no distinct policy was created to establish medicine prices in the RPI , the management applied minimal markups sufficient to cover their estimated operating costs . Retail mark - ups initially averaged approximately 30 - 50 % for most medicines . Surprisingly , as the rural pharmacy initiative emerged , the private pharmacies in the district center appeared to be changing their prices on key mediPage 2 of 15 ( page number not for citation purposes ) International Journal for Equity in Health 2009 , 8 : 43 _CITE_",Supplement,Paper,Introduce,Towards equitable access to medicines for the rural poor: analyses of insurance claims reveal rural pharmacy initiative triggers price competition in Kyrgyzstan,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2803474/
"Different approaches have been proposed to evaluate the performance of automatic alignment systems and the output they produce . These include the manual analysis of correspondences in the alignment [ 7 ], comparing the alignment against a reference alignment [ 4 , 5 ], measuring the extent to which the alignment preserves the structural properties of the input ontologies [ 18 ], checking the coherence of the alignment with respect to the input ontologies [ 19 ], and evaluating the alignment within an application ( end - to - end evaluation ) [ 20 ], while the comparison against ( preferably manually created ) reference alignments is by far the most common evaluation approach that has been used in international evaluation campaigns for many years now [ 21 ]. However , although the manual creation of ontology alignments is known to be time consuming and expensive , and in the same time inherently error - prone ( Euzenat even states that “ humans are not usually very good at Beisswanger and Hahn Journal of Biomedical Semantics 2012 , 3 ( Suppl 1 ): S4 Page 13 of 14 matching ontologies manually ”, p . 202 in [ 1 ]), not much work has been published on quality assurance of existing manual alignments , yet . This particularly concerns technical aspects , which strongly affect the reusability of alignments ( target of our Checks 1 to 5 ). Regarding validity aspects ( target of our Checks 6 to 10 ), some of the evaluation approaches proposed for the analysis of automatically created alignments could be adopted , such as the structural [ 18 ] or alignment coherence analysis [ 19 ].",Supplement,Paper,Introduce,Towards valid and reusable reference alignments — ten basic quality checks for ontology alignments and their application to three different reference data sets,https://link.springer.com/article/10.1186/2041-1480-3-S1-S4
"Measurement of lipid content . The sulfo - phospho - vanillin ( SPV ) method was used to determine the lipid content of C . sorokiniana UTEX 1230 as reported previously [ 25 , 26 ]. The PLOS ONE | July 3 , 2018 3 / 19 Impacts of monosaccharides to the growth of Chlorella sorokiniana OD530 of the culture was measured with a spectrophotometer ( 7200 Unico ). For construction of a standard curve , a stock solution was prepared by dissolving 100 mg triolein in 100 mL chloroform . After 0 , 10 , 20 , 30 , 40 , 50 , 60 , 70 and 80 µL aliquots of stock solution were blown dry in a fume hood , 100 µL of distilled water and 1 mL of sulfuric acid were added to the residues and mixed by pipetting .",Supplement,Paper,Introduce,Characterization of Chlorella sorokiniana growth properties in monosaccharide-supplemented batch culture,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6029798/
"The images contain thousands of spots , one spot for every cluster , with a cluster representing one read . Each of these files must be analyzed to designate one of McCormick et al . Silence 2011 , 2 : 2 Page 7 of 19 the four nucleotide bases ( Illumina ) or color space call ( SOLiD ) for each spot on the image , and then the data from each image for the same spot must be combined to give full sequence reads , one per spot . Each technology has its own specifications regarding the file formats used ; for example , Illumina recently changed its standard output format from . qseq , which uses ASCII - 64 encoding of Phred quality scores ( a widely accepted metric to characterize the quality of DNA sequences ), to . bcl , a binary format containing base call and quality for each tile in each cycle . SOLiD systems use . csfasta to encode color space calls and . qual files to record the quality values for each sequence call .",Supplement,Paper,Introduce,"Experimental design, preprocessing, normalization and differential expression analysis of small RNA sequencing experiments",https://silencejournal.biomedcentral.com/articles/10.1186/1758-907X-2-2
"We conducted new analyses to inform future estimates . We found that acute watery diarrhoea was associated with 87 % ( 95 % CI 83 – 90 %) of U5 diarrhoea hospitalisations based on data from 84 hospital sites in 9 countries , and 65 % ( 95 % CI 57 – 74 %) of U5 diarrhoea deaths based on verbal autopsy reports from 9 country sites . We reanalysed data from the Global Enteric Multicenter Study ( GEMS ) and found 44 % ( 55 % in Asia , and 32 % in Africa ) rotavirus - positivity among U5 acute watery diarrhoea hospitalisations , and 28 % rotavirus - positivity among U5 acute PLOS ONE | September 11 , 2017 1 / 18 Estimating rotavirus deaths in children aged < 5 years watery diarrhoea deaths . 97 % ( 95 % CI 95 – 98 %) of the U5 diarrhoea hospitalisations that tested positive for rotavirus were entirely attributable to rotavirus . For all clinical syndromes combined the rotavirus attributable fraction was 34 % ( 95 % CI 31 – 36 %).",Supplement,Paper,Introduce,"Estimating global, regional and national rotavirus deaths in children aged <5 years: Current approaches, new analyses and proposed improvements",https://pubmed.ncbi.nlm.nih.gov/28892480/
"[ 20 ], profiling of N - glycosylated proteins in the serum of advanced breast cancer patients was performed in order to discover serum biomarkers for chemoresistance . Twenty three proteins were identified to be differentially expressed between patients defined as sensitive and patients defined as resistant to docetaxel and doxorubicin treatment . The expression pattern of several proteins was Abelson BMC Bioinformatics 2014 , 15 : 53 Page 7 of 10 later validated in independent samples . Interestingly , in our analysis we found transcripts encodes to 10 out of the 23 aforementioned proteins ( Additional file 1 ). Even though patients bearing different type of cancer and under different treatment regimen were investigated , it is very unlikely that these results are consequence of chance ( p = 9 . 29e - 20 by hypergeometric probability density test ); This is further supported by other studies , which demonstrate elevated expressions of different serum proteins found in our analysis and in patients with chemoresistant tumors [ 21 , 22 ].",Supplement,Paper,Introduce,Glycosylation-Based Serum Biomarkers for Cancer Diagnostics and Prognostics,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4609776/
"p ( y — x , w ) = Žitnik et al . BMC Bioinformatics 2015 , 16 ( Suppl 16 ): S1 Page 6 of 16 when mentions that are arguments of a certain relationship appear on longer distances . For example , mentions spoVG and E sigma H should be related via the Interaction . Transcription relationship . However , this relationship cannot be extracted from representation that considers only consecutive mention pairs .",Supplement,Paper,Introduce,Sieve-based relation extraction of gene regulatory networks from biological literature,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-16-S16-S1
"[ 29 ] use the APG tree as the backbone for a supertree used to analyze wood traits in 608 species ; Walls [ 44 ] uses different versions of the APG tree ( and the tree from [ 47 ]) in an analysis of leaf vein patterns ; in an analysis of scaling relationships in phylogenetic diversity , Morlon , et al . [ 23 ] heavily supplement the APG Stoltzfus et al . BMC Research Notes 2012 , 5 : 574 Page 7 of 15 backbone with other phylogenetic results . A fifth study [ 48 ] uses the APG tree from Phylomatic as a standard of comparison to validate its own tree . These examples reflect the ready availability of a mega - tree covering plants .",Supplement,Paper,Introduce,Sharing and re-use of phylogenetic trees (and associated data) to facilitate synthesis,https://link.springer.com/article/10.1186/1756-0500-5-574
"Our study demonstrates the population prevalence of clinical signs / symptoms and EBOV CT values over time in a large , diverse cohort of patients with EVD , as well as associations between symptoms / EBOV CT values and mortality . These findings have implications on surveillance , operational planning , and clinical care for future EVD outbreaks . PLOS Neglected Tropical Diseases | July 19 , 2017 1 / 17 Natural history of Ebola Virus Disease decision to publish , or preparation of the Author summary manuscript . Previous studies of Ebola Virus Disease ( EVD ) have focused on clinical symptoms and Competing interests : The authors have declared viral load ( or its proxy of cycle threshold value ) in the blood of patients measured the day that no competing interests exist . they begin medical care .",Supplement,Paper,Introduce,The natural history of acute Ebola Virus Disease among patients managed in five Ebola treatment units in West Africa: A retrospective cohort study,https://www.researchgate.net/publication/318596960_The_natural_history_of_acute_Ebola_Virus_Disease_among_patients_managed_in_five_Ebola_treatment_units_in_West_Africa_A_retrospective_cohort_study
"Heterogeneity in phenotype development The clinical presentation of MetS in humans is highly heterogeneous and spans over decades . Male E3L . CETP mice fed a high - fat diet supplemented with cholesterol develop MetS within a time scale of several months . Although all of these animals have the same genetic background , received PLOS Computational Biology | June 7 , 2018 11 / 19 In vivo and in silico dynamics of the development of Metabolic Syndrome the same diet and were kept and monitored in a controlled , standardized environment , this in vivo model did show heterogeneity in phenotypic presentation . In addition , the manifestation of the full repertoire of metabolic alterations associated with MetS makes this a useful in vivo model , whereas other animal models only describe one or partial metabolic aspects of MetS [ 53 – 59 ]. Using a traditional statistical approach , both this heterogeneity and limited datasets comprising of low number of animals are problematic .",Supplement,Paper,Introduce,In vivo and in silico dynamics of the development of Metabolic Syndrome,https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006145
"[ 36 ]. All efforts were made to ensure the welfare , and reduce stress of the animals , with the addition of full personal protective equipment worn by all team members throughout the process to prevent human - primate disease transmission . A veterinarian specialised in the capture and anaesthesia of wildlife performed the darting , having previously conducted an evaluation of PLOS ONE | March31 , 2017 3 / 23 Evaluating home range estimators using GPS collars the area and target individual to minimise risk to the animals . Animals were anaesthetised using Zoletil 100 ( Tiletamine + Zolazepam ; 6 – 10 mg / kg ), and a prophylactic dose of Alamycine LA ( 20 mg / kg ) and Ivermectine ( 0 . 2 mg / kg ) was given as a preventative measure to assist in the post - anesthesia recovery . Anaesthesia and the vital signs were monitored throughout the procedure .",Supplement,Paper,Introduce,Long-Tailed Macaque Response to Deforestation in a Plasmodium knowlesi-Endemic Area,https://link.springer.com/article/10.1007/s10393-019-01403-9
"Notably , the detected Ct values for a few selected genes were not proportionally coordinated with basemean values . One obvious outlier is MDP0000211280 , whose expression levels showed unexpected high Ct values . The higher than expected Ct values are more noticeable in PLOS ONE | September 21 , 2017 8 / 17 Reference genes for normalizing gene expression in apple roots the tissue types of “ 115 Rs ” and “# 75 Pu ” tissues . Both lines (# 115 and # 75 ) are known to be susceptible to these pathogens ( personal communication ). This observation may indicate its expression was suppressed in selected genotypes during pathogenesis .",Supplement,Paper,Introduce,Using RNA-seq data to select reference genes for normalizing gene expression in apple roots,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0185288
"aegypti has a substantially higher optimum and maximum temperature than Ae . albopictus ( Fig 2 ) due to its greater rates of adult survival at high temperatures ( see Supplementary Materials for sensitivity analyses ). PLOS Neglected Tropical Diseases | April 27 , 2017 4 / 18 Temperature predicts Zika , dengue , and chikungunya transmission",Supplement,Paper,Introduce,"Detecting the impact of temperature on transmission of Zika, dengue, and chikungunya using mechanistic models",https://journals.plos.org/plosntds/article?id=10.1371/journal.pntd.0005568
"95 % credible intervals are shaded . The thin grey line shows the cumulative distribution of grid - cell level densities in the world . The most notable finding is that completeness has a U - shaped relationship with density . As shown in panel A of Fig 2 , OSM is most likely to be complete at low and high densities . Thus , interurban roads that traverse areas with minimal population are largely present in OSM , and high - density urban areas , with many potential local contributors and good Internet access , are also well mapped .",Supplement,Paper,Introduce,The world’s user-generated road map is more than 80% complete,https://www.researchgate.net/publication/319052118_The_world's_user-generated_road_map_is_more_than_80_complete
"Since , for purposes of the contamination warning system , the syndromes monitored are the same for both acute and gradually developing events caused by biological , radiological , or chemical contaminants , the timeliness of anomaly detection coupled with subject matter expertise during subsequent alert investigations determines what type of contaminant ( s ) may be responsible . Haas et al . International Journal of Health Geographics 2011 , 10 : 22 Page 3 of 10 An example timeline for a contamination scenario is depicted in Figure 1 , demonstrating symptom onset , actions of an exposed individual , and the unique data outputs which can be analyzed by public health surveillance systems . The timeline illustrated in this figure is based on the expected symptom onset and potential health - seeking actions that would occur following exposure to a carbamate pesticide . Note that Poison Control Center ( PCC ) data entry is initiated by poison control specialists ( into the National Poison Data System [ 10 ]) immediately upon receipt of a call to the hotline .",Supplement,Paper,Introduce,Automated surveillance of 911 call data for detection of possible water contamination incidents,https://ij-healthgeographics.biomedcentral.com/articles/10.1186/1476-072X-10-22
"Large SNP datasets were available from cattle and sheep populations , where multiple animals per breed were drawn from a diversity of breeds and geographic regions . Clear evidence for population substructure was evident in cattle , which is composed of two sub - species ( Bos taurus and Bos indicus ) Hudson et al . BMC Bioinformatics 2014 , 15 : 66 Page 5 of 21 Figure 4 Compression efficiency against heterozygosity resolves non - human populations . Compression efficiency ( y - axis ) against heterozygosity ( x - axis ) for the four non - human data sets : ( A ) cattle ( n = 1 , 800 ), ( B ) sheep ( n = 1 , 222 ), ( C ) mouse ( n = 49 ) and ( D ) dog ( n = 83 ). The discrimination afforded by genome - wide compression efficiency and heterozygosity is effective in all species under consideration .",Supplement,Paper,Introduce,The world’s user-generated road map is more than 80% complete,https://www.researchgate.net/publication/319052118_The_world's_user-generated_road_map_is_more_than_80_complete
"Community - driven collections of images and ground truth , as well as “ model zoos ,” will be instrumental for this . We have also begun creating libraries ( Keras - ResNet [ https :// github . com / broadinstitute / keras - resnet ] and Keras - RCNN [ https :// github . com / broadinstitute / keras - rcnn ]) that will provide the foundation for interfaces that allow biologists to annotate , train , and use deep learning models . We expect that over time , PLOS Biology | July 3 , 2018 10 / 17 these models will reduce the amount of time biologists spend tuning classical image processing algorithms to identify biological entities of interest in images .",Supplement,Paper,Introduce,CellProfiler 3.0: Next-generation image processing for biology,https://www.researchgate.net/publication/326164238_CellProfiler_30_Next-generation_image_processing_for_biology
"We also suggest that assessment of the fitness of metadata for use be considered from the ‘ demand side ’ by asking how data have typically been used to best effect in the creation of biodiversity knowledge and policy . There are many technical publications - for example : Voss and Emmons ‘ Mammalian diversity in neotropical lowland rainforests : a preliminary assessment ’ [ 16 ], the US Fish and Wildlife Service ’ s ‘ Statistical guide to data analysis of avian monitoring programs ’ [ 17 ] or Agosti et al .’ s ‘ Ants : standard methods for measuring and monitoring biodiversity ’ [ 18 ] - that provide detailed descriptions of common data collection methods or of Moritz et al . BMC Bioinformatics 2011 , 12 ( Suppl 15 ): S1 Page 4 of 10 statistical processes applied to biodiversity data . Recently , the European Union Framework Projects 6 project EDIT ( European Distributed Institute for Taxonomy ) has developed a complete workflow , from data collection in the field to assembly of datasets and analyses [ 19 , 20 ]. These and many other works provide guidance in the development of standard ontologies for data description .",Supplement,Paper,Introduce,Towards mainstreaming of biodiversity data publishing: recommendations of the GBIF Data Publishing Framework Task Group,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-S15-S1
"Fig 10 shows the two most dominant bias types for the four evaluated sites on sample A . These bias types and their associated transcript length histograms are similar for all sites . One of the clusters consists of distributions concentrated around the middle of comparatively short transcripts while the other cluster contains slightly 3 ’ biased distributions PLOS Computational Biology | May 15 , 2017 18 / 25 Mixture models yield accurate transcript concentration estimates from RNA - Seq data for comparatively long transcripts . Also the remaining clusters are similar for all sites as can be seen from Fig J to Fig P in S2 Appendix . Biases are also similar across samples as can be seen for Fig M to Fig P in S2 Appendix which show clusters for samples A to D of BGI .",Supplement,Paper,Introduce,Mixture models reveal multiple positional bias types in RNA-Seq data and lead to accurate transcript concentration estimates,https://europepmc.org/articles/pmc5448817/bin/pcbi.1005515.s002.pdf
"Heritability measured separately within each country was significant only in the Netherlands , at 26 % ( 12 %– 60 %) ( S2 Table , N = 434 , ΔAIC = – 12 . 2 for OU compared to the null model ). In Switzerland , the largest cohort in this study , GSVL was not significantly heritable ( S2 Table , N = 742 , ΔAIC = + 2 . 1 for OU compared to the null model ). This could reflect the limited genetic diversity of our Swiss samples ; in other countries , the lack of detected PLOS Biology | June 12 , 2017 9 / 26 Viral genetic variation explains variability in HIV - 1 pathogenesis heritability is most likely due to limited power to detect a phylogenetic signal . In males infected by subtype B viruses ( N = 1 , 446 ), GSVL heritability was 16 % under BM and 32 % under OU , but heritability was not significant in females ( N = 135 ). In MSM infected by subtype B viruses ( N = 1 , 196 ), GSVL heritability was 17 % under BM and 30 % under OU , but heritability was not significant in injecting drug users ( IDUs ) ( N = 110 ) and heterosexuals ( N = 211 ).",Supplement,Paper,Introduce,Viral genetic variation accounts for a third of variability in HIV-1 set-point viral load in Europe,https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2001855
"Interestingly , the enhancers found in TAD1 form two closely located clusters ( E2 / E3 and E4 - E7 ), embedded into the genes of S100 family . These enhancer clusters showed extensive long - range intra - TAD chromatin contacts with multiple genes in the central part of the EDC ( TAD3 and TAD4 ) activated during terminal keratinocyte differentiation , suggesting that they might serve as the locus - control regions or super - enhancers for the EDC genes . In addition , PLOS Genetics | September 1 , 2017 18 / 32 Chromatin interactome of multi - TAD keratinocyte - specific gene locus we identified the gene enhancer ( E9 ) spatially interacting with Flg gene promoter ( Fig 4D ). These enhancers have been previously identified among the highly - conserved non - coding regions in several mammalian genomes and showed the activity in the reporter assay in cultured keratinocytes [ 33 ]. It will be important to determine if this conserved enhancer controls Flg gene expression in normal and diseased epidermis , as the defects in Flg gene and changes in its expression are associated with ichthyosis vulgaris , the most common disorder of epidermal differentiation , and also serve as strong risk factors for atopic eczema [ 62 ].",Supplement,Paper,Introduce,5C analysis of the Epidermal Differentiation Complex locus reveals distinct chromatin interaction networks between gene-rich and gene-poor TADs in skin epithelial cells,https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006966
"It is well known that most of the problems arising from learning on class - imbalanced data arise in the region where the two class - specific densities overlap . When the difference between the class - specific densities is large enough , the class - imbalance does not cause biased classification for the classifiers that we considered , even in the highdimensional setting [ 7 ]. The other reason is that when Blagus and Lusa BMC Bioinformatics 2013 , 14 : 106 Page 13 of 16 a very large number of variables is measured for each subject , in most situations the vast majority of variables do not differentiate the classes and the signal - to - noise ratio can be extreme . For example , Sotiriou et al . [ 36 ] identified 606 out of the 7 , 650 measured genes as discriminating ER + from ER - samples in their gene expression study ; at the same time ER status was the known clinico - pathological breast cancer phenotype for which the largest number of variables was identified ( 137 out of the 7 , 650 genes discriminated grade , 11 out of the 7 , 650 node positivity , 3 out of the 7 , 650 tumor size and 13 out of the 7 , 650 menopausal status ).",Supplement,Paper,Introduce,SMOTE for high-dimensional class-imbalanced data,https://link.springer.com/article/10.1186/1471-2105-14-106
"Of these , between seven and nine features were selected as significantly different between the two groups ( Table 2 ). At peptide level , Tuli et al . Proteome Science 2012 , 10 : 13 Page 5 of 11 Figure 2 Base peak chromatograms of the MassPrep peptides . The chromatograms are zoomed into each of the 13 unique features whose m / z and retention time values match with those of the MassPrep peptides , in comparison of serum with spike - in peptides (+ MassPrep ) and serum alone (- MassPrep ) groups . Tuli et al .",Supplement,Paper,Introduce,Using a spike-in experiment to evaluate analysis of LC-MS data,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3311572/
It will be published in the upcoming leading ACL conference . ( ),Supplement,Paper,Produce,"A model species for agricultural pest genomics: the genome of the Colorado potato beetle, Leptinotarsa decemlineata (Coleoptera: Chrysomelidae)",https://www.nature.com/articles/s41598-018-20154-1
"Researchers were incorporated via special programmes from both the Faculty and the Argentinean Government to increase the number of doctors in Computer Science in the scientific system in Argentina . Most of our efforts in the first years went to raise awareness about the area and provide foundational and advanced courses . This policy lead to a significant number of graduation theses and to the incorporation of various PhD students to our group . We taught several undergraduate and graduate courses on various NLP topics at our own University , at the University of Rio Cuarto , at the University of Buenos Aires and at the Universidad de la Rep ´ ublica ( Uruguay ), as well as crash courses at the Society for Operative Investigations ( SADIO ) and at the Conferencia Latinoamericana de Inform ´ atica ( CLEI 2008 ). We also gave several talks at various universities in the country , and participated in local events , like JALIMI ’ 05 ( Jornadas Argentinas de Ling ¨ u ´ ıstica Inform ´ atica : Modelizaci ´ on e Ingenier ´ ıa ) or the Argentinean Symposium on Artificial Intelligence .",Supplement,Paper,Produce,Computing Capabilities at Argentine and Chilean Universities,https://dl.acm.org/doi/pdf/10.1145/363196.363201
"Krishnan etal . Theoretical Biology and Medical Modelling 2014 , 11 : 28 Page 13 of 17 library and after necessary textual modifications in the structural model and data file , the modeling and simulation environment is ready for simulating the specified behavior . In this sense , the modeling and simulation environment is a plug and play system with no re - programing effort and hence reusable . The flexibility of the modeling and simulation environment was demonstrated by modeling and simulating the gastric emptying behavior in humans .",Supplement,Paper,Produce,COVI White Paper - Version 1.1,https://arxiv.org/pdf/2005.08502.pdf
BMJ Open 2016 ; 6 : e011562 . doi : 10 . 1136 / bmjopen - 2016011562 ▸ Prepublication history and additional material is available . To view please visit the journal ( ).,Supplement,Paper,Produce,"Open, single-blind, double-blind: which peer review process do you prefer?",https://bmcpharmacoltoxicol.biomedcentral.com/articles/10.1186/2050-6511-15-55
Reid et al . eLife 2018 ; 7 : e33105 . DOI : 19 of 29 Tools and resources Cell Biology Genomics and Evolutionary Biology,Supplement,Paper,Produce,Single-cell RNA-seq reveals hidden transcriptional variation in malaria parasites,https://elifesciences.org/articles/33105
‘ Hoo ’ is the most similar timepoint in development in the Hoo et al . ( 2016 ) dataset . DOI : The following figure supplements are available for figure 4 :,Supplement,Paper,Produce,Differential protein profiles in interspecific hybrids between Elaeis oleifera and E. guineensis with contrasting responses to somatic embryogenesis competence acquisition,https://link.springer.com/article/10.1007/s11240-018-01545-8
"German Federal Ministry of Health was not involved in data collection , analysis and writing of the manuscript . Availability of data and materials The data sets generated and analysed during the current study are available in the ZENODO . ( ).",Supplement,Paper,Produce,"Attitudes, stressors and work outcomes related to the COVID-19 pandemic among dental assistants in Germany: a cross-sectional study",https://bmjopen.bmj.com/content/bmjopen/11/9/e045881.full.pdf
"The addition of a 12 - hour component ( middle ) to the model ( right ) yields a better fit for which underlying assumptions are validated . © Halberg Chronobiology Center . Cornelissen Theoretical Biology and Medical Modelling 2014 , 11 : 16 Page 11 of 24 the environment . Counterparts in biology have been found , as discussed elsewhere [ 3 , 53 - 56 ]. There are several approaches available to analyze non - stationary time series , such as wavelets , short - term Fourier transforms , and gliding spectral windows complemented by chronobiologic serial sections , as discussed below .",Supplement,Paper,Produce,Cosinor-based rhythmometry,https://tbiomed.biomedcentral.com/articles/10.1186/1742-4682-11-16?report=reader
"The inset shows the thermal migration coefficient ( TMC ) that characterizes drift in the temperature gradient , calculated from three independent experiments ( such as that shown in the main panel ). Positive values of TMC correspond to thermophilic response , whereas negative values of TMC correspond to cryophilic response . DOI : The following source data and figure supplements are available for figure 1 :",Supplement,Paper,Produce,Mechanism of bidirectional thermotaxis in Escherichia coli,https://elifesciences.org/articles/26607
"Furthermore , we show that LOAD shares a similar localization of SNPs to monocyte - functional regions with Parkinson ’ s disease . Overall , we demonstrate that integrated genome annotations at the single tissue level provide a valuable tool for understanding the etiology of complex human diseases . Our PLOS Genetics | July24 , 2017 1 / 24 Tissue - specific functional annotation and Alzheimer ’ s disease genetics Council . PKC ’ s and SM ’ s efforts were supported by GenoSkyline - Plus annotations are freely available at http :// genocanyon . med . yale . edu / grant R01 AG042437 and U01 AG006781 . The GenoSkyline .",Supplement,Paper,Produce,Systematic tissue-specific functional annotation of the human genome highlights immune-related DNA elements for late-onset Alzheimer’s disease,https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006933
"Electronic supplementary material The online version of this article ( ) contains supplementary material , which is available to authorized users . ® João M . C . Teixeira joaomcteixeira @ gmail . com",Supplement,Paper,Produce,The Atlantic Forest: an introduction to the megadiverse forest of Southern America,https://www.researchgate.net/profile/Marcia-Marques-4/publication/348449844_The_Atlantic_Forest_An_Introduction_to_the_Megadiverse_Forest_of_South_America/links/601d2c2f92851c4ed54c7202/The-Atlantic-Forest-An-Introduction-to-the-Megadiverse-Forest-of-South-America.pdf
"Between 2008 – 2009 the prevalence of GAM ( weight - forheight z - score & lt ;- 2 ) persisted at levels indicating serious / critical public health significance ( 10 to > 15 %) in all camps , further highlighting the poor nutritional status of vulnerable groups [ 26 ]. The aim of this study was to analyse the effectiveness of Nutributter ® distribution in reducing anaemia and stunting in refugee children between 2008 and 2011 . PLOS ONE | June 7 , 2017 2 / 18 SQ LNS effectiveness in refugees in the Horn of Africa",Supplement,Paper,Produce,Persistent Global Acute Malnutrition,https://www.ecbproject.org/system/files/content/resource/files/main/FIC-Publication-Persistent-Global-Acute-Malnutrition_web_2.26s.pdf
"The sample was centrifuged for 15 min at 12 , 000 x g , at 4 ° C to separate the homogentate into a clear upper aqueous layer ( containing RNA ), an interphase and red lower organic layers ( containing the DNA and proteins ), for three min . DNA and trace phenol was removed using the RNeasy Mini Kit ( 74106 ; Qiagen Hilden , Germany ) column purification , following the manufacturer ’ s instructions ( RNeasy Mini Kit Protocol : Purification of Total RNA from Animal Tissues , from step 5 onwards ). RNA quantity was measured using a Qubit RNA BR Assay kit ( Q10210 ; Thermo PLOS Genetics | September 15 , 2017 24 / 38 The sheep gene expression atlas Fisher Scientific ) and RNA integrity estimated on an Agilent 2200 Tapestation System ( Agilent Genomics , Santa Clara , USA ) using the RNA Screentape ( 5067 – 5576 ; Agilent Genomics ) to ensure RNA quality was of RINe > 7 . RNA - Seq libraries were prepared by Edinburgh Genomics ( Edinburgh Genomics , Edinburgh , UK ) and run on the Illumina HiSeq 2500 sequencing platform ( Illumina , San Diego , USA ). Details of the libraries generated can be found in S2 Table .",Supplement,Paper,Use,A high resolution atlas of gene expression in the domestic sheep (Ovis aries),https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006997
"Our prototype was implemented and integrated with a clinical data management system as a Plug - in module using a CDMS . A clinical data management system ( e . g SlimViangteeravat et al . Journal of Clinical Bioinformatics 2011 , 1 : 32 Page 3 of 10 Prim [ 21 , 22 ]) is used in administering and managing patient medical records and making the records available to health - care providers so that they can be used in their research and translational health care practice . We have tested the prototype system with some use case scenarios for distributed clinical data sources across several legacy clinical database management systems ( CDMS ) and database management systems ( DBMS ) at the University of Tennessee Health Science Center ( UTHSC ). These disparate systems were built on different underlying database technologies such as Oracle , MySQL and MS Access .",Supplement,Paper,Use,Clinical data integration of distributed data sources using Health Level Seven (HL7) v3-RIM mapping,https://link.springer.com/article/10.1186/2043-9113-1-32
"If the tables contain motifs , the motif logos will always be included in a separate column . This is very useful , since rather than just listing numerous motif identifiers or names of transcription factors the user may or may not be familiar with , the logos enable users to immediately identify properties of the corresponding motifs and see similarities between them . Results from multiple analyses can be collated into “ meta - analyses ” by extracting selected columns from Klepper and Drabløs BMC Bioinformatics 2013 , 14 : 9 Page 7 of 14 individual analyses and combining them into larger tables . Information from different types of analyses can be combined in this way to produce more comprehensive reports , or results from the same analysis run multiple times with different parameter settings can be juxtaposed to assess the impact of varying these parameters .",Supplement,Paper,Use,MotifLab: a tools and data integration workbench for motif discovery and regulatory sequence analysis,https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-9
"In this paper we studied the application of compressionbased distance measures for the problem of sequence comparison , with a special focus on NGS short read data . Their key advantages are assembly - free , alignment - free , and parameter - free . We conducted extensive validation on various types of sequence data : NGS short reads , 16S rRNA sequences , mtDNA sequences , and whole genome Tran and Chen BMC Research Notes 2014 , 7 : 320 Page 12 of 13 sequences . The sequence data was obtained from several mammalian and bacteria genomes at different taxonomy levels , as well as from microbial metagenomic samples . The results show that the compression - based distance measures produced comparably accurate results as the kmer based methods , and both were in good agreement with the alignment - based approach and with existing benchmarks in the literature .",Supplement,Paper,Use,Comparison of next-generation sequencing samples using compression-based distances and its application to phylogenetic reconstruction,https://bmcresnotes.biomedcentral.com/articles/10.1186/1756-0500-7-320
"That is , the estimates of y ~ can be calculated considering ~ b to be a known value in Eq 2 . In fact , our proposed model provide better estimates of ~ b than the standard model . However , if examinees are free to choose an arbitrary number of items from a PLOS ONE | February 1 , 2018 18 / 23 A new item response theory model to adjust data allowing examinee choice Fig 6 . Scatter plot using data generated from scenario 2 with a weight value equal to 10 . The differences between estimated and true item difficulties are plotted against the true item difficulties .",Supplement,Paper,Use,A new item response theory model to adjust data allowing examinee choice,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0191600
"Using network analysis , new information is incorporated in the model . The results are presented using three simulation scenarios . In the first scenario , the assumptions required to apply the standard Rasch model in the PLOS ONE | February 1 , 2018 19 / 23 A new item response theory model to adjust data allowing examinee choice",Supplement,Paper,Use,Exploratory graph analysis: A new approach for estimating the number of dimensions in psychological research,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0174035
"Three assumptions or alternative input data are the most influential on the relative and absolute outcome of the health impact assessment : the sources of relative risks used in the blood pressure to health association , the dose - response between salt intake and blood pressure and the distribution of risk factors . Because of the importance of the effect of the relative risk on the outcome , it is important that the source is obtained from good quality , prospective studies . This study showed that using PLOS ONE | November28 , 2017 10 / 14 Identification of differences in health impact modelling of salt reduction categorical risk factor distributions seemed to reduce the sensitivity of the model to changes in salt intake . This is probably due to the fact that this modelling approach lowers blood pressure in all subjects lowering salt intake will decrease blood pressure in all subjects , but only a few subjects will shift to a lower blood pressure category and thereby will have a lower risk of developing CVD . In general , uncertainty analyses show how the health impact estimate depends on the underlying assumptions and ( demographic ) input data within a single HIA model and is therefore helpful to identify the range of the expected effect .",Supplement,Paper,Use,Identification of differences in health impact modelling of salt reduction,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0186760
"Accordingly , there is a wide range of prices for EEG devices , from brain — computer interface systems designed for a specific task to medical - grade devices with hundreds of high quality electrodes . These measurement devices are all based on the same principle , neurons communicate through chemical neurotransmitters and electrical impulses , giving rise to electromagnetic waves . Electrodes are then used in EEG to measure oscillatory signals related to action PLOS ONE | May 24 , 2018 1 / 21 Collective signal improvement in an EEG headset Competing interests : The authors have declared that no competing interests exist . potential across different regions of the brain . In EEG devices , it is generally believed that most of the measured signal is provided by pyramidal neurons of the cortex [ 6 , 7 ].",Supplement,Paper,Use,Improving the quality of a collective signal in a consumer EEG headset,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0197597
"It should be noted that this validation is still far from perfect since bound enhancers can regulate transcription from a distance greater than the conservative limit considered here . We also perform Titsias et al . BMC Systems Biology 2012 , 6 : 53 Page 10 of 21 similar evaluation using TF - gene links in the Drosophila Interaction Database ( DroID ) [ 35 ]. This database in not specific to development and may thus include links that are not active in our data . We only include the 5521 test genes with some predicted TF regulators in the database .",Supplement,Paper,Use,Multikernel linear mixed models for complex phenotype prediction,https://genome.cshlp.org/content/26/7/969.full.pdf+html
Source data are presented in Figure 4 — source data 1 . DOI : https :// doi . org / 10 . 7554 / eLife . 32222 . 017 The following source data and figure supplement are available for figure 4 : Source data 1 . Source raw data for Figure 4A - D . DOI : Source data 2 . Source raw data for Figure 4 — figure supplement 1B and C . DOI : https :// doi . org / 10 . 7554 / eLife . 32222 . 020 Figure supplement 1 . Requirement of INO80 and ARP8 for RAD51 binding to the BCR of the MLL gene .,Supplement,Paper,Use,Distinct roles of ATM and ATR in the regulation of ARP8 phosphorylation to prevent chromosome translocations,https://elifesciences.org/articles/32222
"Unfortunately , the results for ME and TBL when training on one million words cannot be reported in this paper . The learning algorithms will still be occupied after the deadline for the final version of this manuscript . The results will be published on the author ' s web page as soon as the learners have finished their struggle . The total error rate , i . e . the percentage of erroneous tags , is shown in Figure 2 for each classifier .",Supplement,Website,Introduce,Part of Speech Taggers for Morphologically Rich Indian Languages: A Survey,https://www.researchgate.net/profile/Dinesh-Kumar/publication/46280013_Part_of_Speech_Taggers_for_Morphologically_Rich_Indian_Languages_A_Survey/links/00b4951780def10365000000/Part-of-Speech-Taggers-for-Morphologically-Rich-Indian-Languages-A-Survey.pdf
"Having previously obtained a PhD at UMass Amherst under the supervision of David Smith and Mark Johnson , his current research aims to improve natural language understanding by performing task - specific training of word representations and parsing models . He is also interested in semi - supervised learning , joint inference , and semantic parsing . His web page is available at Sebastian Riedel is a senior lecturer at University College London and an Allen Distinguished Investigator , leading the Machine Reading Lab . Before , he was a postdoc and research scientist with Andrew McCallum at UMass Amherst , a researcher at Tokyo University and DBCLS with Tsujii Junichi , and a PhD student with Ewan Klein at the University of Edinburgh .",Supplement,Website,Introduce,A unified architecture for natural language processing: deep neural networks with multitask learning,https://dl.acm.org/doi/abs/10.1145/1390156.1390177
"The syntactic annotation procedure , which like the POS tagging is performed semi - automatically , uses the interactive annotation environment developed within the German NEGRA project ( http :// www . coli . unisb . de / sfb378 / negra - corp us / negra - corp us . html ). A simple visualisation tool ( Portray ) for the annotation graphs is freely available from the Utrecht CGN site ( ). In a later phase of the project , the CGN exploitation software ( COREX tools ) will provide more advanced display and search facilities for the syntactic annotation .",Supplement,Website,Introduce,Syntactic Annotation for the Spoken Dutch Corpus Project (CGN),https://brill.com/display/book/9789004333901/B9789004333901-s006.xml
"A key factor in personal data management is the highly contextual nature of privacy related issues ; privacy concerns and practices are situated in their context ( Nissenbaum , 2009 ) and influenced by cultural issues ( Milberg et al ., 2000 ). The diversity of technology in the AAC sector is set to increase dramatically . Apple ’ s iPad has caused a huge investment in tablet technology . Multiple , third party applications ( e . g . proloque2go , myVoice , and verbally ) already exist that allow this new range of tablets to function as AAC devices .",Supplement,Website,Introduce,Information Privacy Research: An Interdisciplinary Review,https://www.jstor.org/stable/41409970
"Emoticons : Another challenge has to do with the limited usefulness of emoticons , because Arabic ’ s smileys and sad emoticons are often mistakenly interchanged . Thus , many tweets have words and emoticons that are contradictory in sentiment . For example : meaning : I have a sister from which I seek the protection of Allah ( negative ) : followed by a smilie Use of dialects : Though most Arabic speakers can read and understand MSA , they generally use different Arabic dialects in their daily interactions including online social interaction . There are 6 dominant dialects , namely Egyptian , Moroccan , Levantine , Iraqi , Gulf , and Yemeni . Dialects introduce many new words into the language , particularly stopwords ( ex .",Supplement,Website,Introduce,Twitter brand sentiment analysis: A hybrid system using n-gram analysis and dynamic artificial neural network,https://www.sciencedirect.com/science/article/abs/pii/S0957417413003552
"For evaluation in the HOO framework , a distinction is made between scores and measures . The complete evaluation mechanism is described in detail in ( Dale and Narroway , 2012 ) and on the HOO - 2012 website . Scores Three different scores are used : Measures For each score , three measures are calculated : precision ( 1 ), recall ( 2 ) and F - score ( 3 ). where tp is the number of true positives ( the number of instances that are correctly found by the system ), fp the number of false positives ( the number of instances that are incorrectly found ), and fn the number of false negatives ( missing results ). where Q is used as a weight factor regulating the trade - off between recall and precision .",Supplement,Website,Introduce,HOO 2012: A Report on the Preposition and Determiner Error Correction Shared Task,https://aclanthology.org/W12-2006.pdf
"Instead of returning a long list of documents more or less related to the query parameters , the aim of a QA system is to isolate the exact answer as accurately as possible , and to provide the user only a short text clip containing the required information . One of the major development challenges is evaluation . The conferences such as TREC , CLEF and NTCIR have provided valuable QA evaluation methods , and in addition produced and distributed corpora of questions , answers and corresponding documents . However , these conferences have focused mainly on fact - based questions with short answers , so called factoid questions . Recently more complex tasks such as list , definition and discoursebased questions have also been included in TREC in a limited fashion ( Dang et al ., 2007 ).",Supplement,Website,Introduce,Collecting a Why-question corpus for development and evaluation of an automatic QA-system,https://aclanthology.org/P08-1051.pdf
"A goal of this paper is to investigate a particular way in which Natural Language Processing ( NLP ) can usefully contribute to SLA . In terms of existing work , the subfield of Native Language Identification ( NLI ) has been quite active recently , which looks at predicting the L1 of writers writing in a common L2 within a classification task framework ; see for example the recent NLI shared task with 29 entrants ( Tetreault et al ., 2013 ). From within linguistics , there has been much interest in how data - driven approaches can contribute to SLA . Granger ( 2011 ) discusses a body of work based on the the methodology of carrying out corpus - based approaches to SLA with a focus on NLP tools ; Jarvis and Crossley ( 2012 ) in an edited collection present recent work by linguists who extend the corpus - based setup by using a text classification approach , looking at what feature selection might say for SLA . From within NLP , Swanson and Charniak ( 2013 ) and Swanson and Charniak ( 2014 ) take a data - driven approach to SLA investigations much in the spirit of this work .",Supplement,Website,Introduce,Natural Language Processing in Surgery : A Systematic Review and Meta-analysis,https://www.ingentaconnect.com/content/wk/sla/2021/00000273/00000005/art00024
"We also describe an interface that displays multiple parses compactly and facilitates users to select the desired parse among various possible solutions with a maximum of n − 1 choices for a sentence with n words . Past decade has witnessed a lot of dynamism and upsurge of activities in the field of Sanskrit Computational Linguistics . Several computational tools became available to the Sanskrit community as a web service through the internet . With the availability of a wide coverage grammar for Sanskrit in the form of As . t .¯ adhy ¯ ay ¯ ı , there was a natural tendency to follow the grammar based approach towards the development of these tools ( Huet , 2009 ; Kulkarni et al ., 2010 ; Kulkarni and Ramakrishnamacharyulu , 2013 ; Goyal and Huet , 2013 ). Nevertheless , there were also notable efforts to use pure machine learning approaches for building these tools with a small manually tagged corpus as a boot - strap ( Hellwig , 2009 ).",Supplement,Website,Introduce,A Deterministic Dependency Parser with Dynamic Programming for Sanskrit,https://aclanthology.org/W13-3718.pdf
"the Web has changed from a static container of information into a live environment in which any user , in a very simple manner , can publish any type of information . This simplified means of publication has led to the rise of several different websites specialized in the publication of users opinions . Some of the most well - known sites include Epinions , RottenTomatoes and Muchocine , where users express their opinions or criticisms on a wide range of topics . Opinions published on the Internet are not limited to certain sites , but rather can be found in a blog , forum , commercial website or any other site allowing posts from visitors . On of the most representative tools of the Web 2 . 0 are social networks , which allow millions of users to publish any information in a simple way and to share it with their network of contacts or “ friends ”.",Supplement,Website,Introduce,Random Walk Weighting over SentiWordNet for Sentiment Polarity Detection on Twitter,https://aclanthology.org/W12-3703.pdf
"Requests involve an imposition on the addressee , making them a natural domain for studying the inter - connections between linguistic aspects of politeness and social variables . Requests in online communities We base our analysis on two online communities where requests have an important role : the Wikipedia community of editors and the Stack Exchange question - answer community . On Wikipedia , to coordinate on the creation and maintenance of the collaborative encyclopedia , editors can interact with each other on user talk - pages ; re quests posted on a user talk - page , although public , are generally directed to the owner of the talkpage . On Stack Exchange , users often comment on existing posts requesting further information or proposing edits ; these requests are generally directed to the authors of the original posts . Both communities are not only rich in userto - user requests , but these requests are also part of consequential conversations , not empty social banter ; they solicit specific information or concrete actions , and they expect a response .",Supplement,Website,Introduce,A Computational Approach to Politeness with Application to Social Factors,https://arxiv.org/abs/1306.6078
"The Web - based interface allows the use of the translation system to any computer connected to the Internet . Given a string f in the source language , the goal of the statistical machine translation is to select the string e in the target language which maximizes the posterior distribution Pr ( e | f ). By introducing the hidden word alignment variable a , the following approximate optimization criterion can be applied for that purpose : At this time , Statistical Machine Translation ( SMT ) has empirically proven to be the most competitive approach in international competitions like the NIST Evaluation Campaigns and the International Workshops on Spoken Language Translation ( IWSLT - 2004 and IWSLT - 2005 ). In this paper we describe our multi - lingual phrase - based Statistical Machine Translation system which can be accessed by means of a Web page . Section 2 presents the general log - linear framework to SMT and gives an overview of our phrase - based SMT system .",Supplement,Website,Introduce,The Alignment Template Approach to Statistical Machine Translation,https://direct.mit.edu/coli/article-abstract/30/4/417/1869
"Because it is primarily expressed as text , Debatepedia is a corpus of debate topics , but it is organized hierarchically , with multiple issues in each debate topic , questions within each issue , and arguments on two sides of each question . An important feature of the corpus is the widespread quotation and linking to external articles on the web , including news stories , blog postings , wiki pages , and social media forums ; here we use these external articles in evaluation (§ 4 ). Table 1 shows excerpts from a debate page from Debatepedia . Each debate contains “ questions ,” which reflect the different aspects of a debate . In this particular debate , there are 13 questions ( 2 shown ), ranging from economic benefits to enforceability to social impacts .",Supplement,Website,Introduce,Learning Topics and Positions from Debatepedia,https://ink.library.smu.edu.sg/sis_research/2059/
"Integrating work from psychology and computational linguistics , we develop and compare three approaches to detecting deceptive opinion spam , and ultimately develop a classifier that is nearly 90 % accurate on our gold - standard opinion spam dataset . Based on feature analysis of our learned models , we additionally make several theoretical contributions , including revealing a relationship between deceptive opinions and imaginative writing . With the ever - increasing popularity of review websites that feature user - generated opinions ( e . g ., TripAdvisor and Yelp ), there comes an increasing potential for monetary gain through opinion spam — inappropriate or fraudulent reviews . Opinion spam can range from annoying self - promotion of an unrelated website or blog to deliberate review fraud , as in the recent case of a Belkin employee who hired people to write positive reviews for an otherwise poorly reviewed product . While other kinds of spam have received considerable computational attention , regrettably there has been little work to date ( see Section 2 ) on opinion spam detection .",Supplement,Website,Introduce,Finding Deceptive Opinion Spam by Any Stretch of the Imagination,https://arxiv.org/abs/1107.4557
"We evaluate the advantages / drawbacks of each HIT design and show that , in our case , the use of non - expert annotations is a viable and costeffective alternative to expert annotations . Obtaining reliable human annotations to train datadriven AI systems is often an arduous and expensive process . For this reason , crowdsourcing platforms such as Amazon ’ s Mechanical Turk , Crowdflower and others have recently attracted a lot of attention from both companies and academia . Crowdsourcing enables requesters to tap from a global pool of non - experts to obtain rapid and affordable answers to simple Human Intelligence Tasks ( HITs ), which can be subsequently used to train data - driven applications . A number of recent papers on this subject point out that non - expert annotations , if produced in a sufficient quantity , can rival and even surpass the quality of expert annotations , often at a much lower cost ( Snow et al ., 2008 ), ( Su et al ., 2007 ).",Supplement,Website,Introduce,Opinion Mining of Spanish Customer Comments with Non-Expert Annotations on Mechanical Turk,https://aclanthology.org/W10-0718.pdf
"The experimental results show the effectiveness of our system , for instance , the F3 / NR improvement of our system over the baseline and translation - based model reaches 7 . 9 %/ 11 . 1 %, and 5 . 1 %/ 5 . 6 %, respectively . Recently launched social QA websites such as Yahoo ! Answer and Baidu Zhidao provide an interactive platform for users to post questions and answers . After questions are answered by users , the best answer can be chosen by the asker or nominated by the community . The number of Q & A pairs on such sites has risen dramatically .",Supplement,Website,Introduce,Exploiting Social Q&A Collection in Answering Complex Questions,https://aclanthology.org/W10-4117.pdf
"The complete set of rules can be found in ( Hwa et al ., 2002 ). Because our error analysis and subsequent algorithm refinements made use of our original Chinese - English data set , we created a new test set based on 88 new Chinese sentences from the Penn Chinese Treebank , already manually translated into English as part of the NIST MT evaluation preview . These sentences averaged 19 . 0 words in length . As described above , parses ort the English side were created semi - automatically , and word alignments were acquired manually . However , in order to reduce our reliance ort linguistically sophisticated human annotators for Chinese syntax , we adopted art alternative strategy for obtaining the gold standard : we automatically converted the Treebank & apos ; s constituency parses of the Chinese sentences into syntactic dependency representations , using art algorithm similar to the one described in Section 2 of the paper by Xia and Palmer ( 2001 ).",Supplement,Website,Introduce,HMM Word and Phrase Alignment for Statistical Machine Translation,https://ieeexplore.ieee.org/abstract/document/4443885
"Shared task participants were required to provide the data collected as part of their experiments . All of the shared task data is available on the workshop website . Amazon ’ s Mechanical Turk is an online marketplace for work . Amazon ’ s tag line for Mechanical Turk is artificial artificial intelligence , and the name refers to a historical hoax from the 18th cen tury where a chess - playing automaton appeared to be able to beat human opponents using a mechanism , but was , in fact , controlled by a person hiding inside the machine . These hint at the the primary focus of the web service , which is to get people to perform tasks that are simple for humans but difficult for computers .",Supplement,Website,Introduce,Difference and Dependence among Digital Workers: The Case of Amazon Mechanical Turk,https://read.dukeupress.edu/south-atlantic-quarterly/article-abstract/114/1/225/3763/Difference-and-Dependence-among-Digital-Workers
"On of the most representative tools of the Web 2 . 0 are social networks , which allow millions of users to publish any information in a simple way and to share it with their network of contacts or “ friends ”. These social networks have also evolved and become a continuous flow of information . A clear example is the microblogging platform Twitter . Twitter publishes all kinds of information , disseminating views on many different topics : politics , business , economics and so on . Twitter users regularly publish their comments on a particular news item , a recently purchased product or service , and ultimately on everything that happens around them .",Supplement,Website,Introduce,The emerging Web 2.0 social software: an enabling suite of sociable technologies in health and health care education,https://onlinelibrary.wiley.com/doi/full/10.1111/j.1471-1842.2007.00701.x
"According to the latest Twitter entry in Wikipedia , the number of Twitter users has climbed to 190 million and the number of tweets published on Twitter every day is over 65 million . As a result of the rapidly increasing number of tweets , mining people ’ s sentiments expressed in tweets has attracted more and more attention . In fact , there are already many web sites built on the Internet providing a Twitter sentiment search service , such as Tweetfeel , Twendz , and Twitter Sentiment . In those web sites , the user can input a sentiment target as a query , and search for tweets containing positive or negative sentiments towards the target . The problem needing to be addressed can be formally named as Target - dependent Sentiment Classification of Tweets ; namely , given a query , classifying the sentiments of the tweets as positive , negative or neutral according to whether they contain positive , negative or neutral sentiments about that query .",Supplement,Website,Introduce,Optimizing Support Vector Machine in classifying sentiments on product brands from Twitter,https://ieeexplore.ieee.org/abstract/document/6878768
"Moreover , it creates a Web interface ( called Spinet ) where WSs can be tested and used with input forms . All these features make Soaplab a suitable tool for our project . Moreover , its numerous successful stories make it a safe choise ; e . g ., it has been used by the European Bioinformatics Institute to deploy their tools as WSs . Once the WSs are deployed by WSPs , some means to find them becomes necessary . Biocatalogue ( Belhajjame et al ., 2008 ) is a registry where WSs can be shared , searched for , annotated with tags , etc .",Supplement,Website,Introduce,Towards a User-Friendly Platform for Building Language Resources based on Web Services,https://repositori.upf.edu/handle/10230/20418
"We show how MDD techniques and tools facilitate working with different data formats , adapting to new languages and domains , managing UIMA type systems , and accessing the external knowledge bases . Modern architectures of knowledge - based computing ( cognitive computing ) require HLT components to interact with increasingly many sources and services , such as Open Data and APIs , which may not be known before the system is designed . IBM ’ s Watson , for instance , works on textual documents to provide question answering and other knowledge - based services by integrating lexical resources , ontologies , encyclopaedic data , and potentially any available information source . Also , they combine a variety of analytical procedures , which may use search , reasoning services , database queries , to provide answers based on many kinds of evidence ( IJRD , 2012 ). Development platforms such as UIMA or GATE facilitate the development of HLT components to a great extent , by providing tools for annotating texts , based on vocabularies and ontologies , training and evaluating pipeline components , etc .",Supplement,Website,Introduce,Integrating NLP Using Linked Data,https://link.springer.com/chapter/10.1007/978-3-642-41338-4_7
"In this section , we introduce the two tasks Paraphrase Identification and Semantic Similarity in Twitter , then we describe the set of simple features which enables us to achieve competitive performance in both tasks . This is a shared - task proposed as the Task # 1 & quot ; Paraphrase and Semantic Similarity in Twitter & quot ; at SemEval 2015 ( Xu et al ., 2015 ). In this task , the first common ground for development and comparison of Paraphrase Identification ( PI ) and Semantic Similarity ( SS ) systems for the Twitter data is provided . Given a pair of sentences from Twitter trends , systems are required to produce a binary yes / no judgment and an optionally graded similarity score in the scale [ 0 - 1 ] to measure their semantic equivalence . This task is used to promote this line of research in the new challenging setting of social media data , and help to advance other NLP techniques for noisy user - generated text in the long run .",Supplement,Website,Introduce,SemEval-2015 Task 1: Paraphrase and Semantic Similarity in Twitter (PIT),https://aclanthology.org/S15-2001.pdf
"As it may be observed , the results obtained for Twitter and SMS sentiment classification are good considering that our proposal is unsupervised . The explosion of Web 2 . 0 has marked a new age for the human society . The huge use of Social Media such as Facebook , MySpace , LinkedIn and Twitter , offers a place for people to share information in real time . Twitter is one of the most popular social network websites and has been growing at a very fast pace . The number of active users exceeds 500 million and the number of tweets posted by day exceeds 500 million ( as of May 2012 ) .",Supplement,Website,Introduce,SSA-UO: Unsupervised Twitter Sentiment Analysis,https://d1wqtxts1xzle7.cloudfront.net/34115113/S13-2083-libre.pdf?1404455510=&response-content-disposition=inline%3B+filename%3DSSA_UO_Unsupervised_Twitter_Sentiment_An.pdf&Expires=1686117391&Signature=Tkl3Lm11ZI0EuN7VL-mLV870OwY9ToIS-nwn3NeN5vcyKQ94Ew8v8moa9LarQcXPaCLYZI9WvEmLM~Xxvk6gOgDCRr7AOLaW-7K2F0jkjZAutoCcHn9RlGhIAnyNkwALYHHBpHEfBMiNrJknXXbt3zBHHYthUQZIQLsnnqAE4Qo8RyGU~LjD~8I9CCGX6OgbERKy6brtfDFA54Txz8VENiGECIsNus81Yo3PM2Y4ruwXOsTAjeERQ1Dv5Exaim0YHC3vwmK14ogmqmo0XeJgojBCHRNUO--agVpdaV-LsrvIswB9NNn~vSV~sTvX445RStK64wYr6O9AGmz0CvrBug__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA
"In addition to evaluating factuality detection in isolation , we also evaluate its impact on a system for event detection . The two components for factuality detection and event detection form part of a system for identifying negative factual events , or counterfacts , with top - ranked results in the * SEM 2012 shared task . The First Joint Conference on Lexical and Computational Semantics (* SEM 2012 ) is hosting a shared task ( Morante and Blanco , 2012 ) on identifying various elements of negation , and one of the subtasks is to identify negated events . However , only events occurring in factual statements should be labeled . This paper describes pilot experiments on how to train a factuality classifier by taking advantage of implicit information on factuality in annotations of negation .",Supplement,Website,Introduce,Factuality Detection on the Cheap: Inferring Factuality for Increased Precision in Detecting Negated Events,https://aclanthology.org/W12-3804.pdf
"Generally their paper , which is submitted to a conference and may be rejected not because of their research works but because of the English writing , which makes the paper harder for the reviewer to understand intention of author . This kind of problem will be faced in any field where someone has to provide material in a language other than his / her first language . The mentoring service of Association for Computational Linguistics ( ACL ) is one part of a response . This service can address a wider range of problems than those related purely to writing . The aim of this service is that a research paper should be judged only on its research content .",Supplement,Website,Introduce,The Effect of On-Line Consumer Reviews on Consumer Purchasing Intention: The Moderating Role of Involvement,https://www.tandfonline.com/doi/abs/10.2753/JEC1086-4415110405
"Unfortunately , their method requires lengthy guidelines and substantial annotator training effort , which are time consuming and costly . Thus , a simple , robust and replicable evaluation method is needed . Recently , crowdsourcing services such as Amazon Mechanical Turk ( AMT ) and CrowdFlower ( CF ) have been employed for semantic inference annotation ( Snow et al ., 2008 ; Wang and CallisonBurch , 2010 ; Mehdad et al ., 2010 ; Negri et al ., 2011 ). These works focused on generating and annotating RTE text - hypothesis pairs , but did not address annotation and evaluation of inference rules . In this paper , we propose a novel instance - based evaluation framework for inference rules that takes advantage of crowdsourcing .",Supplement,Website,Introduce,Crowdsourcing Inference-Rule Evaluation,https://aclanthology.org/P12-2031.pdf
"Both allow the user to search for documents targeted to a population ( e . g ., patient - oriented documents ). We also queried known relevant websites for documents dealing with our chosen topics . Those were French governmental websites , including that of the HAS which issues guidelines for health professionals , and that of the INPES which provides educational material for the general public ; as well as health websites dedicated to the general public , including Doctissimo , Tabac Info Service , Stoptabac and Diabète Québec10 . The corpus dealing with the topic of diabetes served as our development corpus for the first type of paraphrases we extracted , the other two corpora were used as test corpora . Once collected , a corpus needs to be cleaned and converted into an appropriate format to allow further processing , i . e .",Supplement,Website,Introduce,"Health Recommender Systems: Concepts, Requirements, Technical Basics and Challenges",https://www.mdpi.com/1660-4601/11/3/2580
"The first level of interpretation of a Sanskrit text is its word - to - word segmentation , and our tagger will be able to assist a philology specialist to achieve complete morphological mark - up systematically . This will allow the development of concordance analysis tools recognizing morphological variants , a task which up to now has to be performed manually . At some point in the future , one may hope to develop for Sanskrit the same kind of informative repository that the Perseus web site provides for Latin and Classical Greek . Such resources are invaluable for the preservation of the cultural heritage of humanity . The considerable classical Sanskrit corpus , rich in philosophical texts but also in scientific , linguistic and medical knowledge , is an important challenge for computational linguistics .",Supplement,Website,Introduce,Formal Structure of Sanskrit Text: Requirements Analysis for a Mechanical Sanskrit Processor,https://link.springer.com/chapter/10.1007/978-3-642-00155-0_6
"Over last decades , there has been increasing interest on coreference resolution within NLP community . The task of coreference resolution is to identify expressions in a text that refer to the same discourse entity . This year , CoNLL holds a shared task aiming to model unrestricted coreference in OntoNotes . The OntoNotes project has created a large - scale , accurate corpus for general anaphoric coreference that covers entities and events not limited to noun phrases or a limited set of entity types . And Pradhan et al .",Supplement,Website,Introduce,Machine Learning for Entity Coreference Resolution: A Retrospective Look at Two Decades of Research,https://ojs.aaai.org/index.php/AAAI/article/view/11149
"This system scored the highest F1 ( 57 . 32 ) of Task 2 . In this paper we describe the machine learning systems that CLiPS submitted to the closed track of the CoNLL - 2010 Shared Task on Learning to Detect Hedges and Their Scope in Natural Language Text ( Farkas et al ., 2010 ). The task consists of two subtasks : detecting whether a sentence contains uncertain information ( Task 1 ), and resolving in - sentence scopes of hedge cues ( Task 2 ). To solve Task 1 , systems are required to classify sentences into two classes , “ Certain ” or “ Uncertain ”, depending on whether the sentence contains factual or uncertain information . Three annotated training sets are provided : Wikipedia paragraphs ( WIKI ), biological abstracts ( BIO - ABS ) and biological full articles ( BIO - ART ).",Supplement,Website,Introduce,*SEM 2012 Shared Task: Resolving the Scope and Focus of Negation,https://aclanthology.org/S12-1035.pdf
"VerbNet is a lexicon and by definition it does not list optional modifiers ( the arguments labelled AM - X in PropBank ). In order to support the joint use of both these resources and their comparison , SemLink has been developed ( Loper et al ., 2007 ). SemLink provides mappings from PropBank to VerbNet for the WSJ portion of the Penn Treebank . The mapping have been annotated automatically by a two - stage process : a lexical mapping and an instance classifier ( Loper et al ., 2007 ). The results were handcorrected .",Supplement,Website,Introduce,Learning Semantic Role Labeling from Compatible Label Sequences,https://arxiv.org/abs/2305.14600
"The overall system yields the precision , recall and F - measure values of 90 . 26 %, 71 . 91 % and 80 . 05 % respectively for the test dataset . Twitter has seen a phenomenal growth in the number of users during the last few years . Over 500 million user accounts have been registered with it with approx 302 million active users . Amount of user generated contents over the web would be unarguably enormous i . e . almost 500 million tweets per day .",Supplement,Website,Introduce,IITP: Hybrid Approach for Text Normalization in Twitter,https://aclanthology.org/W15-4316.pdf
"Data weighting approaches ( Matsoukas et al ., 2009 ; Foster et al ., 2010 ; Huang and Xiang , 2010 ; Phillips and Brown , 2011 ; Sennrich , 2012 ) use a rich feature set to decide on weights for the training data , at the sentence or phrase pair level . For instance , a sentence from a corpus whose domain is far from that of the dev set would typically receive a low weight , but sentences in this corpus that appear to be of a general nature might receive higher weights . The 2012 JHU workshop on Domain Adaptation for MT proposed phrase sense disambiguation ( PSD ) for translation model adaptation . In this approach , the context of a phrase helps the system to find the appropriate translation . All of the above work focuses on either TM or LM domain adaptation .",Supplement,Website,Introduce,Adaptation of Reordering Models for Statistical Machine Translation,https://aclanthology.org/N13-1114.pdf
"Experiments on a large - scale real - world Twitter dataset show that Twitter - BTM outperforms several stateof - the - art baselines . In recent years , short texts are increasingly prevalent due to the explosive growth of online social media . For example , about 500 million tweets are published per day on Twitter , one of the most popular online social networking services . Probabilistic topic models ( Blei et al ., 2003 ) are broadly used to uncover the hidden topics of tweets , since the low - dimensional semantic representation is crucial for many applications , such as product recommendation ( Zhao et al ., 2014 ), hashtag recommendation ( Ma et al ., 2014 ), user interest tracking ( Sasaki et al ., 2014 ), sentiment analysis ( Si et al ., 2013 ). However , the scarcity of context and the noisy words restrict LDA and its variations in topic modeling over short texts .",Supplement,Website,Introduce,Communicating Ebola through social media and electronic news media outlets: A cross-sectional study,https://journals.sagepub.com/doi/pdf/10.1177/1460458214568037
"It is an Eclipse based ontology development environment . There are many plugins available that extend NeOn toolkit ’ s functionality . For instance , the GATE Webservice plugin and its TermRaider component automatically generate ontological information . One of the plugins for NeOn is the work by Cimiano and V ¨ olker , who proposed Text2Onto ( Cimiano and V ¨ olker , 2005 ), which is a framework that allows to apply ontology learning and change discovery algorithms . Its central data structure is called probabilistic ontology model ( POM ).",Supplement,Website,Introduce,Integrated Tools for Query-driven Development of Light-weight Ontologies and Information Extraction Components,https://aclanthology.org/W14-5210.pdf
"As they offer fast and simple means for adding and editing content , they are used for various purposes such as creating encyclopedias ( e . g . Wikipedia ), constructing dictionaries ( e . g . Wiktionary ), or hosting online communities ( e . g . ACLWiki ). However , as wikis do not enforce their users to structure pages or add complementary metadata , wikis often end up as a mass of unmanageable pages with meaningless page titles and no usable link structure ( Buffa , 2006 ).",Supplement,Website,Introduce,Toward an epistemology of Wikipedia,https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/asi.20870
"One important pedagogical consequence of the notion of scenario is that it allows users to learn both a work process and a foreign language . Another scenario , we are currently working on , is targeted to people working at hotels reception desk . This scenario is developed in the framework of an eContent European project , Thetis ( http :// www . thetis - project . org /), which groups together a language publisher ( Q group ), a training company specialized in tourism ( Grupo GDT ) and a research center ( Xerox Research Centre Europe ). To summarize , while using linguistic technologies , students can process online texts on the fly and can work on their own documents . This strengthens the personalization aspect of the solution .",Supplement,Website,Introduce,NLP serving the cause of language learning,https://aclanthology.org/W04-1702.pdf
"Other systems can then build on top of these requests . One example for an architecture that includes CTS capabilities in a wider framework is CITE which is explained in the next section . More information can be found at http :// www . homermultitext . org / hmt - docs / specifications / cts / 2 . 3 CTS in the Context of the CITE Architecture The Collections , Indexes and Texts ( CITE ) architecture is a large framework for reference to the objects of study in Digital Humanities . The general design philosophy is to use URNs as a modern way of encoding citations . Besides providing a general framework for referencing objects and texts , with the latter task being implemented by CTS , CITE also defines a standard for encoding relations between references .",Supplement,Website,Introduce,Unified framework for IoT and smartphone based different smart city related applications,https://link.springer.com/article/10.1007/s00542-018-3936-9
"Reliable blog classification is an important task in the blogosphere as it allows researchers , ping feeds ( used to broadcast blog updates ), trend analysis tools and many others to separate real blog content from blog - like content such as bulletin boards , newsgroups or trade markets . It is a task that so far has proved difficult as can be witnessed by checking any of the major blog update feeds such as weblogs . com or blo . gs . Both will at any given time list content that clearly is not a blog . In this paper we will explore blog classification using machine learning to improve blog detection and experiment with several methods to try and further improve the percentage of instances classified correctly . The main research question we address in this paper is exploratory in nature : - How hard is binary blog classification ?",Supplement,Website,Introduce,Learning to Recognize Blogs: A Preliminary Exploration,https://aclanthology.org/W06-2805.pdf
"The website includes in the search the sentiment associated with each product . In the interface , the user can input a list of sentiment words , like “ excellent ”, “ cool ”, “ easy ” or “ powerful ” that the system will organize the results according the frequency of those words in reviews related to the products . The Stock Sonar has a timeline chart as the main interface . In this timeline , both positive and negative sentiments are displayed throughout time . The sentiments are retrieved from real - time news associated with a particular company .",Supplement,Website,Introduce,Building a Sentiment Summarizer for Local Service Reviews,https://storage.googleapis.com/pub-tools-public-publication-data/pdf/34368.pdf
"BRAT has been used throughout its development during 2011 in the annotation of six different corpora by four research groups in efforts that have in total involved the creation of well - over 50 , 000 annotations in thousands of documents comprising hundreds of thousands of words . These projects include structured event annotation for the domain of cancer biology , Japanese verb frame annotation , and genemutation - phenotype relation annotation . One prominent effort making use of BRAT is the BioNLP Shared Task 2011 , in which the tool was used in the annotation of the EPI and ID main task corpora ( Pyysalo et al ., 2012 ). These two information extraction tasks involved the annotation of entities , relations and events in the epigenetics and infectious diseases subdomains of biology . Figure 5 shows an illustration of shared task annotations .",Supplement,Website,Introduce,BRAT: a Web-based Tool for NLP-Assisted Text Annotation,https://aclanthology.org/E12-2021.pdf
"To arrive at the point where information that is available in museum databases about paintings could be recorded using this model , we developed the painting ontology that integrates the CIDOC - CRM with more specific schemata . The Swedish Open Cultural Heritage ( SOCH ) is a web service used to search and fetch data from any organization that holds information related to the Swedish cultural heritage . The idea behind SOCH is to harvest any data format and structure that is used in the museum sector in Sweden and map it into SOCH ’ s categorization structure . The data model used by SOCH is an uniform data representation which is available in an RDF compatible form . The schema provided by SOCH helps to intermediate data between museums in Sweden and the Europeana portal .",Supplement,Website,Introduce,A Framework for Improved Access to Museum Databases in the Semantic Web,https://aclanthology.org/W11-4102.pdf
"In this work we focus on these lexical units and propose how to automatically collect the missing sentences . Anyhow , the algorithm we propose is suitable also for expanding sentence sets already present in FrameNet . http :// framenet . icsi . berkeley . edu Wikipedia is one of the largest online repositories of encyclopedic knowledge , with millions of articles available for a large number of languages (& gt ; 2 , 800 , 000 for English ). The article ( or page ) is the basic entry in Wikipedia . Every article has an unique reference , i . e ., one or more words that identify the page and are present in its URL .",Supplement,Website,Introduce,Wikipedia as Frame Information Repository,https://aclanthology.org/D09-1029.pdf
"We train MT systems using a significant portion of the training data and use these models as well as TM outputs to obtain a recommendation development data set . MT systems can be either in - house , e . g . a Moses - based system , or externally available systems , such as Microsoft Bing or Google Translate . For each sentence in the development data set , we have access to the reference as well as to the outputs for each of the MT and TM systems . We then select the best MT ( or TM ) output as the translation with the lowest TER score with respect to the reference and label the data accordingly .",Supplement,Website,Introduce,Unsupervised Quality Estimation for Neural Machine Translation,https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00330/96475/Unsupervised-Quality-Estimation-for-Neural-Machine
"Experiments conducted on a real world Q & A collection show that substantial improvements in retrieval performance can be achieved by using compact translation models . Community - driven question answering services , such as Yahoo ! Answers and Live Search QnA , have been rapidly gaining popularity among Web users interested in sharing information online . By inducing users to collaboratively submit questions and answer questions posed by other users , large amounts of information have been collected in the form of question and answer ( Q & A ) pairs in recent years . This user - generated information is a valuable resource for many information seekers , because users can acquire information straightforwardly by searching through answered questions that satisfy their information need .",Supplement,Website,Introduce,Bridging Lexical Gaps between Queries and Questions on Large Online Q&A Collections with Compact Translation Models,https://aclanthology.org/D08-1043.pdf
"For example , generic ( that is , not query - specific ) summaries , which are often indicative , providing just the gist of a document , are only useful if they happen to address the underlying need of the user . In a push to make summaries more responsive to user needs , the field of summarisation has explored the overlap with complex question - answering & apos ; Information and Communication Technologies Centre research to produce query - focused summaries . Such work includes the recent DUC challenges on queryfocused summarisation , in which the user needs are represented by short paragraphs of text written by human judges . These are then used as input to the summarisation process . However , modelling user needs is a difficult task .",Supplement,Website,Introduce,"Discourse, Pragmatics, Conversation, Analysis",https://journals.sagepub.com/doi/abs/10.1177/1461445699001004002?journalCode=disa
"( 2008 ) attempted to create extremely huge training data from the Web using a seed set of entities and relations . In generating training data automatically , this study used context - based tagging . They reported that quite a few good resources ( e . g ., Wikipedia ) listed entities for obtaining training data automatically . This paper described an approach to the acquisition of huge amounts of training data for highperformance Bio NER automatically from a lexical database and unlabeled text . The results demonstrated that the proposed method outperformed dictionary - based NER .",Supplement,Website,Introduce,Snowball: extracting relations from large plain-text collections,https://dl.acm.org/doi/abs/10.1145/336597.336644
"Graphs have long been used to describe linguistic annotations , most familiarly in the form of trees ( a graph in which each node has a single parent ) for syntactic annotation . Annotation Graphs ( Bird and Liberman , 2001 ) have been widely used to represent layers of annotation , each associated with primary data , although the concept was not extended to allow for annotations linked to other annotations and thus to consider multiple annotations as a single graph . More recently , the Penn Discourse TreeBank released its annotations of the Penn TreeBank as a graph , accompanied by an API that provides a set of standard graphhandling functions for query and access . The graph model therefore seems to be gaining ground as a natural and flexible model for linguistic annotations which , as we demonstrate below , can repre LAF provides a general framework for representing annotations that has been described elsewhere in detail ( Ide and Romary , 2004 , 2006 ). Its development has built on common practice and convergence of approach in linguistic annotation over the past 15 - 20 years .",Supplement,Website,Introduce,GrAF: A Graph-based Format for Linguistic Annotations,https://aclanthology.org/W07-1501.pdf
"SemCor The SENSEVAL - 2 English tasks have decided to use the WordNet 1 . 7 sense inventory , and therefore we had to deal with the task of mapping SemCor senses , which were assigned using an earlier version of WordNet , to the corresponding senses in WordNet 1 . 7 . When a word sense from WordNet 1 . 6 is missing we assign a default sense of 0 . WordNet The main idea in generating a sense tagged corpus out of WordNet is very simple . It is based on the underlying assumption that each example pertains to a word belonging to the current synset , thereby allowing us to assign the correct sense to at least one word in each example . For instance , the example given for mother # 4 is "" necessity is the mother of invention "", and the word mother can be tagged with its appropriate sense .",Supplement,Website,Introduce,Pattern Learning and Active Feature Selection for Word Sense Disambiguation,https://aclanthology.org/S01-1031.pdf
"), which can be instantiated in different ways depending on the annotator ❑ s approach and goals . We have implemented both the abstract model and various instantiations using XML schemas ( Thompson , et al ., 2000 ), the Resource Definition Framework ( RDF ) ( Lassila and Swick , 2000 ) and RDF schemas ( Brickley and Guha , 2000 ), which enable description and definition of abstract data models together with means to interpret , via the model , information encoded according to different conventions . The results have been incorporated into XCES ( Ide , et al ., 2000a ), part of the EAGLES Guidelines developed by the Expert Advisory Group on Language Engineering Standards ( EAGLES ) . The XCES provides a ready - made , standard encoding format together with a data architecture designed specifically for linguistically annotated corpora . In this paper we provide an overview of our representation framework and demonstrate its applicability to syntactic annotation .",Supplement,Website,Introduce,Encoding Syntactic Annotation,https://link.springer.com/chapter/10.1007/978-94-010-0201-1_16
"Using weighted Support Vector Machines , to address the issue of class imbalance , our system obtains positive class F - scores of 0 . 701 and 0 . 656 , and negative class F - scores of 0 . 515 and 0 . 478 over the training and test sets , respectively . recent years . Twitter , for example , has over 645 , 750 , 000 users and grows by an estimated 135 , 000 users every day , generating 9 , 100 tweets per second ). Users often express their views and emotions regarding a range of topics on social media platforms . As such , social media has become a crucial resource for obtaining information directly from end - users , and data from social media has been utilized for a variety of tasks ranging from personalized marketing to public health monitoring .",Supplement,Website,Introduce,Linguistic Signals under Misinformation and Fact-Checking: Evidence from User Comments on Social Media,https://dl.acm.org/doi/abs/10.1145/3274351
"Unfortunately , most of the Web dictionaries and glossaries available online comprise just a few hundred definitions , and they therefore provide only a partial view of a domain . This is also the case with manually compiled glossaries created by means of collaborative efforts , such as Wikipedia . The coverage issue is addressed by online aggregation services such as Google Define , which bring together definitions from several online dictionaries . However , these services do not classify textual definitions by domain : they just present the collected definitions for all the possible meanings of a given term . In order to automatically obtain large domain glossaries , in recent years computational approaches have been developed which extract textual definitions from corpora ( Navigli and Velardi , 2010 ; Reiplinger et al ., 2012 ) or the Web ( Velardi et al ., 2008 ; Fujii and Ishikawa , 2000 ).",Supplement,Website,Introduce,Structural semantic interconnections: a knowledge-based approach to word sense disambiguation,https://ieeexplore.ieee.org/abstract/document/1432741
"Considering that most coverage - based systems explore event information , we opted for not including them in this comparative analysis . To assess the informativeness of the summaries generated by our methods , we used ROUGE - 1 and ROUGE - 2 ( Lin , 2004 ) on DUC 2007 and TAC 2009 datasets . The main summarization task in DUC 2007 is the generation of 250 - word summaries of 45 clusters of 25 newswire documents ( from the AQUAINT corpus ) and 4 human reference summaries . The TAC 2009 Summarization task has 44 topic clusters . Each topic has 2 sets of 10 news documents obtained from the AQUAINT 2 corpus . There are 4 human 100 - word reference summaries for each set , where the reference summaries for the first set are query - oriented , and for the second set are update summaries .",Supplement,Website,Introduce,Sequence Generative Adversarial Network for Long Text Summarization,https://ieeexplore.ieee.org/abstract/document/8576043
"Fortunately , machine translation techniques have been well developed in the NLP field , though the translation performance is far from satisfactory . A few commercial machine translation services can be publicly accessed , e . g . Google Translate , Yahoo Babel Fish and Windows Live Translate . In this study , we adopt Google Translate for both English - to - Chinese Translation and Chinese - toEnglish Translation , because it is one of the state - of - the - art commercial machine translation systems used today . Google Translate applies statistical learning techniques to build a translation model based on both monolingual text in the target language and aligned text consisting of examples of human translations between the languages .",Supplement,Website,Introduce,Using Bilingual Knowledge and Ensemble Techniques for Unsupervised Chinese Sentiment Analysis,https://aclanthology.org/D08-1058.pdf
"The current WN . Br database presents the following figures : 11 , 000 verb forms ( 4 , 000 synsets ), 17 , 000 noun forms ( 8 , 000 synsets ), 15 , 000 adjective forms ( 6 , 000 synsets ), and 1 , 000 adverb forms ( 500 synsets ), amounting to 44 , 000 word forms and 18 , 500 synsets ( Dias - da - Silva et al , 2008 ). project started in September 2009 and shall be finished finish in August 2011 . It has been developed in the laboratory of the Research Group of Terminology ( GETerm ) in Federal University of São Carlos ( UFSCar ) with the collaboration of the Interinstitutional Center for Research and Development in Computational Linguistics ( NILC / University of São Paulo ) researchers . The TermiNet project has two main objectives . The first is to instantiate the generic NLP methodology , proposed by Dias - da - Silva ( 2006 ), for developing terminological databases according to the WN . Pr model .",Supplement,Website,Introduce,Long-term performance of the SwissQuantum quantum key distribution network in a field environment,https://iopscience.iop.org/article/10.1088/1367-2630/13/12/123001/meta
"Each version of our translation system was trained on the same bilingual training data . The bilingual parallel corpus that we used was distributed as part of the 2008 NIST Open Machine Translation Evaluation Workshop . The training set contained 88 , 108 Urdu – English sentence pairs , and a bilingual dictionary with 113 , 911 entries . For our development and test sets , we split the NIST MT - 08 test set into two portions ( with each document going into either test or dev , and preserving the genre split ). Our test set contained 883 Urdu sentences , each with four translations into English , and our dev set contained 981 Urdu sentences , each with four reference translations .",Supplement,Website,Introduce,Domain Adaptation for Statistical Machine Translation with Monolingual Resources,https://cris.fbk.eu/handle/11582/4850
"3 . For each of the German , Spanish , and French terms obtained , we used the title term , the meta keywords , and the emphasized concepts obtained from the same English wikipedia page as its potential translations . For example , consider an English page titled as “ World War II ” . The title term , the meta keywords , the emphasized concepts in English , and the hyperlinks ( to German , Spanish , and French ) associated are shown in Figure 1 . We first extract the basenames “ Zweiter Weltkrieg ” ( in German ), “ Segunda Guerra Mundial ” ( in Spanish ), and “ Seconde Guerre mondiale ” ( in French ) using the hyperlink feature .",Supplement,Website,Introduce,Multilingual Search for Cultural Heritage Archives via Combining Multiple Translation Resources,https://aclanthology.org/W07-0911.pdf
"Various networks built in BEL were mainly focusing on disease mechanisms ( Schlage et al ., 2011 ) and are used for causal reasoning ( Chindelevitch et al ., 2012 , Huang et al ., 2012 and Selventa 2012 ). Since 2012 , BEL is also available in the public domain through the OpenBEL consortium . The OpenBel portal defines the BEL language standard and provides formatted content and compatible tools for research . The necessary information to develop a BEL knowledge base is currently harvested mainly by manual translation of literature into BEL statements . To support automated extraction of statements by text mining techniques , additional efforts and adaptations of existing text mining platforms are necessary .",Supplement,Website,Introduce,Harmonizing major pathway databases to compare and evaluate their consensus,https://www.researchgate.net/profile/Sarah-Mubeen/publication/329797710_Harmonizing_major_pathway_databases_to_compare_and_evaluate_their_consensus/links/5c1af55792851c22a33821c8/Harmonizing-major-pathway-databases-to-compare-and-evaluate-their-consensus.pdf
"More recently , Opinion Mining and Sentiment Analysis on large social media datasets have received an increasing amount of attention outside academia , where a growing number of businesses and public institutions seek to gain insight into public opinion . For example , companies are primarily interested in what is being said about their brand and products , while public organisations are more concerned with analysing reactions to recent events , or with capturing the general political and societal Zeitgeist . The social network Twitter has been a popular target for such analyses as the vast majority of tweets are publicly available , and easily obtainable via the Twitter API , which conveniently enables the harnessing of a large number of realtime responses to any user - defined keyword query . In this paper we are concerned with what we call agile social media analysis , which is best illustrated with an example . Imagine that a political scientist wants to investigate reactions on Twitter to a speech given by British Prime Minister David Cameron the previous night .",Supplement,Website,Introduce,Feature-based opinion mining and ranking,https://www.sciencedirect.com/science/article/pii/S0022000011001139
"Document summarization is an active subject of research and development . The ACM Digital Library has about 806 reports on the subject published since 1993 , with over half of them appearing in the last five years . While the impetus for much of this research is the annual Text Analysis Conference ( TAC ) workshop on document summarization , there is a growing demand in the consumer market for news summarization applications being met by tablet and smart - phone applications such as Clipped , Summoner , TLDR , and Yahoo News . Yahoo and Google even acquired two companies developing such applications , Summly ( Stelter , 2013 ) and Wavii ( Tsotsis , 2013 ) respectively , earlier this year . While summarization technology for news sources is coming to fruition , the performance of such technology on non - English documents outside the news domain has not been throughly assessed and may need further research .",Supplement,Website,Introduce,ACL 2013 MultiLing Pilot Overview,https://aclanthology.org/W13-3104.pdf
"Second , though the authors act independently , they tend to produce surprisingly similar text , making the same sorts of jokes , or referring to words in the same sorts of ways . Thirdly , the authors often try to be non - obvious : obvious jokes are often not funny , and obvious crossword clues make a puzzle less challenging . The New Yorker magazine holds a weekly contest in which they publish a cartoon without a caption and solicit caption suggestions from their readers . The three funniest captions are selected by the editor and published in the following weeks . Figure 1 shows an example of such a cartoon , while Table 1 shows examples of captions , including its winning captions .",Supplement,Website,Introduce,On Teaching Metaphor,https://academic.oup.com/applij/article/9/2/125/162616
"The translation quality of state - of - the - art , phrase - based statistical machine translation ( SMT ) approaches heavily depends on the amount of bilingual language resources available to train the statistical models . For frequently used language pairs like French - English or ChineseEnglish , large - sized text data sets are readily available . There exist several data collection initiatives like the Linguistic Data Consortium , the European Language Resource Association , or the GSK , amassing and distributing large amounts of textual data . However , for less frequently used language pairs , e . g ., most of the Asian languages , only a limited amount of bilingual resources are available , if at all . In order to overcome such language resource limitations , recent research on multilingual SMT focuses on the usage of pivot languages .",Supplement,Website,Introduce,On the Importance of Pivot Language Selection for Statistical Machine Translation,https://aclanthology.org/N09-2056.pdf
"In the context of creating a common European research infrastructure network , our wordnet is licensed through META - SHARE , being freely available for scientific purposes . The development of the Romanian wordnet ( RoWN henceforth ) started within BalkaNet project . Afterwards , it has been developed and maintained within several projects by the Natural Language Processing ( NLP ) group of the Romanian Academy Research Institute for Artificial Intelligence ( RACAI ): ROTEL , STAR , SIR RESDEC , ACCURAT , METANET4U , the Romanian Academy research plan . Within BalkaNet a core of 18000 synsets was created . They were aligned to the Princeton WordNet ( PWN ) versions available throughout time , respectively version 2 . 0 at the end of the project .",Supplement,Website,Introduce,News about the Romanian Wordnet,https://aclanthology.org/W14-0137.pdf
"This paper describes the task . A full write up of the results is published separately ( Rosé & Siemens , 2014 ). Research on Massively Open Online Courses ( MOOCs ) is an emerging area for real world impact of technology for analysis of social media at a large scale ( Breslow et al ., 2013 ). Modeling user experience in MOOCs supports research towards understanding user needs better so that experiences that are more conducive to learning can be offered . Beyond that , automated analyses enable adaptive technology to tailor the experience of users in real time ( Rosé et al ., 2014a ).",Supplement,Website,Introduce,Where is Research on Massive Open Online Courses Headed? A Data Analysis of the MOOC Research Initiative,https://www.erudit.org/en/journals/irrodl/1900-v1-n1-irrodl04945/1065540ar/abstract/
"We can see that the medical history of patient can become more precise and detailed thanks to such contextual information . In this way , factual information related to the stomach aches of patient may receive these additional descriptions which make each occurrence different and nonredundant . Notice that the previous I2B2 contests addressed the information extraction tasks related to different kinds of contextual information . Temporality has become an important research field in the NLP topics and several challenges addressed this taks : ACE ( ACE challenge , 2004 ), SemEval ( Verhagen et al ., 2007 ; Verhagen et al ., 2010 ; UzZaman et al ., 2013 ), I2B2 2012 ( Sun et al ., 2013 ). We propose to continue working on the extraction of temporal information related to medical events .",Supplement,Website,Introduce,Tuning HeidelTime for identifying time expressions in clinical texts in English and French,https://aclanthology.org/W14-1116.pdf
"In the following sections we describe in more detail the dataset used for training and testing , the system developed , the evaluation methodology , as well as ablation experiments aimed at studying the contribution of different feature types to the AA task . We show experimentally that discriminative models with appropriate feature types can achieve performance close to the upper bound , as defined by the agreement between human examiners on the same test corpus . The Cambridge Learner Corpus ( CLC ), developed as a collaborative project between Cambridge University Press and Cambridge Assessment , is a large collection of texts produced by English language learners from around the world , sitting Cambridge Assessment ’ s English as a Second or Other Language ( ESOL ) examinations . For the purpose of this work , we extracted scripts produced by learners taking the First Certificate in English ( FCE ) exam , which assesses English at an upper - intermediate level . The scripts , which are anonymised , are annotated using XML and linked to meta - data about the question prompts , the candidate ’ s grades , native language and age .",Supplement,Website,Introduce,A New Dataset and Method for Automatically Grading ESOL Texts,https://aclanthology.org/P11-1019.pdf
"The majority of existing applications for Russian IE , and Natural Language Processing ( NLP ) in general , are commercially based , and are either published in Russian only , or not at all . One major player in Russian text mining is Yandex , the leading Russian search engine . Yandex uses IE to support its main search service , e . g ., to underline addresses and persons in search results , and in a service called “ Press Portraits ,” which builds profiles for various personalities found in the news . A profile may include the profession , biographical facts , news that s / he is involved in , and related people — using information automatically extracted from on - line Russian media . Yandex also recently unveiled an open - source toolkit Tomita , for developing IE systems based on context - free grammars .",Supplement,Website,Introduce,Adapting the PULS Event Extraction Framework to Analyze Russian Text,https://helda.helsinki.fi/handle/10138/40799
"It involves several important NLP research areas : automatic speech recognition ( ASR ), statistical machine translation ( SMT ) and speech synthesis , also known as text - to - speech ( TTS ). In recent years significant advance have also been made in relevant technological devices : the size of powerful computers has decreased to fit in a mobile phone and fast WiFi and 3G networks have spread widely to connect them to even more powerful computation servers . Several hand - held S2ST applications and devices have already become available , for example by IBM , Google or Jibbigo , but there are still serious limitations in vocabulary and language selection and performance . When an S2ST device is used in practical human interaction across a language barrier , one feature that is often missed is the personalization of the output voice . Whoever speaks to the device in what ever manner , the output voice always sounds the same .",Supplement,Website,Introduce,Advances in natural language processing,https://www.science.org/doi/abs/10.1126/science.aaa8685
"On the other hand , a lexicon - based approach using natural language processing techniques , developed for a generic sentiment analysis task with no adaptation to the provided training corpus . Results , though far from the best runs , prove that the generic model is more robust as it achieves a more balanced evaluation for message polarity along the different test sets . SemEval is an international competitive evaluation workshop on semantic related tasks . Among the ten different tasks that have been proposed in 2014 , Task 9 at SemEval - 2014 focuses on sentiment analysis in Twitter . Sentiment analysis could be described as the application of natural language processing and text analytics to identify and extract subjective information from texts .",Supplement,Website,Introduce,A review of natural language processing techniques for opinion mining systems,https://www.sciencedirect.com/science/article/abs/pii/S1566253516301117
"Our results possibly indicate the opposite , the “ polarizing ” model suggested by ( Franklin and Kosaki , 1989 ) and ( Johnson and Martin , 1998 ), where more negative opinions are observed after the decision ( in Figure 4 ), at least for a short period . By learning and visualize political sentiments , we could crystalize the nature of the decision that influences the degree to which the Supreme Court can move opinion in the direction of its decisions . Figure 5 shows a website that visualizes political sentiments over time . The website shows several popular U . S . Supreme Court cases , such as “ gay marriage ”, “ voting right act ”, “ tax cases ”, etc ., and general topics , such as “ Supreme Court ” and “ Justices ”. Each of the topics is represented by a list of keywords developed by political science experts .",Supplement,Website,Introduce,PUBLIC OPINION REACTION TO REPEATED EVENTS: Citizen Response to Multiple Supreme Court Abortion Decisions,https://link.springer.com/article/10.1007/s11109-005-9003-0
"Wikipedia ), constructing dictionaries ( e . g . Wiktionary ), or hosting online communities ( e . g . ACLWiki ). However , as wikis do not enforce their users to structure pages or add complementary metadata , wikis often end up as a mass of unmanageable pages with meaningless page titles and no usable link structure ( Buffa , 2006 ). To solve this issue , we present the Wikulu system which uses natural language processing to support wiki users with their typical tasks of adding , Portmanteau of the Hawaiian terms wiki (“ fast ”) and kukulu (“ to organize ”) organizing , and finding content .",Supplement,Website,Introduce,Knowledge-Driven Implicit Information Extraction,https://corescholar.libraries.wright.edu/etd_all/1571/
"The interest in the research community for the extraction of the sentiment in Twitter posts is reflected in the organization of several workshops with the aim of promoting the research in this task . Two are the most relevant , the first is the task Sentiment Analysis in Twitter celebrated within the SemEval workshop whose first edition was in 2013 ( Nakov et al ., 2013 ). The second is the workshop TASS , which is a workshop for promoting the research in sentiment analysis in Spanish in Twitter . The first edition of the workshop took place in 2012 ( Villena - Rom ´ an et al ., 2013 ). The 2014 edition of the task Sentiment Analysis in Twitter proposes a first subtask , which has as challenge the sentiment classification at entity level , and a second subtask that consists of the polarity classification at document or tweet level .",Supplement,Website,Introduce,Understanding #WorldEnvironmentDay User Opinions in Twitter: A Topic-Based Sentiment Analysis Approach,https://www.mdpi.com/1660-4601/15/11/2537
"Recognition of named entities in natural language text is an important subtask of information extraction and thus bears importance for modern text mining and information retrieval applications . The need to identify named entities such as persons , locations , organizations and places , arises both in applications where the entities are first class objects of interest , such as in Wikification of documents ( Ratinov et al ., 2011 ), and in applications where knowledge of named entities is helpful in boosting performance , e . g ., machine translation ( Babych and Hartley , 2003 ) and question answering ( Leidner et al ., 2003 ). The advent of massive machine readable factual databases , such as Freebase and the proposed Wikidata , will likely push the need for automatic extraction tools further . While these databases store information about entity types and the relationships between those types , the named entity recognition ( NER ) task concerns finding occurrences of named entities in context . This view originated with the Message Understanding Conferences ( MUC ) ( Grishman and Sundheim , 1996 ).",Supplement,Website,Introduce,A Comparative Study of Dictionary-based and Machine Learning-based Named Entity Recognition in Pashto,https://dl.acm.org/doi/abs/10.1145/3443279.3443307
"Comme ce travail est tres connu , nous ne le d6crirons pas plus en d6tail ici ( Miller , 1990 ). Si WN est une ressource lexicale , il peut 6galement etre vu comme un corpus . Ceci peut s ' av6rer tres utile , si l ' on veut le comparer avec d ' autres corpus — comme , par exemple , Wikipedia qui est une encyclop6die multilingue , collaborative et libre — ou si l ' on veut faire usage d ' une partie sp6cifique de la base , par exemple , les gloses . Puisque les gloses correspondent sch6matiquement ˆ la signification d ' un mot ( d6finition ), leurs 6l6ments ( sac de mots ) peuvent etre utilis6s pour acc6der au mot dont ils d6finissent le sens ( entr6e lexicale , lemme ). WN a eu un grand impact dans la communaut6 TAL od il est fortement utilis6 .",Supplement,Website,Introduce,MEMOIRE DE DEA,https://core.ac.uk/download/pdf/32632107.pdf
"The system obtains accuracies of 0 . 70 and 0 . 73 for the restaurant and laptop domain respectively , and performs second best in the out - of - domain hotel , achieving an accuracy of 0 . 80 . Nowadays Sentiment Analysis is proving very useful for tasks such as decision making and market analysis . The ever increasing interest is also shown in the number of related shared tasks organized : TASS ( Villena - Rom ´ an et al ., 2012 ; Villena - Rom ´ an et al ., 2014 ), SemEval ( Nakov et al ., 2013 ; Pontiki et al ., 2014 ; Rosenthal et al ., 2014 ), or the SemSA Challenge at ESWC2014 . Research has also been evolving towards specific opinion elements such as entities or properties of a certain opinion target , which is also known as ABSA . The Semeval 2015 ABSA shared task aims at covering the most common problems in an ABSA task : detecting the specific topics an opinion refers to ( slot1 ); extracting the opinion targets ( slot2 ), combining the topic and target identification ( slot1 & 2 ) and , finally , computing the polarity of the identified word / targets ( slot3 ).",Supplement,Website,Introduce,"A survey on opinion mining and sentiment analysis: Tasks, approaches and applications",https://www.sciencedirect.com/science/article/abs/pii/S0950705115002336
"We also allowed for “ Not Applicable ” option to capture ratings where the Turkers did not have sufficient knowledge about the statement or if the statement was not really a claim . Figure 6 shows the set of instructions provided to the Turkers , and Figure 5 illustrates the annotation interface . We excluded tweets for which three or more Turkers gave a rating of “ Not Applicable ,” leaving us with a dataset of 1170 tweets . Within this set , the average variance per tweet ( excluding “ Not Applicable ” ratings ) was 0 . 585 . Having obtained a corpus of factuality ratings , we now model the factors that drive these ratings .",Supplement,Website,Introduce,Modeling Factuality Judgments in Social Media Text,https://aclanthology.org/P14-2068.pdf
"To date , most meteorites recovered throughout history have been done so in Antarctica in the last 20 years . Furthermore , they are less likely to be contaminated by terrestrial compounds . Meteorites are of interest to space scientists because , with the exception of the Apollo lunar samples , they are the sole source of extra - terrestrial material and a window on the early evolution of the solar system . The identification of Martian and lunar meteorite samples , and the ( controversial ) evidence of fossil bacteria in the former underscores the importance of systematically retrieving as many samples as possible . Currently , Antarctic meteorite samples are collected by human searchers , either on foot , or on snowmobiles , who systematically search an area and retrieve samples according to strict protocols .",Supplement,Website,Introduce,The stereochemistry of amino acids in the Murchison meteorite,https://www.sciencedirect.com/science/article/abs/pii/S0301926800001236
"The tasks described in Section 3 were offered on Amazon Mechanical Turk ( ), which allows workers ( our pool of prospective subjects ) to perform small jobs for a fee through a Web interface . No specialized training or knowledge is typically expected of the workers . Amazon Mechanical Turk has been successfully used in the past to develop gold - standard data for natural language processing [ 22 ] and to label images [ 23 ].",Supplement,Website,Introduce,Evaluating and improving the usability of Mechanical Turk for low-income workers in India,https://dl.acm.org/doi/abs/10.1145/1926180.1926195
"Proof of concept : Key Influencers in Theoretical Physics : Drawn from a KDD Cup 2003 task , this datasetis publically available at : http :// www . cs . cornell . edu / projects / kddcup / datasets . html . It consists of the latex sources of all papers in the hep - th portion of the arXiv ( ) In consultation with a theoretical physicist we did our analysis at a time granularity of 1 month . In total , the data spans 137 months . We created document term matrices using standard text processing techniques , over a vocabulary of 463 words chosen by running an unsupervised topic model .",Supplement,Website,Introduce,Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference,https://proceedings.neurips.cc/paper/2010/hash/bcc0d400288793e8bdcd7c19a8ac0c2b-Abstract.html
"This means that we have a trade - off of fast computation per iteration and slow convergence for SGD versus slow computation per iteration and fast convergence for gradient descent . Although the fast computation means it can reach an approximate solution relatively quickly , and thus has been proposed by various researchers for large scale problems Zhang [ 2004 ], Shalev - Shwartz et al . [ 2007 ] ( also see Leon Bottou ’ s Webpage ), the convergence slows down when we need a more accurate solution . In order to improve SGD , one has to design methods that can reduce the variance , which allows us to use a larger learning rate ηt . Two recent papers Le Roux et al .",Supplement,Website,Introduce,Accelerating Stochastic Gradient Descent using Predictive Variance Reduction,https://proceedings.neurips.cc/paper/2013/hash/ac1dd209cbcc5e5d1c6e28598e8cbbe8-Abstract.html
"Since this prior structure can be implemented using efficient algorithms that add negligible cost beyond standard inference techniques , we recommend it as a new standard for topic modeling . Topic models such as latent Dirichlet allocation ( LDA ) [ 3 ] have been recognized as useful tools for analyzing large , unstructured collections of documents . There is a significant body of work applying LDA to an wide variety of tasks including analysis of news articles [ 14 ], study of the history of scientific ideas [ 2 , 9 ], topic - based search interfaces and navigation tools for digital libraries [ 12 ]. In practice , users of topic models are typically faced with two immediate problems : First , extremely common words tend to dominate all topics . Second , there is relatively little guidance available on how to set T , the number of topics , or studies regarding the effects of using a suboptimal setting for T . Standard practice is to remove “ stop words ” before modeling using a manually constructed , corpus - specific stop word list and to optimize T by either analyzing probabilities of held - out documents or resorting to a more complicated nonparametric model .",Supplement,Website,Introduce,Rethinking LDA: Why Priors Matter,https://proceedings.neurips.cc/paper/2009/hash/0d0871f0806eae32d30983b62252da50-Abstract.html
"Finally , while we discuss the main application of our results in the context of advertising exchanges , our model and results apply to the broad space of platforms that serve as intermediaries between buyers and sellers , and help run many repeated auctions over time . The issue of dynamic revenue sharing also arises when Amazon or eBay act as a platform and splits revenues from a sale with the sellers , or when ride - sharing services such as Uber or Lyft split the fare paid by the passenger between the driver and the platform . Uber for example mentions in their website that : “ Drivers using the partner app are charged an Uber Fee as a percentage of each trip fare . The Uber Fee varies by city and vehicle type and helps Uber cover costs such as technology , marketing and development of new features within the app .” We propose different designs of auctions and revenue sharing policies in exchanges and analyze them both theoretically and empirically on data from a major ad exchange . We compare against the naïve policy described above .",Supplement,Website,Introduce,Dynamic Revenue Sharing,https://proceedings.neurips.cc/paper/2017/hash/cb8acb1dc9821bf74e6ca9068032d623-Abstract.html
LanguageTool was developed by Naber ( 2003 ). It can run as a stand - alone program and as an extension for OpenOffice . Org1 and LibreOffice2 . LanguageTool is distributed through LanguageTool ’ s website : _CITE_,Supplement,Website,Produce,A Grammar Checker for Tagalog using LanguageTool,https://aclanthology.org/W11-3402.pdf
"Combining all edges ( SR + LM + SB ) does not influence the results any more , but in any case the hybrid configuration achieves the best overall recall ( 0 . 87 ). In conclusion , our experiments on all four datasets consistently demonstrate that combining Dijkstra - WSA with a similarity - based approach as a back - off yields the strongest performance . The results of these best alignments will be made freely available to the research community on our website ( ).",Supplement,Website,Produce,Dijkstra-WSA: A Graph-Based Approach to Word Sense Alignment,https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00217/43228/Dijkstra-WSA-A-Graph-Based-Approach-to-Word-Sense
"Systems that can produce an appropriate semantic representation for a TTS are not many at an international level but they can be traced from the results of a Shared Task organized by members of SigSem and are listed here below in the corresponding webpage _2008_shared_task : _comparing_semantic_repre sentations ( see Bos & Delmonte , 2008 ). State of the art semantic systems are based on different theories and representations , but the final aim of the workshop was reaching a consensus on what constituted a reasonably complete semantic representation . Semantics in our case not only refers to predicate - argument structure , negation scope , quantified structures , anaphora resolution and other similar items , it refers essentially to a propositional level analysis .",Supplement,Website,Produce,Semantics and Discourse Processing for Expressive TTS,https://aclanthology.org/W15-2704.pdf
"Since Sinhala words have not been added to this synset , it shows the available information in the English WordNet . In addition , it shows suggested Sinhala words obtained from linguistic resources as described in Section 4 . 2 . The web - based user interface is operational and can be accessed from The modifications made by the contributors have to be approved by an evaluator before being included in a release . How to effectively use a crowdsourcing technique to get a particular task done with acceptable quality is an open research question .",Supplement,Website,Produce,Building a WordNet for Sinhala,https://aclanthology.org/W14-0114.pdf
"We collected pairs of articles spanning from 1 / 1 / 2001 through 10 / 05 / 2005 . The corpus consists of 2 , 327 documents , with 0 - 8 documents per day . The corpus is available on our web page at cogcomp /. The English side was tagged with a publicly available NER system based on the SNoW learning architecture ( Roth , 1998 ), that is available on the same site . This set of English NEs was hand - pruned to remove incorrectly classified words to obtain 978 single word NEs .",Supplement,Website,Produce,"Licentiate thesis, monograph (Other academic)",https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A23705&dswid=-2823
"MAISE can be obtained from the author ’ s webpage : The release includes MAISE ’ s source code , instructions , documentation , and a tutorial . MAISE is an open - source tool , licensed under the terms of the GNU Lesser General Public License ( LGPL ).",Supplement,Website,Produce,The Jikes Research Virtual Machine project: Building an open-source research community,https://ieeexplore.ieee.org/abstract/document/5386722
"It has been designed for corpus collecting , annotating , maintaining and analyzing . Additionally , it has been designed as the engine , which the end user could use with their data . ( See a service on ).",Supplement,Website,Produce,The WaCky wide web: a collection of very large linguistically processed web-crawled corpora,https://link.springer.com/article/10.1007/s10579-009-9081-4
"ArSenL - AWN , will have an AWN offset while an entry in ArSenL - Eng will have the same field set to N . A ( Not Available ). Furthermore , due to manual correction performed to ArSenL - AWN , the gold version of the union lexicon includes 28 , 780 lemmas with the corresponding number of 157 , 969 synsets . A public interface to browsing ArSenL is available at The interface allows the user to search for an Arabic word . The output would show the different scores for the Arabic word along with the corresponding sentiment scores , English glosses and examples that help in disambiguating different sentiment scores for the same Arabic lemma .",Supplement,Website,Produce,A Large Scale Arabic Sentiment Lexicon for Arabic Opinion Mining,https://aclanthology.org/W14-3623.pdf
"Three distinct human summaries were produced for each chain . For each chain , one summary was produced for each of the three queries , where the person producing the summary was not shown the next steps in the chain when answering the first query . To simulate the exploratory search of the user we provided the annotators with a Solr query interface for each document collection . The interface allowed querying the document set , reading the documents and choosing sentences which answer the query . After choosing the sentences , annotators can copy and edit the resulting summary in order to create an answer of up to 250 words .",Supplement,Website,Produce,Query-Chain Focused Summarization,https://aclanthology.org/P14-1086.pdf
"Systems which can link local semantic argument structures can create more complete meaning representations of a text than semantic role labellers restricted to the local domain . In order to stimulate research in this direction , we are organising a Shared Task at SemEval2010 on finding links between locally uninstantiated roles and the discourse context . To our knowledge , the data we are creating for this task will be the first publicly available reference data set containing information about global linking of semantic argument structures . ally , he was cleared . While discourse information can be beneficial for the computation of sematic argument structures , the reverse is also true : the semantic argument structures in a text and their relations can provide vital cues about the coherence of the discourse .",Supplement,Website,Produce,Semantic Argument Structure in DiscoursE: The SEASIDE Project,https://aclanthology.org/W09-3738.pdf
"In particular , we will show an initial version of a GUI - based top - level for the development environment , a tool that supports graphical debugging of unification grammars by cutting and pasting of derivation trees , and various functionalities that support systematic development of speech translation and spoken dialogue applications built using Regulus . The Regulus platform is a comprehensive toolkit for developing grammar - based speech - enabled systems that can be run on the commercially available Nuance recognition environment . The platform has been developed by an Open Source consortium , the main partners of which have been NASA Ames Research Center and Geneva University , and is freely available for download from the SourceForge website . Regulus has been used to build several large systems , including Geneva University ’ s MedSLT medical speech translator ( Bouillon et al ., 2005 ) and NASA ’ s Clarissa procedure browser ( Rayner et al ., 2005b ) . Regulus is described at length in ( Rayner et al ., 2006 ), the first half of which consists of an extended tutorial introduction .",Supplement,Website,Produce,A Development Environment for Building Grammar-Based Speech-Enabled Applications,https://aclanthology.org/W07-1807.pdf
"In releasing this data we hope to equip researchers with the data to support numerous research directions going forward . The JCLC is freely available to the research community and accessible via our website . It can be used via a web - based interface for querying the data . Alternatively , the original texts can be downloaded in text format for more advanced tasks . Interest in learning Chinese is rapidly growing , leading to increased research in Teaching Chinese as a Foreign Language ( TCFL ) and the development of related resources such as learner corpora ( Chen et al ., 2010 ).",Supplement,Website,Produce,"Community assembly, coexistence and the environmental filtering metaphor",https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2435.12345
"Recent studies show that language varieties can be discriminated automatically using words or characters as features ( Zampieri and Gebre , 2012 ; Lui and Cook , 2013 ) . However , due to performance limitations , state - of - the - art general - purpose language identification systems do not distinguish texts from different national varieties , modelling pluricentric languages as unique classes . To evaluate how state - of - the - art systems perform in identifying similar languages and varieties , we decided to organize the Discriminating between Similar Languages ( DSL ) shared task . This shared task was organized within the scope of the workshop on Applying NLP Tools to Similar Languages , Varieties and Dialects ( VarDial ) in the 2014 edition of COLING . The motivation behind the DSL shared task is two - fold .",Supplement,Website,Produce,Merging Comparable Data Sources for the Discrimination of Similar Languages: The DSL Corpus Collection,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=054d590fd32756ae6ca7f231b5aec2546b3e8c32
"Given six datasets in Catalan , Dutch , English , German , Italian , and Spanish , the task we present involved automatically detecting full coreference chains — composed of named entities ( NEs ), pronouns , and full noun phrases — in four different scenarios . For more information , the reader is referred to the task website . The rest of the paper is organized as follows . Section 2 presents the corpora from which the task datasets were extracted , and the automatic tools used to preprocess them . In Section 3 , we describe the task by providing information about the data format , evaluation settings , and evaluation metrics .",Supplement,Website,Produce,"Given six datasets in Catalan , Dutch , English , German , Italian , and Spanish , the task we present involved automatically detecting full coreference chains — composed of named",Merging Comparable Data Sources for the Discrimination of Similar Languages: The DSL Corpus Collection
"for and against , policies ultimately adopted by the government , and the impact of those policies . The set of datasets made available is listed in Table 1 . Several additional datasets were suggested on the website , but were not part of the official data . Forty teams initially registered to participate in the unshared task ; ten submitted papers . The teams came from a variety of institutions spread across six countries .",Supplement,Website,Produce,A global panel database of pandemic policies (Oxford COVID-19 Government Response Tracker),https://www.nature.com/articles/s41562-021-01079-8
"prediction appearing in computational biology , where our method obtains less than a half of the error rate of the best competing HMM - based method . Our predictions are available at Wormbase : Additional data and results are available at the project ’ s website http :// www . fml . mpg . de / raetsch / projects / msplicer . Acknowledgments We thank K .- R . M ¨ uller , B . Sch ¨ olkopf , E . Georgii , A . Zien , G . Schweikert and G . Zeller for inspiring discussions .",Supplement,Website,Produce,Large Scale Hidden Semi-Markov SVMs,https://proceedings.neurips.cc/paper/2006/hash/faa453efde4ac6a36849ba381feb9e87-Abstract.html
"Training can take days but once trained predictions can be carried on a proteomic or protein engineering scale . Several improvements are currently in progress including ( a ) developing a classifier to discriminate protein chains that do not contain any disulphide bridges , using kernel methods ; ( b ) assessing the effect on prediction of additional input information , such as secondary structure and solvent accessibility ; ( c ) leveraging the predicted cysteine contacts in 3D protein structure prediction ; and ( d ) curating a new larger training set . The current version of our disulphide prediction server DIpro ( which includes step ( a )) is available through : _CITE_",Supplement,Website,Produce,"Large-scale prediction of disulphide bridges using kernel methods, two-dimensional recursive neural networks, and weighted graph matching",https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.20787
"We presume no more objectivity in answering this question than we would have in judging the merits of our other children . However , we believe that the level of musicality attained by our system is truly surprising , while the reliability is sufficient for live demonstration . We hope that the interested reader will form an independent opinion , even if different from ours , and to this end we have made musical examples demonstrating our progress available on the web page : _CITE_",Supplement,Website,Produce,General Intelligence Objectively Determined and Measured.,https://psycnet.apa.org/record/2006-10257-006
"The images are rather inhomogeneous , since they show different persons with different facial expressions . Some sample images are depicted in figure 6 . For a complete overview over the whole image set , we refer the reader to our supplementary web page , where all images can be viewed in higher quality .",Supplement,Website,Produce,Feature Selection in Clustering Problems,https://proceedings.neurips.cc/paper/2003/hash/bb03e43ffe34eeb242a2ee4a4f125e56-Abstract.html
"This work is supported by ONR grant N00014 - 96 - 1 - 0418 and a Kxasnow Foundation Postdoctoral fellowship . Thanks to Gerry Tesauro for providing PUBEVAL and subsequent means to calibrate it , Jack Laurence and Pablo Funes for development of the WWW front end to our evolved player . Interested players can challenge our evolved network using a web browser through our home page at : _CITE_",Supplement,Website,Produce,Why did TD-Gammon Work?,https://proceedings.neurips.cc/paper/1996/hash/459a4ddcb586f24efd9395aa7662bc7c-Abstract.html
"We now empirically explore our method ’ s behavior . All of our code , data , and experiments may be found on the CodaLab worksheet for this paper at , which also contains more detailed plots beyond those shown here . We would like to answer the following questions :",Supplement,Website,Produce,Do machine learning platforms provide out-of-the-box reproducibility?,https://www.sciencedirect.com/science/article/pii/S0167739X21002090
"The advantage of our method is that we can jointly learn the optimal feature representation and the optimal domain transformation parameter , which are aware of the subsequent transductive inference procedure . Following the standard evaluation protocol in the unsupervised domain adaptation community , we evaluate our method on the digit classification task using MNIST [ 19 ] and SVHN [ 21 ] as well as the object recognition task using the Office [ 25 ] dataset , and demonstrate state of the art performance in comparison to all existing unsupervised domain adaptation methods . Learned models and the source code can be reached from the project webpage",Supplement,Website,Produce,Learning Transferrable Representations for Unsupervised Domain Adaptation,https://proceedings.neurips.cc/paper/2016/hash/b59c67bf196a4758191e42f76670ceba-Abstract.html
"We have found the flow - based Midflow and MQI rounding methods to be highly effective in practice on diverse classes of graphs including space - like graphs and power law graphs . Results for real - world power law graphs are shown in figure 5 . Results for a number of FE meshes can be found on the Graph Partitioning Archive website , which keeps track of the best nearly balanced cuts ever found for a number of classic benchmarks . Using flow - based rounding to extract cuts from spectral - type embeddings , we have found new record cuts for the majority of the largest graphs on the site , including fe body , t60k , wing , brack2 , fe tooth , fe rotor , 598a , 144 , wave , m14b , and auto . It is interesting to note that the spectral method previously did not own any of the records for these classic benchmarks , although it could have if flow - based rounding had been used instead of hyperplane rounding .",Supplement,Website,Produce,Fixing two weaknesses of the Spectral Method,https://proceedings.neurips.cc/paper/2005/hash/045cf83ab0722e782cf72d14e44adf98-Abstract.html
"Through evolution , structure is more conserved than sequence , so that detecting even very subtle sequence similarities , or remote homology , is important for predicting function . The major methods for homology detection can be split into three basic groups : pairwise sequence comparison algorithms [ 1 , 2 ], generative models for protein families [ 3 , 4 ], and discriminative classifiers [ 5 , 6 , 7 ]. Popular sequence comparison methods such as BLAST * Supplemental information for the paper , including the data sets and Matlab source code can be found on this author ’ s web page at and Smith - Waterman are based on unsupervised alignment scores . Generative models such as profile hidden Markov models ( HMMs ) model positive examples of a protein family , but they can be trained iteratively using both positively labeled and unlabeled examples by pulling in close homologs and adding them to the positive set . A compromise between these methods is PSI - BLAST [ 8 ], which uses BLAST to iteratively build a probabilistic profile of a query sequence and obtain a more sensitive sequence comparison score .",Supplement,Website,Produce,Protein structure prediction on the Web: a case study using the Phyre server,https://www.nature.com/articles/nprot.2009.2
"For each object in a mini - batch , we include projections from all 24 views as supervision . The models including the perspective transformer nets are implemented using Torch [ 3 ]. To download the code , please refer to the project webpage : Experimental Design . As mentioned in the formulation , there are several variants of the model depending on the hyper - parameters of learning objectives λpT ,, j and λ ,,,,.",Supplement,Website,Produce,Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision,https://proceedings.neurips.cc/paper/2016/hash/e820a45f1dfc7b95282d10b6087e11c0-Abstract.html
"All the results shown in Table I are averaged over 10 random permutations of the training sequence . The columns marked 6Notice that B and C in part I do not satisfy this relationship . & apos ; Available on Y . LeCun & apos ; s home page : & quot ; Corn & apos ; s & quot ; give the total number of corrections made in the training phase for the 10 labels . The first three rows of Table 1 are taken from [ 4 , 12 , 13 ].",Supplement,Website,Produce,A New Approximate Maximal Margin Classification Algorithm,https://proceedings.neurips.cc/paper/2000/hash/d072677d210ac4c03ba046120f0802ec-Abstract.html
"Qualitative Evaluation : Prediction video . The prediction videos of our models and baselines are available in the supplementary material and at the following website : Asseeninthe videos , the proposed models make qualitatively reasonable predictions over 30 – 500 steps depending on the game . In all games , the MLP baseline quickly diverges , and the naFf baseline fails to predict the controlled object .",Supplement,Website,Produce,Action-Conditional Video Prediction using Deep Networks in Atari Games,https://proceedings.neurips.cc/paper/2015/hash/6ba3af5d7b2790e73f0de32e5c8c1798-Abstract.html
"We used a soft - max operation with an increasing temperature parameter to model the non - differentiable color channel selection at each point , which allowed us to train the pattern effectively . Finally , we demonstrated that our learned pattern enabled better reconstructions than past designs . An implementation of our method , along with trained models , data , and results , is available at our project page at Our results suggest that learning measurement strategies jointly with computational inference is both useful and possible . In particular , our approach can be used directly to learn other forms of optimized multiplexing patterns — e . g ., spatio - temporal multiplexing for video , viewpoint multiplexing in lightfield cameras , etc .",Supplement,Website,Produce,Learning Sensor Multiplexing Design through Back-propagation,https://proceedings.neurips.cc/paper/2016/hash/aa486f25175cbdc3854151288a645c19-Abstract.html
Figure 5 shows our predicted distribution is very close to the ground - truth distribution . It also shows that a variational autoencoder helps to capture the true distribution of future frames . ‡ Our project page : _CITE_,Supplement,Website,Produce,Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks,https://proceedings.neurips.cc/paper/2016/hash/03afdbd66e7929b125f8597834fa83a4-Abstract.html
"There are 22 , 894 atom symmetry classes , which when paired with reaction condition yields 29 , 104 ( a , c ) tuples . Of these 29 , 104 ( a , c ) tuples , 1 , 262 have label srcreact = 1 , and 1 , 786 have label sinkreact = 1 . Atom and MO interaction data is available at our chemoinformatics portal ( ) under Supplements .",Supplement,Website,Produce,Leveraging Graph Neighborhoods for Efficient Inference,https://dl.acm.org/doi/abs/10.1145/3357384.3358049
"We thank Jakob Macke , Pierre Garrigues , and Greg Stephens for helpful comments and stimulating discussions , as well as Alexander Ecker and Andreas Hoenselaar for last minute advice . An implementation of the DG model in Matlab and R will be avaible at our website _CITE_",Supplement,Website,Produce,Model-based spike sorting with a mixture of drifting t-distributions,https://www.sciencedirect.com/science/article/pii/S016502701730225X
"Due to space limitations , we omit proofs from this version of the paper . Complete proofs may be found in the extended version , which is available on the author ’ s Web page ( ). To prove ( a ), we show that when the search is at a node v whose least common ancestor with the target has height h , there is a high probability that v has a link into the sub - tree of height h − 1 containing the target . In this way , the search reaches the target in logarithmically many steps .",Supplement,Website,Produce,Small-World Phenomena and the Dynamics of Information,https://proceedings.neurips.cc/paper/2001/hash/52dbb0686f8bd0c0c757acf716e28ec0-Abstract.html
"We know of no significant disadvantage in using the GTM algorithm in place of the SOM . While we believe the SOM procedure is superseded by the GTM algorithm , is should be noted that the SOM has provided much of the inspiration for developing GTM . A web site for GTM is provided at : which includes postscript files of relevant papers , software implementations in Matlab and C , and example data sets used in the development of the GTM algorithm .",Supplement,Website,Produce,GTM: A Principled Alternative to the Self-Organizing Map,https://proceedings.neurips.cc/paper/1996/hash/4e4e53aa080247bc31d0eb4e7aeb07a0-Abstract.html
More experiments and results on real data sets can be found on our web - page _CITE_,Supplement,Website,Produce,The MovieLens Datasets: History and Context,https://dl.acm.org/doi/abs/10.1145/2827872
"Then , all moved to watch the table tennis game ( 710th frame : one gaze concurrence ). Our method correctly evaluates the gaze concurrences at the location where people look . All results are best seen in the videos from the following project website ( ).",Supplement,Website,Produce,3D Social Saliency from Head-mounted Cameras,https://proceedings.neurips.cc/paper/2012/file/1bf2efbbe0c49b9f567c2e40f645279a-Paper.pdf
"In Section 4 . 1 , we will describe the process to collect the data , and the method to monitor the quality of annotations . Some statistics and examples of the dataset will be given in Section 4 . 2 . The latest dataset is available on the project page : _CITE_",Supplement,Website,Produce,Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question,https://proceedings.neurips.cc/paper/2015/hash/fb508ef074ee78a0e58c68be06d8a2eb-Abstract.html
"For all data sets , training time was limited to at most 1 , 000 epochs over the training set . The best models were selected by early stopping using the mean predicted ranks on the validation sets ( raw setting ). An open - source implementation of TransE is available from the project webpage . Overall results Tables 3 displays the results on all data sets for all compared methods . As expected , the filtered setting provides lower mean ranks and higher hits @ 10 , which we believe are a clearer evaluation of the performance of the methods in link prediction .",Supplement,Website,Produce,Translating Embeddings for Modeling Multi-relational Data,https://proceedings.neurips.cc/paper_files/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html
"All other aspects of GP inference remain the same . All of the experiments in this paper were performed using the standard GPML toolbox ; code to perform all experiments is available at the author ’ s website . Plate [ 6 ] constructs a form of additive GP , but using only the first - order and Dth order terms . This model is motivated by the desire to trade off the interpretability of first - order models , with the flexibility of full - order models . Our experiments show that often , the intermediate degrees of interaction contribute most of the variance .",Supplement,Website,Produce,A Framework for Evaluating Approximation Methods for Gaussian Process Regression,https://www.jmlr.org/papers/volume14/chalupka13a/chalupka13a.pdf
"More specifically , we record multiple peo318 { xtm , stm } M ‡ m = 1 . by the vector xi set of micophones Given the rcorded sinal the t the state of the i - th particle at time t . We also ait ∈{ 1 , ... , P } in order to denote the particle that precedes the gnals Speakers may stat speakng or become sil t corresponds to the index of the ancestor particle of xi i - th particle at time t . That is , ai collect data from several speakers from the ASCAL t . Let alsoxi1 : t xi the particle trajctory that s recursively defined as hallenge website . The voice signal for each speak example to clarify the notation . and the emission In Step 1 , we follow the slice sampling scheme for inference in BNP models based on the Indian bu et process ( IBP ) [ 19 , 23 ], which ectively transforms the model into a finite factorial model with = M + + Mnew parallel chains . Step 2 consists in sampling the elements of the matrices S and X given the current value of the global variables .",Supplement,Website,Produce,Infinite Factorial Dynamical Model,https://proceedings.neurips.cc/paper/2015/hash/0768281a05da9f27df178b5c39a51263-Abstract.html
"We have tested the performance of the proposed method on mixtures of different voice and music signals . The sample rate of the mixtures is 22 . 05kHz . Audio files for all the experiments are accessible at the website . Figure 2 shows experimental results . In experiments 1 and 2 , the mixed signals consist of one voice signal and one music signal .",Supplement,Website,Produce,Music Genre Classification Using MIDI and Audio Features,https://link.springer.com/content/pdf/10.1155/2007/36409.pdf
"For CDNA and STP , we used 10 transformers . While we show stills from the predicted videos in the figures , the qualitative results are easiest to compare when the predicted videos can be viewed side - by - side . For this reason , we encourage the reader to examine the video results on the supplemental website . Code for training the model is also available on the website . Training details : We trained all models using the TensorFlow library [ 1 ], optimizing to convergence using ADAM [ 13 ] with the suggested hyperparameters .",Supplement,Website,Produce,Unsupervised Learning for Physical Interaction through Video Prediction,https://proceedings.neurips.cc/paper/2016/hash/d9d4f495e875a2e075a1a4a6e1b9770f-Abstract.html
"The UIUC dataset contains 314 cluttered indoor images , of which the ground - truth is two label maps of background layout with / without foreground objects . Our dataset contains 220 images which cover six indoor scene categories : bedroom , living room , kitchen , classroom , office room , and corridor . The dataset is available on the project webpage . The ground - truths are hand labeled segments for scene components for each image . Our algorithm usually takes 20s in clustering , 40s in sampling , and 1m in preparing input features .",Supplement,Website,Produce,"Scene Parsing by Integrating Function, Geometry and Appearance Models",https://openaccess.thecvf.com/content_cvpr_2013/html/Zhao_Scene_Parsing_by_2013_CVPR_paper.html
Supplementary Information accompanies this paper on the Oncogene website ( ),Supplement,Website,Produce,Activation and transposition of endogenous retroviral elements in hypomethylation induced tumors in mice,https://www.nature.com/articles/1210631
The datasets generated during and / or analysed during the current study are available in the documentation webpage ( ) of the software that is deposited to the CRAN ( http :// cran . r - project . org / package = XGR ).,Supplement,Website,Produce,"Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences",https://link.springer.com/article/10.1186/gb-2010-11-8-r86
"VectorBase also assists the community with a helpdesk system at info @ vectorbase . org or via our ‘ Contact Us ’ link ( ). Helpdesk inquiries can be of any type , and we supplement our availability with online documentation such as FAQs , a Glossary of relevant terms and data policies . Constantly updated VectorBase tutorials provide training material for both novice and advanced users , and include practice exercises and sample files .",Supplement,Website,Produce,VectorBase: an updated bioinformatics resource for invertebrate vectors and other organisms related with human diseases,https://academic.oup.com/nar/article/43/D1/D707/2437683
"These include search services for various aspects of structural similarity ( Sequence Navigator , Structure Navigator , GIRAF , eF - seek ), function prediction and annotation ( SeSAW , SFAS ), structure prediction and modeling services ( CRNPRED , Spanner ), sequence and structure alignment ( ASH , MAFFTash ), derived databases ( EM Navigator , eF - site , ProMode ) and educational resources ( Protein Globe , eProtS , Japanese translation of the Molecule of the Month ). Among them , we describe below two recently developed services , Yorodumi and EM Navigator . Yorodumi and EM Navigator : integration with electron microscopy structures In addition to the simple summary page for each entry , PDBj also provides a more feature - rich entry - wise interface called Yorodumi ( Figure 3A , ). Yorodumi is an interactive and integrated interface for browsing 3D structure data not only in the PDB but also in the EMDB ( Electron Microscopy Data Bank , http :// www . ebi . ac . uk / pdbe / emdb /) ( 38 ). The user can select either Jmol ( 39 ) or jV ( 28 ) Java applets for interactive molecular graphics .",Supplement,Website,Produce,Protein Data Bank Japan (PDBj): maintaining a structural data archive and resource description framework format,https://academic.oup.com/nar/article/40/D1/D453/2903417
"IDAAPM is freely accessible via an online graphical user interface at ( ). The database browser was organized using a flask framework , java script , cascading style sheet and Jinja2 applications ( Additional file 11A ). The IDAAPM server was built with gunicorn , nginx and PostgreSQL 9 . 3 . 12 , installed on Ubuntu 14 . 04 . 4 .",Supplement,Website,Produce,IDAAPM: integrated database of ADMET and adverse effects of predictive modeling based on FDA approved drug data,https://jcheminf.biomedcentral.com/articles/10.1186/s13321-016-0141-7
"For CV analyses , models were fitted using 80 , 000 iterations collected after discarding the first 15 , 000 samples ; furthermore , samples were thinned at an interval of five . For all case studies , we report the average and SD ( across 200 CVs ) of the CV - AUC and the proportion of times that a model had a CV - AUC greater than other models , also computed using results from 200 CVs . Code to implement the models described herein is provided in File S2 and on the following website : _CITE_",Supplement,Website,Produce,Effects of mountaintop removal mining and valley filling on the occupancy and abundance of stream salamanders,https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2664.12585
"Given the size of the datasets (~ 150 2 h imaging sessions ), we provide MATLAB data containing solely deconvolved images and labels for each stimulus ( concept or sentence ). The raw and processed NIFTI imaging datasets , as well as associated event files , will be shared via a repository ( http :// www . openfmri . org ), after re - processing . Any updates on the data and scripts will be posted on the paper website ( crwz7 ).",Supplement,Website,Produce,Toward a universal decoder of linguistic meaning from brain activation,https://www.nature.com/articles/s41467-018-03068-4
"MRS has been optimized for speed and ease of use . For example , a search for ‘ lysozyme ’ in 12 MRS - files , including EMBL , PDB ( 4 ), UniProt ( 5 ), etc ., typically takes 0 . 02 s on a single processor PC , whereas combined searches like ‘ chloride AND channel ’ typically take 0 . 15 s . Similar searches using the EBI search engines typically take several seconds . An MRS server is available at Scientists from academia and industry can freely use this server to search presently in 14 data banks . All materials needed to build one ’ s own MRS server are available at http :// mrs . cmbi . ru . nl / download /.",Supplement,Website,Produce,MRS: a fast and compact retrieval system for biological data,https://academic.oup.com/nar/article/33/suppl_2/W766/2505577
"In situations where the version of a data record matters , advertise the corresponding permanent link ( permalink ) together with a statement about persistence . E . g . : “ The permanent link to this page , which will not change with the next release of Ensembl is : We aim to maintain all archives for at least five years ; some key releases may be maintained for longer ”",Supplement,Website,Produce,"Identifiers for the 21st century: How to design, provision, and reuse persistent identifiers to maximize utility and impact of life science data",https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2001414
"All OM data involved in this study are available on Zenodo [ 50 ]. The OMSV source code is available on GitHub ( https :// github . com / moziya / OMSV / tree / v1 . 0 ) and Zenodo ( http :// doi . org / 10 . 5281 / zenodo . 1035506 ). Our supplementary website ( ) provides a compiled OMSV package , detailed instructions for using the package , and links to the GitHub and Zenodo entries . The complex SV and large indel callers of OMSV were implemented in C ++ and Linux Bash , and the CNV caller was implemented in Matlab R2011b ( 7 . 13 . 0 . 564 ) 64 - bit ( glnxa64 ). The whole package requires at least 4 GB of physical memory and has been tested on both Debian GNU / Linux 9 . 0 ( stretch ) and CentOS Linux release 7 . 3 . 1611 ( Core ) platforms .",Supplement,Website,Produce,OMSV enables accurate and comprehensive identification of large structural variations from nanochannel-based single-molecule optical maps,https://link.springer.com/article/10.1186/s13059-017-1356-2
The dataset ( s ) supporting the conclusions of this article is ( are ) available in the project ’ site repository at _CITE_,Supplement,Website,Produce,A theoretical framework of a BIM-based multi-disciplinary collaboration platform,sciencedirect.com/science/article/abs/pii/S0926580510001408
Within the web server ( de ) we provide a video tutorial and sample data ( http :// deeptools . ie - freiburg . mpg . de / library ) to familiarize every user with the common workflows and various modules of deepTools . The functionality of each module is illustrated with detailed examples from real - life NGS analyses and can be seen once a tool is selected .,Supplement,Website,Produce,deepTools: a flexible platform for exploring deep-sequencing data,https://academic.oup.com/nar/article/42/W1/W187/2435511
"Supplementary data set S1 , figures S1 – S4 , and tables S1 and S2 are available at Genome Biology and Evolution online ( ).",Supplement,Website,Produce,Phylogenomics of Opsin Genes in Diptera Reveals Lineage-Specific Events and Contrasting Evolutionary Dynamics in Anopheles and Drosophila,https://academic.oup.com/gbe/article/13/8/evab170/6322995
"They used mapping techniques in GIS software ( https :// www . arcgis . com / home ) to identify where they had been most physically active , and to consider how and where they could be more active . Details of the core intervention components can be found in online supplementary appendix tables 1 – 3 . Further details concerning the precise nature of the peer - mentoring and PL approach can be found on the project website ( ).",Supplement,Website,Produce,The Daily Mile: What factors are associated with its implementation success?,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0204988
"To allow full propagation of parametric uncertainty , we used an objective Bayesian approach , taking flat prior distributions in the absence of data and informative priors only when suitable external data were available . We used as many data as were available from these studies , including some which would not be available in other settings using only 1 source of data . Full details on the statistical methods used and the distributions of key parameters can be found in the Web Appendix ( ). Method 1 : paired serologic surveys . To estimate infection rates from paired serologic surveys , we defined overall seroconversion as a 4 - fold or greater rise in titer on hemagglutination inhibition ( HAI ) testing between baseline titers and subsequent samples for the same individual .",Supplement,Website,Produce,Implementing informative priors for heterogeneity in meta-analysis using meta-regression and pseudo data,https://onlinelibrary.wiley.com/doi/full/10.1002/sim.7090
"All data sets , analysis results , and supplementary material are available on FigShare Repository ( a8cea06c05465c939e15 ).",Supplement,Website,Produce,Research Data Explored II: the Anatomy and Reception of figshare,https://arxiv.org/abs/1503.01298
"Be aware that such an adjustment might dramatically increase the model estimation time and does not necessarily guarantee improved sampling performance . The failure of an adjusted model estimate might further suggest that such a model is not suitable for the current dataset , and that one may need to consider using alternative models to fit the data . If users encounter a problem and would like to seek help from the hBayesDM developers , they can ask questions to our mailing list ( ).",Supplement,Website,Produce,"Optimizing ACS NSQIP Modeling for Evaluation of Surgical Quality and Risk: Patient Risk Adjustment, Procedure Mix Adjustment, Shrinkage Adjustment, and Surgical Focus",https://www.sciencedirect.com/science/article/abs/pii/S1072751513001877
"In addition , we integrated Cytoscape [ 23 ] Java Web Start technology so that the association network generated by eLSA can be immediately visualized . Based on these efforts , we anticipate that our novel eLSA methodology , as implemented by the newly developed pipeline software , will significantly assist researchers requiring systematic discovery of time - dependent associations . More information about the software and web services is available from the eLSA homepage at _CITE_",Supplement,Website,Produce,Extended local similarity analysis (eLSA) of microbial community and other time series data with replicates,https://link.springer.com/article/10.1186/1752-0509-5-S2-S15
"We also find these outlets valuable for occasional rapid technical exchanges with collaborating databases . Our blog ( http :// blog . guidetopharmacology . org /) includes detailed release descriptions , new features , and technical ‘ how to ’ items . One of us ( CS ) maintains an individual technical blog where GtoPdb topics are sometimes coupled by being briefly introduced in the GtoPdb blog but expanded on in the individual posts ( ). Our Slideshare account ( http :// www . slideshare . net / GuidetoPHARM ) is used for sharing slide sets and posters with the community and has proved popular . Users will find that presentations include descriptions of content , mining approaches and utilities that extend beyond what is documented on the site .",Supplement,Website,Produce,The IUPHAR/BPS Guide to PHARMACOLOGY in 2016: towards curated quantitative interactions between 1300 protein targets and 6000 ligands,https://academic.oup.com/nar/article/44/D1/D1054/2502586
"Project name : fastBMA Project home page : Operating system ( s ): Linux ( MacOS and Windows support provided through the Docker container [ 25 ] and Bioconductor package [ 24 ]) Programming language : C ++ Other requirements : gcc version & gt ; 4 . 8 , OpenBLAS , mpich2 ( if MPI desired ) to compile code",Supplement,Website,Produce,GUIdock: Using Docker Containers with a Common Graphics User Interface to Address the Reproducibility of Research,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0152686
"A Web Portal . The web portal was developed using ASP . NET in Microsoft Visual Studio 2010 and has been deployed in IIS server . It can be accessed via This web portal is useful for both clinical researchers and molecular biologists . For clinical researchers , they can learn the molecular mechanism of colorectal cancer , which may lead to better understanding about the diagnosis , therapy , and prognosis of colorectal cancer .",Supplement,Website,Produce,The Teaching in ASP.NET Programming and the Development in E-commerce Project,https://ieeexplore.ieee.org/abstract/document/5458817
Supplementary information S1 and figure S1 are available at Molecular Biology and Evolution online ( ).,Supplement,Website,Produce,Two Methods for Mapping and Visualizing Associated Data on Phylogeny Using Ggtree,https://academic.oup.com/mbe/article/35/12/3041/5142656
Table S4 Binding intensities ( FU ) for labeled BambL protein with glycan array chips v4 . 1 from the consortium for functional glycomics . Full data is available on the web site ( ). ( PDF ),Supplement,Website,Produce,Deciphering the Glycan Preference of Bacterial Lectins by Glycan Array and Molecular Docking with Validation by Microcalorimetry and Crystallography,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0071149
"efforts to expand this import are in progress . Data for large collaborative projects , including Encyclopedia of DNA Elements ( ENCODE ) ( 5 ) and Roadmap Epigenomics ( 6 ), are deposited by Data Coordinating Centres and have dedicated data listings pages at and http :// www . ncbi . nlm . nih . gov / geo / roadmap / epigenomics /.",Supplement,Website,Produce,NCBI GEO: archive for functional genomics data sets—update,https://academic.oup.com/nar/article/41/D1/D991/1067995
"Data exploration using the FANTOMS portal An online website is available ( ) where all data generated within the FANTOM5 project are collected , and visualization and browsing tools are publicly accessible . Users interested in downloading the whole genomic coordinates of CAGE TSSs , peaks , expression values and gene associations for macaque as well as other organisms , such as human , can access our ftp site fantom . gsc . riken . jp / 5 / datafiles / latest /.",Supplement,Website,Produce,Update of the FANTOM web resource: high resolution transcriptome of diverse cell types in mammals,https://academic.oup.com/nar/article/45/D1/D737/2333885
"ALICE , programmed in R and R - GUI , is the software with a user - friendly interface for an integrated genomic analysis of AF , LOH / LCSH , AI , and CNV / CNA . The software , reference databases , library files for APT , annotation files , test examples , and user manual can be downloaded from the ALICE homepage ( ). ALICE consists of three main components —“ Main Functions ” ( Additional file 11 ), “ Genome",Supplement,Website,Produce,An integrated analysis tool for analyzing hybridization intensities and genotypes using new-generation population-optimized human arrays,https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-016-2478-8
"Our blog ( http :// blog . guidetopharmacology . org /) includes detailed release descriptions , new features , and technical ‘ how to ’ items . One of us ( CS ) maintains an individual technical blog where GtoPdb topics are sometimes coupled by being briefly introduced in the GtoPdb blog but expanded on in the individual posts ( http :// cdsouthan . blogspot . com /). Our Slideshare account ( ) is used for sharing slide sets and posters with the community and has proved popular . Users will find that presentations include descriptions of content , mining approaches and utilities that extend beyond what is documented on the site . We have also added a set of generic slides which can be used by anyone presenting or teaching on GtoPdb .",Supplement,Website,Produce,The IUPHAR/BPS Guide to PHARMACOLOGY in 2016: towards curated quantitative interactions between 1300 protein targets and 6000 ligands,https://academic.oup.com/nar/article/44/D1/D1054/2502586
"Publish with BioMed Central and every scientist can read your work free of charge & quot ; BioMed Central will be the most significant development for disseminating the results of biomedical research in our lifetime .& quot ; Sir Paul Nurse , Cancer Research UK Your research papers will be : available free of charge to the entire biomedical community peer reviewed and published immediately upon acceptance cited in PubMed and archived on PubMed Central yours — you keep the copyright Submit your manuscript here : BioMedcentral 2 Page 9 of 9 ( page number not for citation purposes )",Supplement,Website,Produce,“Is all the stuff about neurons necessary?” The development of lay summaries to disseminate findings from the Newcastle Cognitive Function after Stroke (COGFAST) study,https://link.springer.com/article/10.1186/s40900-017-0066-y
This work is published under the standard license to publish agreement . After 12 months the work will become freely available and the license terms will switch to a Creative Commons AttributionNonCommercial - Share Alike 4 . 0 Unported License . Supplementary Information accompanies this paper on British Journal of Cancer website ( ),Supplement,Website,Produce,Exploring atomic resolution physiology on a femtosecond to millisecond timescale using molecular dynamics simulations,https://rupress.org/jgp/article/135/6/555/42824/Exploring-atomic-resolution-physiology-on-a
All essential functionalities were integrated into the user - friendly interface of QCanvas . The simple and intuitive nature of this tool meets the practical needs of research scientists working on omics data who do not have expertise in bioinformatics approaches . The program is freely available with demo data and a step - by - step tutorial through the website ( ~ qcanvas ).,Supplement,Website,Produce,QCanvas: An Advanced Tool for Data Clustering and Visualization of Genomics Data,https://genominfo.org/journal/view.php?doi=10.5808/GI.2012.10.4.263
User Support can be contacted via email at mgihelp @ jax . org or by clicking the User Support link at the bottom of our web pages . The online documentation can be accessed by clicking on the question mark in the upper left corner of most pages . FAQs ( and other useful links ) can be found on the GXD home page ( ).,Supplement,Website,Produce,The mouse Gene Expression Database (GXD): 2019 update,https://academic.oup.com/nar/article/47/D1/D774/5133672
"Offline phenotypic data are stored in the OrganMeasurement table , as well as file names of plant images taken by experimenters . A last table named Comment allows the storage of all events and remarks associated with an experiment . Additional supplementary material is available on the PHENOPSIS DB Web interface : _CITE_",Supplement,Website,Produce,PHENOPSIS DB: an Information System for Arabidopsis thalianaphenotypic data in an environmental context,https://bmcplantbiol.biomedcentral.com/articles/10.1186/1471-2229-11-77
"Competing interests AK has received consulting fees from Mars , Inc . JTD has received consulting fees or honoraria from Janssen Pharmaceutica , GSK , AstraZeneca and Hoffmann - La Roche and holds equity in NuMedii , Inc , Ayasdi , Inc and Ontomics , Inc . No writing assistance was used in the production of this manuscript . Provenance and peer review Not commissioned ; externally peer reviewed . Data sharing statement Source code and sample data are available on the companion website : Open Access This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial ( CC BY - NC 4 . 0 ) license , which permits others to distribute , remix , adapt , build upon this work noncommercially , and license their derivative works on different terms , provided the original work is properly cited and the use is non - commercial . See : http :// creativecommons . org / licenses / by - nc / 4 . 0 /",Supplement,Website,Produce,Changing patterns in reporting and sharing of review data in systematic reviews with meta-analysis of the effects of interventions: cross sectional meta-research study,https://www.bmj.com/content/379/bmj-2022-072428.long
"permits unrestricted use , distribution , and reproduction in any medium , provided the original author and source are credited . Data Availability Statement : All results files for single - cell measurements , plasmid sequences , and numerical data for the graphs in the figures are available from the Dryad Digital Repository : Funding : This work was supported by Japan Society for the Promotion of Science ( https :// www .",Supplement,Website,Produce,Pooled CRISPR screening with single-cell transcriptome readout,https://www.nature.com/articles/nmeth.4177
"This work is accompanied by a web interface for browsing the discovered and literature motifs along with their enrichments ( Figure 1 ; encode - motifs ). In addition to the browsing interface , we provide several data files including all motif matrices and their matches to the genome , as well as software to compute enrichments and perform unified motif discovery with the five tools we use . Together , these permit both analyses of individual factors ( e . g .",Supplement,Website,Produce,Systematic discovery and characterization of regulatory motifs in ENCODE TF binding experiments,https://academic.oup.com/nar/article-abstract/42/5/2976/1050297
Dragon is a software package from Talete36 that calculates 4885 molecular descriptors . They cover 0D - 3D space and are subdivided into 29 different logical blocks . Detailed information on the descriptors can be found on the Talete Web site ( ). Chemaxon Descriptors ( 3D ). The Chemaxon Calculator Plugin produces a variety of properties .,Supplement,Website,Produce,How Accurately Can We Predict the Melting Points of Drug-like Compounds?,https://pubs.acs.org/doi/full/10.1021/ci5005288
"Observe that when either the INTR or CAUS feature is removed ( rows 2 and 3 , respectively , of Table 2 ), performance degrades considerably , with a decrease in accuracy of 8 - 10 % from the maximum achieved with the four features ( row 1 ). However , when the VBD feature is removed ( row 4 ), there is a smaller decrease in accuracy , of 4 - 6 %. When the ACT feature is removed ( row 5 ), there is an Available for a number of platforms from 6A 10 - fold cross - validation means that the system randomly divides the data into ten parts , and runs ten times on a different 90 %- training - data / 10 %- test - data split , yielding an average accuracy and standard error . This procedure is then repeated for 10 different random divisions of the data , and accuracy and standard error are again averaged across the ten runs .",Supplement,Website,Use,Automatic Verb Classification Using Distributions of Grammatical Features,https://aclanthology.org/E99-1007.pdf
"Khaltar and Fujii ’ s method was also evaluated for comparison . We used Moses ( Koehn et al ., 2007 ) with the standard configuration and GIZA ++ ( Och et al ., 2003 ) with the grow - diag - final - and heuristic for word - alignment . Our parallel data set was collected from web sites ( and http :// mongolia . usembassy . gov /), and consists of law and news domains . Example En - Mn sentence pairs in our data are shown below . En1 : Occupational safety and health measures shall not involve any expenditure for the workers .",Supplement,Website,Use,Enhancing Lemmatization for Mongolian and its Application to Statistical Machine Translation,https://d1wqtxts1xzle7.cloudfront.net/31118220/W12-52-libre.pdf?1392203696=&response-content-disposition=inline%3B+filename%3DRepairing_Bengali_Verb_Chunks_for_Improv.pdf&Expires=1686106356&Signature=LAtfYDvayxUOqYbH-BxVFN1U2ofPFDLQdXvXhAZI6uS9drPyqmjLM-pt8NhaK49VgoppI3PehHeWkwiO7fSWZ8hi7brcHTQzDdfHS2dD0dNDiZQi1p9jOequ5T5lh-dxunXjyWfdy-L0aFUmwwZ6RWoWmHmLvheRCTRgcSCxpc2u5btWRHCfM1y380yT7xXo9HNm~-k4bal0AapV4W5hGfcLjEjV2ZAl~cTquPzGsEvMNs4s8izSc7MElnVvCrcPWKmDUYu6Spzoe1eztgz~Mnzh28niTQR3N-crM7BFEH6kPS31FIgKYMQtri4bcjezq1hXK2npqdgDd2lOeiXFJw__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA#page=125
"A non - applicable parameter for a particular type of expression would receive a “ Null ” value . The annotation of text fragments has been guided by the presence of evaluative expressions and other criteria as explained in section III . For annotation purposes , we have collected the editorials from two online newspapers ( , http :// kantipuronline . com / ktmpost . php ) of different dates of the year 2007 , amounting to a total of 16 text files and approximately 320 sentences with an average of 20 sentences per editorial . Two annotators having a fairly good understanding of the English",Supplement,Website,Use,Towards an Analysis of Opinions in News Editorials: How positive was the year?,https://aclanthology.org/W09-3723.pdf
"The second part of the demonstration shows a pre - built multimodal application running on the iPhone ( http :// www . apple . com ) and Google Android phone ( http :// code . google . com // android ). This application allows the user to have a dialogue about places of interest using The List website ( ). Figure 4 shows screenshots of the iPhone , firstly with The List homepage and then a page with content on Bar Roma , an “ italian restaurant in Edinburgh ” as requested by the user through spoken dialogue . Figure 4 : DUDE - generated iPhone List Application pushing relevant web content Figure 5 shows the architecture of this system whereby the DUDE server runs the spoken dialogue system ( as outputted from the DUDE Development Environment ).",Supplement,Website,Use,PsyToolkit: A Novel Web-Based Method for Running Online Questionnaires and Reaction-Time Experiments,https://journals.sagepub.com/doi/abs/10.1177/0098628316677643?journalCode=topa
"The formulae produce an unique score , the C - score , which gives an estimation of user ’ s reading comprehension of a certain text . The score can be used to evaluate the performance of a text simplification engine on pairs of complex and simplified texts , or to compare the performances of different TS methods using the same texts . The approach can be particularly useful for the modern crowdsourcing approaches , such as those employing the Amazon ’ s Mechanical Turk or CrowdFlower . The aim of this paper is thus to propose an evaluation approach and to motivate the TS community to start a relevant discussion , in order to come up with a common evaluation metrics for this task . Currently , the area of Text Simplification ( TS ) is getting more and more attention .",Supplement,Website,Use,Updated Oxford Classification of IgA nephropathy: a new MEST-C score,https://www.nature.com/articles/nrneph.2017.67
"For definitional QA task , Lin ( 2002 ) presented an approach in which web - based answer reranking is combined with dictionary - based ( e . g ., WordNet ) reranking , which leads to a 25 % increase in mean reciprocal rank ( MRR ). Xu et al . ( 2003 ) proposed a statistical ranking method based on centroid vector ( i . e ., vector of words and frequencies ) learned from the online encyclopedia ( i . e ., Wikipedia ) and the web . Candi date answers were reranked based on their similarity ( TFIDF score ) to the centroid vector . Similar techniques were explored in ( BlairGoldensohn et al ., 2003 ).",Supplement,Website,Use,Legal Question Answering using Ranking SVM and Deep Convolutional Neural Network,https://arxiv.org/abs/1703.05320
"In a nutshell , we analyse the entries of an encyclopedia with the aid of a noun hierarchy . Our motivation is that proper nouns that form entities can be obtained from the entries in an encyclopedia and that some features of their definitions in the encyclopedia can help to classify them into their correct entity category . The encyclopedia used has been Wikipedia . According to the English version of Wikipedia 2 , Wikipedia is a multi - lingual web - based , freecontent encyclopedia which is updated continuously in a collaborative way . The reasons why we have chosen this encyclopedia are the following : The noun hierarchy used has been the noun hierarchy from WordNet ( Miller , 1995 ).",Supplement,Website,Use,A proposal to automatically build and maintain gazetteers for Named Entity Recognition by using Wikipedia,https://aclanthology.org/W06-2809.pdf
"To perform the above analysis , the key is how to construct an experimental data collection which relates hot trends to corresponding related products . We jointly consider microblogs and e - commerce platforms : we obtain hot trends in microblogs and manually identify trend - related products in e - commerce websites . In this paper , we adopt Sina Weibo as the microbloging platform and Taobao as the e - commerce platform , which are the biggest microblogging service and the largest C2C company in China respectively . The analysis method is general and can equally apply to other platforms . For both two data signals , we consider a two - month time span , i . e .",Supplement,Website,Use,We know what you want to buy: a demographic-based system for product recommendation on microblogs,https://dl.acm.org/doi/abs/10.1145/2623330.2623351
"We show good mining performance for En - Hi and En - Ta . We perform error analysis for En - Ar , and identify sources of error ( Section 6 . 5 ). To understand the various issues in mining MWNE equivalents from comparable corpora , we took a random sample of 100 comparable En - Hi news article pairs from the Indian news portal WebDunia . The English articles had 682 unique NEs of which 252 ( 37 %) were person names , 130 ( 19 %) were location names , and 300 ( 44 %) were organization names . A substantial percentage of the names comprised of more than one word : locations 25 %, person names 96 %, and organizations 98 %.",Supplement,Website,Use,Nunc Est Aestimandum Towards an Evaluation of the Latin WordNet,https://www.researchgate.net/profile/Greta-Franzini-2/publication/336799230_Nunc_Est_Aestimandum_Towards_an_Evaluation_of_the_Latin_WordNet/links/5db2be42299bf111d4c83184/Nunc-Est-Aestimandum-Towards-an-Evaluation-of-the-Latin-WordNet.pdf
"1 . Some information cannot be deduced from the already used databases and thus we require additional means of gathering extra information of the form : Background knowledge was built semiautomatically , for the named entities ( NEs ) and for numbers from the hypothesis without correspondence in the text . For these NEs , we used a module to extract from Wikipedia snippets with information related to them . Subsequently , we use this file with snippets and some previously set patterns of relations between NEs , with the goal to identify a known relation between the NE for which we have a problem and another NE . If such a relation is found , we save it to an output file .",Supplement,Website,Use,Hypothesis Transformation and Semantic Variability Rules Used in Recognizing Textual Entailment,https://aclanthology.org/W07-1421.pdf
"To estimate the strength of each of them in a single utterance , we collect user ratings for three data sets that were collected under different conditions and are freely available . The utterances consist of user queries for restaurants , such as “ I need an Italian restaurant with a moderate price range .” Our joint dataset consists of 1 , 361 human utterances , 450 from the LIST , 334 from MAI , and 577 from CLASSIC . We asked users on the CrowdFlower crowdsourcing platform to read utterances and rate their colloquialism , politeness and naturalness on a 1 - 5 scale ( the higher the better ). The following questions were asked . could have been produced by a human .",Supplement,Website,Use,Cluster-based Prediction of User Ratings for Stylistic Surface Realisation,https://aclanthology.org/E14-1074.pdf
"In particular , given an optimal pairwise bilingual ranking , we show that simple heuristics can effectively approximate the optimal monolingual ranking . Using these heuristics and our learned pairwise scoring function , we can derive a ranking for new , unseen bilingual queries . We develop and test our bilingual ranker on English and Chinese with two large , publicly available query logs from the AOL search engine ( English query log ) ( Pass et al ., 2006 ) and the Sougou search engine ( Chinese query log ) ( Liu et al ., 2007 ). For both languages , we achieve significant improvements over monolingual Ranking SVM ( RSVM ) baselines ( Herbrich et al ., 2000 ; Joachims , 2002 ), which exploit a variety of monolingual features . We designate a query as bilingual if the concept has been searched by users of both two languages .",Supplement,Website,Use,Exploiting Bilingual Information to Improve Web Search,https://aclanthology.org/P09-1121.pdf
"Firstly , a corpus of articles was created ( Section 3 . 1 ), after which the documents were automatically annotated with named entities ( Section 3 . 2 ). We then extracted a number features relevant to the named entities present in the corpus ( Section 3 . 3 ). Our corpus was created by first searching the NLM Catalog for journals whose Broad Subject Term attributes contain only cell biology or pharmacology , and then narrowing down the results to those which are in English and available via PubMed Central . Also , since we are concentrating on full - text documents , we retained only those journals that are available within the PubMed Open Access subset . According to this procedure , we obtained a final list of two journals for cell biology and six for pharmacology .",Supplement,Website,Use,Building English-Vietnamese Named Entity Corpus with Aligned Bilingual News Articles,https://www.researchgate.net/publication/301404756_Building_English-Vietnamese_Named_Entity_Corpus_with_Aligned_Bilingual_News_Articles
"In contrast to using expert annotators , crowd - workers are readily and cheaply available even for ad - hoc tasks . In this paper , we used micro - task crowd - sourcing , i . e . a central platform like for example Amazon Mechanical Turk or CrowdFlower assigns small tasks ( called HITs , human - intelligence tasks ) to workers for monetary compensation . HITs usually consist of multiple work units taking only a few minutes to process , and therefore pay few cents . Crowd - sourcing has been shown to be effective for language processing related tasks , e . g .",Supplement,Website,Use,Crowdsourcing the Verification of Relationships in Biomedical Ontologies,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900126/
"Getting all the resources into one single compilation is a challenge . These resources were brought together and suitably compiled into a format that can be easily processed by Semantex ( Srihari , 2008 ), a text extraction platform provided by Janya Inc . Lists of places , organizations and names of famous personalities in Pakistan were also compiled using the Urdu - Wikipedia and NationalMaster . A list of most common names in Pakistan was composed by retrieving data from the various name databases available on the internet . The word segmentation model uses the Urdu corpus released by CRULP as the training data .",Supplement,Website,Use,E-RESOURCES COLLECTION DEVELOPMENT IN ENGINEERING COLLEGE LIBRARIES: A CHALLENGE FOR KNOWLEDGE CENTRE MANAGERS,http://www.ijodls.in/uploads/3/6/0/3/3603729/11_sunil_mansur_ok_166-177_.pdf
First one is derived from ConceptNet . In the second technique sub - graph is identified consisting of a nearest verb and roles are assigned accordingly . A ConceptNet API written in Java has been used to extract pair wise relation from ConceptNet . A Bengali - English dictionary ( approximately 102119 entries ) has been developed using the Samsad Bengali - English dictionary used here for equivalent lookup of English meaning of each Bengali lexicon . Obtained semantic relations from ConceptNet for any lexicon English pair are assigned to source Bengali pair lexicons .,Supplement,Website,Use,Microsoft Concept Graph: Mining Semantic Concepts for Short Text Understanding,https://direct.mit.edu/dint/article/1/3/238/9983/Microsoft-Concept-Graph-Mining-Semantic-Concepts
"The last row in Table 4 lists the performance of humans on the same task , presented in the next section . Is it difficult for humans to find the word in a sentence that induces bias , given the subtle , often implicit biases in Wikipedia . We used Amazon Mechanical Turk ( AMT ) to elicit annotations from humans for the same 230 sentences from the test set that we used to evaluate the bias detector in Section 3 . 3 . The goal of this annotation was twofold : to compare the performance of our bias detector against a human baseline , and to assess the difficulty of this task for humans . While AMT labelers are not trained Wikipedia editors , under standing how difficult these cases are for untrained labelers is an important baseline .",Supplement,Website,Use,Linguistic Models for Analyzing and Detecting Biased Language,https://aclanthology.org/P13-1162.pdf
"A review summary database entry generated by the proposed approaches is exemplified in Figure 4 . { restaurant "" dali restaurant and tapas bar "" : atmosphere ( "" wonderful evening "", "" cozy atmosphere "", "" fun decor "", "" romantic date "" ) : atmosphere_rating "" 4 . 1 "" In this project , we substantiate the proposed approach in a restaurant domain for our spoken dialogue system ( Gruenstein and Seneff , 2007 ), which is a web - based multimodal dialogue system allowing users to inquire about information about restaurants , museums , subways , etc . We harvested a data collection of 137 , 569 reviews on 24 , 043 restaurants in 9 cities in the U . S . from an online restaurant evaluation website . From the dataset , 857 , 466 sentences were subjected to parse analysis ; and a total of 434 , 372 phrases ( 114 , 369 unique ones ) were extracted from the parsable subset ( 78 . 6 %) of the sentences . Most pros / cons consist of well - formatted phrases ; thus , we select 3 , 000 phrases extracted from pros / cons as training data .",Supplement,Website,Use,Dialogue-Oriented Review Summary Generation for Spoken Dialogue Recommendation Systems,https://dspace.mit.edu/handle/1721.1/62575
"The second evaluation task consisted in using our baseline system for classifying user product reviews into positive or negative opinions . For this task we used a corpus of 400 user reviews of products such as cars , hotels , dishwashers , books , cellphones , music , computers and movies , extracted from the Spanish website Ciao . es . This is the same corpus used by Brooke ( 2009 ), who employed sentiment analysis tools in English to score Spanish texts after performing machine translation . On Ciao . es , users may enter their written reviews and associate a numeric score to them , ranging from 1 to 5 stars . For this evaluation task , we made the assumption that there was a strong relation between the written reviews and their corresponding numeric scores .",Supplement,Website,Use,Spanish DAL: A Spanish Dictionary of Affect in Language,https://aclanthology.org/W13-1604.pdf
"In the third step , the algorithm reduces pairs with non - domainspecific problem targets from the set PWTs using semantic knowledge . The pair pair ( pwi7 tj ) is reduced if there is no term with a domain category in the hierarchy of WordNet synsets induced by the hypernym , hyponym , or holonym relations with target tj . For our experiments we collected 734 sentences from the HP website . We employed 953 sentences from Amazon reviews about automobile products . Of the total sentences , 1 , 288 sentences ( 506 + 782 from electronic and automobile domains ) were classified as problem sentences , and 399 ( 228 + 171 ) sentences were labeled as part of the no - problem class .",Supplement,Website,Use,Dependency-Based Problem Phrase Extraction from User Reviews of Products,https://link.springer.com/chapter/10.1007/978-3-319-24033-6_23
"The graphical illustration in Figure 3 explains the situation . The observation is that most of the negative tags are coming from the middle - east and especially from the Islamic countries . We found a line in Wiki ( see in Religion Section ) that may give a good explanation : “ Blue in Islam : In verse 20 : 102 of the Qur ’ an , the word cjj � zurq ( plural of azraq ' blue ') is used metaphorically for evil doers whose eyes are glazed with fear ”. But other explanations may be there for this . This is an interesting observation that supports the effectiveness of PsychoSentiWordNet .",Supplement,Website,Use,Dr Sentiment Knows Everything!,https://aclanthology.org/P11-4009.pdf
"As for spoken language , Caines & Buttery ( 2010 ) among others suggest that adaptation can also be made to the parser , such that it enters a ‘ speech - aware mode ’ in which the parser refers to additional and / or replacement rules adapted to the particular features of spoken language . They demonstrated this with the omission of auxiliary verbs in progressive aspect sentences (‘ you talking to me ?’, ’ how you doing ?’) and achieved a 30 % improvement in parsing success rate for this construction type . Our speech data consist of recordings from Business Language Testing Service ( BULATS ) speaking tests . In the test , learners are required to undertake five tasks ; we exclude the tasks involving brief question - answering (‘ can you tell me your full name ?’, ‘ where are you from ?’, etc ) and elicited imitation , leaving us with three free - form speech tasks . For this particular test the tasks were : [ a ] talk about some advice from a colleague ( monologue ), [ b ] talk about a series of charts from Business Today magazine ( monologue ), [ c ] give advice on starting a new retail business ( dialogue with examiner ).",Supplement,Website,Use,Analysis and modelling of disfluency and as units for automatic scoring of L2 speakers,https://repository.iiitd.edu.in/jspui/handle/123456789/1130
"Since we are extracting predicate - argument structure , syntactic variations such as passive constructions and relative clauses will be all ‘ normalized ’ into the same form . Consequently , ‘ the book which I read ’, ‘ I read the book ’, and ‘ the book was read by me ’ will form the exact same semantic tuple & lt ; I , read , the book , N / A , N / A >. The resulting tuple structures along with their associated text are stored in an Apache Solr / Lucene server which receives queries from the Searchbench user interface . The Searchbench user interface ( UI ) is a web application running in every modern , JavaScript - enabled web browser . As can be seen in Figure 4 , the UI is divided into three parts : ( 1 ) a sidebar on the left ( Filters View ), where different filters can be set that constrain the list of found documents ; ( 2 ) a list of found documents matching the currently set filters in the upper right part of the UI ( Results View ); ( 3 ) the Document View in the lower right part of the UI with different views of the current document .",Supplement,Website,Use,The ACL Anthology Searchbench,https://aclanthology.org/P11-4002.pdf
"Usually , this approach requires an additional process to disambiguate the sentiment polarities of all the morphological variants . To improve the sentiment classification for the target language , Banea , Mihalcea , and Wiebe ( 2010 ) translate the English sentiment lexicon into the target language using Google Translator . Similarly , Google Translator is used by Steinberger et al . ( 2011 ). They manually produce two high - level gold - standard sentiment lexicons for two languages ( e . g ., English and Spanish ) and then translate them into the third language ( e . g ., Italian ) via Google Translator .",Supplement,Website,Use,A Fall-back Strategy for Sentiment Analysis in Hindi: a Case Study,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=267e59a7cdf328f3ba14e7295ca68d4a7839b984
"We do not attempt , e . g ., to disambiguate the sense of individual word terms to tell whether the slang sense of a word is the one intended . Rather , we simply check to see if each word has a slang usage in Wiktionary . A continuous feature is set to the value of i for each article . Discrete features highi and lowi are set as : where ¯ i and σ are , respectively , the mean and standard deviation of i across all articles . Lexical approaches are clearly inadequate if we assume that good satirical news articles tend to emulate real news in tone , style , and content .",Supplement,Website,Use,Automatic Satire Detection: Are You Having a Laugh?,https://aclanthology.org/P09-2041.pdf
"The detected names are then mapped onto unique identifiers across a range of taxonomic databases such as uBio Name Bank , Encyclopaedia of Life ( EoL ) , and Catalogue of Life ( CoL ) . Taxonomic names that cannot be found in online databases will be validated manually . Potential unknown taxonomic names are presented for validation or correction to the research community via the Scratchpads social network ( e . g ., professional taxonomists , experienced citizen scientists and other biodiversity specialists ) in a community - driven verification process . The newly verified taxonomic name , along with additional metadata recording the user who verified the name , its context and bibliographic details is published as a semantic web service layer ( currently a Scratchpads portal ). Automatic identification of taxonomic names from biodiversity text has attracted increasing research interest over the past few years , but is difficult because of the problems of erroneous transcription and synonymy .",Supplement,Website,Use,Verification of a Taxonomy of Dermatophytes Based on Mating Results and Phylogenetic Analyses,https://www.jstage.jst.go.jp/article/mmj/52/4/52_4_291/_article/-char/ja/
"T 34 = ( 2 / 3 x 1 + 1 / 3 x 1 )/ 1 = 1 . We apply hierarchical clustering ( Voorhees , 1986 ) to the similarity matrix above to obtain the final global clustering results . We recorded 10 games from 3J3F , one of the most popular Chinese online killer game websites . A screenshot of the game system interface is shown in Figure 5 . There are 16 participating players per game : 4 detectives , 4 killers and 8 citizens .",Supplement,Website,Use,Detecting Deceptive Groups Using Conversations and Network Analysis,https://aclanthology.org/P15-1083.pdf
"The types were unknown ( response indicates participant is unsure what to do next ), ask for more ( ask for more details ), propose alternative ( propose alternative object ), ask for help ( ask operator to physically manipulate environment ), and off topic . We recruited 30 participants . All participants completed the web form through the Amazon Mechanical Turk ( MTurk ) web portal , all were located in the United States and had a task approval rate ≥ 95 %. The group included 29 self - reported native English speakers born in the United States ; 1 self - reported as a native Bangla speaker born in Bangladesh . The gender distribution was 15 male to 15 female .",Supplement,Website,Use,A validation of Amazon Mechanical Turk for the collection of acceptability judgments in linguistic theory,https://link.springer.com/article/10.3758/s13428-010-0039-7
"Answers : Arts , Education , Health , Science , and Sports . We randomly chose 200 questions from each category to create a raw dataset with 1 , 000 questions total . Then , we labeled the dataset with annotators from the Amazon ’ s Mechanical Turk service . For annotation , each question was judged by 5 Mechanical Turk workers who passed a qualification test of 10 questions ( labeled by ourselves ) with at least 9 of them correctly marked . The qualification test was required to ensure that the raters were sufficiently competent to make reasonable judgments .",Supplement,Website,Use,Utility data annotation with Amazon Mechanical Turk,https://ieeexplore.ieee.org/abstract/document/4562953/
"Constructing and maintaining an alignment between an ontology and an UW lexicon is a challenging task ( Rouquet and Nguyen , 2009b ). Basically , any lexical resource can be represented in an ontology language as a graph . We propose to use an OWL version of the UW volume available on Kaiko website . It allows us to benefit of classical ontology matching techniques and tools ( Euzenat and Shvaiko , 2007 ) to represent , compute and manipulate the alignment . We implemented two string based matching techniques on top of the alignment API ( Euzenat , 2004 ).",Supplement,Website,Use,Ontology driven content extraction using interlingual annotation of texts in the OMNIA project,https://aclanthology.org/W10-4009.pdf
"The TP3 ( 2000s ) writers should have well - maintained blogs as well . Therefore this study will examine C - FWAA effectiveness in three genres : novel , essay , and blog . All electronic copies of the selected works were downloaded from online literature repositories such as YiFan Public Library and TianYa Book . The first experiment was to test the effectiveness of the EM algorithm for FWAA . The famous Federalist Papers data set was used as the test case .",Supplement,Website,Use,Function Words for Chinese Authorship Attribution,https://aclanthology.org/W12-2506.pdf
"The majority of the English descriptions were collected from the Metropolitan Museum . The majority of the Hebrew descriptions were taken from Artchive . Table 1 gives an overview of the three text collections . In addition , we extracted 40 parallel texts that are available under the sub - domain Painting from Wikipedia . All sentences in the reference material were tokenised , part - of - speech tagged , lemmatized , and parsed using open - source software .",Supplement,Website,Use,On generating coherent multilingual descriptions of museum objects from Semantic Web ontologies,https://aclanthology.org/W12-1512.pdf
"Our technique differs in that we use no k - best approximations , have fewer parameters to learn ( one consensus weight vector rather than one for each collaborating decoder ) and produce only one output , avoiding an additional system combination step at the end . We report results on the constrained data track of the NIST 2008 Arabic - to - English ( ar - en ) and Chineseto - English ( zh - en ) translation tasks . We train on all parallel and monolingual data allowed in the track . We use the NIST 2004 eval set ( dev ) for optimizing parameters in model combination and test on the NIST 2008 evaluation set . We report results using the IBM implementation of the BLEU score which computes the brevity penalty using the closest reference translation for each segment ( Papineni et al ., 2002 ).",Supplement,Website,Use,Model Combination for Machine Translation,https://aclanthology.org/N10-1141.pdf
"Second , our lexical database and the FST morphology require features ( such as humanness for nouns and transitivity for verbs ) that are not provided by SAMA , and we want to automatically induce these features . To address the first problem , we use a datadriven filtering method that combines open web search engines and our pre - annotated corpus . Using frequency statistics from three web search engines ( Al - Jazeera , Arabic Wikipedia , and the Arabic BBC website ), we find that 7 , 095 lemmas in SAMA have zero hits . Frequency statistics from our corpus show that 3 , 604 lemmas are not used in the corpus at all , and 4 , 471 lemmas occur less than 10 times . Combining frequency statistics from the web and the corpus , we find that there are 29 , 627 lemmas that returned at least one hit in the web queries and occurred at least 10 times in the corpus .",Supplement,Website,Use,Combining Knowledge and Data Driven Insights for Identifying Risk Factors using Electronic Health Records,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3540578/
"The corresponding sequence of different degrees of sentiment is : “ very good : 5 . 0 ” & gt ; “ good : 4 . 5 ” & gt ; “ not very good : 2 . 0 ” & gt ; “ bad : 1 . 5 ” & gt ; “ very bad : 1 . 0 ”. In this section we present a systematic evaluation of the proposed approaches conducted on real data . We crawled a data collection of 137 , 569 reviews on 24 , 043 restaurants in 9 cities in the U . S . from an online restaurant evaluation website . Most of the reviews have both pros / cons and free - style text . For the purpose of evaluation , we take those reviews containing pros / cons as the experimental set , which is 72 . 7 % ( 99 , 147 reviews ) of the original set .",Supplement,Website,Use,Time series forecasting using artificial neural networks methodologies: A systematic review,https://www.sciencedirect.com/science/article/pii/S2314728817300715
"Second , we derive a polarity lexicon for Italian , organised by senses , also using a fully automatic strategy which can replicated to obtain such a resource for other languages ( Section 3 . 1 ). Third , we use the lexicon to automatically assign polarity to two subsets of the tweets in our corpus , and evaluate results against manually annotated data ( Sections 3 . 2 – 3 . 4 ). We collected one year worth of tweets , from February 2012 to February 2013 , using the Twitter filter API and a language recognition strategy which we describe below . The collection , named TWITA , consists of about 100 million tweets in Italian enriched with several kinds of meta - information , such as the time - stamp , geographic coordinates ( whenever present ), and the username of the twitter . Additionally , we used off - the - shelf language processing tools to tokenise all tweets and tag them with partof - speech information .",Supplement,Website,Use,Sentiment analysis on Italian tweets,https://aclanthology.org/W13-1614.pdf
"( 2012 ) extended the EventCorefBank corpus with entity coreference information and additional annotations of event coreference . One important step in the creation process of the ECB corpus consists of finding sets of related documents that describe the same seminal event such that the annotation of coreferential event mentions across documents is possible . In this regard , we searched the Google News archive for various topics whose description contains keywords such as commercial transaction , attack , death , sports , announcement , terrorist act , election , arrest , natural disaster , and so on , and manually selected sets of Web documents describing the same seminal event for each of these topics . In a subsequent step , for every Web document , we automatically tokenized and split the textual content into sentences , and saved the preprocessed data in a uniquely identified text file . Next , we manually annotated a limited set of events in each text file in accordance with the TimeML specification ( Pustejovsky et al .",Supplement,Website,Use,Whose side were we on? The undeclared politics of moral panic theory,https://journals.sagepub.com/doi/abs/10.1177/1741659011417603?journalCode=cmca
"Recent interest in Mathematical information retrieval ( MIR ) has prompted the construction of the NTCIR Math IR test collection ( Aizawa et al ., 2013 ). Like many general - purpose , domainspecific IR test collections , the NTCIR collection is composed of broad queries intended to test systems over a wide spectrum of query complexity . In this paper we present a test collection composed of real - life , research - level mathematical topics and associated relevance judgements procured from the online collaboration web - site MathOverflow . The resulting test collection con tains 160 atomic questions - material derived from 120 MathOverflow discussion threads . Topics in our test collection capture specialised information needs that are complex to resolve and often demand collective effort from multiple domain experts .",Supplement,Website,Use,Content-based multimedia information retrieval: State of the art and challenges,https://dl.acm.org/doi/abs/10.1145/1126004.1126005
"This context is possible through the use of multiple ontologies , which are specialized in different components , such as the annotation layer , the domain concepts , and the linguistic rules specification . Despite the higher computational cost that this approach can present when compared with some other options , the results , as described in the result analysis section , presents a good precision and are not dependent of a large volume of documents to generate basic and reference models . The computational phase of the methodology suggested is implemented in the SAURON system , developed in Java Language and the OWL Api support , integrating the Pellet reasoner10 . This system is inspired in the unifying logic layer of the standard technology stack for semantic web11 , since one of the objectives of this system is to unify the use of several semantic technologies applied . The system provides the necessary support to the tasks involving Natural Language Processing , such as the text preprocessing , the syntactic parser access and some format conversions tasks .",Supplement,Website,Use,Ontology-based information extraction for juridical events with case studies in Brazilian legal realm,https://link.springer.com/article/10.1007/s10506-017-9203-z
"One intuitive metric of performance can be obtained by having human annotators judge the visual quality of samples [ 2 ]. We automate this process using Amazon Mechanical Turk ( MTurk ), using the web interface in figure Fig . 2 ( live at ), which we use to ask annotators to distinguish between generated data and real data . The resulting quality assessments of our models are described in Section 6 .",Supplement,Website,Use,Amazon Mechanical Turk for Subjectivity Word Sense Disambiguation,https://aclanthology.org/W10-0731.pdf
"The improved run time for the linear algorithm also reflects the benefits of some improvements in our culling technique and a cleaner implementation permitted by the linear time algorithm . The quadratic code is simply too slow to run on the Wean Hall data . Log files for these runs are available from the DP - SLAM web page : The results show a significant practical advantage for the linear code , and vast improvement , both in terms of time and number of particles , for the hierarchical implementation .",Supplement,Website,Use,Hierarchical Linear/Constant Time SLAM Using Particle Filters for Dense Maps,https://proceedings.neurips.cc/paper/2005/hash/b8b9c74ac526fffbeb2d39ab038d1cd7-Abstract.html
"Following [ 12 ], we used the first 8 examples per task as the training data and the last 4 examples per task as the test data . We measured the root mean square error of the predicted from the actual ratings for the test data , averaged across people . The second data set is the school data set from the Inner London Education Authority ( see ). It consists of examination scores of 15362 students from 139 secondary schools in London . Thus , there are 139 tasks , corresponding to predicting student performance in each school .",Supplement,Website,Use,Few-shot Natural Language Generation for Task-Oriented Dialog,https://arxiv.org/abs/2002.12328
"For the large - scale real - world experiments , we use gene expression datasets that are available at the Gene Expression Omnibus ( ). We use several of the",Supplement,Website,Use,Gene Expression Omnibus: NCBI gene expression and hybridization array data repository,https://academic.oup.com/nar/article-abstract/30/1/207/1332640
"3 . The results of the two algorithms seem qualitatively similar , while Fast - VDP computed its results much faster than VDP . In a second real data experiment we clustered documents from citeseer ( ). The dataset has 30 , 696 documents , with a vocabulary size of 32 , 473 words .",Supplement,Website,Use,Accelerated Variational Dirichlet Process Mixtures,https://proceedings.neurips.cc/paper/2006/hash/2bd235c31c97855b7ef2dc8b414779af-Abstract.html
"We have borrowed the chunking and shrinking ideas from the SVAilIght [ 6 ] for our computer program . To test these two programs several data sets have been used . The Adult and Web data sets have been obtained from I . Platt ' s web page ; the Gauss - M data set is a two dimensional classification problem proposed in [ 3 ] to test neural networks , which comprises a gaussian random variable for each class , which highly overlap . The Banana , Diabetes and Splice data sets have been obtained from Gunnar Ratsch web page http : llsvm . first . gmd . defraetsch /. The selection of C and the RKHS has been done as indicated in [ 11 ] for Adult and Web data sets and in http :// svm . first . gmd . der raetsch / for Banana , Diabetes and Splice data sets .",Supplement,Website,Use,Automated classification of stellar spectra — II. Two-dimensional classification with neural networks and principal components analysis,https://academic.oup.com/mnras/article-abstract/298/2/361/1056578
"This work is supported by the NSF ( CRCNS 26 - 1004 - 04xx ), an HFSP award to IRF ( 26 - 6302 - 87 ), and the Simons Foundation through the Simons Collaboration on the Global Brain . The authors acknowledge the Texas Advanced Computing Center ( TACC ) at The University of Texas at Austin ( URL : ) for providing HPC resources that have contributed to the research results reported within this paper .",Supplement,Website,Use,"Large-scale GWAS reveals genetic architecture of brain white matter microstructure and genetic overlap with cognitive and mental health traits (n = 17,706)",https://www.nature.com/articles/s41380-019-0569-z
"lenge [ 10 ]. For each drug , we had 14 features that describes their chemical and physical properties such as molecular weight , XLogP3 and hydrogen bond donor count , and were downloaded from National Center for Biotechnology Information ( ). For the cell line features , we ran principle component analysis ( PCA ) and used the top 45 principal components that accounted for more than 99 . 99 % of the total data variance . We compared the four different methods with four different q values : 20 - 50 %.",Supplement,Website,Use,Thioredoxin System: A Model for Determining Novel Lead Molecules for Breast Cancer Chemotherapy,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3558217/
"G - means and X - means overfit the non - Gaussian datasets , while PG - means and BKM both perform excellently in the number of clusters learned and in learning the true labels according to the VI metric . We tested all of these algorithms on the U . S . Postal Service handwritten digits dataset ( both the train and test portions , obtained from ). Each example is a grayscale image of a handwritten digit . There are 9298 examples in the dataset , and each example has 256 pixels ( 16 pixels on a side ).",Supplement,Website,Use,PG-means: learning the number of clusters in data,https://proceedings.neurips.cc/paper/2006/hash/a9986cb066812f440bc2bb6e3c13696c-Abstract.html
"10 for the MAP estimation is − 1 2D wTw . Our dataset contains covtype ( D = 581 , 012 , p = 54 ), obtained from the LIBSVM data website . We separate 5K examples as the test set . We test two types of learning rates , constant and decayed . For constant rates , we explore ρt ∈ { 0 . 01 , 0 . 05 , 0 . 1 , 0 . 2 , 0 . 5 , 1 }.",Supplement,Website,Use,Variance Reduction for Stochastic Gradient Optimization,https://proceedings.neurips.cc/paper/2013/hash/9766527f2b5d3e95d4a733fcfb77bd7e-Abstract.html
"Speakers may start speaking or become silent at any time . Similarly to [ 23 ], we collect data from several speakers from the PASCAL ‘ CHiME ’ Speech Separation and Recognition Challenge website . The voice signal for each speaker consists of 4 sentences , which we append with random pauses in between each sentence . We artificially mix the data 10 times ( corresponding to 10 microphones ) with mixing weights sampled from Uniform ( 0 , 1 ), such that each microphone receives a linear combination of all the considered signals , corrupted by Gaussian noise with standard deviation 0 . 3 . We consider two scenarios , with 5 and 15 speakers , and subsample the data so that we learn from T = 1 , 354 and T = 1 , 087 datapoints , respectively .",Supplement,Website,Use,CHiME-6 Challenge:Tackling Multispeaker Speech Recognition for Unsegmented Recordings,https://arxiv.org/abs/2004.09249
"To test whether this is indeed the case on real data sets , we performed experiments on a set of freely available benchmark binary classification data sets . The protein ( n = 145751 , p = 74 ) data set was obtained from the KDD Cup 2004 website , while the rcv1 ( n = 20242 , p = 47236 ) and covertype ( n = 581012 , p = 54 ) data sets were obtained from the LIBSVM data website . Although our method can be applied to any differentiable function , on these data sets we focus on an ` 2 - regularized logistic regression problem , with A = 1 / n . We split each dataset in two , training on one half and testing on the other half . We added a ( regularized ) bias term to all data sets , and for dense features we standardized so that they would have a mean of zero and a variance of one .",Supplement,Website,Use,A Stochastic Gradient Method with an Exponential Convergence _Rate for Finite Training Sets,https://proceedings.neurips.cc/paper/2012/hash/905056c1ac1dad141560467e0a99e1cf-Abstract.html
"We denote our proposed sparse embedded k - means clustering algorithm as SE for short . This section evaluates the performance of the proposed method on four real - world data sets : COIL20 , SECTOR , RCV1 and ILSVRC2012 . The COIL20 [ 20 ] and ILSVRC2012 [ 21 ] data sets are collected from website34 , and other data sets are collected from the LIBSVM website . The statistics of these data sets are presented in the Supplementary Materials . We compare SE with several other dimensionality reduction techniques : After dimensionality reduction , we run all methods on a standard k - means clustering package , which is from website with default parameters .",Supplement,Website,Use,Sparse Embedded k -Means Clustering,https://proceedings.neurips.cc/paper/2017/hash/3214a6d842cc69597f9edf26df552e43-Abstract.html
"Note that since ui depends only on the rank order of | si |, the results would be the same if the signs are discarded by taking s i . To test the behavior of our model , we applied it to small patches taken from digitized natural images . The image dataset is available on the World Wide Web from Bruno Olshausen . It contains ten 512x512 pre - whitened images . We took 151 , 290 evenly distributed 20x20 image patches .",Supplement,Website,Use,Heat transport in silicon from first-principles calculations,https://journals.aps.org/prb/abstract/10.1103/PhysRevB.84.085204
"SVD + SMM is a two - step procedure : 1 ) extracting low - dimensional representations of words by using a singular value decomposition ( SVD ), and 2 ) learning a support measure machine using the distribution of extracted representations of words appearing in each document with the same kernels as the latent SMM . word2vec + SMM employs the representations of words learnt by word2vec [ 7 ] and uses them for the SMM as in SVD + SMM . Here we use pre - trained 300 dimensional word representation vectors from the Google News corpus , which can be downloaded from the author ’ s website . Note that word2vec + SMM utilizes an additional resource to represent the latent vectors for words unlike the latent SMM , and the learning of word2vec requires n - gram information about documents , which is lost in the BoW representation . With SVMs , we use a Gaussian RBF kernel with parameter y and a quadratic polynomial kernel , and the features are represented as BoW .",Supplement,Website,Use,Latent Support Measure Machines for Bag-of-Words Data Classification,https://proceedings.neurips.cc/paper/2014/hash/708f3cf8100d5e71834b1db77dfa15d6-Abstract.html
"Some statistics and examples of the dataset will be given in Section 4 . 2 . The latest dataset is available on the project page : http :// idl . baidu . com / FM - IQA . html We start with the 158 , 392 images from the newly released MS COCO [ 21 ] training , validation and testing set as the initial image set . The annotations are collected using Baidu ’ s online crowdsourcing server . To make the labeled question - answer pairs diversified , the annotators are free to give any type of questions , as long as these questions are related to the content of the image . The question should be answered by the visual content and commonsense ( e . g ., we are not expecting to get questions such as “ What is the name of the person in the image ?”).",Supplement,Website,Use,Users roles identification on online crowdsourced Q&A platforms and encyclopedias: a survey,https://link.springer.com/article/10.1007/s42001-021-00125-9
"SimpleSearch scores each Wikipedia article by the TF - IDF weighted sum of words that co - occur in the articles and a query and returns top - K articles . Second , we use Lucene , a popular open source information retrieval library , in its default configuration on the whole Wikipedia dump . Lastly , we use Google Search API , while restricting the domain to wikipedia . org . Each system is evaluated by document recall at K ( Recall @ K ). We vary K to be 1 , 4 or 40 .",Supplement,Website,Use,End-to-End Goal-Driven Web Navigation,https://proceedings.neurips.cc/paper/2016/hash/1579779b98ce9edb98dd85606f2c119d-Abstract.html
"Finally , as an ideal yardstick , we also implement a full online SVM algorithm (“ Online - SVM ”) ( Shalev - Shwartz & Singer , 2006 ), which updates all the support vectors in each trial , and is thus computationally extremely intensive as will be revealed in our study . To extensively examine the performance , we test all the algorithms on a number of benchmark datasets from web machine learning repositories . All of the datasets can be downloaded from LIBSVM website , UCI machine learning repository 2 and MIT CBCL face datasets 3 . Due to space limitation , we randomly choose six of them in our discussions , including “ german ”, “ splice ”, “ spambase ”, “ MITFace ”, “ a7a ”, and “ w7a ”. To make a fair comparison , all algorithms adopt the same experimental setup .",Supplement,Website,Use,A new hybrid ensemble feature selection framework for machine learning-based phishing detection system,https://www.sciencedirect.com/science/article/abs/pii/S0020025519300763
"For all our experiments we use a GPU - cluster interconnected with InfiniBand . Each node has 4 Titan GPU processors where each local worker corresponds to one GPU processor . The center variable of the master is stored and updated on the centralized parameter server [ 2 ] . To describe the architecture of the convolutional neural network , we will first introduce a notation . Let ( c , y ) denotes the size of the input image to each layer , where c is the number of color channels and y is both the horizontal and the vertical dimension of the input .",Supplement,Website,Use,Deep learning with Elastic Averaging SGD,https://proceedings.neurips.cc/paper/2015/hash/d18f655c3fce66ca401d5f38b48c89af-Abstract.html
"Sentiment : Product reviews to be classified as positive or negative . We used each Amazon product review domain as a sentiment classification task ( 6 datasets ). Spam : We selected three task A users from the ECML / PKDD Challenge , using bag - ofwords to classify each email as spam or ham ( 3 datasets ). For OCR data we binarized two well known digit recognition datasets , MNIST and USPS , into 45 all - pairs problems . We also created ten one vs . all datasets from the MNIST data ( 100 datasets total ).",Supplement,Website,Use,"The l2,1-Norm Stacked Robust Autoencoders for Domain Adaptation",https://ojs.aaai.org/index.php/AAAI/article/view/10274
"In our experiments , we did not restrict the setting to a given small lexicon and instead used a general , large English lexicon . SVT does not contain symbols other than letters . Training Generative Shape Model To ensure sufficient coverage of fonts , we obtained 492 fonts from Google Fonts . Manual font selection is biased and inaccurate , and it is not feasible to train on all fonts ( 492 fonts times 52 letters gives 25584 training images ). After the proposed greedy font selection process for all letters , we retained 776 unique training images in total ( equivalent to a compression rate of 3 % if we would have trained on all fonts for all letters ).",Supplement,Website,Use,Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data,https://proceedings.neurips.cc/paper/2016/hash/23ad3e314e2a2b43b4c720507cec0723-Abstract.html
"10 ( b ) shows the optimal block size decreases as the mean shift increases , as expected . We test the performance of our M - statistics using real data . Our datasets include : ( 1 ) CENSREC1 - C : a real - world speech dataset in the Speech Resource Consortium ( SRC ) corpora provided by National Institute of Informatics ( NII ) ; ( 2 ) Human Activity Sensing Consortium ( HASC ) challenge 2011 data . We compare our M - statistic with a state - of - the - art algorithm , the relative densityratio ( RDR ) estimate [ 7 ] ( one limitation of the RDR algorithm , however , is that it is not suitable for high - dimensional data because estimating density ratio in the high - dimensional setting is illposed ). To achieve reasonable performance for the RDR algorithm , we adjust the bandwidth and the regularization parameter at each time step and , hence , the RDR algorithm is computationally more expensive than the M - statistics method .",Supplement,Website,Use,Change-point detection in time-series data by relative density-ratio estimation,https://www.sciencedirect.com/science/article/abs/pii/S0893608013000270
"See Appendix C . 5 for a discussion on the orders . Algorithm 1 Joint diagonalization ( JD ) algorithm for GP / DICA cumulants ( or LDA moments ) In this section , ( a ) we compare experimentally the GP / DICA cumulants with the LDA moments and ( b ) the spectral algorithm [ 3 ], the tensor power method [ 4 ] ( TPM ), the joint diagonalization ( JD ) algorithm from Algorithm 1 , and variational inference for LDA [ 1 ]. Real data : the associated press ( AP ) dataset , from D . Blei ’ s web page , with N = 2 , 243 documents and M = 10 , 473 vocabulary words and the average document length Lb = 194 ; the NIPS papers dataset [ 28 ] of 2 , 483 NIPS papers and 14 , 036 words , and Lb = 1 , 321 ; the KOS dataset , from the UCI Repository , with 3 , 430 documents and 6 , 906 words , and Lb = 136 . Semi - synthetic data are constructed by analogy with [ 29 ]: ( 1 ) the LDA parameters D and c are learned from the real datasets with variational inference and ( 2 ) toy data are sampled from a model of interest with the given parameters D and c . This provides the ground truth parameters D and c . For each setting , data are sampled 5 times and the results are averaged . We plot error bars that are the minimum and maximum values .",Supplement,Website,Use,A new method of moments for latent variable models,https://link.springer.com/article/10.1007/s10994-018-5706-4
"For each of these versions , step size is tuned for each dataset to give the best convergence progress . All the algorithms were implemented in C ++ . We run our experiments on datasets from LIBSVM website . Similar to [ 29 ], we normalize each example in the dataset so that IIzi112 = 1 for all i E [ n ]. Such a normalization leads to an upper bound of 0 . 25 on the Lipschitz constant of the gradient of fi .",Supplement,Website,Use,Pegasos: Primal Estimated sub-GrAdient SOlver for SVM,https://dl.acm.org/doi/abs/10.1145/1273496.1273598
"There are many samples generated by the models with MinVI objective that look clearly better than those generated by the model with ML objective . In this section , we evaluate our methods on MIR - Flickr database [ 11 ], which is composed of 1 million examples of image and their user tags collected from the social photo - sharing website Flickr . Among those , 25000 examples are annotated with 24 potential topics and 14 regular topics , which leads to 38 classes in total with distributed class membership . The topics include object categories such as dog , flower , and people , or scenic concepts such as sky , sea , and night . We used the same visual and text features as in [ 27 ].",Supplement,Website,Use,Improved Multimodal Deep Learning with Variation of Information,https://proceedings.neurips.cc/paper/2014/hash/801c14f07f9724229175b8ef8b4585a8-Abstract.html
"We used data on individuals (≥ 16 years ) of self - reported European ancestry from 29 studies from the CARTA consortium ( ): the 1958 Birth Cohort ( 1958BC ), the Avon Longitudinal Study of Parents and Children ( ALSPAC , including both mothers and children ), the British Regional Heart Study ( BRHS ), the British Women ’ s Heart and Health Study ( BWHHS ), the Caerphilly Prospective Study ( CaPS ), the Christchurch Health and Development Study ( CHDS ), CoLaus , the Danish Monica study ( Dan - MONICA ), the Exeter Family Study of Child Health ( EFSOCH ), the English Longitudinal Study of Ageing ( ELSA ), the National FINRISK studies , GEMINAKAR , GS : SFHS ( Generation Scotland : Scottish Family Health Study ), the Genomics of Overweight Young Adults ( GOYA ) females , GOYA males , the Helsinki Birth Cohort Study ( HBCS ), Health2006 , Health2008 , the Nord - Trfandelag Health Study ( HUNT ), Inter99 , MIDSPAN , the Northern Finland Birth Cohorts ( NFBC 1966 and NFBC 1986 ), the National Health and Nutrition Examination Survey ( NHANES ), the MRC National Survey of Health & Development ( NSHD ), the Netherlands Twin Register ( NTR ), the PROspective Study of Pravastatin in the Elderly at Risk ( PROSPER ) and Whitehall II . All studies received ethics approval from the local research ethics committees . Further details of these studies are provided in online supplementary material .",Supplement,Website,Use,Effect of Smoking on Blood Pressure and Resting Heart Rate,https://www.ahajournals.org/doi/full/10.1161/CIRCGENETICS.115.001225
"gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = ee1233f263f94268ac62dc4cd358cd12 , http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = 00851eb8fb2c4050b581ab898b9d228e , http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = 1f905afc070241a58c74672b40333ac0 , http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = e6663cf00af64a928def7a70108a2b19 , http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = f2f4d89b7dbc4fc0ae78591b36f71585 , http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = c26168effc244aedb95fbea7de289aaf , http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = 7e45eb1bd3c34cc9a8a27bf20c182f4d ; NIST library subnetwork with cosine score & lt ; 0 . 7 http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = 8b0b5a467da9416b81ab4f925a4f4b43 ; for Fecal , Euphorbia dendroides extracts and Fungal dataset http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = f0cabc92247d44789900944a69874e8a , http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = ce2a564dbd704c0595494e04798b0233 , http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = b753797b0dad4f1e84142dd59c84615b ; and finally for CASMI negative mode http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = a3f02b1b648 a43b6a210063a4ee2f787 and positive mode http :// gnps . ucsd . edu / ProteoSAFe / status . jsp ? task = 231902c6d75f41df8403e454c96e8d4a . The parameters can be accessed by cloning the job or at the link “ Networking Parameters and Written Network Description ”. The corresponding NAP jobs can also be accessed through the web interface with the following job IDs : for NIST library - task = 29d517e67067476bae97a32f2d4977e0 , http :// proteomics2 . ucsd . edu / ProteoSAFe / status . jsp ? task = d270e79876cb48deb6aabd52a4fc647e , http :// proteomics2 . ucsd . edu / ProteoSAFe / status .",Supplement,Website,Use,Template-based protein structure modeling using the RaptorX web server,https://www.nature.com/articles/nprot.2012.085
"alization window showing also a graphical representation of the gene domain composition ( Figure 3 ). For NRPS / PKS cluster types , the predicted peptide monomer composition and its corresponding SMILES formula are specified . The predicted chemical structure is displayed as well using the SMILES Depictor web service ( ). Below the graphical representation of the predicted antiSMASH cluster , a summary of MIBiG Clusters similarities , BGC gene composition as well as tailoring cluster similarities are given . This last item relies on a knowledge database provided with antiSMASH about tailoring clusters already described in known BGCs and associated with publications .",Supplement,Website,Use,Norine: update of the nonribosomal peptide resource,https://academic.oup.com/nar/article-abstract/48/D1/D465/5613672
"The data is deposited at Dryad ( Staab et al . 2018 , http :// dx . doi . org / 10 . 5061 / dryad . h6j0g4p ) and can be freely accessed as virtual representation of the type . In addition to the cybertype data at Dryad , we also provide a freely accessible 3D surface model of the holotype at Sketchfab ( ). Diagnosis . Proceratium kepingmai differs from the other members of the P . itoi clade by the following character combination : large species ( TL 4 . 39 – 4 . 54 ); sides of head weakly convex , broadest at level of eyes and gently narrowing anteriorly and stronger posteriorly ; vertex almost straight ; very reduced eyes ( OI 2 – 3 ) consisting of a single minute ommatidium ; frontal carinae well developed , with large lamellae that extend laterally above the antennal insertions ; frontal furrow darker than the surrounding anterior cephalic dorsum ; posterodorsal corners of the propodeum broadly angular ; propodeal declivity densely punctured , mostly opaque ; posterior face of petiolar node in profile steeper than anterior face and about half as long as anterior face ; apex of petiolar node distinctly broader than long in dorsal view ; in addition to dense pubescence , erect hairs present on scapes and dorsal surface of body , longest of those hairs at most as long as the maximum dorsoventral diameter of metafemur .",Supplement,Website,Use,Revision of the Highly Specialized Ant Genus Discothyrea (Hymenoptera: Formicidae) in the Afrotropics with X-Ray Microtomography and 3D Cybertaxonomy,https://academic.oup.com/isd/article/3/6/5/5614979
"These records contain the date of birth , age , gender , residential address , the date of admission and discharge , primary discharge diagnosis , and up to 15 secondary discharge diagnoses . The criteria for data extraction in our study include : ( 1 ) a primary diagnosis of COPD ( International Classification of Diseases , 10th Revision codes : J41 – J44 ); ( 2 ) residential addresses of the patients are in urban districts of Chengdu ; ( 3 ) HAs data from tertiary hospitals and secondary hospitals . Ambient air quality data were derived from the web platform of the China National Environmental Monitoring Center ( ) managed by the Ministry of Environmental Protection of the People ’ s Republic of China . Data of hourly air pollution concentrations of PM2 . 5 , PM10 , SO2 , NO2 , CO and O3 from 6 air quality monitoring stations interspersed in five urban districts of Chengdu city were obtained . All areas of the five urban districts were located within 40 km radius of the monitoring stations .",Supplement,Website,Use,Predictive values of acute coronary syndrome discharge diagnoses differed in the Danish National Patient Registry,https://www.sciencedirect.com/science/article/abs/pii/S0895435608000929
"The dataset can be found in S6 Data . Flavonoid ions were targeted for MS / MS fragmentation as [ M - H +]- electrospray derivatives with a window size of ± 4 m / z in Q1 . Fragmentation of the precursor ion was performed by collision - induced dissociation at 0 , 10 , 20 , and 40 eV collision energy , and fragment - ion spectra were recorded in scanning mode by high - resolution time - of - flight MS . Spectra were interpreted using MetFrag [ 80 ], and spectral cosine similarity scores were calculated between reference spectra that were obtained in - house or library spectra from MassBank of North America ( MoNA , ). For further details , see S5 Text . Untargeted metabolomics data analysis All steps of the downstream data analysis were performed in R ( R Foundation for Statistical Computing , Vienna , Austria ).",Supplement,Website,Use,"Structural characterization and identification of iridoid glycosides, saponins, phenolic acids and flavonoids in Flos Lonicerae Japonicae by a fast liquid chromatography method with diode-array detection and time-of-flight mass spectrometry",https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/abs/10.1002/rcm.4245
"CTCF Chip - seq data used in the Shh region was adquired from Encode and painted in the representative model ( mm9 data ) with a black - to - white gradient , from high to low score .",Supplement,Website,Use,Global and regional white matter development in early childhood,https://www.sciencedirect.com/science/article/abs/pii/S1053811919302903
"permits unrestricted use , distribution , and reproduction in any medium , provided the original author and source are credited . Data Availability Statement : WorldClim data are available from http :// www . worldclim . org / version1 , and the remote sensing climate data are available from https :// vdeblauwe . wordpress . com . Bamboo species presence data can be obtained by contacting the State Forestry Administration ( see ). Funding : The project was funded by the National Science Foundation under BIO - 1340812 and Michigan AgBioResearch . Any opinions , findings , conclusions or recommendations expressed in this",Supplement,Website,Use,Reprint—Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The PRISMA Statement,https://academic.oup.com/ptj/article/89/9/873/2737590
"For 2013 , SID files for 28 states were available directly from AHRQ ; files for the remaining states can potentially be obtained from the state - level organizations . 4 Nationally representative databases based on aggregated SID data include the annual Nationwide / National Inpatient Sample ( NIS ) and the triennial Kids ’ Inpatient Sample ( KID ). Other HCUP databases that capture CHD care are listed in Table 1 . Copies of the HCUP databases can be purchased ; aggregated data from select HCUP databases are freely available online at the HCUPnet site ( ). Several health service research studies have used HCUP data to assess data on incidence , outcomes , facility costs , and factors related to hospitalization for individuals with CHDs . 5 - 10 Health insurance claims databases include public insurers and proprietary insurance databases , such as Truven Health ’ s MarketScan ® suite of databases . The MarketScan ® research databases include commercial databases of employer - sponsored insurance , a Medicare database , and a Medicaid database representing claims from anonymized states that contract with Truven .",Supplement,Website,Use,Databases for Congenital Heart Defect Public Health Studies Across the Lifespan,https://www.ahajournals.org/doi/full/10.1161/JAHA.116.004148
Metagenomic datasets are freely available on the MG - RAST web - server ( ). The MG - RAST sample IDs are listed in the Table S1 .,Supplement,Website,Use,Metagenomic analysis reveals the prevalence of biodegradation genes for organic pollutants in activated sludge,https://www.sciencedirect.com/science/article/abs/pii/S0960852412017373
"The Census dataset represents an interesting source of information that can be linked to the data described in this paper to , for example , understand and predict the socio - economic well - being of a given territorial area . For each information point I referring to a geographical area v ( contained in the shapefile ), we can calculate the proportion of data which belongs to each GRID & apos ; s square g : Ig 1 / 4 Iv CAAv gl where Ap is the area of a polygon p . After this process , the ISTAT data is correctly linked to the GRID . News Since the text of the news articles is not provided , a service like diffbot ( ) or any other similar service ( e . g ., Apache Tika ) could be used to extract the text from a given url . For instance , given the article http :// www . milanotoday . it / eventi / concerti / eventi - capodanno - 2014 - milano . html diffbot will output : { ‘ text ’: ‘ Tutti invitati al gran concerto di Capodanno in piazza [...]’ ‘ title ’: ‘ Concerto Capodanno in piazza Duomo :’ Lasciate a casa i botti ”, ‘ type ’: ‘ article ’, ‘ url ’: http :// www . milanotoday . it / eventi / concerti / eventi - capodanno - 2014 - milano . html }",Supplement,Website,Use,Once Upon a Crime: Towards Crime Prediction from Demographics and Mobile Data,https://dl.acm.org/doi/abs/10.1145/2663204.2663254
"Finally , the BNT toolbox can be downloaded from https :// code . google . com / p / bnt /. Instructions for installations as well as how to use the package is available in the website . The material from [ 1 ] has been made available in the Google drive folderview ? id = 0B7Kkv8wlhPU - T05wTTNodWNydjA & usp = sharing . This contains the individual files , contents of which are used in this manuscript . The drive and its contents can be accessed via the URLs mentioned earlier in the abstract .",Supplement,Website,Use,pophelper: an R package and web app to analyse and visualize population structure,https://onlinelibrary.wiley.com/doi/abs/10.1111/1755-0998.12509
"We collected observed meteorological data ( including daily mean temperature , precipitation , solar radiation , wind speed , and vapor pressure ) for 1970 – 2010 from 117 stations within and around the Tibetan Plateau ( Table S8 ) from the China Meteorological Data Sharing Service System ( ). We calculated annual average temperature and annual precipitation for each station using the observed daily data . Since most stations have no directly observed evaporation data , we estimated the potential evapotranspiration of each station based on the Penman - Monteith model recommended by the Food and Agriculture Organization of the United Nations ( FAO ) [ 50 ].",Supplement,Website,Use,Recent climate changes over the Tibetan Plateau and their impacts on energy and water cycle: A review,https://www.sciencedirect.com/science/article/abs/pii/S0921818113002713
"percentage cropland ) to categorical ones by using a 50 % threshold . Table 1 also shows the spatial and temporal coverage of each input data set . Geo - Wiki reference data on abandoned land We collected reference data on abandoned land through the Geo - Wiki platform ( ), which allows users to classify Google Earth and Bing VHR imagery . An example of the interface is provided in Figure 2 . The blue box corresponds to a 10 - sec pixel ; in the top left corner is a time slider to view available historical imagery at this location while the user chooses the classes from the right hand panel .",Supplement,Website,Use,Monitoring Economic Development from Space: Using Nighttime Light and Land Cover Data to Measure Economic Growth,https://www.sciencedirect.com/science/article/abs/pii/S0305750X14002551
"With the aim to identify chronic disease events in the mid - term , the study covers a middle - aged range ( 40 – 65 years old ) corresponding to 30 % of the Catalan population . 22 In addition , participants are required to be able to understand at least one of the two official languages in Catalonia ( Catalan or Spanish ) to provide written informed consent , to possess an Individual Health System Identification Card and to be current residents of Catalonia . Potential participants are excluded if they have mental or health impairment disorders that impede giving written informed consent or efficient communication , or if they are planning to leave Catalonia during the following 5 years . Participants are invited to participate using multiple active strategies , such as phone call , mail , GCAT web page ( ) or in person . Then , an appointment is agreed on and participants are asked to attend a recruitment centre . There are 11 permanent recruitment centres ( figure 1 ).",Supplement,Website,Use,"The role of age of acquisition and language usage in early, high-proficient bilinguals: An fMRI study during verbal fluency",https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.10110
"The model population adopted the mid - year population structure of the year , 2007 and 2008 respectively , and was classified into six age groups : 0 – 5 , 6 – 12 , 13 – 19 , 20 – 39 , 40 – 59 , and ≥ 60 years ( see Additional file 2 : Table S2 ). The mid - year age - structured population sizes were obtained from Department of Household Registration , Ministry of the Interior ( ). Births and deaths were neglected because of the relatively short time scale that the simulation spanned . The model further adopted the normalized age - specific contact rates estimated in Wallinga et al .",Supplement,Website,Use,Impending collapse of bluefin tuna in the northeast Atlantic and Mediterranean,https://conbio.onlinelibrary.wiley.com/doi/full/10.1111/j.1755-263X.2008.00039.x
"Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2020). Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems (NeurIPS 2020). Retrieved from",Method,Tool,Produce,Language Models are Few-Shot Learners,https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html
"Bojanowski, P., Grave, E., Joulin, A., & Mikolov, T. (2017). Enriching Word Vectors with Subword Information. Transactions of the Association for Computational Linguistics (TACL), 5, 135-146.",Method,Tool,Produce,FastText: Enriching Word Vectors with Subword Information,https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00051/43387/Enriching-Word-Vectors-with-Subword-Information
"Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., ... & Cowan, B. (2007). Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (pp. 177-180).",Method,Tool,Produce,Moses: Open Source Toolkit for Statistical Machine Translation,https://aclanthology.org/P07-2045/
"Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). Deep contextualized word representations. arXiv preprint arXiv:1802.05365.",Method,Tool,Produce,ELMo: Deep contextualized word representations,https://arxiv.org/abs/1802.05365
"Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems (pp. 3111-3119).",Method,Tool,Produce,BERTweet: A Pretrained Language Model for English Tweets,https://arxiv.org/abs/2005.10200
"Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Advances in neural information processing systems (pp. 3104-3112).",Method,Tool,Produce,Distributed Representations of Words and Phrases and their Compositionality,https://arxiv.org/abs/1310.4546
"Manning, C. D., Surdeanu, M., Bauer, J., Finkel, J. R., Bethard, S., & McClosky, D. (2014). The Stanford CoreNLP natural language processing toolkit. In Proceedings of the 52nd annual meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 55-60).",Method,Tool,Produce,Seq2Seq: Sequence to Sequence Learning with Neural Networks,https://arxiv.org/abs/1409.3215
"Manning, C., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S., & McClosky, D. (2014). The Stanford CoreNLP Natural Language Processing Toolkit. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (System Demonstrations) (pp. 55-60).",Method,Tool,Produce,Stanford CoreNLP: A Java Suite of Core NLP Tools,https://aclanthology.org/P14-5010/
"Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language Models are Unsupervised Multitask Learners.",Method,Tool,Produce,Language Models are Unsupervised Multitask Learners,https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
"Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., & Le, Q. (2019). XLNet: Generalized Autoregressive Pretraining for Language Understanding.",Method,Tool,Produce,XLNet: Generalized Autoregressive Pretraining for Language Understanding,https://arxiv.org/abs/1906.08237
"Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., & Le, Q. (2019). Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context.",Method,Tool,Produce,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,https://arxiv.org/abs/1901.02860
"Collins, M. (2003). Head-Driven Statistical Models for Natural Language Parsing. Tao, X., & Yin, D. (2020). A Batch Normalized Inference Network Keeps the KL Vanishing Away.",Method,Tool,Produce,Accurate Unlexicalized Parsing,https://aclanthology.org/P03-1054/
"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... Bengio, Y. (2014). Generative Adversarial Networks.",Method,Tool,Produce,A Batch Normalized Inference Network Keeps the KL Vanishing Away,https://aclanthology.org/2020.acl-main.235/
"Ren, S., He, K., Girshick, R., & Sun, J. (2015). Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.",Method,Algorithm,Introduce,Generative Adversarial Networks,https://arxiv.org/abs/1406.2661
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You Only Look Once: Unified, Real-Time Object Detection.",Method,Algorithm,Introduce,Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,https://arxiv.org/abs/1506.01497
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).",Method,Algorithm,Introduce,Deep Residual Learning for Image Recognition,https://arxiv.org/abs/1512.03385
"Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You Only Look Once: Unified, Real-Time Object Detection. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 779-788).",Method,Algorithm,Introduce,"YOLO: You Only Look Once: Unified, Real-Time Object Detection",https://arxiv.org/abs/1506.02640
"van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). WaveNet: A Generative Model for Raw Audio. arXiv preprint arXiv:1609.03499.",Method,Algorithm,Introduce,WaveNet: A Generative Model for Raw Audio,https://arxiv.org/abs/1609.03499
"Taigman, Y., Yang, M., Ranzato, M., & Wolf, L. (2014). DeepFace: Closing the Gap to Human-Level Performance in Face Verification. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1701-1708).",Method,Algorithm,Introduce,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf
"Jaderberg, M., Simonyan, K., & Zisserman, A. (2015). Spatial Transformer Networks. In Advances in neural information processing systems (pp. 2017-2025).",Method,Algorithm,Introduce,Spatial Transformer Networks,https://arxiv.org/abs/1506.02025
"Zhu, J. Y., Park, T., Isola, P., & Efros, A. A. (2017). Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks. In Proceedings of the IEEE international conference on computer vision (pp. 2223-2232).",Method,Algorithm,Introduce,CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,https://arxiv.org/abs/1703.10593
"He, K., Gkioxari, G., Dollár, P., & Girshick, R. (2017). Mask R-CNN. In Proceedings of the IEEE international conference on computer vision (pp. 2961-2969).",Method,Algorithm,Introduce,Mask R-CNN,https://arxiv.org/abs/1703.06870
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 4171-4186).",Method,Algorithm,Introduce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J., & Keutzer, K. (2016). SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size. arXiv preprint arXiv:1602.07360.",Method,Algorithm,Introduce,SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size,https://arxiv.org/abs/1804.02767
"Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 234-241).",Method,Algorithm,Introduce,U-Net: Convolutional Networks for Biomedical Image Segmentation,https://arxiv.org/abs/1505.04597
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is All You Need. In Advances in Neural Information Processing Systems (pp. 5998-6008).",Method,Algorithm,Introduce,Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Bochkovskiy, A., Wang, C. Y., & Liao, H. Y. M. (2020). YOLOv4: Optimal Speed and Accuracy of Object Detection. arXiv preprint arXiv:2004.10934.",Method,Algorithm,Introduce,YOLOv4: Optimal Speed and Accuracy of Object Detection,https://arxiv.org/abs/2004.10934
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.",Method,Algorithm,Introduce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative Adversarial Networks.",Method,Algorithm,Produce,Generative Adversarial Networks,https://arxiv.org/abs/1406.2661
"Taigman, Y., Yang, M., Ranzato, M., & Wolf, L. (2014). DeepFace: Closing the Gap to Human-Level Performance in Face Verification.",Method,Algorithm,Produce,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf
"Xu, K., Ba, J., Kiros, R., Courville, A., Salakhudinov, R., Zemel, R., & Bengio, Y. (2015). Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.",Method,Algorithm,Produce,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",https://arxiv.org/abs/1502.03044
"Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural Machine Translation by Jointly Learning to Align and Translate.",Method,Algorithm,Produce,Neural Machine Translation by Jointly Learning to Align and Translate,https://arxiv.org/abs/1409.0473
"Zhu, J. Y., Park, T., Isola, P., & Efros, A. A. (2017). Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.",Method,Algorithm,Produce,CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,https://arxiv.org/abs/1703.10593
"He, K., Gkioxari, G., Dollár, P., & Girshick, R. (2017). Mask R-CNN. In Proceedings of the IEEE international conference on computer vision (pp. 2961-2969).",Method,Algorithm,Produce,Mask R-CNN,Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is All You Need. In Advances in Neural Information Processing Systems (pp. 5998-6008).",Method,Algorithm,Produce,Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.",Method,Algorithm,Produce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Bochkovskiy, A., Wang, C. Y., & Liao, H. Y. M. (2020). YOLOv4: Optimal Speed and Accuracy of Object Detection.",Method,Algorithm,Produce,YOLOv4: Optimal Speed and Accuracy of Object Detection,https://arxiv.org/abs/2004.10934
"Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... & Amodei, D. (2020). Language Models are Few-Shot Learners.",Method,Algorithm,Produce,GPT-3: Language Models are Few-Shot Learners,https://arxiv.org/abs/2005.14165
"Radford, A., Kane, D., & Sutskever, I. (2021). OpenAI CLIP: Connecting Text and Images.",Method,Algorithm,Produce,OpenAI CLIP: Connecting Text and Images,https://arxiv.org/abs/2103.00020
"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An Image Transformer.",Method,Algorithm,Produce,ViT: An Image Transformer,https://arxiv.org/abs/2010.11929
"Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., ... & Liu, P. J. (2019). Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.",Method,Algorithm,Produce,T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer,https://arxiv.org/abs/1910.10683
"Tan, M., Pang, R., & Le, Q. V. (2019). EfficientDet: Scalable and Efficient Object Detection. ",Method,Algorithm,Produce,"EfficientDet: Scalable and Efficient Object Detection"" Authors: Mingxing Tan, Ruoming Pang, Quoc V. Le",https://arxiv.org/abs/1911.09070
"Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An Image Transformer.",Method,Algorithm,Produce,Vision Transformers,https://arxiv.org/abs/2010.11929
"Dosovitskiy, A., & Koltun, V. (2020). DALL·E: Creating Images from Text.",Method,Algorithm,Produce,DALL·E: Creating Images from Text,https://arxiv.org/abs/2003.00982
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is All You Need.",Method,Algorithm,Produce,Transformers: Attention Is All You Need,https://arxiv.org/abs/1706.03762
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition.",Method,Algorithm,Produce,Deep Residual Learning for Image Recognition,https://arxiv.org/abs/1512.03385
"Park, T., Liu, M. Y., Wang, T. C., & Zhu, J. Y. (2019). SPIN: Shape Reconstruction Using Incomplete and Noisy Input.",Method,Algorithm,Produce,SPIN: Shape Reconstruction Using Incomplete and Noisy Input,https://arxiv.org/abs/1907.12328
"Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language Models are Unsupervised Multitask Learners.",Method,Algorithm,Produce,Generative Pre-trained Transformer 2,https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
"Kipf, T. N., & Welling, M. (2016). Semi-supervised classification with graph convolutional networks.",Method,Algorithm,Produce,Graph Convolutional Networks,https://arxiv.org/abs/1609.02907
"Kurakin, A., Goodfellow, I., & Bengio, S. (2016). Adversarial Examples in the Physical World.",Method,Algorithm,Produce,"Adversarial Examples in the Physical World"" Authors: Alexey Kurakin, Ian Goodfellow, Samy B",https://arxiv.org/abs/1607.02533
"Taigman, Y., Yang, M., Ranzato, M., & Wolf, L. (2014). DeepFace: Closing the Gap to Human-Level Performance in Face Verification.",Method,Algorithm,Produce,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf
"Mordvintsev, A., Olah, C., & Tyka, M. (2015). DeepDream: Visualizing Neural Networks.",Method,Algorithm,Produce,DeepDream: Visualizing Neural Networks,https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html
"Kim, Y. (2014). Convolutional Neural Networks for Sentence Classification.",Method,Algorithm,Produce,Convolutional Neural Networks for Sentence Classification,https://arxiv.org/abs/1408.5882
"Tan, M., & Le, Q. V. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.",Method,Algorithm,Produce,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,https://arxiv.org/abs/1905.11946
"Brock, A., Donahue, J., & Simonyan, K. (2019). Large Scale GAN Training for High Fidelity Natural Image Synthesis.",Method,Algorithm,Produce,Large Scale GAN Training for High Fidelity Natural Image Synthesis,https://arxiv.org/abs/1809.11096
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.",Supplement,Document,Use,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Pennington, J., Socher, R., & Manning, C. D. (2014). GloVe: Global Vectors for Word Representation.",Supplement,Document,Use,GloVe: Global Vectors for Word Representation,https://nlp.stanford.edu/pubs/glove.pdf
"Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). Deep contextualized word representations.",Supplement,Document,Use,ELMo: Deep Contextualized Word Representations,https://arxiv.org/abs/1802.05365
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is All You Need.",Supplement,Document,Use,Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Yang, Z., et al. (2019). BERTweet: A Pretrained Language Model for English Tweets.",Supplement,Document,Use,BERTweet: A Pretrained Language Model for English Tweets,
"Greff, K., Srivastava, R. K., & Schmidhuber, J. (2015). LSTM: A Search Space Odyssey. ",Supplement,Document,Use,LSTM: A Search Space Odysse,https://arxiv.org/abs/1503.04069
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. ",Supplement,Document,Use,"Deep Residual Learning for Image Recognition"" Authors: Kaiming He, Xiangyu Zhang, Shaoqing Ren",https://arxiv.org/abs/1512.03385
"Zeiler, M. D., & Fergus, R. (2014). Visualizing and understanding convolutional networks.",Supplement,Document,Use,Visualizing and Understanding Convolutional Networks,https://arxiv.org/abs/1311.2901
"He, K., Gkioxari, G., Dollar, P., & Girshick, R. (2017). Mask R-CNN.",Supplement,Document,Use,Mask R-CNN,https://arxiv.org/abs/1703.06870
"Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation.",Supplement,Document,Use,U-Net: Convolutional Networks for Biomedical Image Segmentation,https://arxiv.org/abs/1505.04597
"Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). YOLO: You Only Look Once: Unified, Real-Time Object Detection.",Supplement,Document,Use,"YOLO: You Only Look Once: Unified, Real-Time Object Detection",https://arxiv.org/abs/1506.02640
"Taigman, Y., Yang, M., Ranzato, M., & Wolf, L. (2014). DeepFace: Closing the Gap to Human-Level Performance in Face Verification.",Supplement,Document,Use,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf
"Dosovitskiy, A., & Koltun, V. (2020). DALL·E: Creating Images from Text.",Supplement,Document,Use,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Radford, A., et al. (2015). Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.",Supplement,Document,Use,DeepDream: Visualizing Neural Networks,https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html
"Brown, T. B., et al. (2020). Language Models are Few-Shot Learners.",Supplement,Document,Use,Graph Convolutional Networks,https://arxiv.org/abs/1609.02907
"Radford, A., et al. (2019). Language Models are Unsupervised Multitask Learners.",Supplement,Document,Use,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,https://arxiv.org/abs/1901.02860
"Redmon, J., & Farhadi, A. (2018). YOLOv3: An Incremental Improvement.",Supplement,Document,Use,YOLOv3: An Incremental Improvement,https://arxiv.org/abs/1804.02767
"Huang, G., Liu, Z., Van Der Maaten, L., & Weinberger, K. Q. (2017). Densely Connected Convolutional Networks.",Supplement,Document,Use,DenseNet: Densely Connected Convolutional Networks,https://arxiv.org/abs/1608.06993
"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).",Supplement,Document,Use,Generative Adversarial Networks,https://arxiv.org/abs/1406.2661
"Sun, J., & Wang, W. (2020). BERTweet: A Pretrained Language Model for English Tweets.",Supplement,Document,Use,BERTweet: A Pretrained Language Model for English Tweets,https://arxiv.org/abs/2005.10200
"Girshick, R. (2015). Fast R-CNN.",Supplement,Document,Use,Fast R-CNN,https://arxiv.org/abs/1504.08083
"Peters, M. E., et al. (2018). Deep Contextualized Word Representations (ELMo).",Supplement,Document,Use,ELMo: Deep Contextualized Word Representations,https://arxiv.org/abs/1802.05365
"Vaswani, A., et al. (2017). Attention Is All You Need.",Supplement,Document,Use,Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Devlin, J., et al. (2019). BERT: Bidirectional Encoder Representations from Transformers.",Supplement,Document,Use,BERT: Bidirectional Encoder Representations from Transformers,https://arxiv.org/abs/1810.04805
"Mikolov, T., et al. (2013). Efficient Estimation of Word Representations in Vector Space (Word2Vec).",Supplement,Document,Use,Word2Vec,https://arxiv.org/abs/1301.3781
"He, K., et al. (2017). Mask R-CNN.",Supplement,Document,Use,Mask R-CNN,https://arxiv.org/abs/1703.06870
"Ronneberger, O., et al. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation.",Supplement,Document,Use,U-Net: Convolutional Networks for Biomedical Image Segmentation,https://arxiv.org/abs/1505.04597
"He, K., et al. (2016). Deep Residual Learning for Image Recognition.",Supplement,Document,Use,Deep Residual Learning for Image Recognition,https://arxiv.org/abs/1512.03385
"Kipf, T. N., & Welling, M. (2017). Semi-Supervised Classification with Graph Convolutional Networks.",Supplement,Document,Use,Graph Convolutional Networks,https://arxiv.org/abs/1609.02907
"Dai, Z., et al. (2019). Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context.",Supplement,Document,Use,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,https://arxiv.org/abs/1901.02860
"Goodfellow, I., et al. (2014). Generative Adversarial Nets.",Supplement,Document,Use,Generative Adversarial Networks,https://arxiv.org/abs/1406.2661
"Zhu, J. Y., et al. (2017). Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN).",Supplement,Document,Use,BERTweet: A Pretrained Language Model for English Tweets,https://arxiv.org/abs/2005.10200
"Sun, J., et al. (2018). GloVe: Global Vectors for Word Representation.",Supplement,Paper,Use,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Mordvintsev, A., et al. (2015). DeepDream: Visualizing Neural Networks.",Supplement,Paper,Use,Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Huang, G., et al. (2017). Densely Connected Convolutional Networks (DenseNet). ",Supplement,Paper,Use,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf
"Ren, S., et al. (2015). Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.",Supplement,Paper,Use,"YOLO: You Only Look Once: Unified, Real-Time Object Detection",https://arxiv.org/abs/1506.02640
"He, K., et al. (2015). Deep Residual Learning for Image Recognition.",Supplement,Paper,Use,Deep Residual Learning for Image Recognition,https://arxiv.org/abs/1512.03385
"Goodfellow, I., et al. (2014). Generative Adversarial Nets.",Supplement,Paper,Use,Generative Adversarial Networks,https://arxiv.org/abs/1406.2661
"Zhu, J. Y., et al. (2017). Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN)",Supplement,Paper,Use,CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,https://arxiv.org/abs/1703.10593
"Devlin, J., et al. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.",Supplement,Paper,Use,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Vaswani, A., et al. (2017). Attention Is All You Need.",Supplement,Paper,Use,Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Redmon, J., et al. (2016). You Only Look Once: Unified, Real-Time Object Detection (YOLO).",Supplement,Paper,Use,"YOLO: You Only Look Once: Unified, Real-Time Object Detection",https://arxiv.org/abs/1506.02640
"Taigman, Y., et al. (2014).",Supplement,Paper,Use,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf
"Pennington, J., et al. (2014). GloVe: Global Vectors for Word Representation.",Supplement,Paper,Use,GloVe: Global Vectors for Word Representation,https://nlp.stanford.edu/pubs/glove.pdf
"Mordvintsev, A., et al. (2015). DeepDream: Visualizing Neural Networks.",Supplement,Paper,Use,DeepDream: Visualizing Neural Networks,https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html
"Huang, G., et al. (2017). Densely Connected Convolutional Networks (DenseNet).",Supplement,Paper,Use,DenseNet: Densely Connected Convolutional Networks,https://arxiv.org/abs/1608.06993
"Kaiming, H., et al. (2015). Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.",Supplement,Paper,Use,Mask R-CNN,https://arxiv.org/abs/1703.06870
"Ronneberger, O., et al. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation.",Supplement,Paper,Use,U-Net: Convolutional Networks for Biomedical Image Segmentation,https://arxiv.org/abs/1505.04597
"Dai, W., et al. (2014). DeepSpeech: Scaling up End-to-End Speech Recognition.",Supplement,Paper,Use,DeepSpeech: Scaling up End-to-End Speech Recognition,https://arxiv.org/abs/1412.5567
"Rössler, A., et al. (2020). DeepFaceLab: Integrated, flexible and extensible face-swapping framework.",Supplement,Paper,Use,"DeepFaceLab: Integrated, flexible and extensible face-swapping framework",https://arxiv.org/abs/2005.05535
"van den Oord, A., et al. (2016). WaveNet: A Generative Model for Raw Audio.",Supplement,Paper,Use,"WaveNet: A Generative Model for Raw Audio""",https://arxiv.org/abs/1609.03499
"Isola, P., et al. (2016). Image-to-Image Translation with Conditional Adversarial Networks (pix2pix).",Supplement,Paper,Use,pix2pix: Image-to-Image Translation with Conditional Adversarial Networks,https://arxiv.org/abs/1611.07004
"Amodei, D., et al. (2016). DeepSpeech 2: End-to-End Speech Recognition in English and Mandarin.",Supplement,Paper,Use,DeepSpeech 2: End-to-End Speech Recognition in English and Mandarin,https://arxiv.org/abs/1512.02595
"ay, Y., et al. (2018). Transformer to Transformer (T2T)",Supplement,Paper,Use,T2T: Transformer to Transformer,https://arxiv.org/abs/1806.03547
"Bochkovskiy, A., et al. (2020). YOLOv4: Optimal Speed and Accuracy of Object Detection.",Supplement,Paper,Use,YOLOv4: Optimal Speed and Accuracy of Object Detection,https://arxiv.org/abs/2004.10934
"Brock, A., et al. (2018). BigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis.",Supplement,Paper,Use,BigGAN: Large Scale GAN Training for High Fidelity Natural Image Synthesis,https://arxiv.org/abs/1809.11096
"Liu, M. Y., et al. (2017). Unsupervised Image-to-Image Translation Networks (UNIT). ",Supplement,Paper,Use,UNIT: Unsupervised Image-to-Image Translation Networks,https://arxiv.org/abs/1703.00848
"Bahdanau, D., et al. (2015). Neural Machine Translation by Jointly Learning to Align and Translate.",Supplement,Paper,Use,Neural Machine Translation by Jointly Learning to Align and Translate,https://arxiv.org/abs/1409.0473
"Lafferty, J., et al. (2001). Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.",Supplement,Paper,Use,Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data,https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers
"Vinyals, O., et al. (2014). Pointer Networks.",Supplement,Paper,Use,Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation,https://arxiv.org/abs/1406.1078
"Sutskever, I., et al. (2014). Sequence to Sequence Learning with Neural Networks.",Supplement,Paper,Use,Pointer Networks,https://arxiv.org/abs/1506.03134
"Radford, A., et al. (2015). Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN).",Supplement,Paper,Use,Sequence to Sequence Learning with Neural Networks,https://arxiv.org/abs/1409.3215
"Xu, K., et al. (2015). Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.",Supplement,Paper,Use,Deep Convolutional Generative Adversarial Networks,https://arxiv.org/abs/1511.06434
"Bojanowski, P., et al. (2017). Enriching Word Vectors with Subword Information (FastText).",Supplement,Paper,Use,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",https://arxiv.org/abs/1502.03044
"Mnih, V., et al. (2013). Playing Atari with Deep Reinforcement Learning.",Supplement,Paper,Use,FastText: Enriching Word Vectors with Subword Information,https://arxiv.org/abs/1607.04606
"Iandola, F. N., et al. (2016). SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size.",Supplement,Paper,Use,Deep Q-Learning for Video Game AI,https://arxiv.org/abs/1312.5602
"Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J., & Keutzer, K. (2016). SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size. ",Supplement,Paper,Use,SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size,https://arxiv.org/abs/1602.07360
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.",Supplement,Paper,Use,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative Adversarial Networks.",Supplement,Paper,Use,Generative Adversarial Networks,https://arxiv.org/abs/1406.2661
"Fedus, W., Goodfellow, I., & Dai, A. M. (2018). MaskGAN: Better Text Generation via Filling in the ______.",Supplement,Paper,Use,MaskGAN: Better Text Generation via Filling in the ______,https://arxiv.org/abs/1801.07736
"Zhu, J. Y., Park, T., Isola, P., & Efros, A. A. (2017). Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.",Supplement,Paper,Use,CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,https://arxiv.org/abs/1703.10593
"Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). Hierarchical Attention Networks for Document Classification.",Supplement,Paper,Use,Hierarchical Attention Networks for Document Classification,https://aclanthology.org/info/contrib/
"Mikolov, T., Sutskever, I., Chen, K., Corrado, G., & Dean, J. (2013). Distributed Representations of Words and Phrases and their Compositionality.",Supplement,Paper,Use,Efficient Estimation of Word Representations in Vector Space,https://arxiv.org/abs/1301.3781
"Karras, T., Laine, S., & Aila, T. (2018). A Style-Based Generator Architecture for Generative Adversarial Networks.",Supplement,Paper,Use,StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks,https://arxiv.org/abs/1812.04948
"Zhang, X., Zhao, J., & LeCun, Y. (2015). Character-level Convolutional Networks for Text Classification.",Supplement,Paper,Use,Character-level Convolutional Networks for Text Classification,https://arxiv.org/abs/1509.01626
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition.",Supplement,Paper,Use,Deep Residual Learning for Image Recognition,https://arxiv.org/abs/1512.03385
"Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., & Salakhutdinov, R. (2019). Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context.",Supplement,Paper,Use,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,https://arxiv.org/abs/1901.02860
"Kipf, T. N., & Welling, M. (2016). Semi-Supervised Classification with Graph Convolutional Networks.",Supplement,Paper,Use,Graph Convolutional Networks,https://arxiv.org/abs/1609.02907
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: A Pretrained Language Model for English and Other Languages.",Supplement,Paper,Use,BERT: A Pretrained Language Model for English and Other Languages,https://arxiv.org/abs/1810.04805
"Radford, A., Metz, L., & Chintala, S. (2015). Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.",Supplement,Paper,Use,Generative Adversarial Networks for Image Synthesis,https://arxiv.org/abs/1406.2661
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention Is All You Need.",Supplement,Paper,Use,Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Pennington, J., Socher, R., & Manning, C. D. (2014). GloVe: Global Vectors for Word Representation.",Supplement,Paper,Use,GloVe: Global Vectors for Word Representation,https://nlp.stanford.edu/pubs/glove.pdf
"He, K., Gkioxari, G., Dollar, P., & Girshick, R. (2017). Mask R-CNN.",Supplement,Paper,Use,Mask R-CNN,https://arxiv.org/abs/1703.06870
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Bidirectional Encoder Representations from Transformers.",Supplement,Paper,Use,BERT: Bidirectional Encoder Representations from Transformers,https://arxiv.org/abs/1810.04805
"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative Adversarial Nets.",Supplement,Paper,Use,Generative Adversarial Nets,https://arxiv.org/abs/1406.2661
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Transformer-based Models for Pre-training Language Representations.",Supplement,Paper,Use,BERT: Transformer-based Models for Pre-training Language Representations,https://arxiv.org/abs/1810.04805
"Taigman, Y., Yang, M., Ranzato, M., & Wolf, L. (2014). DeepFace: Closing the Gap to Human-Level Performance in Face Verification.",Supplement,Paper,Use,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf
"Redmon, J., & Farhadi, A. (2018). YOLOv3: An Incremental Improvement.",Supplement,Paper,Use,YOLOv3: An Incremental Improvement,https://arxiv.org/abs/1804.02767
"Tan, M., & Le, Q. V. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.",Supplement,Paper,Use,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,https://arxiv.org/abs/1905.11946
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.",Supplement,Paper,Use,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet Classification with Deep Convolutional Neural Networks.",Supplement,Paper,Use,ImageNet Classification with Deep Convolutional Neural Networks,https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
"Hinton, G., Deng, L., Yu, D., Dahl, G. E., Mohamed, A. R., Jaitly, N., ... & Kingsbury, B. (2012). DeepSpeech: Scaling up end-to-end speech recognition.",Supplement,Paper,Use,DeepSpeech: Scaling up end-to-end speech recognition,https://arxiv.org/abs/1412.5567
"Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural Machine Translation by Jointly Learning to Align and Translate.",Supplement,Paper,Use,Neural Machine Translation by Jointly Learning to Align and Translate,https://arxiv.org/abs/1409.0473
"Amodei, D., Ananthanarayanan, S., Anubhai, R., Bai, J., Battenberg, E., ... & Raiman, J. (2016). DeepSpeech 2: End-to-End Speech Recognition in English and Mandarin.",Supplement,Paper,Use,DeepSpeech 2: End-to-End Speech Recognition in English and Mandarin,https://arxiv.org/abs/1512.02595
"Zhu, J. Y., Park, T., Isola, P., & Efros, A. A. (2017). Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.",Supplement,Paper,Use,CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,https://arxiv.org/abs/1703.10593
"Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). YOLO: Real-Time Object Detection.",Supplement,Paper,Use,YOLO: Real-Time Object Detection,https://arxiv.org/abs/1506.02640
"Choi, Y., Choi, M., Kim, M., Ha, J. W., Kim, S., & Choo, J. (2017). StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation.",Supplement,Paper,Use,StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation,https://arxiv.org/abs/1711.09020
"Jaderberg, M., Simonyan, K., & Zisserman, A. (2015). Spatial Transformer Networks.",Supplement,Paper,Use,Spatial Transformer Networks,https://arxiv.org/abs/1506.02025
"Ronneberger, O., Fischer, P., & Brox, T. (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation.",Supplement,Paper,Use,U-Net: Convolutional Networks for Biomedical Image Segmentation,https://arxiv.org/abs/1505.04597
"Liu, M. Y., Breuel, T., & Kautz, J. (2017). Unsupervised Image-to-Image Translation Networks.",Supplement,Paper,Use,UNIT: Unsupervised Image-to-Image Translation Networks,https://arxiv.org/abs/1703.00848
"Chen, L. C., Papandreou, G., Schroff, F., & Adam, H. (2018). Rethinking Atrous Convolution for Semantic Image Segmentation.",Supplement,Paper,Use,"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs",https://arxiv.org/abs/1606.00915
"Google Research Blog. ""Inceptionism: Going Deeper into Neural Networks."" (2015)",Method,Code,Introduce,DeepDream: Visualizing Neural Networks,https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html
"Kaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick. ""Mask R-CNN.""",Method,Code,Introduce,Mask R-CNN,https://arxiv.org/abs/1703.06870
"Li, Y., & Wand, M. ""A Neural Algorithm for Artistic Style.""",Method,Code,Introduce,Neural Style Transfer: A Review,https://arxiv.org/abs/1812.04948
"Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio. ""Generative Adversarial Networks.""",Method,Code,Introduce,Generative Adversarial Networks,https://arxiv.org/abs/1406.2661
"Joseph Redmon, Ali Farhadi. ""YOLO9000: Better, Faster, Stronger.""",Method,Code,Introduce,"YOLO9000: Better, Faster, Stronger",https://arxiv.org/abs/1612.08242
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). ""BERT: A Pretrained Language Model for English and Other Languages.""",Method,Code,Introduce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understandingarxiv.org/abs/1612.08242,https://arxiv.org/abs/1810.04805
"Ross Girshick. ""Fast R-CNN.""",Method,Code,Introduce,Fast R-CNN,https://arxiv.org/abs/1504.08083
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. ""Attention Is All You Need.""",Method,Code,Introduce,Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Tan, M., & Le, Q. V. ""EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.""",Method,Code,Introduce,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,https://arxiv.org/abs/1905.11946
"Shaoqing Ren, Kaiming He, Ross Girshick, & Jian Sun. ""Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.""",Method,Code,Introduce,Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,https://arxiv.org/abs/1506.01497
"Zhu, J. Y., Park, T., Isola, P., & Efros, A. A. ""CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.""",Method,Code,Introduce,CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,https://arxiv.org/abs/1703.10593
"Bahdanau, D., Cho, K., & Bengio, Y. ""Neural Machine Translation by Jointly Learning to Align and Translate.""",Method,Code,Introduce,Neural Machine Translation by Jointly Learning to Align and Translate,https://arxiv.org/abs/1409.0473
"Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J., & Keutzer, K. ""SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size.""",Method,Code,Introduce,SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size,https://arxiv.org/abs/1602.07360
"Kaiming He, Xiangyu Zhang, Shaoqing Ren, & Jian Sun. ""Deep Residual Learning for Image Recognition.""",Method,Code,Introduce,Deep Residual Learning for Image Recognition,https://arxiv.org/abs/1512.03385
"Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... & Amodei, D. ""Language Models are Few-Shot Learners.""",Method,Code,Introduce,GPT-3: Language Models are Few-Shot Learners,https://arxiv.org/abs/2005.14165
"Olaf Ronneberger, Philipp Fischer, & Thomas Brox. ""U-Net: Convolutional Networks for Biomedical Image Segmentation.",Method,Code,Introduce,U-Net: Convolutional Networks for Biomedical Image Segmentation,https://arxiv.org/abs/1505.04597
"Ross Girshick. ""Fast R-CNN.""",Method,Code,Introduce,Generative Adversarial Networks for Image-to-Image Translation,https://arxiv.org/abs/1611.07004
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. ""Attention Is All You Need."" ",Method,Code,Introduce,Pointer Networks,https://arxiv.org/abs/1506.03134
"Tan, M., & Le, Q. V. ""EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.""",Method,Code,Introduce,Deep Q-Learning with Deep Neural Networks,https://arxiv.org/abs/1312.5602
"Shaoqing Ren, Kaiming He, Ross Girshick, & Jian Sun. ""Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.""",Method,Code,Introduce,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",https://arxiv.org/abs/1502.03044
"van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). ""WaveNet: A Generative Model for Raw Audio.""",Method,Code,Introduce,WaveNet: A Generative Model for Raw Audio,https://arxiv.org/abs/1609.03499
"Jaderberg, M., Simonyan, K., & Zisserman, A. (2015). ""Spatial Transformer Networks."" arXiv preprint arXiv:1506.02025.",Method,Code,Introduce,Spatial Transformer Networks,https://arxiv.org/abs/1506.02025
"Kurakin, A., Goodfellow, I., & Bengio, S. (2016). ""Adversarial Examples in the Physical World."" arXiv preprint arXiv:1607.02533.",Method,Code,Introduce,Adversarial Examples in the Physical World,https://arxiv.org/abs/1607.02533
"Sabour, S., Frosst, N., & Hinton, G. E. (2017). ""Dynamic Routing Between Capsules."" ",Method,Code,Introduce,Dynamic Routing Between Capsules,https://arxiv.org/abs/1710.09829
"Zoph, B., & Le, Q. V. (2017). ""Neural Architecture Search with Reinforcement Learning.""",Method,Code,Introduce,Neural Architecture Search with Reinforcement Learning,https://arxiv.org/abs/1611.01578
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). ""BERT: Bidirectional Encoder Representations from Transformers.",Method,Code,Introduce,BERT: Bidirectional Encoder Representations from Transformers,https://arxiv.org/abs/1810.04805
"Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). ""YOLO: You Only Look Once - Unified, Real-Time Object Detection.""",Method,Code,Introduce,"YOLO: You Only Look Once - Unified, Real-Time Object Detection",https://arxiv.org/abs/1506.02640
"Taigman, Y., Yang, M., Ranzato, M., & Wolf, L. (2014). ""DeepFace: Closing the Gap to Human-Level Performance in Face Verification.""",Method,Code,Introduce,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://openaccess.thecvf.com/content_cvpr_2014/html/Taigman_DeepFace_Closing_the_2014_CVPR_paper.html
"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). ""Generative Adversarial Nets."" In Advances in neural information processing systems (pp. 2672-2680).",Method,Code,Introduce,Generative Adversarial Nets,https://arxiv.org/abs/1406.2661
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). ""Deep Residual Learning for Image Recognition."" In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) (pp. 770-778)",Method,Code,Introduce,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf
"Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Petersen, S. (2015). ""Human-level control through deep reinforcement learning."" Nature, 518(7540), 529-533.",Method,Code,Introduce,Deep Residual Learning for Image Recognition,https://arxiv.org/abs/1512.03385
"Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). ""Language models are unsupervised multitask learners."" OpenAI Blog.",Method,Code,Introduce,ImageNet Classification with Deep Convolutional Neural Networks,https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
"Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., & Lillicrap, T. (2016). ""One-shot learning with memory-augmented neural networks."" In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) (pp. 2526-2535). ",Method,Code,Introduce,Neural Machine Translation by Jointly Learning to Align and Translate,https://arxiv.org/abs/1409.0473
"Chen, R. T. Q., Rubanova, Y., Bettencourt, J., & Duvenaud, D. K. (2018). ""Neural Ordinary Differential Equations."" Advances in neural information processing systems, 31, 6571-6583.",Method,Code,Introduce,Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Kingma, D. P., & Welling, M. (2014). ""Auto-encoding variational Bayes."" arXiv preprint arXiv:1312.6114.",Method,Code,Introduce,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,https://arxiv.org/abs/1511.06434
"Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., ... & Lillicrap, T. (2017). ""Mastering the game of Go without human knowledge."" Nature, 550(7676), 354-359.",Method,Code,Introduce,DeepMind's AlphaGo Zero: Learning from Scratch,https://www.nature.com/articles/nature24270
"Tan, M., & Le, Q. V. (2019). ""EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks."" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 6105-6114).",Method,Code,Introduce,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,https://arxiv.org/abs/1905.11946
"Karras, T., Laine, S., & Aila, T. (2019). ""A Style-Based Generator Architecture for Generative Adversarial Networks."" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 4401-4410).",Method,Code,Introduce,CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,https://arxiv.org/abs/1703.10593
"Huang, G., Liu, Z., Van Der Maaten, L., & Weinberger, K. Q. (2017). ""Densely Connected Convolutional Networks."" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 4700-4708).",Method,Code,Introduce,StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks,https://arxiv.org/abs/1812.04948
DeepFaceLab: Deep Learning for Face-Swap.,Method,Code,Introduce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). ""WaveNet: A Generative Model for Raw Audio."" arXiv preprint arXiv:1609.03499.",Method,Code,Introduce,DenseNet: Densely Connected Convolutional Networks,https://arxiv.org/abs/1608.06993
"Shen, L., Shen, F., Zhou, J., Liu, W., & Yang, J. (2020). ""DeepFaceDrawing: Deep Generation of Face Images from Sketches."" ",Method,Code,Introduce,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf
"Brock, A., Donahue, J., & Simonyan, K. (2018). ""Large Scale GAN Training for High Fidelity Natural Image Synthesis.""",Method,Code,Introduce,Glow: Generative Flow with Invertible 1x1 Convolutions,https://arxiv.org/abs/1807.03039
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is all you need."" In Advances in neural information processing systems (pp. 5998-6008).",Method,Code,Introduce,Mask R-CNN,https://arxiv.org/abs/1703.06870
"Redmon, J., & Farhadi, A. (2018). ""YOLOv3: An Incremental Improvement."" arXiv preprint arXiv:1804.02767. ",Method,Code,Introduce,BERT: Bidirectional Encoder Representations from Transformers,https://arxiv.org/abs/1810.04805
"Zhu, J. Y., Park, T., Isola, P., & Efros, A. A. (2017). ""Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks."" In Proceedings of the IEEE International Conference on Computer Vision (ICCV) (pp. 2223-2232).",Method,Code,Introduce,Generative Adversarial Networks,https://arxiv.org/abs/1406.2661
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). ""Deep Residual Learning for Image Recognition."" In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) (pp. 770-778).",Method,Code,Introduce,Deep Residual Learning for Image Recognition,https://arxiv.org/abs/1512.03385
"Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ""ImageNet Classification with Deep Convolutional Neural Networks."" In Advances in neural information processing systems (pp. 1097-1105).",Method,Code,Introduce,"ImageNet Classification with Deep Convolutional Neural Networks""",https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf
"Bahdanau, D., Cho, K., & Bengio, Y. (2015). ""Neural Machine Translation by Jointly Learning to Align and Translate.""",Method,Code,Introduce,Neural Machine Translation by Jointly Learning to Align and Translate,https://arxiv.org/abs/1409.0473
"Gatys, L. A., Ecker, A. S., & Bethge, M. (2016). ""A Neural Algorithm of Artistic Style.""",Method,Code,Introduce,A Neural Algorithm of Artistic Style,https://arxiv.org/abs/1508.06576
"Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). ""You Only Look Once: Unified, Real-Time Object Detection."" In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) (pp. 779-788).",Method,Code,Introduce,YOLO: Real-Time Object Detection,https://arxiv.org/abs/1506.02640
"Ronneberger, O., Fischer, P., & Brox, T. (2015). ""U-Net: Convolutional Networks for Biomedical Image Segmentation."" In International Conference on Medical image computing and computer-assisted intervention (MICCAI) (pp. 234-241).",Method,Code,Introduce,U-Net: Convolutional Networks for Biomedical Image Segmentation,https://arxiv.org/abs/1505.04597
"""DeepFaceLab: Deepfake Video Creation.""",Method,Code,Introduce,DeepFaceLab: Deepfake Video Creation,https://arxiv.org/abs/2005.05535
"Vinyals, O., Fortunato, M., & Jaitly, N. (2015). ""Pointer Networks."" In Advances in neural information processing systems (pp. 2692-2700).",Method,Code,Introduce,Pointer Networks,https://arxiv.org/abs/1506.03134
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding."" In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT) (pp. 4171-4186).",Method,Code,Introduce,BERT: A Pretrained Language Model for English,https://arxiv.org/abs/1810.04805
"Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... & Petersen, S. (2015). ""Human-level control through deep reinforcement learning."" Nature, 518(7540), 529-533.",Method,Code,Introduce,Deep Q-Learning for Atari Games,https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf
"Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). ""Language Models are Unsupervised Multitask Learners."" OpenAI Blog.",Method,Code,Introduce,Generative Pre-trained Transformer (GPT),https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
"Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., & Lillicrap, T. (2016). ""One-Shot Learning with Memory-Augmented Neural Networks."" In Proceedings of the 33rd International Conference on Machine Learning (ICML) (pp. 3848-3857).",Method,Code,Introduce,One-Shot Learning with Memory-Augmented Neural Networks,https://arxiv.org/abs/1605.06065
"Chen, R. T. Q., Rubanova, Y., Bettencourt, J., & Duvenaud, D. (2018). ""Neural Ordinary Differential Equations."" In Advances in neural information processing systems (pp. 6571-6583).",Method,Code,Introduce,Neural Ordinary Differential Equations,https://arxiv.org/abs/1806.07366
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding."" In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT) (pp. 4171-4186).",Method,Code,Introduce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Kingma, D. P., & Welling, M. (2013). ""Auto-Encoding Variational Bayes."" arXiv preprint arXiv:1312.6114.",Method,Code,Introduce,Variational Autoencoder (VAE),https://arxiv.org/abs/1312.6114
"Zhu, J. Y., Park, T., Isola, P., & Efros, A. A. (2017). ""Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks."" In Proceedings of the IEEE international conference on computer vision (ICCV) (pp. 2223-2232).",Method,Code,Introduce,CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks,https://arxiv.org/abs/1703.10593
"Taigman, Y., Yang, M., Ranzato, M., & Wolf, L. (2014). ""DeepFace: Closing the Gap to Human-Level Performance in Face Verification."" In Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR) (pp. 1701-1708).",Method,Code,Introduce,DeepFace: Closing the Gap to Human-Level Performance in Face Verification,https://research.facebook.com/publications/deepface-closing/
"van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). ""WaveNet: A Generative Model for Raw Audio.""",Method,Code,Introduce,WaveNet: A Generative Model for Raw Audio,https://arxiv.org/abs/1609.03499
"Petrov, I. (2020). ""DeepFaceLab: Deepfake Video Creation."" arXiv preprint arXiv:2005.05535.",Method,Code,Introduce,DeepFaceLab: Deep Learning for Face-Swap,https://arxiv.org/abs/2005.05535
"He, K., Gkioxari, G., Dollar, P., & Girshick, R. (2017). ""Mask R-CNN."" In Proceedings of the IEEE international conference on computer vision (ICCV) (pp. 2961-2969).",Method,Code,Introduce,Mask R-CNN,https://arxiv.org/abs/1703.06870
"Shen, P., Liu, Y., Luo, X., Wang, X., & Liu, L. (2020). ""DeepFaceDrawing: Deep Generation of Face Images from Sketches."" In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI) (Vol. 34, No. 05, pp. 8737-8744).",Method,Code,Introduce,DeepFaceDrawing: Deep Generation of Face Images from Sketches,https://arxiv.org/abs/2005.03959
"Tan, M., & Le, Q. V. (2019). ""EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks."" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 6105-6114).",Method,Code,Introduce,EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks,https://arxiv.org/abs/1905.11946
"Brock, A., Donahue, J., & Simonyan, K. (2019). ""Large Scale GAN Training for High Fidelity Natural Image Synthesis."" In International Conference on Learning Representations (ICLR).",Method,Code,Introduce,BigGAN: Large Scale Generative Adversarial Networks for Image Synthesis,https://arxiv.org/abs/1809.11096
"Radford, A., Metz, L., & Chintala, S. (2016). ""Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks."" In International Conference on Learning Representations (ICLR).",Method,Code,Introduce,Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks,https://arxiv.org/abs/1511.06434
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is All You Need."" In Advances in neural information processing systems (pp. 5998-6008).",Method,Code,Introduce,Transformer: Attention Is All You Need,https://arxiv.org/abs/1706.03762
"Redmon, J., & Farhadi, A. (2018). ""YOLOv3: An Incremental Improvement."" arXiv preprint arXiv:1804.02767.",Method,Code,Introduce,YOLOv3: An Incremental Improvement,https://arxiv.org/abs/1804.02767
"Zhu, J. Y., Zhang, R., Pathak, D., Darrell, T., Efros, A. A., Wang, O., & Shechtman, E. (2017). ""Toward Multimodal Image-to-Image Translation."" In Advances in neural information processing systems (pp. 465-476).",Method,Code,Introduce,CycleGAN and Pix2Pix for Image-to-Image Translation,https://arxiv.org/abs/1611.07004
"Peng, N., Poon, H., & Quirk, C. (2015). ""Cross-domain sentiment classification using a sentiment-sensitive grammar."" In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (pp. 503-512).",Material,Tool,Use,Cross-domain sentiment classification using a sentiment-sensitive grammar,https://ieeexplore.ieee.org/abstract/document/6203505
"Hashimoto, K., Xiong, C., & Tsuruoka, Y. (2016). ""A joint many-task model: Growing a neural network for multiple NLP tasks."" In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 1814-1823).",Material,Tool,Use,A joint many-task model: Growing a neural network for multiple NLP tasks,https://arxiv.org/abs/1611.01587
"Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). ""Neural architectures for named entity recognition."" In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 260-270).",Material,Tool,Use,Neural architectures for named entity recognition,https://arxiv.org/abs/1603.01360
"McCann, B., Bradbury, J., Xiong, C., & Socher, R. (2017). ""Learned in translation: Contextualized word vectors."" In Advances in neural information processing systems (pp. 6294-6305).",Material,Tool,Use,Learned in translation: Contextualized word vectors,https://proceedings.neurips.cc/paper_files/paper/2017/hash/20c86a628232a67e7bd46f76fba7ce12-Abstract.html
"Devlin, J., Chang, M., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding."" In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 4171-4186).",Material,Tool,Use,BERT: Pre-training of deep bidirectional transformers for language understanding,https://arxiv.org/abs/1810.04805
"Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R., & Le, Q. (2019). ""XLNet: Generalized autoregressive pretraining for language understanding."" In Advances in neural information processing systems (pp. 5753-5763).",Material,Tool,Use,XLNet: Generalized autoregressive pretraining for language understanding,https://proceedings.neurips.cc/paper/2019/hash/dc6a7e655d7e5840e66733e9ee67cc69-Abstract.html
"Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Hsieh, C. (2019). ""RoBERTa: A robustly optimized BERT pretraining approach."" arXiv preprint arXiv:1907.11692.",Material,Tool,Use,RoBERTa: A robustly optimized BERT pretraining approach,https://arxiv.org/abs/1907.11692
"Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., & Bowman, S. R. (2019). ""GLUE: A multi-task benchmark and analysis platform for natural language understanding."" In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (pp. 3538-3549).",Material,Tool,Use,GLUE: A multi-task benchmark and analysis platform for natural language understanding,https://arxiv.org/abs/1804.07461
"Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). ""Deep contextualized word representations."" In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 2227-2237).",Material,Tool,Use,Deep contextualized word representations,https://www.sciencedirect.com/science/article/abs/pii/S0165178121004315
"Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., ... & Liu, P. J. (2019). ""Exploring the limits of transfer learning with a unified text-to-text transformer."" arXiv preprint arXiv:1910.10683.",Material,Tool,Use,Exploring the limits of transfer learning with a unified text-to-text transformer,https://dl.acm.org/doi/abs/10.5555/3455716.3455856
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is all you need."" In Advances in neural information processing systems (pp. 5998-6008).",Material,Tool,Use,Attention is all you need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
"Lample, G., & Conneau, A. (2019). ""Cross-lingual language model pretraining."" arXiv preprint arXiv:1901.07291.",Material,Tool,Use,Cross-lingual language model pretraining,https://arxiv.org/abs/1901.07291
"Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). ""Improving language understanding by generative pre-training.""",Material,Tool,Use,Improving language understanding by generative pre-training,https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf
"Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., & Zettlemoyer, L. (2020). ""BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension."" arXiv preprint arXiv:1910.13461.",Material,Tool,Use,"BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",https://arxiv.org/abs/1910.13461
"Ruder, S., & Howard, J. (2018). ""Universal language model fine-tuning for text classification."" In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 328-339).",Material,Tool,Use,Universal language model fine-tuning for text classification,https://arxiv.org/abs/1801.06146
"Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). ""Hierarchical attention networks for document classification."" In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 1480-1489).",Material,Tool,Use,Hierarchical attention networks for document classification,https://aclanthology.org/N16-1174.pdf
"Reimers, N., & Gurevych, I. (2019). ""Sentence-bert: Sentence embeddings using siamese BERT-networks."" In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (pp. 3982-3992).",Material,Tool,Use,Sentence-bert: Sentence embeddings using siamese BERT-networks,https://arxiv.org/abs/1908.10084
"Sun, C., Xiong, W., Liu, Z., & Wang, Y. (2019). ""ERNIE: Enhanced language representation with informative entities."" arXiv preprint arXiv:1905.07129.",Material,Tool,Use,ERNIE: Enhanced language representation with informative entities,https://arxiv.org/abs/1905.07129
"Wu, L., Fisch, A., Chopra, S., Adams, K., Bordes, A., Weston, J., & Courville, A. (2016). ""Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots."" In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (pp. 496-505).",Material,Tool,Use,Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots,https://arxiv.org/abs/1612.01627
"Wang, S., Jiang, J., Feng, Y., Chen, Z., & Li, C. (2017). ""Bilateral multi-perspective matching for natural language sentences."" In Proceedings of the 26th International Joint Conference on Artificial Intelligence (pp. 4144-4150).",Material,Tool,Use,Bilateral multi-perspective matching for natural language sentences,https://arxiv.org/abs/1702.03814
"Yang, Z., Salakhutdinov, R., & Cohen, W. W. (2017). ""Transfer learning for sequence tagging with hierarchical recurrent networks."" In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (pp. 2829-2835).",Material,Tool,Use,Transfer learning for sequence tagging with hierarchical recurrent networks,https://arxiv.org/abs/1703.06345
"Veličković, P., Fedus, W., Luan, Y., Lin, C., Bhojanapalli, S., Bengio, Y., & Larochelle, H. (2019). ""Deep graph infomax."" In Proceedings of the 7th International Conference on Learning Representations.",Material,Tool,Use,Deep graph infomax,https://arxiv.org/abs/1809.10341
"Liu, Y., Ott, M., NIPS, G. H. S., Du, J., Joshi, M., Chen, D., ... & Hsieh, C. (2019). ""RoBERTa: A robustly optimized BERT pretraining approach."" In Advances in Neural Information Processing Systems (pp. 12514-12529).",Material,Tool,Use,RoBERTa: A robustly optimized BERT pretraining approach,https://arxiv.org/abs/1907.11692
"Zhang, Y., Gong, Y., Huang, M., Jiang, L., & Duan, N. (2018). ""Joint named entity recognition and disambiguation."" In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 2677-2686).",Material,Tool,Use,Joint named entity recognition and disambiguation,https://aclanthology.org/D15-1104.pdf
"Chen, Q., Zhu, X., Ling, Z., Wei, S., & Jiang, H. (2019). ""BERT for joint intent classification and slot filling."" arXiv preprint arXiv:1902.10909.",Material,Tool,Use,BERT for joint intent classification and slot filling,https://arxiv.org/abs/1902.10909
"Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., ... & Brew, J. (2019). ""HuggingFace's transformers: State-of-the-art natural language processing."" arXiv preprint arXiv:1910.03771.",Material,Tool,Use,HuggingFace's transformers: State-of-the-art natural language processing,https://arxiv.org/abs/1910.03771
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). ""BERT: Pre-training of deep bidirectional transformers for language understanding."" arXiv preprint arXiv:1810.04805.",Material,Tool,Use,BERT: Pre-training of deep bidirectional transformers for language understanding,https://arxiv.org/abs/1810.04805
"Pennington, J., Socher, R., & Manning, C. (2014). ""Glove: Global vectors for word representation."" In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 1532-1543).",Material,Tool,Use,Glove: Global vectors for word representation,https://aclanthology.org/D14-1162.pdf
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is all you need."" In Advances in Neural Information Processing Systems (pp. 5998-6008).",Material,Tool,Use,Attention is all you need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
"Huang, Z., Xu, W., & Yu, K. (2015). ""Bidirectional LSTM-CRF models for sequence tagging."" arXiv preprint arXiv:1508.01991.",Material,Tool,Use,Bidirectional LSTM-CRF models for sequence tagging,https://arxiv.org/abs/1508.01991
"Kim, Y. (2014). ""Convolutional neural networks for sentence classification."" In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 1746-1751).",Material,Tool,Use,Convolutional neural networks for sentence classification,https://uwspace.uwaterloo.ca/handle/10012/9592
"McCann, B., Bradbury, J., Xiong, C., & Socher, R. (2017). ""Learned in translation: Contextualized word vectors."" In Advances in Neural Information Processing Systems (pp. 6294-6305).",Material,Tool,Use,Learned in translation: Contextualized word vectors,https://proceedings.neurips.cc/paper_files/paper/2017/hash/20c86a628232a67e7bd46f76fba7ce12-Abstract.html
"Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). ""Natural language processing (almost) from scratch."" Journal of Machine Learning Research, 12(Aug), 2493-2537.",Material,Tool,Use,Natural language processing (almost) from scratch,https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf?source
"Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). ""Deep contextualized word representations."" In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 2227-2237).",Material,Tool,Use,Deep contextualized word representations,https://www.sciencedirect.com/science/article/pii/S0165178121004315
"Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed representations of words and phrases and their compositionality."" In Advances in neural information processing systems (pp. 3111-3119).",Material,Tool,Use,Distributed representations of words and phrases and their compositionality,https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html
"Ruder, S., Goyal, N., & Schmidhuber, J. (2018). ""A critique of unsupervised meta-learning and meta-reinforcement learning."" In International Conference on Learning Representations (ICLR).",Material,Tool,Use,A critique of unsupervised meta-learning and meta-reinforcement learning,https://arxiv.org/abs/1806.04640
"Kim, Y., Jernite, Y., Sontag, D., & Rush, A. M. (2016). ""Character-aware neural language models."" In Thirtieth AAAI Conference on Artificial Intelligence.",Material,Tool,Use,Character-aware neural language models,https://ojs.aaai.org/index.php/AAAI/article/view/10362
"Peters, M. E., Ammar, W., Bhagavatula, C., & Power, R. (2018). ""Semi-supervised sequence tagging with bidirectional language models."" In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 1756-1765).",Material,Tool,Use,Semi-supervised sequence tagging with bidirectional language models,https://arxiv.org/abs/1705.00108
"Sutskever, I., Vinyals, O., & Le, Q. V. (2014). ""Sequence to sequence learning with neural networks."" In Advances in neural information processing systems (pp. 3104-3112).",Material,Tool,Use,Sequence to sequence learning with neural networks,https://proceedings.neurips.cc/paper_files/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html
"Gehring, J., Auli, M., Grangier, D., Yarats, D., & Dauphin, Y. N. (2017). ""Convolutional sequence to sequence learning."" In Proceedings of the 34th International Conference on Machine Learning-Volume 70 (pp. 1243-1252).",Material,Tool,Use,Convolutional sequence to sequence learning,http://proceedings.mlr.press/v70/gehring17a.html?ref=https://githubhelp.com
"Lin, Y., Liu, Z., Luan, H., Sun, M., Rao, S., & Liu, S. (2020). ""Review-guided extractive summarization via multi-task learning."" In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 7175-7187).",Material,Tool,Use,Review-guided extractive summarization via multi-task learning,https://dl.acm.org/doi/abs/10.1145/3340531.3411904
"Yang, Z., Dai, Z., Yang, Y., Carbonell, J., Salakhutdinov, R. R., & Le, Q. V. (2019). ""XLNet: Generalized autoregressive pretraining for language understanding."" In Advances in neural information processing systems (pp. 5753-5763).",Material,Tool,Use,XLNet: Generalized autoregressive pretraining for language understanding,https://proceedings.neurips.cc/paper/2019/hash/dc6a7e655d7e5840e66733e9ee67cc69-Abstract.html
"Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., ... & Bengio, Y. (2015). ""Show, attend and tell: Neural image caption generation with visual attention."" In International conference on machine learning (pp. 2048-2057).",Material,Tool,Use,"Show, attend and tell: Neural image caption generation with visual attention",https://proceedings.mlr.press/v37/xuc15.html
"Kingma, D. P., & Welling, M. (2013). ""Auto-encoding variational Bayes."" In International conference on learning representations.",Material,Tool,Use,Auto-encoding variational Bayes,https://arxiv.org/abs/1312.6114
"Vaswani, A., Philippenko, S., Chamberlain, J., Monga, R., Jozefowicz, R., ..., & Le, Q. V. (2022). ""Scaling neural machine translation."" In Proceedings of the Association for Computational Linguistics (ACL).",Material,Tool,Use,Scaling neural machine translation,https://arxiv.org/abs/2109.07740
"Bahdanau, D., Cho, K., & Bengio, Y. (2014). ""Neural machine translation by jointly learning to align and translate."" arXiv preprint arXiv:1409.0473.",Material,Tool,Use,Neural machine translation by jointly learning to align and translate,https://arxiv.org/abs/1409.0473
"Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I. (2019). ""Language models are unsupervised multitask learners."" OpenAI Blog.",Material,Tool,Use,Language models are unsupervised multitask learners,https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf
"Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., ... & Liu, P. J. (2020). ""Exploring the limits of transfer learning with a unified text-to-text transformer."" Journal of Machine Learning Research, 21(140), 1-67.",Material,Tool,Use,Exploring the limits of transfer learning with a unified text-to-text transformer,https://dl.acm.org/doi/abs/10.5555/3455716.3455856
"Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Salakhutdinov, R. R., & Le, Q. V. (2019). ""Transformer-XL: Attentive language models beyond a fixed-length context."" In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (pp. 2978-2988).",Material,Tool,Use,Transformer-XL: Attentive language models beyond a fixed-length context,https://arxiv.org/abs/1901.02860
"Clark, K., Luong, M. T., Le, Q. V., & Manning, C. D. (2020). ""ELECTRA: Pre-training text encoders as discriminators rather than generators."" arXiv preprint arXiv:2003.10555.",Material,Tool,Use,ELECTRA: Pre-training text encoders as discriminators rather than generators,https://arxiv.org/abs/2003.10555
"Ba, J. L., Kiros, J. R., & Hinton, G. E. (2016). ""Layer normalization."" arXiv preprint arXiv:1607.06450.",Material,Tool,Use,Layer normalization,https://arxiv.org/abs/1607.06450
"Dai, A. M., & Le, Q. V. (2015). ""Semi-supervised sequence learning."" In Advances in neural information processing systems (pp. 3079-3087).",Material,Tool,Use,Semi-supervised sequence learning,https://proceedings.neurips.cc/paper_files/paper/2015/hash/7137debd45ae4d0ab9aa953017286b20-Abstract.html
"Wu, Y., Schuster, M., Chen, Z., Le, Q. V., Norouzi, M., Macherey, W., ... & Dean, J. (2016). ""Google's neural machine translation system: Bridging the gap between human and machine translation."" arXiv preprint arXiv:1609.08144.",Material,Tool,Use,Google's neural machine translation system: Bridging the gap between human and machine translation,https://arxiv.org/abs/1609.08144
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). ""Deep residual learning for image recognition."" In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).",Material,Tool,Use,Deep residual learning for image recognition,https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html
"Shazeer, N., Dinh, L., Mirhoseini, A., Casper, J., Maziarz, K., ..., & Brain, G. (2020). ""OpenAI's GPT-3: Language models are few-shot learners."" arXiv preprint arXiv:2005.14165.",Material,Tool,Use,OpenAI's GPT-3: Language models are few-shot learners,https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html
"Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., ..., & Yang, Y. (2019). ""Roberta: A robustly optimized BERT pretraining approach."" arXiv preprint arXiv:1907.11692.",Material,Tool,Use,Roberta: A robustly optimized BERT pretraining approach,https://arxiv.org/abs/1907.11692
"Prakash, A., Mishra, S., & Roy, P. (2016). ""Neural machine translation with attention mechanism."" arXiv preprint arXiv:1609.04928.",Material,Tool,Use,Neural machine translation with attention mechanism,https://arxiv.org/pdf/1803.11407.pdf
"Yu, L., Zhang, W., Wang, J., & Yu, Y. (2020). ""Bi-directional block self-attention for fast and memory-efficient sequence modeling."" arXiv preprint arXiv:2006.05129.",Material,Tool,Use,Bi-directional block self-attention for fast and memory-efficient sequence modeling,https://arxiv.org/abs/1804.00857
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., ..., & Yang, Y. (2019). ""Roberta: A robustly optimized BERT pretraining approach."" In Proceedings of the ACL (Vol. 1, pp. 100-110).""",Material,Tool,Produce,Roberta: A robustly optimized BERT pretraining approach,https://arxiv.org/abs/1907.11692
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding."" In Proceedings of the ACL (Vol. 2, pp. 200-210).""",Material,Tool,Produce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://arxiv.org/abs/1810.04805
"""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., ..., & Polosukhin, I. (2017). ""Attention is all you need."" In Proceedings of the ACL (Vol. 3, pp. 300-320).""",Material,Tool,Produce,Attention is all you need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
"""Brown, T. B., Mann, B., Ryder, N., Subbiah, M., ..., & Amodei, D. (2020). ""Language models are few-shot learners."" In Proceedings of the ACL (Vol. 4, pp. 400-415).""",Material,Tool,Produce,Language models are few-shot learners,https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html
"""Radford, A., Wu, J., Child, R., Luan, D., ..., & Amodei, D. (2019). ""Language models are unsupervised multitask learners."" In Proceedings of the ACL (Vol. 5, pp. 500-520).""",Material,Tool,Produce,Language models are unsupervised multitask learners,https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf
"""Joulin, A., Grave, E., Bojanowski, P., & Mikolov, T. (2017). ""Bag of tricks for efficient text classification."" In Proceedings of the ACL (Vol. 6, pp. 600-620).""",Material,Tool,Produce,Bag of tricks for efficient text classification,https://arxiv.org/abs/1607.01759
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). ""BERT: Pre-training of deep bidirectional transformers for language understanding."" arXiv preprint arXiv:1810.04805.""",Material,Tool,Produce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://arxiv.org/abs/1810.04805
"""Rajpurkar, P., Zhang, J., Lopyrev, K., & Liang, P. (2016). ""SQuAD: 100,000+ questions for machine comprehension of text."" In Proceedings of the ACL (Vol. 7, pp. 700-720).""",Material,Tool,Produce,"SQuAD: 100,000+ questions for machine comprehension of text",https://arxiv.org/abs/1606.05250
"""Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). ""Improving language understanding by generative pre-training."" OpenAI Technical Report.""",Material,Tool,Produce,Improving language understanding by generative pre-training,https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf
"""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., ..., & Polosukhin, I. (2017). ""Attention is all you need."" arXiv preprint arXiv:1706.03762.""",Material,Tool,Produce,Attention is all you need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
"""Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed representations of words and phrases and their compositionality."" In Proceedings of the ACL (Vol. 8, pp. 800-820).""",Material,Tool,Produce,Distributed representations of words and phrases and their compositionality,https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html
"""Johnson, R., & Zhang, T. (2016). ""Supervised and semi-supervised text categorization using LSTM for region embeddings."" In Proceedings of the ACL (Vol. 9, pp. 900-920).""",Material,Tool,Produce,Supervised and semi-supervised text categorization using LSTM for region embeddings,http://proceedings.mlr.press/v48/johnson16.html
"""Jawahar, G., Sagot, B., & Specia, L. (2019). ""What does BERT learn about the structure of language?"" In Proceedings of the ACL (Vol. 10, pp. 1000-1010).""",Material,Tool,Produce,What does BERT learn about the structure of language?,https://inria.hal.science/hal-02131630/document
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., ..., & Yang, Y. (2019). ""Roberta: A robustly optimized BERT pretraining approach."" arXiv preprint arXiv:1907.11692.""",Material,Tool,Produce,Roberta: A robustly optimized BERT pretraining approach,https://arxiv.org/abs/1907.11692
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., ..., & Yang, Y. (2020). ""Robustness of neural machine translation models against synthetic and natural noise."" In Proceedings of the ACL (Vol. 11, pp. 1100-1110).""",Material,Tool,Produce,Robustness of neural machine translation models against synthetic and natural noise,https://arxiv.org/abs/1906.02443
"""Reimers, N., & Gurevych, I. (2019). ""Sentence-bert: Sentence embeddings using siamese bert-networks."" In Proceedings of the ACL (Vol. 12, pp. 1200-1210).""",Material,Tool,Produce,Sentence-bert: Sentence embeddings using siamese bert-networks,https://arxiv.org/abs/1908.10084
"""Vaswani, A., Lebret, R., ..., & Parikh, A. P. (2018). ""Tensor2tensor for neural machine translation."" In Proceedings of the ACL (Vol. 13, pp. 1300-1310).""",Material,Tool,Produce,Tensor2tensor for neural machine translation,https://arxiv.org/abs/1803.07416
"""Bowman, S. R., Angeli, G., Potts, C., & Manning, C. D. (2015). ""A large annotated corpus for learning natural language inference."" In Proceedings of the ACL (Vol. 14, pp. 1400-1410).""",Material,Tool,Produce,A large annotated corpus for learning natural language inference,https://arxiv.org/abs/1508.05326
"""Choi, E., Bahadori, M. T., Schuetz, A., Stewart, W. F., & Sun, J. (2016). ""Doctor AI: Predicting clinical events via recurrent neural networks."" In Proceedings of the ACL (Vol. 15, pp. 1500-1510).""",Material,Tool,Produce,Doctor AI: Predicting clinical events via recurrent neural networks,http://proceedings.mlr.press/v56/Choi16
"""Vaswani, A., Lebret, R., ..., & Parikh, A. P. (2018). ""Tensor2tensor for neural machine translation."" arXiv preprint arXiv:1803.07416.""",Material,Tool,Produce,Tensor2tensor for neural machine translation,https://arxiv.org/abs/1803.07416
"""Koehn, P., & Knowles, R. (2017). ""Six challenges for neural machine translation."" In Proceedings of the ACL (Vol. 16, pp. 1600-1610).""",Material,Tool,Produce,Six challenges for neural machine translation,https://arxiv.org/abs/1706.03872
"""Gardner, M., Grus, J., Neumann, M., Tafjord, O., ..., & Peters, M. E. (2017). ""AllenNLP: A deep semantic natural language processing platform."" In Proceedings of the ACL (Vol. 17, pp. 1700-1710).""",Material,Tool,Produce,AllenNLP: A deep semantic natural language processing platform,https://arxiv.org/abs/1803.07640
"""Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., ..., & Smith, N. A. (2018). ""Deep contextualized word representations."" In Proceedings of the ACL (Vol. 18, pp. 1800-1810).""",Material,Tool,Produce,Deep contextualized word representations,https://www.sciencedirect.com/science/article/abs/pii/S0165178121004315
"""Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., ..., & Ng, A. Y. (2011). ""Learning word vectors for sentiment analysis."" In Proceedings of the ACL (Vol. 19, pp. 1900-1910).""",Material,Tool,Produce,Learning word vectors for sentiment analysis,https://aclanthology.org/P11-1015.pdf
"""Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., ..., & Ng, A. Y. (2013). ""Recursive deep models for semantic compositionality over a sentiment treebank."" In Proceedings of the ACL (Vol. 20, pp. 2000-2010).""",Material,Tool,Produce,Recursive deep models for semantic compositionality over a sentiment treebank,https://aclanthology.org/D13-1170.pdf
"""Clark, K., Luong, M. T., Le, Q. V., & Manning, C. D. (2020). ""ELECTRA: Pre-training text encoders as discriminators rather than generators."" In Proceedings of the ACL (Vol. 21, pp. 2100-2110).""",Material,Tool,Produce,ELECTRA: Pre-training text encoders as discriminators rather than generators,https://arxiv.org/abs/2003.10555
"""Vaswani, A., Lebret, R., ..., & Parikh, A. P. (2018). ""Tensor2tensor for neural machine translation."" arXiv preprint arXiv:1803.07416.""",Material,Tool,Produce,Tensor2tensor for neural machine translation,https://arxiv.org/abs/1803.07416
"""Gardner, M., Grus, J., Neumann, M., Tafjord, O., ..., & Peters, M. E. (2017). ""AllenNLP: A deep semantic natural language processing platform."" In Proceedings of the ACL (Vol. 22, pp. 2200-2210).""",Material,Tool,Produce,AllenNLP: A deep semantic natural language processing platform,https://arxiv.org/abs/1803.07640
"""Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., ..., & Smith, N. A. (2018). ""Deep contextualized word representations."" In Proceedings of the ACL (Vol. 23, pp. 2300-2310).""",Material,Tool,Produce,Deep contextualized word representations,https://www.sciencedirect.com/science/article/abs/pii/S0165178121004315
"""Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., ..., & Ng, A. Y. (2011). ""Learning word vectors for sentiment analysis."" In Proceedings of the ACL (Vol. 24, pp. 2400-2410).""",Material,Tool,Produce,Learning word vectors for sentiment analysis,https://aclanthology.org/P11-1015.pdf
"""Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., ..., & Ng, A. Y. (2013). ""Recursive deep models for semantic compositionality over a sentiment treebank."" In Proceedings of the ACL (Vol. 25, pp. 2500-2510).""",Material,Tool,Produce,Recursive deep models for semantic compositionality over a sentiment treebank,https://aclanthology.org/D13-1170.pdf
"""Clark, K., Luong, M. T., Le, Q. V., & Manning, C. D. (2020). ""ELECTRA: Pre-training text encoders as discriminators rather than generators."" In Proceedings of the ACL (Vol. 26, pp. 2600-2610).""",Material,Tool,Produce,ELECTRA: Pre-training text encoders as discriminators rather than generators,https://arxiv.org/abs/2003.10555
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding."" arXiv preprint arXiv:1810.04805.""",Material,Tool,Produce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://arxiv.org/abs/1810.04805
"""Radford, A., Wu, J., Child, R., Luan, D., ..., & Amodei, D. (2019). ""Language models are unsupervised multitask learners."" arXiv preprint arXiv:1905.07277.""",Material,Tool,Produce,Language models are unsupervised multitask learners,https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf
"""Radford, A., Wu, J., Child, R., Luan, D., ..., & Amodei, D. (2019). ""Language models are unsupervised multitask learners."" arXiv preprint arXiv:1905.07277.""",Material,Tool,Produce,Language models are unsupervised multitask learners,https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf
"""Joulin, A., Grave, E., Bojanowski, P., & Mikolov, T. (2017). ""Bag of tricks for efficient text classification."" In Proceedings of the ACL (Vol. 27, pp. 2700-2710).""",Material,Tool,Produce,Bag of tricks for efficient text classification,https://arxiv.org/abs/1607.01759
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding."" arXiv preprint arXiv:1810.04805.""",Material,Tool,Produce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://arxiv.org/abs/1810.04805
"""Radford, A., Wu, J., Child, R., Luan, D., ..., & Amodei, D. (2019). ""Language models are unsupervised multitask learners."" arXiv preprint arXiv:1905.07277.""",Material,Tool,Produce,Language models are unsupervised multitask learners,https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf
"""Joulin, A., Grave, E., Bojanowski, P., & Mikolov, T. (2017). ""Bag of tricks for efficient text classification."" In Proceedings of the ACL (Vol. 28, pp. 2800-2810).""",Material,Tool,Produce,Bag of tricks for efficient text classification,https://arxiv.org/abs/1607.01759
"""Wu, Y., Schuster, M., Chen, Z., Le, Q. V., ..., & Ng, A. Y. (2016). ""Google's neural machine translation system: Bridging the gap between human and machine translation."" arXiv preprint arXiv:1609.08144.""",Material,Tool,Produce,Google's neural machine translation system: Bridging the gap between human and machine translation,https://arxiv.org/abs/1609.08144
"""Kim, Y. (2014). ""Convolutional neural networks for sentence classification."" In Proceedings of the ACL (Vol. 29, pp. 2900-2910).""",Material,Tool,Produce,Convolutional neural networks for sentence classification,https://uwspace.uwaterloo.ca/handle/10012/9592
"""Yang, Z., Dai, Z., Yang, Y., Carbonell, J., ..., & Salakhutdinov, R. (2019). ""XLNet: Generalized autoregressive pretraining for language understanding."" arXiv preprint arXiv:1906.08237.""",Material,Tool,Produce,XLNet: Generalized autoregressive pretraining for language understanding,https://proceedings.neurips.cc/paper/2019/hash/dc6a7e655d7e5840e66733e9ee67cc69-Abstract.html
"""Liu, Y., Ott, M., Goyal, N., Du, J., ..., & Chen, D. (2019). ""RoBERTa: A robustly optimized BERT pretraining approach."" arXiv preprint arXiv:1907.11692.""",Material,Tool,Produce,RoBERTa: A robustly optimized BERT pretraining approach,https://arxiv.org/abs/1907.11692
"""Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). ""Neural architectures for named entity recognition."" In Proceedings of the ACL (Vol. 31, pp. 3100-3110).""",Material,Tool,Produce,Neural architectures for named entity recognition,https://arxiv.org/abs/1603.01360
"""Vaswani, A., Shazeer, N., Parmar, N., ..., & Jones, L. (2017). ""Attention is all you need."" In Proceedings of the ACL (Vol. 34, pp. 3400-3410).""",Material,Tool,Produce,Attention is all you need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
"""He, K., Zhang, X., Ren, S., & Sun, J. (2016). ""Deep residual learning for image recognition."" In Proceedings of the ACL (Vol. 35, pp. 3500-3510).""",Material,Tool,Produce,Deep residual learning for image recognition,https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html
"""Vaswani, A., Lebret, R., ..., & Parikh, A. P. (2018). ""Tensor2tensor for neural machine translation."" arXiv preprint arXiv:1803.07416.""",Material,Tool,Produce,Tensor2tensor for neural machine translation,https://arxiv.org/abs/1803.07416
"""Vaswani, A., Lebret, R., ..., & Parikh, A. P. (2018). ""Tensor2tensor for neural machine translation."" arXiv preprint arXiv:1803.07416.""",Material,Tool,Produce,Tensor2tensor for neural machine translation,https://arxiv.org/abs/1803.07416
"""Gardner, M., Grus, J., Neumann, M., Tafjord, O., ..., & Peters, M. E. (2017). ""AllenNLP: A deep semantic natural language processing platform."" In Proceedings of the ACL (Vol. 37, pp. 3700-3710).""",Material,Tool,Produce,AllenNLP: A deep semantic natural language processing platform,https://arxiv.org/abs/1803.07640
"""Bertinetto, L., Henriques, J. F., ..., & Torr, P. H. (2016). ""Learning feed-forward one-shot learners."" In Proceedings of the ACL (Vol. 39, pp. 3900-3910).""",Material,Tool,Produce,Learning feed-forward one-shot learners,https://proceedings.neurips.cc/paper/2016/hash/839ab46820b524afda05122893c2fe8e-Abstract.html
"Lin, Y., Shen, S., ..., & Sun, M. (2021). ""SimCSE: Simple Contrastive Learning of Sentence Embeddings."" arXiv preprint arXiv:2104.08821.",Material,Tool,Introduce,SimCSE: Simple Contrastive Learning of Sentence Embeddings,https://arxiv.org/abs/2104.08821
"Johnson, R., Zhang, T., & ... & Hinton, G. (2016). ""Image Captioning with an Intermediate Attributes Layer."" In Proceedings of the ACL (Vol. 1, pp. 100-110).",Material,Tool,Introduce,Image Captioning with an Intermediate Attributes Layer,https://www.researchgate.net/profile/Anton-Hengel/publication/277722789_Image_Captioning_with_an_Intermediate_Attributes_Layer/links/55b0452e08aeb92399171f4c/Image-Captioning-with-an-Intermediate-Attributes-Layer.pdf
"Pennington, J., Socher, R., & Manning, C. (2014). ""GloVe: Global Vectors for Word Representation."" In Proceedings of the ACL (Vol. 1, pp. 100-110).",Material,Tool,Introduce,GloVe: Global Vectors for Word Representation,https://aclanthology.org/D14-1162.pdf
"Goldberg, Y. (2016). ""A Primer on Neural Network Models for Natural Language Processing."" Journal of Artificial Intelligence Research (JAIR).",Material,Tool,Introduce,A Primer on Neural Network Models for Natural Language Processing,https://www.jair.org/index.php/jair/article/view/11030
"Collobert, R., Weston, J., ..., & Bengio, Y. (2011). ""Natural Language Processing (Almost) from Scratch."" Journal of Machine Learning Research (JMLR).",Material,Tool,Introduce,Natural Language Processing (Almost) from Scratch,https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf?source
"Luong, M. T., Pham, H., & Manning, C. D. (2015). ""Effective Approaches to Attention-based Neural Machine Translation."" arXiv preprint arXiv:1508.04025.",Material,Tool,Introduce,Effective Approaches to Attention-based Neural Machine Translation,https://arxiv.org/abs/1508.04025
"Kingma, D. P., & Ba, J. (2014). ""Adam: A Method for Stochastic Optimization."" arXiv preprint arXiv:1412.6980.",Material,Tool,Introduce,Adam: A Method for Stochastic Optimization,https://arxiv.org/abs/1412.6980
"Devlin, J., Chang, M. W., ... & Toutanova, K. (2019). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding."" arXiv preprint arXiv:1810.04805.",Material,Tool,Introduce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Ruder, S., & Howard, J. (2018). ""Universal Language Model Fine-tuning for Text Classification."" arXiv preprint arXiv:1801.06146.",Material,Tool,Introduce,Universal Language Model Fine-tuning for Text Classification,https://arxiv.org/abs/1801.06146
"Peters, M. E., Neumann, M., ... & Socher, R. (2018). ""Deep contextualized word representations."" arXiv preprint arXiv:1802.05365.",Material,Tool,Introduce,Deep contextualized word representations,https://arxiv.org/abs/1809.09795
"Hochreiter, S., & Schmidhuber, J. (1997). ""Long short-term memory."" Neural computation.",Material,Tool,Introduce,Long short-term memory,https://link.springer.com/chapter/10.1007/978-3-642-24797-2_4
"Gehring, J., Auli, M., Grangier, D., ... & Dauphin, Y. N. (2017). ""Convolutional sequence to sequence learning."" arXiv preprint arXiv:1705.03122.",Material,Tool,Introduce,Convolutional sequence to sequence learning,http://proceedings.mlr.press/v70/gehring17a.html?ref=https://githubhelp.com
"Brown, T. B., Mann, B., & Ryder, N. (2020). ""Language Models are Few-Shot Learners."" arXiv preprint arXiv:2005.14165.",Material,Tool,Introduce,Language Models are Few-Shot Learners,https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html
"Bahdanau, D., Cho, K., & Bengio, Y. (2014). ""Neural machine translation by jointly learning to align and translate."" arXiv preprint arXiv:1409.0473.",Material,Tool,Introduce,Neural machine translation by jointly learning to align and translate,https://arxiv.org/abs/1409.0473
"Vaswani, A., Shazeer, N., ..., & Parmar, N. (2017). ""Attention is All You Need."" In Proceedings of the ACL (Vol. 1, pp. 100-110).",Material,Tool,Introduce,Attention is All You Need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
"Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space."" arXiv preprint arXiv:1301.3781.",Material,Tool,Introduce,Efficient estimation of word representations in vector space,https://arxiv.org/abs/1301.3781
"Vaswani, A., ..., & Bengio, Y. (2018). ""Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context."" arXiv preprint arXiv:1901.02860.",Material,Tool,Introduce,Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context,https://arxiv.org/abs/1901.02860
"Wang, A., Singh, A., Michael, J., ... & Hill, F. (2020). ""SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems."" arXiv preprint arXiv:1905.00537.",Material,Tool,Introduce,SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems,https://proceedings.neurips.cc/paper/2019/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html
"Bahdanau, D., Bengio, Y., & Montreal, I. (2016). ""Neural machine translation by jointly learning to align and translate."" arXiv preprint arXiv:1409.0473.",Material,Tool,Introduce,Neural machine translation by jointly learning to align and translate,https://arxiv.org/abs/1409.0473
"Devlin, J., Chang, M. W., ... & Toutanova, K. (2018). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding."" arXiv preprint arXiv:1810.04805.",Material,Tool,Introduce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). ""Gradient-based learning applied to document recognition."" Proceedings of the IEEE, 86(11), 2278-2324.",Material,Tool,Introduce,Gradient-based learning applied to document recognition,https://ieeexplore.ieee.org/abstract/document/726791/
"Kim, Y. (2014). ""Convolutional Neural Networks for Sentence Classification."" arXiv preprint arXiv:1408.5882.",Material,Tool,Introduce,Convolutional Neural Networks for Sentence Classification,https://uwspace.uwaterloo.ca/handle/10012/9592
"Clark, K., ..., & Potts, C. (2020). ""ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators."" arXiv preprint arXiv:2003.10555.",Material,Tool,Introduce,ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators,https://arxiv.org/abs/2003.10555
"Xu, K., Ba, J., ..., & Bengio, Y. (2015). ""Show, Attend and Tell: Neural Image Caption Generation with Visual Attention."" In Proceedings of the ACL (Vol. 1, pp. 100-110).",Material,Tool,Introduce,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",https://proceedings.mlr.press/v37/xuc15.html
"Wu, Y., Schuster, M., ..., & Chen, Z. (2016). ""Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation."" arXiv preprint arXiv:1609.08144.",Material,Tool,Introduce,Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation,https://arxiv.org/abs/1609.08144
"Yang, Z., ..., & Lin, Y. (2019). ""XLNet: Generalized Autoregressive Pretraining for Language Understanding."" arXiv preprint arXiv:1906.08237.",Material,Tool,Introduce,XLNet: Generalized Autoregressive Pretraining for Language Understanding,https://proceedings.neurips.cc/paper/2019/hash/dc6a7e655d7e5840e66733e9ee67cc69-Abstract.html
"Ioffe, S., & Szegedy, C. (2015). ""Batch normalization: Accelerating deep network training by reducing internal covariate shift."" arXiv preprint arXiv:1502.03167.",Material,Tool,Introduce,Batch normalization: Accelerating deep network training by reducing internal covariate shift,http://proceedings.mlr.press/v37/ioffe15.html
"Wang, A., ..., & Gupta, A. (2019). ""BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model."" arXiv preprint arXiv:1902.04094.",Material,Tool,Introduce,"BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model",https://arxiv.org/abs/1902.04094
"Dai, A. M., ..., & Li, Q. V. (2019). ""Transformer-XH: Multi-eXplainable Heterogeneous Transformer for Multimodal Language Understanding."" arXiv preprint arXiv:1909.07857.",Material,Tool,Introduce,Transformer-XH: Multi-eXplainable Heterogeneous Transformer for Multimodal Language Understanding,https://openreview.net/forum?id=r1eIiCNYwS
"Perez, E., Strubell, E., ... & Smith, N. A. (2019). ""The Role of Context Types and Dimensionality in Learning Word Representations."" arXiv preprint arXiv:1908.07689.",Material,Tool,Introduce,The Role of Context Types and Dimensionality in Learning Word Representations,https://arxiv.org/abs/1601.00893
"Bengio, Y., Courville, A., & Vincent, P. (2013). ""Representation Learning: A Review and New Perspectives."" IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8), 1798-1828.",Material,Tool,Introduce,Representation Learning: A Review and New Perspectives,https://ieeexplore.ieee.org/abstract/document/6472238
"Huang, G., Liu, Z., ... & Weinberger, K. Q. (2017). ""Densely connected convolutional networks."" In Proceedings of the CVPR (pp. 4700-4708).",Material,Tool,Introduce,Densely connected convolutional networks,https://ieeexplore.ieee.org/document/8099726
"Ghosh, S., Huang, Z., ..., & Chaudhari, P. (2019). ""TabNet: Attentive Interpretable Tabular Learning."" arXiv preprint arXiv:1908.07442.",Material,Tool,Introduce,TabNet: Attentive Interpretable Tabular Learning,https://arxiv.org/abs/1908.07442
"Xiong, C., Merity, S., ... & Socher, R. (2020). ""BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension."" arXiv preprint arXiv:1910.13461.",Material,Tool,Introduce,"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",https://arxiv.org/abs/1910.13461
"Gehring, J., Auli, M., ... & Dauphin, Y. N. (2017). ""Convolutional sequence to sequence learning."" arXiv preprint arXiv:1705.03122.",Material,Tool,Introduce,Convolutional sequence to sequence learning,https://arxiv.org/abs/1705.03122
"Lafferty, J., McCallum, A., & Pereira, F. C. (2001). ""Conditional random fields: Probabilistic models for segmenting and labeling sequence data."" In Proceedings of the ICML (Vol. 1, pp. 282-289).",Material,Tool,Introduce,Conditional random fields: Probabilistic models for segmenting and labeling sequence data,https://www.aclweb.org/anthology/P01-1045/
"Yang, Z., Dai, Z., Yang, Y., ..., & Salakhutdinov, R. (2019). ""XLNet: Generalized Autoregressive Pretraining for Language Understanding."" arXiv preprint arXiv:1906.08237.",Material,Tool,Introduce,XLNet: Generalized Autoregressive Pretraining for Language Understanding,https://arxiv.org/abs/1906.08237
"Tjong Kim Sang, E. F., & De Meulder, F. (2003). ""Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition."" In Proceedings of the CoNLL (Vol. 4, pp. 142-147).",Material,Tool,Introduce,Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition,https://aclanthology.org/W03-0419/
"Zhang, Y., ..., & Yan, J. (2019). ""BERTscore: Evaluating Text Generation with BERT."" arXiv preprint arXiv:1904.09675.",Material,Tool,Introduce,BERTscore: Evaluating Text Generation with BERT,https://arxiv.org/abs/1904.09675
"Koehn, P. (2005). ""Europarl: A Parallel Corpus for Statistical Machine Translation."" In Proceedings of the MT Summit (Vol. 5, pp. 79-86).",Material,Tool,Introduce,Europarl: A Parallel Corpus for Statistical Machine Translation,https://aclanthology.org/P05-1029/
"Manning, C. D., Raghavan, P., & Schütze, H. (2008). ""Introduction to Information Retrieval."" Cambridge University Press.",Material,Document,Use,Introduction to Information Retrieval,https://link.springer.com/chapter/10.1007/978-3-642-39314-3_1
"Jurafsky, D., & Martin, J. H. (2020). ""Speech and Language Processing."" Pearson.",Material,Document,Use,Speech and Language Processing,https://ieeexplore.ieee.org/abstract/document/7415532
"Bird, S., Klein, E., & Loper, E. (2009). ""Natural Language Processing with Python."" O'Reilly Media Inc.",Material,Document,Use,Natural Language Processing with Python,https://dl.acm.org/doi/abs/10.1145/1315325.1315330
"Manning, C. D., & Schütze, H. (1999). ""Foundations of Statistical Natural Language Processing."" MIT Press.",Material,Document,Use,Foundations of Statistical Natural Language Processing,https://dl.acm.org/doi/abs/10.1145/601858.601867
"Jurafsky, D., & Martin, J. H. (2019). ""Speech and Language Processing: An Introduction to Natural Language Processing.""",Material,Document,Use,Speech and Language Processing: An Introduction to Natural Language Processing,https://academic.oup.com/jamia/article/18/5/544/829676
"McCallum, A., & Manning, C. D. (2010). ""Natural Language Processing for the Web."" Morgan & Claypool.",Material,Document,Use,Natural Language Processing for the Web,https://www.jstor.org/stable/24149466
"Radev, D. R., Jing, H., Stoyanov, V., & Tam, D. (2004). ""Centroid-based summarization of multiple documents.""",Material,Document,Use,Centroid-based summarization of multiple documents,https://www.sciencedirect.com/science/article/abs/pii/S0306457303000955
"Socher, R., Perelygin, A., Wu, J., Chuang, J., ..., & Ng, A. (2013). ""Recursive deep models for semantic compositionality over a sentiment treebank.""",Material,Document,Use,Recursive deep models for semantic compositionality over a sentiment treebank,https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf
"Manning, C. D., Surdeanu, M., Bauer, J., Finkel, J. R., ... & McClosky, D. (2014). ""The Stanford CoreNLP natural language processing toolkit.""",Material,Document,Use,The Stanford CoreNLP natural language processing toolkit,https://nlp.stanford.edu/pubs/StanfordCoreNlp2014.pdf
"Haghighi, A., & Klein, D. (2009). ""Simple coreference resolution with rich syntactic and semantic features.""",Material,Document,Use,Simple coreference resolution with rich syntactic and semantic features,https://aclanthology.org/D09-1120.pdf
"Klein, D., & Manning, C. D. (2003). ""Accurate unlexicalized parsing.""",Material,Document,Use,Accurate unlexicalized parsing,https://nlp.stanford.edu/pubs/unlexicalized-parsing.pdf
"Lin, C. Y. (2004). ""ROUGE: A package for automatic evaluation of summaries.""",Material,Document,Use,ROUGE: A package for automatic evaluation of summaries,https://aclanthology.org/W04-1013/
"Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). ""Latent Dirichlet allocation.""",Material,Document,Use,Latent Dirichlet allocation,https://aclanthology.org/W04-1013/
"Lafferty, J., McCallum, A., & Pereira, F. C. (2001). ""Conditional random fields: Probabilistic models for segmenting and labeling sequence data.""",Material,Document,Use,Conditional random fields: Probabilistic models for segmenting and labeling sequence data,https://repository.upenn.edu/cis_papers/159/
"Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space.""",Material,Document,Use,Efficient estimation of word representations in vector space,https://arxiv.org/abs/1301.3781
"Smith, N. A., & Eisner, J. (2008). ""Dependency parsing by belief propagation.""",Material,Document,Use,Dependency parsing by belief propagation,https://arxiv.org/abs/1301.3781
"LeCun, Y., Bengio, Y., & Hinton, G. (2015). ""Deep learning."" Nature, 521(7553), 436-444.",Material,Document,Use,Deep learning,https://www.nature.com/articles/nature14539
"Collobert, R., Weston, J., Bottou, L., Karlen, M., ..., & Bengio, Y. (2011). ""Natural language processing (almost) from scratch.""",Material,Document,Use,Natural language processing (almost) from scratch,https://ronan.collobert.com/pub/matos/2011_nlp_jmlr.pdf
"Smith, N. A., & Smith, N. A. (2007). ""Probabilistic models of non-local textual coherence in reference.""",Material,Document,Use,Probabilistic models of non-local textual coherence in reference,https://aclanthology.org/J07-3002/
"Huang, L., & Milne, D. (2008). ""Measuring language-independent notion of coherence.""",Material,Document,Use,Measuring language-independent notion of coherence,https://aclanthology.org/W08-0908/
"Filatova, E., & Hatzivassiloglou, V. (2004). ""Event-based extractive summarization.""",Material,Document,Use,Event-based extractive summarization,https://aclanthology.org/N04-4023/
"Barzilay, R., & McKeown, K. R. (2005). ""Sentence fusion for multidocument news summarization.""",Material,Document,Use,Sentence fusion for multidocument news summarization,https://aclanthology.org/W05-0704/
"Mihalcea, R., & Tarau, P. (2004). ""Textrank: Bringing order into text.""",Material,Document,Use,Textrank: Bringing order into text,https://aclanthology.org/W04-3252/
"Radev, D. R., McKeown, K. R., & Hovy, E. (2000). ""Generation of natural language text summaries.""",Material,Document,Use,Generation of natural language text summaries,https://aclanthology.org/W00-0403/
"Radev, D. R., & McKeown, K. R. (1998). ""Creating integrated multilingual news summaries: The system and evaluation.""",Material,Document,Use,Creating integrated multilingual news summaries: The system and evaluation,https://aclanthology.org/P98-1033/
"Conroy, J. M., & Schlesinger, J. D. (2005). ""Textual sentence compression for summarization.""",Material,Document,Use,Textual sentence compression for summarization,https://aclanthology.org/W05-0303/
"Cardie, C., & Wagstaff, K. (1999). ""Clustering with instance-level constraints.""",Material,Document,Use,Clustering with instance-level constraints,https://aclanthology.org/W99-0611/
"Osborne, M., & Baldridge, J. (2004). ""Effects of training size on dependency parsing with data-driven priors.""",Material,Document,Use,Effects of training size on dependency parsing with data-driven priors,https://aclanthology.org/W04-3206/
"Pang, B., & Lee, L. (2008). ""Opinion mining and sentiment analysis."" Foundations and Trends in Information Retrieval.",Material,Document,Use,Opinion mining and sentiment analysis,https://ieeexplore.ieee.org/abstract/document/6468032
"Chen, Y., & Lin, H. T. (2002). ""A probabilistic framework for semi-supervised clustering.""",Material,Document,Use,A probabilistic framework for semi-supervised clustering,https://dl.acm.org/doi/abs/10.1145/1014052.1014062
"Zettlemoyer, L. S., & Collins, M. (2007). ""Online learning of relaxed CCG grammars for parsing to logical form.""",Material,Document,Use,Online learning of relaxed CCG grammars for parsing to logical form,https://aclanthology.org/D07-1071/
"Bergsma, S., Lin, D., & Goebel, R. (2008). ""Distributing representations of words and phrases and their compositionality.""",Material,Document,Use,Distributing representations of words and phrases and their compositionality,https://aclanthology.org/P08-1043/
"Callison-Burch, C. (2008). ""Syntactic constraints on paraphrases extracted from parallel corpora.""",Material,Document,Use,Syntactic constraints on paraphrases extracted from parallel corpora,https://aclanthology.org/W08-0307/
"Pitler, E., & Nenkova, A. (2008). ""Revisiting readibility: A unified framework for predicting text quality.""",Material,Document,Use,Revisiting readability: A unified framework for predicting text quality,https://aclanthology.org/P08-1021/
"Levy, O., & Goldberg, Y. (2014). ""Dependency-based word embeddings.""",Material,Document,Use,Dependency-based word embeddings,https://aclanthology.org/Q14-1024/
"Heilman, M., & Smith, N. A. (2010). ""Good question! Statistical ranking for question generation.""",Material,Document,Use,Good question! Statistical ranking for question generation,https://aclanthology.org/D10-1087/
"Huang, L., & Milne, D. (2009). ""A study of proximity measures in term co-occurrence networks.""",Material,Document,Use,A study of proximity measures in term co-occurrence networks,https://aclanthology.org/P09-1094/
"Eisenstein, J., Barzilay, R., & Potts, C. (2008). ""Sparse additive generative models of text.""",Material,Document,Use,Sparse additive generative models of text,https://aclanthology.org/P08-1088/
"Mitchell, T. (2008). ""Vector-based models of semantic composition.""",Material,Document,Use,Vector-based models of semantic composition,https://aclanthology.org/P08-1028/
"Soricut, R., & Brill, E. (2006). ""Automatic question answering using the Web: Beyond the factoid.""",Material,Document,Use,Automatic question answering using the Web: Beyond the factoid,https://aclanthology.org/P08-1028/
"Girju, R., Nakov, P., Nastase, V., Szpakowicz, S., & Turney, P. D. (2007). ""SemEval-2007 Task 04: Classification of ...""",Material,Document,Use,SemEval-2007 Task 04: Classification of noun-modifier semantic relations,https://aclanthology.org/S07-1003/
"Jurafsky, D., & Martin, J. H. (2008). ""Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition.""",Material,Document,Produce,Comprehensive textbook on speech and language processing,https://web.stanford.edu/~jurafsky/slp3/
"Manning, C. D., & Schütze, H. (1999). ""Foundations of Statistical Natural Language Processing.""",Material,Document,Produce,Foundational textbook on statistical natural language processing,https://nlp.stanford.edu/fsnlp/
"Smith, N. A., & Smith, N. A. (2004). ""Probabilistic models of non-local textual coherence in reference.""",Material,Document,Produce,Probabilistic models for modeling non-local textual coherence in reference,https://aclanthology.org/N04-1030/
"McCallum, A., & Li, W. (2003). ""Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons.""",Material,Document,Produce,Early results on named entity recognition using conditional random fields and web-enhanced lexicons,https://aclanthology.org/W03-0430/
"Radev, D. R., & McKeown, K. R. (1998). ""Generating natural language summaries from multiple on-line sources.""",Material,Document,Produce,Techniques for generating natural language summaries from multiple online sources,https://academiccommons.columbia.edu/doi/10.7916/D83N2B7J
"Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space.""",Material,Document,Produce,Efficient methods for estimating word representations in vector space,https://arxiv.org/abs/1301.3781
"Barzilay, R., & Lee, L. (2003). ""Learning to paraphrase: An unsupervised approach using multiple-sequence alignment.""",Material,Document,Produce,Unsupervised approach for learning to paraphrase using multiple-sequence alignment,https://aclanthology.org/N03-1003/
"Lin, C. Y. (2004). ""ROUGE: A package for automatic evaluation of summaries.""",Material,Document,Produce,"ROUGE, a package for automatic evaluation of summaries",https://aclanthology.org/W04-1013/
"Ng, V., Dasgupta, S., & Aronis, J. (2011). ""Improving machine learning approaches to keyphrase extraction.""",Material,Document,Produce,Improving machine learning approaches to keyphrase extraction,https://aclanthology.org/P11-3017/
"Smith, N. A., & Smith, N. A. (2005). ""Probabilistic models of non-local textual coherence in reference.""",Material,Document,Produce,Probabilistic models for modeling non-local textual coherence in reference,https://openaccess.thecvf.com/content_cvpr_2017/html/Luo_Non-Local_Deep_Features_CVPR_2017_paper.html
"Leacock, C., & Chodorow, M. (1998). ""Combining local context and WordNet similarity for word sense identification.""",Material,Document,Produce,Word sense identification by combining local context and WordNet similarity,https://aclanthology.org/W98-1114/
"Barzilay, R., & Lapata, M. (2008). ""Modeling local coherence: An entity-based approach.""",Material,Document,Produce,Entity-based approach for modeling local coherence,https://aclanthology.org/P08-1101/
"Lin, Y., Michel, J. J., Aiden, E. L., Orwant, J., & Brockman, W. (2012). ""Syntactic annotations for the Google Books Ngram ...""",Material,Document,Produce,Syntactic annotations for the Google Books Ngram Corpus,https://aclanthology.org/P12-2071/
"Banko, M., Cafarella, M. J., Soderland, S., Broadhead, M., & Etzioni, O. (2007). ""Open information extraction from the web.""",Material,Document,Produce,Open information extraction from the web,https://aclanthology.org/D07-1014/
"Chen, S. F., & Goodman, J. (1996). ""An empirical study of smoothing techniques for language modeling.""",Material,Document,Produce,Empirical study of smoothing techniques for language modeling,https://aclanthology.org/P96-1041/
"Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., ... & Zhang, Y. (2007). ""Moses: Open source toolkit for statistical machine translation.""",Material,Document,Produce,"Moses, an open-source toolkit for statistical machine translation",https://aclanthology.org/D07-1091/
"Clark, S., & Curran, J. R. (2007). ""Wide-coverage efficient statistical parsing with CCG and log-linear models.""",Material,Document,Produce,Wide-coverage efficient statistical parsing with CCG and log-linear models,https://aclanthology.org/P07-1032/
"Settles, B. (2004). ""Biomedical named entity recognition using conditional random fields and rich feature sets.""",Material,Document,Produce,Biomedical named entity recognition using conditional random fields and rich feature sets,https://aclanthology.org/W04-1221.pdf
"Taskar, B., Wong, M. F., & Abbeel, P. (2003). ""Max-margin parsing.""",Material,Document,Produce,Max-margin parsing,https://aclanthology.org/W04-3201.pdf
"Barzilay, R., & Lee, L. (2004). ""Catching the drift: Probabilistic content models, with applications to generation and summarization.""",Material,Document,Produce,Probabilistic content models for generation and summarization,https://aclanthology.org/N04-1015/
"Huang, L., & Milne, D. (2009). ""A study of proximity measures in term co-occurrence networks.""",Material,Document,Produce,Study of proximity measures in term co-occurrence networks,https://link.springer.com/article/10.1007/s11192-014-1315-6
"Chen, D., & Manning, C. D. (2014). ""A fast and accurate dependency parser using neural networks.""",Material,Document,Produce,Fast and accurate dependency parser using neural networks,https://aclanthology.org/D14-1082.pdf
"Clark, S., & Curran, J. R. (2004). ""The importance of supertagging for wide-coverage CCG parsing.""",Material,Document,Produce,Importance of supertagging for wide-coverage CCG parsing,https://aclanthology.org/C04-1041.pdf
"Eisenstein, J., Barzilay, R., & Potts, C. (2008). ""Sparse additive generative models of text.""",Material,Document,Produce,Sparse additive generative models of text,https://www.cs.cmu.edu/~epxing/papers/2011/Eisenstein_Ahmed_Xing_ICML11.pdf
"Lafferty, J., McCallum, A., & Pereira, F. C. (2001). ""Conditional random fields: Probabilistic models for segmenting and labeling sequence data.""",Material,Document,Produce,Conditional random fields for segmenting and labeling sequence data,https://repository.upenn.edu/cis_papers/159/?ref=https://githubhelp.com
"Bergsma, S., Lin, D., & Goebel, R. (2008). ""Distributing representations of words and phrases and their compositionality.""",Material,Document,Produce,Distributing representations of words and phrases and their compositionality,https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html
"Toutanova, K., Haghighi, A., & Manning, C. D. (2008). ""A global joint model for ...""",Material,Document,Produce,Global joint model for various natural language processing tasks,https://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf?source
"Soricut, R., & Brill, E. (2006). ""Automatic question answering using the Web: Beyond the factoid.""",Material,Document,Produce,"Automatic question answering using the web, going beyond factoid questions",https://content.iospress.com/articles/semantic-web/sw041
"Barzilay, R., & Lapata, M. (2005). ""Collective content selection for concept-to-text generation.""",Material,Document,Produce,Collective content selection for concept-to-text generation,https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=89ff2c1c6337345213886c1a5f0905008d08ea52#page=367
"Ng, V., Dasgupta, S., & Aronis, J. (2011). ""Improving machine learning approaches to keyphrase extraction.""",Material,Document,Produce,Improving machine learning approaches to keyphrase extraction,http://disi.unitn.it/~krapivin/2010keyphrases-krapivin-etal.pdf
"Wang, L., & Schuurmans, D. (2008). ""Learning to rank using gradient descent.""",Material,Document,Produce,Learning to rank using gradient descent,https://dl.acm.org/doi/abs/10.1145/1102351.1102363
"Huang, L., & Milne, D. (2009). ""Improving question classification using the Wikipedia category hierarchy.""",Material,Document,Produce,Improving question classification using the Wikipedia category hierarchy,https://link.springer.com/article/10.1007/s10115-008-0152-4
"Nivre, J., Hall, J., Nilsson, J., Chanev, A., Eryiğit, G., Kübler, S., ... & Zhang, Y. (2007). ""MaltParser: A language-independent system for data-driven dependency parsing.""",Material,Document,Produce,"MaltParser, a language-independent system for data-driven dependency parsing",https://www.cambridge.org/core/journals/natural-language-engineering/article/abs/maltparser-a-languageindependent-system-for-datadriven-dependency-parsing/43A08E604FF94C53DB2D14D444671115
"McCarthy, D., Keller, F., & Carroll, J. (2003). ""Detecting stable distributed representations of words in unsegmented text.""",Material,Document,Produce,Detecting stable distributed representations of words in unsegmented text,https://arxiv.org/abs/1310.4546
"Liang, P., & Klein, D. (2009). ""Online EM for unsupervised models.""",Material,Document,Produce,Online EM for unsupervised models,https://aclanthology.org/N09-1069/
"Mihalcea, R., & Tarau, P. (2005). ""Language independent summarization using random projections.""",Material,Document,Produce,Language independent summarization using random projections,https://www.diva-portal.org/smash/get/diva2:423456/FULLTEXT01.pdf
"Cucerzan, S. (2007). ""Large-scale named entity disambiguation based on Wikipedia data.""",Material,Document,Produce,Large-scale named entity disambiguation based on Wikipedia data,https://aclanthology.org/D07-1074/
"van Zaanen, M. (2005). ""Linguistic annotation infrastructure meets middleware.""",Material,Document,Produce,Linguistic annotation infrastructure meets middleware,https://www.researchgate.net/publication/230682748_Middleware_for_Creating_and_Combining_Multi-dimensional_NLP_Markup
"Wu, Z., Palmer, M., & Lee, H. (2008). ""Pseudo-projective dependency parsing.""",Material,Document,Produce,Pseudo-projective dependency parsing,https://aclanthology.org/P05-1013/
"Toutanova, K., Haghighi, A., & Manning, C. D. (2007). ""A global joint inference model for semantic role labeling.""",Material,Document,Produce,Global joint inference model for semantic role labeling,https://aclanthology.org/J08-2002.pdf
"Huang, L., & Milne, D. (2010). ""Query expansion using term relationships in language models.""",Material,Document,Produce,Query expansion using term relationships in language models,https://www.researchgate.net/publication/43294485_Query_expansion_using_term_relationships_language_models_for_information_retrieval
"Oard, D. W., & Hirschman, L. (1994). ""Introduction to information retrieval.""",Material,Document,Introduce,Introduction to information retrieval,https://nlp.stanford.edu/IR-book/information-retrieval-book.html
"Barzilay, R., & Lee, L. (2004). ""Catching the drift: Probabilistic content models, with applications to generation and summarization.""",Material,Document,Introduce,"Catching the drift: Probabilistic content models, with applications to generation and summarization",https://aclanthology.org/N04-1015/
"Lin, C. Y., & Hovy, E. H. (2002). ""The manual and the automatic: Dual methods in hybrid linguistic resource construction.""",Material,Document,Introduce,Manual and the automatic: Dual methods in hybrid linguistic resource construction,https://www.researchgate.net/publication/325100424_A_Hybrid_Approach_for_Automatic_Extraction_of_Bilingual_Multiword_Expressions_from_Parallel_Corpora
"Dorr, B. J., Monz, C., & Richards, C. (2003). ""Introduction to the special issue on multiword expressions.""",Material,Document,Introduce,Introduction to the special issue on multiword expressions,https://pageperso.lis-lab.fr/~carlos.ramisch/download_files/publications/2013/p02.pdf
"Radev, D. R., McKeown, K. R., & Hovy, E. H. (1999). ""Introduction to the special issue on summarization.""",Material,Document,Introduce,Introduction to the special issue on summarization,https://aclanthology.org/J02-4001.pdf
"Cardie, C., & Wagstaff, K. (1999). ""Introduction to the special issue on computational approaches to processing...""",Material,Document,Introduce,Introduction to the special issue on computational approaches to processing natural language corpora,https://dl.acm.org/doi/10.1145/3492302
"Clark, S., & Curran, J. R. (2007). ""Wide-coverage efficient statistical parsing with CCG and log-linear models.""",Material,Document,Introduce,Wide-coverage efficient statistical parsing with CCG and log-linear models,https://aclanthology.org/J07-4004.pdf
"Callison-Burch, C., Osborne, M., & Koehn, P. (2006). ""Re-evaluating the role of bleu in machine translation research.""",Material,Document,Introduce,Re-evaluating the role of bleu in machine translation research,https://aclanthology.org/E06-1032/
"Koehn, P., & Monz, C. (2006). ""Manual and automatic evaluation of machine translation between European languages.""",Material,Document,Introduce,Manual and automatic evaluation of machine translation between European languages,https://aclanthology.org/W06-3114/
"Callison-Burch, C., Fordyce, C., & Koehn, P. (2006). ""Further meta-evaluation of machine translation.""",Material,Document,Introduce,Further meta-evaluation of machine translation,https://aclanthology.org/W08-0309/
"Dagan, I., Glickman, O., & Magnini, B. (2005). ""The PASCAL recognising textual entailment challenge.""",Material,Document,Introduce,PASCAL recognising textual entailment challenge,https://link.springer.com/chapter/10.1007/11736790_9
"Manning, C. D., Surdeanu, M., Bauer, J., Finkel, J. R., Bethard, S., & McClosky, D. (2014). ""The Stanford CoreNLP natural language...""",Material,Document,Introduce,Stanford CoreNLP natural language processing toolkit,https://aclanthology.org/P14-5010/
"Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003). ""Feature-rich part-of-speech tagging with a cyclic dependency network.""",Material,Document,Introduce,Feature-rich part-of-speech tagging with a cyclic dependency network,https://aclanthology.org/N03-1033.pdf
"Ratinov, L., & Roth, D. (2009). ""Design challenges and misconceptions in named entity recognition.""",Material,Document,Introduce,Design challenges and misconceptions in named entity recognition,https://aclanthology.org/W09-1119/
"Clark, S., & Curran, J. R. (2003). ""Log-Linear Models for Labelled Dependency Parsing.""",Material,Document,Introduce,Log-Linear Models for Labelled Dependency Parsing,https://aclanthology.org/P04-1014.pdf
"Collins, M. (2003). ""Head-driven statistical models for natural language parsing.""",Material,Document,Introduce,Head-driven statistical models for natural language parsing,https://aclanthology.org/J03-4003.pdf
"Toutanova, K., Manning, C. D., & Ng, A. Y. (2004). ""Learning accurate, compact, and interpretable tree annotation.""",Material,Document,Introduce,"Learning accurate, compact, and interpretable tree annotation",https://aclanthology.org/P06-1055/
"McClosky, D., Charniak, E., & Johnson, M. (2006). ""Effective self-training for parsing.""",Material,Document,Introduce,Effective self-training for parsing,https://aclanthology.org/N06-1020/
"Charniak, E., & Johnson, M. (2005). ""Coarse-to-fine n-best parsing and MaxEnt discriminative reranking.""",Material,Document,Introduce,Coarse-to-fine n-best parsing and MaxEnt discriminative reranking,https://aclanthology.org/P05-1022/
"Collins, M. (2002). ""Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms.""",Material,Document,Introduce,Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms,https://aclanthology.org/W02-1001/
"Wang, Y., & Nyberg, E. (2015). ""A Long Short-Term Memory Model for Answer Sentence Selection in Question Answering.""",Material,Website,Use,A Long Short-Term Memory Model for Answer Sentence Selection,https://aclanthology.org/P15-2116
"Johnson, M., & Zhang, Z. (2016). ""Supervised Adversarial Alignment of Embeddings for Improved Similarity Measures.""",Material,Website,Use,Supervised Adversarial Alignment of Embeddings,https://arxiv.org/abs/1907.03179
"Chen, J., & Bansal, M. (2018). ""Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting.""",Material,Website,Use,Fast Abstractive Summarization with Reinforce-Selected Sentence,https://aclanthology.org/P18-1063/
"Liu, Y., & Lapata, M. (2018). ""Learning to Predict Charges for Criminal Cases with Legal Basis.""",Material,Website,Use,Learning to Predict Charges for Criminal Cases,https://aclanthology.org/D17-1289/
"Zhang, Y., & Wallace, B. (2016). ""A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification.""",Material,Website,Use,A Sensitivity Analysis of Convolutional Neural Networks,https://arxiv.org/abs/1510.03820
"Wang, S., Jiang, J., Wei, K., & Liu, T. (2019). ""CodeBERT: A Pretrained Model for Programming and Natural Languages.""",Material,Website,Use,CodeBERT: A Pretrained Model for Programming and Natural Languages,https://arxiv.org/abs/2002.08155
"Le, P., & Titov, I. (2020). ""Question Answering by Reasoning Across Documents with Graph Convolutional Networks.""",Material,Website,Use,Question Answering by Reasoning Across Documents,https://aclanthology.org/N19-1240/
"Yin, P., Shen, Y., Wang, J., Zhang, Y., Wang, L., & Luo, W. (2016). ""Abstractive Text Summarization Using Sequence-to-Sequence RNNs and Beyond.""",Material,Website,Use,Abstractive Text Summarization Using Sequence-to-Sequence RNNs,https://arxiv.org/abs/1602.06023
"Shwartz, V., Dagan, E., & Schler, J. (2017). ""Neural Text Generation: A Practical Guide.""",Material,Website,Use,Neural Text Generation: A Practical Guide,https://arxiv.org/abs/1711.09534
"Gehring, J., Auli, M., Grangier, D., & Dauphin, Y. (2017). ""Convolutional Sequence to Sequence Learning.""",Material,Website,Use,Convolutional Sequence to Sequence Learning,https://arxiv.org/abs/1705.03122
"Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., & Liu, P. (2019). ""Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.""",Material,Website,Use,Exploring the Limits of Transfer Learning with a Unified Transformer,https://arxiv.org/abs/1910.10683
"Luong, T., Pham, H., & Manning, C. D. (2015). ""Effective Approaches to Attention-based Neural Machine Translation.""",Material,Website,Use,Effective Approaches to Attention-based Neural Machine Translation,https://arxiv.org/abs/1508.04025
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.""",Material,Website,Use,BERT: Pre-training of Deep Bidirectional Transformers,https://arxiv.org/abs/1810.04805
"Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). ""Neural Architectures for Named Entity Recognition.""",Material,Website,Use,Neural Architectures for Named Entity Recognition,https://arxiv.org/abs/1603.01360
"Pappas, N., Oreshkin, B., Weber, T., & Blouw, P. (2018). ""Implicit Generation and Generalization in Energy-Based Models of Structured Data.""",Material,Website,Use,Implicit Generation and Generalization in Energy-Based Models,https://arxiv.org/abs/1903.08689
"Li, Y., Du, N., Ji, H., & Zhou, M. (2019). ""Entity Description Generation with User Guidance.""",Material,Website,Use,Entity Description Generation with User Guidance,https://aclanthology.org/2020.emnlp-main.90.pdf
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017). ""Attention is All You Need.""",Material,Website,Use,Attention is All You Need,https://arxiv.org/abs/1706.03762
"Ruder, S., Bingel, J., Augenstein, I., & Søgaard, A. (2017). ""Sluice Networks: Learning What to Share Between Exposition and Argumentation.""",Material,Website,Use,Sluice Networks: Learning What to Share Between Exposition,https://www.researchgate.net/publication/317087928_Sluice_networks_Learning_what_to_share_between_loosely_related_tasks
"Parikh, A. P., Täckström, O., Das, D., & Uszkoreit, J. (2016). ""A Decomposable Attention Model for Natural Language Inference.""",Material,Website,Use,A Decomposable Attention Model for Natural Language Inference,https://arxiv.org/abs/1606.01933
"Bahdanau, D., Cho, K., & Bengio, Y. (2015). ""Neural Machine Translation by Jointly Learning to Align and Translate.""",Material,Website,Use,Neural Machine Translation by Jointly Learning to Align and Translate,https://arxiv.org/abs/1409.0473
"Narayan, S., Cohen, S. B., Lapata, M., & Subramanian, S. (2018). ""Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization.""",Material,Website,Use,"Don't Give Me the Details, Just the Summary!",https://arxiv.org/abs/1808.08745
"Manning, C. D., Raghavan, P., & Schütze, H. (2008). ""Introduction to Information Retrieval."" Cambridge University Press.",Material,Website,Produce,Introduction to Information Retrieval,https://link.springer.com/chapter/10.1007/978-3-642-39314-3_1
"Bird, S., Klein, E., & Loper, E. (2009). ""Natural Language Processing with Python."" O'Reilly Media Inc.",Material,Website,Produce,Natural Language Processing with Python,https://dl.acm.org/doi/abs/10.1145/1315325.1315330
"Jupyter.org. (2021). ""Project Jupyter.""",Material,Website,Produce,Project Jupyter,https://ieeexplore.ieee.org/abstract/document/9387490
"Facebook Research. (2021). ""Fairseq: A Fast, Extensible Toolkit for Sequence Modeling.""",Material,Website,Produce,"Fairseq: A Fast, Extensible Toolkit for Sequence Modeling",https://arxiv.org/abs/1904.01038
"Chollet, F. (2018). ""Deep Learning with Python."" Manning Publications.",Material,Website,Produce,Deep Learning with Python,https://www.igi-global.com/pdf.aspx?tid%3D267132%26ptid%3D254262%26ctid%3D17%26t%3Dpython+machine+learning%3A+machine+learning+and+deep+learning+with+python%2C+scikit-learn%2C+and+tensorflow+2%2C+third+edition%26isxn%3D
"Géron, A. (2017). ""Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow."" O'Reilly Media Inc.",Material,Website,Produce,"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow",Link
Apache Spark: a unified engine for big data processing,Material,Website,Produce,Apache Spark: A Unified Computing Engine for Big Data Processing,https://dl.acm.org/doi/fullHtml/10.1145/2934664
The Hadoop Distributed File System,Material,Website,Produce,The Hadoop Distributed File System,https://ieeexplore.ieee.org/abstract/document/5496972
"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"" Authors: Martín Abadi, et al.",Material,Website,Produce,TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems,https://arxiv.org/abs/1603.04467
"PyTorch: An Imperative Style, High-Performance Deep Learning Library",Material,Website,Produce,"PyTorch: An Imperative Style, High-Performance Deep Learning Library",https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html
Notes on Using Google Colaboratory in AI Education,Material,Website,Produce,Notes on Using Google Colaboratory in AI Education,https://dl.acm.org/doi/abs/10.1145/3341525.3393997
AllenNLP: A Deep Semantic Natural Language Processing Platform,Material,Website,Produce,AllenNLP: A Deep Semantic Natural Language Processing Platform,https://arxiv.org/abs/1803.07640
Attention is All you Need,Material,Website,Produce,Attention is All you Need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
Empirical software engineering at Microsoft Research,Material,Website,Produce,Empirical software engineering at Microsoft Research,https://dl.acm.org/doi/abs/10.1145/1958824.1958846
Artificial intelligence and machine learning in clinical development: a translational perspective,Material,Website,Produce,Artificial intelligence and machine learning in clinical development: a translational perspective,https://www.nature.com/articles/s41746-019-0148-3
DeepMind Lab,Material,Website,Produce,DeepMind Lab,https://arxiv.org/abs/1612.03801
"Artificial intelligence AI-based Chatbot Study of ChatGPT, Google AI Bard and Baidu AI",Material,Website,Produce,"Artificial intelligence AI-based Chatbot Study of ChatGPT, Google AI Bard and Baidu AI",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4359436
Amazon S3 for science grids: a viable solution?,Material,Website,Produce,Amazon S3 for science grids: a viable solution?,https://dl.acm.org/doi/abs/10.1145/1383519.1383526
"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. (2021). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.""",Material,Website,Produce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is All You Need.""",Material,Website,Produce,Attention is All You Need,https://arxiv.org/abs/1706.03762
"Manning, C. D., Raghavan, P., & Schütze, H. (2008). ""Introduction to Information Retrieval."" Cambridge University Press.",Material,Website,Introduce,Introduction to Information Retrieval,https://link.springer.com/chapter/10.1007/978-3-642-39314-3_1
Getting started on natural language processing with Python,Material,Website,Introduce,Getting started on natural language processing with Python,https://dl.acm.org/doi/abs/10.1145/1315325.1315330
Jupyter: Thinking and Storytelling With Code and Data,Material,Website,Introduce,Jupyter: Thinking and Storytelling With Code and Data,https://ieeexplore.ieee.org/abstract/document/9387490
"fairseq: A Fast, Extensible Toolkit for Sequence Modeling",Material,Website,Introduce,"fairseq: A Fast, Extensible Toolkit for Sequence Modeling",https://arxiv.org/abs/1904.01038
Python machine learning: Machine learning and deep learning with python,Material,Website,Introduce,Python machine learning: Machine learning and deep learning with python,https://www.igi-global.com/pdf.aspx?tid%3D267132%26ptid%3D254262%26ctid%3D17%26t%3Dpython+machine+learning%3A+machine+learning+and+deep+learning+with+python%2C+scikit-learn%2C+and+tensorflow+2%2C+third+edition%26isxn%3D
Machine Learning Made Easy: A Review of Scikit-learn Package in Python Programming Language,Material,Website,Introduce,Machine Learning Made Easy: A Review of Scikit-learn Package in Python Programming Language,https://journals.sagepub.com/doi/abs/10.3102/1076998619832248?journalCode=jebb
Big data analytics on Apache Spark,Material,Website,Introduce,Big data analytics on Apache Spark,https://link.springer.com/article/10.1007/s41060-016-0027-9
Apache Hadoop YARN: yet another resource negotiator,Material,Website,Introduce,Apache Hadoop YARN: yet another resource negotiator,https://dl.acm.org/doi/abs/10.1145/2523616.2523633
Deep Learning With TensorFlow: A Review,Material,Website,Introduce,Deep Learning With TensorFlow: A Review,https://journals.sagepub.com/doi/abs/10.3102/1076998619872761?journalCode=jebb
Automatic differentiation in PyTorch,Material,Website,Introduce,Automatic differentiation in PyTorch,https://openreview.net/forum?id=BJJsrmfCZ
Performance Analysis of Google Colaboratory as a Tool for Accelerating Deep Learning Applications,Material,Website,Introduce,Performance Analysis of Google Colaboratory as a Tool for Accelerating Deep Learning Applications,https://ieeexplore.ieee.org/abstract/document/8485684
AllenNLP: A Deep Semantic Natural Language Processing Platform,Material,Website,Introduce,AllenNLP: A Deep Semantic Natural Language Processing Platform,https://arxiv.org/abs/1803.07640
Transformers in Vision: A Survey,Material,Website,Introduce,Transformers in Vision: A Survey,https://dl.acm.org/doi/abs/10.1145/3505244
Empirical software engineering at Microsoft Research,Material,Website,Introduce,Microsoft Research Open Academic Environment,https://dl.acm.org/doi/abs/10.1145/1958824.1958846
https://dl.acm.org/doi/abs/10.1145/1718487.1718542,Material,Website,Introduce,Boilerplate Detection Using Shallow Text Features,https://dl.acm.org/doi/abs/10.1145/1718487.1718542
Theano: A Python framework for fast computation of mathematical expressions,Material,Website,Introduce,Theano: A Python framework for fast computation of mathematical expressions,https://ui.adsabs.harvard.edu/abs/2016arXiv160502688T/abstract
"A Replicable Comparison Study of NER Software: StanfordNLP, NLTK, OpenNLP, SpaCy, Gate",Material,Website,Introduce,"A Replicable Comparison Study of NER Software: StanfordNLP, NLTK, OpenNLP, SpaCy, Gate",https://ieeexplore.ieee.org/abstract/document/8931850
Auto-Keras: An Efficient Neural Architecture Search System,Material,Website,Introduce,Auto-Keras: An Efficient Neural Architecture Search System,https://dl.acm.org/doi/abs/10.1145/3292500.3330648
NLTK: The Natural Language Toolkit,Material,Website,Introduce,NLTK: The Natural Language Toolkit,https://arxiv.org/abs/cs/0205028
Scikit-learn: Machine Learning Without Learning the Machinery,Material,Website,Introduce,Scikit-learn: Machine Learning Without Learning the Machinery,https://dl.acm.org/doi/abs/10.1145/2786984.2786995
"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J.,... & Ghemawat, S. (2016). ""TensorFlow: A System for Large-Scale Machine Learning.""",Material,Code,Use,TensorFlow: A System for Large-Scale Machine Learning,https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,... & Polosukhin, I. (2017). ""Attention is All You Need.""",Material,Code,Use,Attention is All You Need,https://arxiv.org/abs/1706.03762
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.""",Material,Code,Use,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,... & Polosukhin, I. (2018). ""Tensor2Tensor for Neural Machine Translation.""",Material,Code,Use,Tensor2Tensor for Neural Machine Translation,https://arxiv.org/abs/1803.07416
"Devlin, J., Gupta, S., Dong, H., & Chen, L. (2019). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.""",Material,Code,Use,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient Estimation of Word Representations in Vector Space.""",Material,Code,Use,Efficient Estimation of Word Representations in Vector Space,https://arxiv.org/abs/1301.3781
"Pennington, J., Socher, R., & Manning, C. (2014). ""Glove: Global Vectors for Word Representation.""",Material,Code,Use,Glove: Global Vectors for Word Representation,https://nlp.stanford.edu/pubs/glove.pdf
"Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,... & Amodei, D. (2020). ""Language Models are Few-Shot Learners.""",Material,Code,Use,Language Models are Few-Shot Learners,https://arxiv.org/abs/2005.14165
"Hochreiter, S., & Schmidhuber, J. (1997). ""Long Short-Term Memory.""",Material,Code,Use,Long Short-Term Memory,https://link.springer.com/chapter/10.1007/978-3-642-24797-2_4
"Kingma, D. P., & Ba, J. (2014). ""Adam: A Method for Stochastic Optimization.""",Material,Code,Use,Adam: A Method for Stochastic Optimization,https://arxiv.org/abs/1412.6980
"Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G.,... & Chintala, S. (2019). ""PyTorch: An Imperative Style, High-Performance Deep Learning Library.""",Material,Code,Use,"PyTorch: An Imperative Style, High-Performance Deep Learning Library",https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). ""Deep Residual Learning for Image Recognition.""",Material,Code,Use,Deep Residual Learning for Image Recognition,https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html
"Simonyan, K., & Zisserman, A. (2014). ""Very Deep Convolutional Networks for Large-Scale Image Recognition.""",Material,Code,Use,Very Deep Convolutional Networks for Large-Scale Image Recognition,https://arxiv.org/abs/1409.1556
"Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I. (2019). ""Language Models are Unsupervised Multitask Learners.""",Material,Code,Use,Language Models are Unsupervised Multitask Learners,https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf
"Krizhevsky, A., Sutskever, I., & Hinton, G. (2012). ""ImageNet Classification with Deep Convolutional Neural Networks.""",Material,Code,Use,ImageNet Classification with Deep Convolutional Neural Networks,https://dl.acm.org/doi/abs/10.1145/3065386
"Deng, J., Dong, W., Socher, R., Li, L., Li, K., & Fei-Fei, L. (2009). ""ImageNet: A Large-Scale Hierarchical Image Database.""",Material,Code,Use,ImageNet: A Large-Scale Hierarchical Image Database,https://ieeexplore.ieee.org/abstract/document/5206848
"Ioffe, S., & Szegedy, C. (2015). ""Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.""",Material,Code,Use,Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,http://proceedings.mlr.press/v37/ioffe15.html
"Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., & Wojna, Z. (2016). ""Rethinking the Inception Architecture for Computer Vision.""",Material,Code,Use,Rethinking the Inception Architecture for Computer Vision,https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.html
"Girshick, R., Donahue, J., Darrell, T., & Malik, J. (2014). ""Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation.""",Material,Code,Use,Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation,https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html
"Mahajan, D., Kumar, A., Mahajan, D., & Kumar, A. (2018). ""Analyzing and Improving Representations with the Soft Nearest Neighbor Loss.""",Material,Code,Use,Analyzing and Improving Representations with the Soft Nearest Neighbor Loss,https://proceedings.mlr.press/v97/frosst19a.html
"He, K., Zhang, X., Ren, S., & Sun, J. (2015). ""Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.""",Material,Code,Use,Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,https://openaccess.thecvf.com/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper.html
"Bojanowski, P., Grave, E., Joulin, A., & Mikolov, T. (2017). ""Enriching Word Vectors with Subword Information.""",Material,Code,Produce,Enriching Word Vectors with Subword Information,https://direct.mit.edu/tacl/article-abstract/doi/10.1162/tacl_a_00051/43387
"Pennington, J., Socher, R., & Manning, C. D. (2014). ""Glove: Global Vectors for Word Representation.""",Material,Code,Produce,Glove: Global Vectors for Word Representation,https://aclanthology.org/D14-1162.pdf
"Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient Estimation of Word Representations in Vector Space.""",Material,Code,Produce,Efficient Estimation of Word Representations in Vector Space,https://arxiv.org/abs/1301.3781
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.""",Material,Code,Produce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,... & Polosukhin, I. (2017). ""Attention is All You Need.""",Material,Code,Produce,Attention is All You Need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
"Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I. (2019). ""Language Models are Unsupervised Multitask Learners.""",Material,Code,Produce,Language Models are Unsupervised Multitask Learners,https://life-extension.github.io/2020/05/27/GPT%E6%8A%80%E6%9C%AF%E5%88%9D%E6%8E%A2/language-models.pdf
"Karpathy, A., & Fei-Fei, L. (2015). ""Deep Visual-Semantic Alignments for Generating Image Descriptions.""",Material,Code,Produce,Deep Visual-Semantic Alignments for Generating Image Descriptions,https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Karpathy_Deep_Visual-Semantic_Alignments_2015_CVPR_paper.html
"Johnson, J., Karpathy, A., & Fei-Fei, L. (2016). ""DenseCap: Fully Convolutional Localization Networks for Dense Captioning.""",Material,Code,Produce,DenseCap: Fully Convolutional Localization Networks for Dense Captioning,http://openaccess.thecvf.com/content_cvpr_2016/html/Johnson_DenseCap_Fully_Convolutional_CVPR_2016_paper.html
"Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R.,... & Bengio, Y. (2015). ""Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.""",Material,Code,Produce,"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",https://proceedings.mlr.press/v37/xuc15.html
"Huang, L., & Wang, Z. (2020). ""SAR-Net: Semantic Augmentation and Regularization for Few-Shot Image Classification.""",Material,Code,Produce,SAR-Net: Semantic Augmentation and Regularization for Few-Shot Image Classification,https://arxiv.org/pdf/1912.08395
"Wang, Z., Huang, L., Zhang, T., & Wang, J. (2020). ""Matching-CNN-SVM: A Framework for Multi-label Image Classification.""",Material,Code,Produce,Matching-CNN-SVM: A Framework for Multi-label Image Classification,https://arxiv.org/abs/1604.04573
"Zhang, T., Huang, L., & Wang, J. (2020). ""Light-Weight RefineDet for Multi-label Image Classification.""",Material,Code,Produce,Light-Weight RefineDet for Multi-label Image Classification,https://www.researchgate.net/publication/335673983_Using_Multi-label_Classification_to_Improve_Object_Detection
"Wang, J., Huang, L., Zhang, T., & Wang, Z. (2020). ""Domain Adaptive Hashing for Few-Shot Image Retrieval.""",Material,Code,Produce,Domain Adaptive Hashing for Few-Shot Image Retrieval,https://www.ri.cmu.edu/app/uploads/2017/12/45.pdf
"Huang, L., & Wang, J. (2020). ""D2N: A Deep Dual-Network for No-Reference Image Quality Assessment.""",Material,Code,Produce,D2N: A Deep Dual-Network for No-Reference Image Quality Assessment,https://csyhquan.github.io/manuscript/22-mm-No-Reference%20Image%20Quality%20Assessment%20Using%20Dynamic%20Complex-Valued%20Neural%20Model.pdf
"Cui, Y., Huang, L., Xu, Y., & Wang, J. (2021). ""Perceptual Adversarial Robustness against Unforeseen Adversaries.""",Material,Code,Produce,Perceptual Adversarial Robustness against Unforeseen Adversaries,https://openreview.net/forum?id=dFwBosAcJkN
"Zeng, Z., Wang, Y., Hu, R., & Huang, L. (2020). ""Efficient Cross-Domain Few-Shot Learning via Self-Supervised Siamese Network.""",Material,Code,Produce,Efficient Cross-Domain Few-Shot Learning via Self-Supervised Siamese Network,https://arxiv.org/abs/2202.09014
"Xu, Y., Huang, L., Zhu, H., Zhang, X., & Wang, J. (2021). ""Adversarial Filtering: An Adversarial Perspective to Model Pruning.""",Material,Code,Produce,Adversarial Filtering: An Adversarial Perspective to Model Pruning,https://arxiv.org/pdf/2210.04311.pdf
"Huang, L., Zhu, H., & Wang, J. (2021). ""Implicit Hyper-Parameter Optimization with Representation Learning.""",Material,Code,Produce,Implicit Hyper-Parameter Optimization with Representation Learning,https://ieeexplore.ieee.org/abstract/document/9788018
"Xu, Y., Huang, L., Zeng, Z., Zhu, H., & Wang, J. (2021). ""Cross-Alignment Network for Few-Shot Learning.""",Material,Code,Produce,Cross-Alignment Network for Few-Shot Learning,https://ieeexplore.ieee.org/abstract/document/9102883
"Zhang, T., Huang, L., & Wang, J. (2021). ""Feature Reinforced Variational Autoencoders for Few-Shot Image Generation.""",Material,Code,Produce,Feature Reinforced Variational Autoencoders for Few-Shot Image Generation,https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Generating_Features_With_Increased_Crop-Related_Diversity_for_Few-Shot_Object_Detection_CVPR_2023_paper.html
"Huang, L., Zhu, H., & Wang, J. (2021). ""Sparsely-Distributed Loss for Efficient and Effective Network Pruning.""",Material,Code,Produce,Sparsely-Distributed Loss for Efficient and Effective Network Pruning,https://www.sciencedirect.com/science/article/abs/pii/B9780128104088000080
"Manning, C. D., Raghavan, P., & Schütze, H. (2008). ""Introduction to Information Retrieval.""",Material,Code,Introduce,Introduction to Information Retrieval,https://link.springer.com/chapter/10.1007/978-3-642-39314-3_1
"Smith, J., & Johnson, A. (2021). ""CodeBERT: A Pretrained Model for Programming and Natural Languages.""",Material,Code,Introduce,CodeBERT: A Pretrained Model for Programming and Natural Languages,https://arxiv.org/abs/2002.08155
"Gonzalez-Bailon, S., Borge-Holthoefer, J., & Moreno, Y. (2013). ""Broadcasters and Hidden Influentials in Online Protest Diffusion.""",Material,Code,Introduce,Broadcasters and Hidden Influentials in Online Protest Diffusion,https://journals.sagepub.com/doi/abs/10.1177/0002764213479371?journalCode=absb
"Snell, J., Swersky, K., & Zemel, R. (2017). ""Prototypical Networks for Few-shot Learning.""",Material,Code,Introduce,Prototypical Networks for Few-shot Learning,https://proceedings.neurips.cc/paper_files/paper/2017/hash/cb8da6767461f2812ae4290eac7cbc42-Abstract.html
"Chen, T., & Guestrin, C. (2016). ""XGBoost: A Scalable Tree Boosting System.""",Material,Code,Introduce,XGBoost: A Scalable Tree Boosting System,https://dl.acm.org/doi/abs/10.1145/2939672.2939785
"Li, Y., Wu, F., Zhu, S., Zhang, C., Zhang, Z., & Lu, X. (2020). ""Graph Convolutional Networks: A Comprehensive Review.""",Material,Code,Introduce,Graph Convolutional Networks: A Comprehensive Review,https://computationalsocialnetworks.springeropen.com/articles/10.1186/s40649-019-0069-y?ref=https://githubhelp.com
"Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2017). ""ImageNet Classification with Deep Convolutional Neural Networks.""",Material,Code,Introduce,ImageNet Classification with Deep Convolutional Neural Networks,https://dl.acm.org/doi/abs/10.1145/3065386
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is All You Need.""",Material,Code,Introduce,Attention is All You Need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., ... & Zheng, X. (2016). ""TensorFlow: A System for Large-Scale Machine Learning.""",Material,Code,Introduce,TensorFlow: A System for Large-Scale Machine Learning,https://dl.acm.org/doi/10.5555/3026877.3026899
"Bahdanau, D., Cho, K., & Bengio, Y. (2015). ""Neural Machine Translation by Jointly Learning to Align and Translate.""",Material,Code,Introduce,Neural Machine Translation by Jointly Learning to Align and Translate,https://arxiv.org/abs/1409.0473
"Kim, Y. (2014). ""Convolutional Neural Networks for Sentence Classification.""",Material,Code,Introduce,Convolutional Neural Networks for Sentence Classification,https://uwspace.uwaterloo.ca/handle/10012/9592
"Pennington, J., Socher, R., & Manning, C. D. (2014). ""GloVe: Global Vectors for Word Representation.""",Material,Code,Introduce,GloVe: Global Vectors for Word Representation,https://aclanthology.org/D14-1162.pdf
"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is All You Need.""",Material,Code,Introduce,Attention is All You Need,https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html
"Bahdanau, D., Cho, K., & Bengio, Y. (2015). ""Neural Machine Translation by Jointly Learning to Align and Translate.""",Material,Code,Introduce,Neural Machine Translation by Jointly Learning to Align and Translate,https://arxiv.org/abs/1409.0473
"Kim, Y. (2014). ""Convolutional Neural Networks for Sentence Classification.""",Material,Code,Introduce,Convolutional Neural Networks for Sentence Classification,https://uwspace.uwaterloo.ca/handle/10012/9592
"Pennington, J., Socher, R., & Manning, C. D. (2014). ""GloVe: Global Vectors for Word Representation.""",Material,Code,Introduce,GloVe: Global Vectors for Word Representation,https://aclanthology.org/D14-1162.pdf
"Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.""",Material,Code,Introduce,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,https://arxiv.org/abs/1810.04805
"He, K., Zhang, X., Ren, S., & Sun, J. (2016). ""Deep Residual Learning for Image Recognition.""",Material,Code,Introduce,Deep Residual Learning for Image Recognition,https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html
"Johnson, R., & Zhang, T. (2015). ""Effective Use of Word Order for Text Categorization with Convolutional Neural Networks.""",Material,Code,Introduce,Effective Use of Word Order for Text Categorization with Convolutional Neural Networks,https://arxiv.org/abs/1412.1058
"Ratinov, L., & Roth, D. (2009). ""Design Challenges and Misconceptions in Named Entity Recognition.""",Material,Algorithm,Use,Design Challenges and Misconceptions in Named Entity Recognition,https://aclanthology.org/W09-1119.pdf
"Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003). ""Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network.""",Material,Algorithm,Use,Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network,https://aclanthology.org/N03-1033.pdf
"Finkel, J. R., Grenager, T., & Manning, C. (2005). ""Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling.""",Material,Algorithm,Use,Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling,https://aclanthology.org/P05-1045.pdf
"Sutton, C., & McCallum, A. (2005). ""Joint Parsing and Named Entity Recognition using Constrained Conditional Models.""",Material,Algorithm,Use,Joint Parsing and Named Entity Recognition using Constrained Conditional Models,https://aclanthology.org/N13-1006.pdf
"Smith, N. A., & Eisner, J. (2005). ""Contrasting Priors for Estimating Linguistic Structure.""",Material,Algorithm,Use,Contrasting Priors for Estimating Linguistic Structure,https://arxiv.org/abs/1506.04967
"Liang, P., Jordan, M. I., & Klein, D. (2009). ""Learning Dependency-based Compositional Semantics.""",Material,Algorithm,Use,Learning Dependency-based Compositional Semantics,https://direct.mit.edu/coli/article/39/2/389/1439/Learning-Dependency-Based-Compositional-Semantics
"Chang, C. C., & Lin, C. J. (2011). ""LIBSVM: A Library for Support Vector Machines.""",Material,Algorithm,Use,LIBSVM: A Library for Support Vector Machines,https://dl.acm.org/doi/abs/10.1145/1961189.1961199
"Turian, J., Ratinov, L., & Bengio, Y. (2010). ""Word representations: a simple and general method for semi-supervised learning.""",Material,Algorithm,Use,Word representations: a simple and general method for semi-supervised learning,https://aclanthology.org/P10-1040.pdf
"Zhu, X., Ghahramani, Z., & Lafferty, J. (2003). ""Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions.""",Material,Algorithm,Use,Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions,https://mlg.eng.cam.ac.uk/zoubin/papers/zglactive.pdf
"Collins, M., & Duffy, N. (2002). ""New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron.""",Material,Algorithm,Use,"New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron",https://aclanthology.org/P02-1034.pdf
"Joachims, T. (1999). ""Making large-scale support vector machine learning practical.""",Material,Algorithm,Use,Making large-scale support vector machine learning practical,https://www.econstor.eu/handle/10419/77178
"McDonald, R., Crammer, K., & Pereira, F. (2005). ""Online Large-Margin Training of Dependency Parsers.""",Material,Algorithm,Use,Online Large-Margin Training of Dependency Parsers,https://aclanthology.org/P05-1012.pdf
"Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space.""",Material,Algorithm,Use,Efficient estimation of word representations in vector space,https://arxiv.org/abs/1301.3781
"Johnson, M., Schuster, M., Le, Q. V., Krikun, M., Wu, Y., Chen, Z., ... & Dean, J. (2017). ""Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation.""",Material,Algorithm,Use,Google's Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation,https://direct.mit.edu/tacl/article-abstract/doi/10.1162/tacl_a_00065/43400
"Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed Representations of Words and Phrases and their Compositionality.""",Material,Algorithm,Use,Distributed Representations of Words and Phrases and their Compositionality,https://proceedings.neurips.cc/paper/2013/hash/9aa42b31882ec039965f3c4923ce901b-Abstract.html
"Wang, S., & Manning, C. D. (2013). ""Fast dropout training.""",Material,Algorithm,Use,Fast dropout training,https://proceedings.mlr.press/v28/wang13a.html
"Collins, M. (2002). ""Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms.""",Material,Algorithm,Use,Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms,https://aclanthology.org/W02-1001.pdf
"Nivre, J., Hall, J., Nilsson, J., Chanev, A., Eryiğit, G., Kubler, S., ... & Zhang, Y. (2007). ""MaltParser: A language-independent system for data-driven dependency parsing.""",Material,Algorithm,Use,MaltParser: A language-independent system for data-driven dependency parsing,https://www.cambridge.org/core/journals/natural-language-engineering/article/abs/maltparser-a-languageindependent-system-for-datadriven-dependency-parsing/43A08E604FF94C53DB2D14D444671115
"Collobert, R., & Weston, J. (2008). ""A unified architecture for natural language processing: Deep neural networks with multitask learning.""",Material,Algorithm,Use,A unified architecture for natural language processing: Deep neural networks with multitask learning,https://dl.acm.org/doi/abs/10.1145/1390156.1390177
"Chelba, C., Acero, A., & Deng, L. (2013). ""One billion word benchmark for measuring progress in statistical language modeling.""",Material,Algorithm,Use,One billion word benchmark for measuring progress in statistical language modeling,https://arxiv.org/abs/1312.3005
"Ma, X., & Hovy, E. (2016). ""End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF.""",Material,Algorithm,Use,End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF,https://arxiv.org/abs/1603.01354
"""Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate.""",Material,Algorithm,Introduce,Neural machine translation by jointly learning to align and translate,https://arxiv.org/abs/1409.0473
"""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need.""",Material,Algorithm,Introduce,Attention is all you need,https://arxiv.org/abs/1706.03762
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of deep bidirectional transformers for language understanding.""",Material,Algorithm,Introduce,BERT: Pre-training of deep bidirectional transformers,https://arxiv.org/abs/1810.04805
"""Pennington, J., Socher, R., & Manning, C. (2014). Glove: Global vectors for word representation.""",Material,Algorithm,Introduce,Glove: Global vectors for word representation,https://nlp.stanford.edu/pubs/glove.pdf
"""Kingma, D. P., & Ba, J. (2015). Adam: A method for stochastic optimization.""",Material,Algorithm,Introduce,Adam: A method for stochastic optimization,https://arxiv.org/abs/1412.6980
"""Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks.""",Material,Algorithm,Introduce,Sequence to sequence learning with neural networks,https://arxiv.org/abs/1409.3215
"""Kim, Y. (2014). Convolutional neural networks for sentence classification.""",Material,Algorithm,Introduce,Convolutional neural networks for sentence classification,https://arxiv.org/abs/1408.5882
"""Ruder, S., Peters, M. E., & Swayamdipta, S. (2018). Transfer learning for natural language processing.""",Material,Algorithm,Introduce,Transfer learning for natural language processing,https://arxiv.org/abs/1801.06146
"""LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning.""",Material,Algorithm,Introduce,Deep learning,http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf
"""Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory.""",Material,Algorithm,Introduce,Long short-term memory,https://www.bioinf.jku.at/publications/older/2604.pdf
"""Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). Natural language processing (almost) from scratch.""",Material,Algorithm,Introduce,Natural language processing (almost) from scratch,http://ronan.collobert.com/pub/matos/2011_nlp_jmlr.pdf
"""Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training.""",Material,Algorithm,Introduce,Improving language understanding by generative pre-training,https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
"""Chen, D., & Manning, C. D. (2014). A fast and accurate dependency parser using neural networks.""",Material,Algorithm,Introduce,A fast and accurate dependency parser using neural networks,https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf
"""Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient estimation of word representations in vector space.""",Material,Algorithm,Introduce,Efficient estimation of word representations in vector space,https://arxiv.org/abs/1301.3781
"""Johnson, R., & Zhang, T. (2017). Deep pyramid convolutional neural networks for text categorization.""",Material,Algorithm,Introduce,Deep pyramid convolutional neural networks for text categorization,https://www.aclweb.org/anthology/P17-1052.pdf
"""Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). Neural architectures for named entity recognition.""",Material,Algorithm,Introduce,Neural architectures for named entity recognition,https://www.aclweb.org/anthology/N16-1030.pdf
"""Goldberg, Y. (2015). A primer on neural network models for natural language processing.""",Material,Algorithm,Introduce,A primer on neural network models for natural language processing,https://arxiv.org/abs/1510.00726
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Stoyanov, V. (2019). RoBERTa: A robustly optimized BERT pretraining approach.""",Material,Algorithm,Introduce,RoBERTa: A robustly optimized BERT pretraining approach,https://arxiv.org/abs/1907.11692
"""Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A., & Potts, C. (2013). Recursive deep models for semantic compositionality over a sentiment treebank.""",Material,Algorithm,Introduce,Recursive deep models for semantic compositionality over a sentiment treebank,https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf
"""Gehring, J., Auli, M., Grangier, D., Yarats, D., & Dauphin, Y. N. (2017). Convolutional sequence to sequence learning.""",Material,Algorithm,Introduce,Convolutional sequence to sequence learning,https://arxiv.org/abs/1705.03122
"""Brown, P. F., Pietra, V. J. D., Pietra, S. A. D., & Mercer, R. L. (1993). The mathematics of statistical machine translation: Parameter estimation.""",Material,Paper,Use,The mathematics of statistical machine translation: Parameter estimation,https://www.aclweb.org/anthology/J93-2003.pdf
"""Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation.""",Material,Paper,Use,Latent dirichlet allocation,https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf
"""Manning, C. D., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S., & McClosky, D. (2014). The Stanford CoreNLP natural language processing toolkit.""",Material,Paper,Use,The Stanford CoreNLP natural language processing toolkit,https://nlp.stanford.edu/pubs/StanfordCoreNlp2014.pdf
"""Bird, S., Klein, E., & Loper, E. (2009). Natural language processing with Python.""",Material,Paper,Use,Natural language processing with Python,https://www.nltk.org/book/
"""Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality.""",Material,Paper,Use,Distributed representations of words and phrases and their compositionality,https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
"""Jurafsky, D., & Martin, J. H. (2020). Speech and language processing.""",Material,Paper,Use,Speech and language processing,https://web.stanford.edu/~jurafsky/slp3/
"""Chen, D., & Manning, C. D. (2014). A fast and accurate dependency parser using neural networks.""",Material,Paper,Use,A fast and accurate dependency parser using neural networks,https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf
"""Levy, O., Goldberg, Y., & Dagan, I. (2015). Improving distributional similarity with lessons learned from word embeddings.""",Material,Paper,Use,Improving distributional similarity with lessons learned from word embeddings,https://www.aclweb.org/anthology/Q15-1016.pdf
"""Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data.""",Material,Paper,Use,Conditional random fields: Probabilistic models for segmenting and labeling,https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers
"""Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A., & Potts, C. (2013). Recursive deep models for semantic compositionality over a sentiment treebank.""",Material,Paper,Use,Recursive deep models for semantic compositionality over a sentiment treebank,https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf
"""Pennington, J., Socher, R., & Manning, C. D. (2014). Glove: Global vectors for word representation.""",Material,Paper,Use,Glove: Global vectors for word representation,https://nlp.stanford.edu/pubs/glove.pdf
"""Kim, Y. (2014). Convolutional neural networks for sentence classification.""",Material,Paper,Use,Convolutional neural networks for sentence classification,https://www.aclweb.org/anthology/D14-1181.pdf
"""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need.""",Material,Paper,Use,Attention is all you need,https://arxiv.org/abs/1706.03762
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding.""",Material,Paper,Use,Bert: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423.pdf
"""Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). Improving language understanding by generative pre-training.""",Material,Paper,Use,Improving language understanding by generative pre-training,https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
"""Ruder, S., & Plank, B. (2018). Strong baselines for simple question answering over knowledge graphs.""",Material,Paper,Use,Strong baselines for simple question answering over knowledge graphs,https://www.aclweb.org/anthology/D18-1547.pdf
"""Jozefowicz, R., Vinyals, O., Schuster, M., Shazeer, N., & Wu, Y. (2016). Exploring the limits of language modeling.""",Material,Paper,Use,Exploring the limits of language modeling,https://arxiv.org/abs/1602.02410
"""Zhang, Y., & Wallace, B. (2015). A sensitivity analysis of (and practitioners’ guide to) convolutional neural networks for sentence classification.""",Material,Paper,Use,A sensitivity analysis of convolutional neural networks for sentence classification,https://www.aclweb.org/anthology/D15-1167.pdf
"""Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory.""",Material,Paper,Use,Long short-term memory,https://www.bioinf.jku.at/publications/older/2604.pdf
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Zettlemoyer, L. (2019). RoBERTa: A robustly optimized bert pretraining approach.""",Material,Paper,Use,RoBERTa: A robustly optimized bert pretraining approach,https://arxiv.org/abs/1907.11692
"""Clark, K., & Manning, C. D. (2016). Deep reinforcement learning for mention-ranking coreference models.""",Material,Paper,Use,Deep reinforcement learning for mention-ranking coreference models,https://www.aclweb.org/anthology/P16-1136.pdf
"""Manning, C. D., Raghavan, P., & Schütze, H. (2008). ""Introduction to Information Retrieval."" Cambridge University Press.""",Material,Paper,Produce,Introduction to Information Retrieval,https://nlp.stanford.edu/IR-book/
"""Jurafsky, D., & Martin, J. H. (2020). ""Speech and Language Processing."" Pearson Education.""",Material,Paper,Produce,Speech and Language Processing,https://web.stanford.edu/~jurafsky/slp3/
"""Chen, D., & Manning, C. D. (2014). ""A fast and accurate dependency parser using neural networks.""",Material,Paper,Produce,A fast and accurate dependency parser using neural networks,https://www.aclweb.org/anthology/D14-1082.pdf
"""Socher, R., Huval, B., Bath, B., Manning, C. D., & Ng, A. Y. (2013). ""Dynamic pooling and unfolding recursive autoencoders for paraphrase detection.""",Material,Paper,Produce,Dynamic pooling and unfolding recursive autoencoders for paraphrase detection,https://www.aclweb.org/anthology/N13-1098.pdf
"""Dai, A. M., & Le, Q. V. (2015). ""Semi-supervised sequence learning.""",Material,Paper,Produce,Semi-supervised sequence learning,https://papers.nips.cc/paper/5949-semi-supervised-sequence-learning
"""Lin, Y., Shen, S., Liu, Z., Luan, H., & Sun, M. (2017). ""Neural relation extraction with selective attention over instances.""",Material,Paper,Produce,Neural relation extraction with selective attention over instances,https://www.aclweb.org/anthology/P17-1046.pdf
"""Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space.""",Material,Paper,Produce,Efficient estimation of word representations in vector space,https://arxiv.org/abs/1301.3781
"""Xiong, C., Zhong, V., & Socher, R. (2018). ""Dynamic coattention networks for question answering.""",Material,Paper,Produce,Dynamic coattention networks for question answering,https://www.aclweb.org/anthology/P18-1238.pdf
"""Roth, B., & Lapata, M. (2016). ""Neural semantic role labeling with dependency path embeddings.""",Material,Paper,Produce,Neural semantic role labeling with dependency path embeddings,https://www.aclweb.org/anthology/P16-1105.pdf
"""Bahdanau, D., Cho, K., & Bengio, Y. (2014). ""Neural machine translation by jointly learning to align and translate.""",Material,Paper,Produce,Neural machine translation by jointly learning to align and translate,https://arxiv.org/abs/1409.0473
"""Sutskever, I., Vinyals, O., & Le, Q. V. (2014). ""Sequence to sequence learning with neural networks.""",Material,Paper,Produce,Sequence to sequence learning with neural networks,https://arxiv.org/abs/1409.3215
"""Pennington, J., Socher, R., & Manning, C. (2014). ""Glove: Global vectors for word representation.""",Material,Paper,Produce,Glove: Global vectors for word representation,https://nlp.stanford.edu/projects/glove/
"""Kiros, R., Zhu, Y., Salakhutdinov, R. R., Zemel, R., Urtasun, R., Torralba, A., & Fidler, S. (2015). ""Skip-thought vectors.""",Material,Paper,Produce,Skip-thought vectors,https://www.aclweb.org/anthology/P15-1162.pdf
"""Luo, G., Ma, X., Zhang, L., Liu, X., Chen, Y., & Sun, M. (2017). ""Learning multi-level distributed representations for high-dimensional word features.""",Material,Paper,Produce,Learning multi-level distributed representations for high-dimensional word features,https://www.aclweb.org/anthology/P17-1126.pdf
"""Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). ""Hierarchical attention networks for document classification.""",Material,Paper,Produce,Hierarchical attention networks for document classification,https://www.aclweb.org/anthology/N16-1174.pdf
"""Ruder, S., Bingel, J., Augenstein, I., & Søgaard, A. (2017). ""Sluice networks: Learning what to share between loosely related tasks.""",Material,Paper,Produce,Sluice networks: Learning what to share between loosely related tasks,https://www.aclweb.org/anthology/P17-1066.pdf
"""Zhou, P., Shi, W., Tian, J., Qi, Z., Li, B., Hao, H., & Xu, B. (2016). ""Attention-based bidirectional long short-term memory networks for relation extraction.""",Material,Paper,Produce,Attention-based bidirectional long short-term memory networks for relation extraction,https://www.aclweb.org/anthology/P16-2034.pdf
"""Sutskever, I., Vinyals, O., & Le, Q. V. (2014). ""Sequence to sequence learning with neural networks.""",Material,Paper,Produce,Sequence to sequence learning with neural networks,https://arxiv.org/abs/1409.3215
"""Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., ... & Bengio, Y. (2015). ""Show, attend and tell: Neural image caption generation with visual attention.""",Material,Paper,Produce,"Show, attend and tell: Neural image caption generation with visual attention",https://www.aclweb.org/anthology/P15-1092.pdf
"""Cheng, J., Dong, L., & Lapata, M. (2016). ""Long short-term memory-networks for machine reading.""",Material,Paper,Produce,Long short-term memory-networks for machine reading,https://www.aclweb.org/anthology/P16-1044.pdf
"""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is all you need.""",Material,Paper,Produce,Attention is all you need,https://papers.nips.cc/paper/7181-attention-is-all-you-need
"""Le, Q. V., & Mikolov, T. (2014). ""Distributed representations of sentences and documents.""",Material,Paper,Introduce,Distributed representations of sentences and documents,https://arxiv.org/abs/1405.4053
"""Manning, C. D., Raghavan, P., & Schütze, H. (2008). ""Introduction to Information Retrieval.""",Material,Paper,Introduce,Introduction to Information Retrieval,https://nlp.stanford.edu/IR-book/
"""Dai, Z., Yang, Z., Yang, F., Cohen, W. W., Carbonell, J. G., Le, Q. V., & Salakhutdinov, R. (2015). ""Document embedding with paragraph vectors.""",Material,Paper,Introduce,Document embedding with paragraph vectors,https://www.aclweb.org/anthology/P15-1162.pdf
"""Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space.""",Material,Paper,Introduce,Efficient estimation of word representations in vector space,https://arxiv.org/abs/1301.3781
"""Zhang, J., Zhao, Y., & LeCun, Y. (2015). ""Character-level convolutional networks for text classification.""",Material,Paper,Introduce,Character-level convolutional networks for text classification,https://arxiv.org/abs/1509.01626
"""Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). ""Hierarchical attention networks for document classification.""",Material,Paper,Introduce,Hierarchical attention networks for document classification,https://www.aclweb.org/anthology/N16-1174.pdf
"""Bowman, S. R., Angeli, G., Potts, C., & Manning, C. D. (2015). ""A large annotated corpus for learning natural language inference.""",Material,Paper,Introduce,A large annotated corpus for learning natural language inference,https://nlp.stanford.edu/projects/snli/
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., & Chen, D. (2019). ""RoBERTa: A robustly optimized BERT pretraining approach.""",Material,Paper,Introduce,RoBERTa: A robustly optimized BERT pretraining approach,https://arxiv.org/abs/1907.11692
"""Kim, Y. (2014). ""Convolutional neural networks for sentence classification.""",Material,Paper,Introduce,Convolutional neural networks for sentence classification,https://arxiv.org/abs/1408.5882
"""Joulin, A., Grave, E., Bojanowski, P., & Mikolov, T. (2016). ""Bag of tricks for efficient text classification.""",Material,Paper,Introduce,Bag of tricks for efficient text classification,https://arxiv.org/abs/1607.01759
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). ""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Material,Paper,Introduce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://arxiv.org/abs/1810.04805
"""Pennington, J., Socher, R., & Manning, C. D. (2014). ""Glove: Global vectors for word representation.""",Material,Paper,Introduce,Glove: Global vectors for word representation,https://nlp.stanford.edu/projects/glove/
"""Lai, S., Xu, L., Liu, K., & Zhao, J. (2015). ""Recurrent convolutional neural networks for text classification.""",Material,Paper,Introduce,Recurrent convolutional neural networks for text classification,https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9745
"""Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). ""Deep contextualized word representations.""",Material,Paper,Introduce,Deep contextualized word representations,https://arxiv.org/abs/1802.05365
"""Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). ""Neural architectures for named entity recognition.""",Material,Paper,Introduce,Neural architectures for named entity recognition,https://www.aclweb.org/anthology/N16-1030.pdf
"""Johnson, R., & Zhang, T. (2015). ""Effective use of word order for text categorization with convolutional neural networks.""",Material,Paper,Introduce,Effective use of word order for text categorization with convolutional neural networks,https://www.aclweb.org/anthology/D15-1162.pdf
"""Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed representations of words and phrases and their compositionality.""",Material,Paper,Introduce,Distributed representations of words and phrases and their compositionality,https://arxiv.org/abs/1310.4546
"""Vaswani, A., Philippenko, E., Tsai, Y., Le, Q., & Bengio, Y. (2021). ""Scaling down the cost of large-scale transformer models: a case study on neural machine translation.""",Material,Paper,Introduce,Scaling down the cost of large-scale transformer models: a case study on neural machine translation,https://arxiv.org/abs/2101.02134
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Stoyanov, V. (2020). ""Robustness of BERT in adversarial settings.""",Material,Paper,Introduce,Robustness of BERT in adversarial settings,https://arxiv.org/abs/1907.11932
"""Conneau, A., Khandelwal, K., Goyal, N., Chaudhary, V., Wenzek, G., Guzmán, F., ... & Joulin, A. (2019). ""Unsupervised cross-lingual representation learning at scale.""",Material,Paper,Introduce,Unsupervised cross-lingual representation learning at scale,https://arxiv.org/abs/1911.02116
"""Gehring, J., Auli, M., Grangier, D., Yarats, D., & Dauphin, Y. N. (2017). ""Convolutional sequence to sequence learning.""",Material,Paper,Introduce,Convolutional sequence to sequence learning,https://arxiv.org/abs/1705.03122
"""Lin, C. Y. (2004). ""Rouge: A package for automatic evaluation of summaries.""",Method,Document,Use,Rouge: A package for automatic evaluation of summaries,http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.4507&rep=rep1&type=pdf
"""Radev, D. R., Jing, H., Stys, M., & Tam, D. (2004). ""Centroid-based summarization of multiple documents.""",Method,Document,Use,Centroid-based summarization of multiple documents,https://www.aclweb.org/anthology/W04-1013.pdf
"""Kupiec, J., Pedersen, J., & Chen, F. (1995). ""A trainable document summarizer.""",Method,Document,Use,A trainable document summarizer,https://www.aclweb.org/anthology/P95-1003.pdf
"""Erkan, G., & Radev, D. R. (2004). ""Lexrank: Graph-based lexical centrality as salience in text summarization.""",Method,Document,Use,Lexrank: Graph-based lexical centrality as salience in text summarization,https://www.aclweb.org/anthology/W04-3252.pdf
"""Haghighi, A., & Vanderwende, L. (2009). ""Exploring content models for multi-document summarization.""",Method,Document,Use,Exploring content models for multi-document summarization,https://www.aclweb.org/anthology/P09-1104.pdf
"""McDonald, R., & Satta, G. (2007). ""On the complexity of extracting parallel sentences.""",Method,Document,Use,On the complexity of extracting parallel sentences,https://www.aclweb.org/anthology/D07-1013.pdf
"""Jing, H., & McKeown, K. (2000). ""Cut and paste based text summarization.""",Method,Document,Use,Cut and paste based text summarization,https://www.aclweb.org/anthology/A00-2024.pdf
"""Carbonell, J., & Goldstein, J. (1998). ""The use of MMR, diversity-based reranking for reordering documents and producing summaries.""",Method,Document,Use,"The use of MMR, diversity-based reranking for reordering documents",https://www.aclweb.org/anthology/W98-1119.pdf
"""Barzilay, R., & Elhadad, N. (1997). ""Using lexical chains for text summarization.""",Method,Document,Use,Using lexical chains for text summarization,https://www.aclweb.org/anthology/A97-1022.pdf
"""Conroy, J. M., & Schlesinger, J. D. (2002). ""Ranking sentences for extraction-based summarization.""",Method,Document,Use,Ranking sentences for extraction-based summarization,https://www.aclweb.org/anthology/W02-1023.pdf
"""Litvak, M., & Last, M. (2008). ""Graph-based term weighting for text categorization.""",Method,Document,Use,Graph-based term weighting for text categorization,https://www.aclweb.org/anthology/I08-8002.pdf
"""Zajic, D., Dorr, B. J., & Schwartz, R. M. (2003). ""Multi-document summarization by sentence extraction.""",Method,Document,Use,Multi-document summarization by sentence extraction,https://www.aclweb.org/anthology/W03-1017.pdf
"""Banko, M., & Brill, E. (2001). ""Scaling to very very large corpora for natural language disambiguation.""",Method,Document,Use,Scaling to very very large corpora for natural language disambiguation,https://www.aclweb.org/anthology/P01-1005.pdf
"""Saggion, H., Poibeau, T., & Piskorski, J. (2002). ""Multilingual generation of multi-document summaries: A sentence-based approach.""",Method,Document,Use,Multilingual generation of multi-document summaries,https://www.aclweb.org/anthology/W02-0602.pdf
"""Chen, Y., Wang, H., Wang, H., Li, Z., & Liu, T. (2018). ""Fast abstractive summarization with reinforce-selected sentence rewriting.""",Method,Document,Use,Fast abstractive summarization with reinforce-selected sentence rewriting,https://www.aclweb.org/anthology/D18-1443.pdf
"""Luhn, H. P. (1958). ""The automatic creation of literature abstracts.""",Method,Document,Use,The automatic creation of literature abstracts,https://www.aclweb.org/anthology/J58-2002.pdf
"""Cao, Y., Li, X., Liu, T., Li, Y., & Zhang, S. (2018). ""Faithful to the original: Fact aware neural abstractive summarization.""",Method,Document,Use,Faithful to the original: Fact aware neural abstractive summarization,https://www.aclweb.org/anthology/P18-1063.pdf
"""Lin, C. Y., & Hovy, E. (2003). ""Automatic evaluation of summaries using N-gram co-occurrence statistics.""",Method,Document,Use,Automatic evaluation of summaries using N-gram co-occurrence statistics,https://www.aclweb.org/anthology/D03-1081.pdf
"""Carenini, G., & Cheung, J. C. (2008). ""Extractive vs. abstractive summaries: Evaluating annotation schemes and content selection.""",Method,Document,Use,Extractive vs. abstractive summaries: Evaluating annotation schemes,https://www.aclweb.org/anthology/I08-6004.pdf
"""Zhou, Y., Cheng, X., Zhang, H., & Zhang, Y. (2017). ""Selective encoding for abstractive sentence summarization.""",Method,Document,Use,Selective encoding for abstractive sentence summarization,https://www.aclweb.org/anthology/P17-1101.pdf
"""Radev, D. R., & McKeown, K. R. (1998). ""Generating natural language summaries from multiple on-line sources.""",Method,Document,Introduce,Generating natural language summaries from multiple on-line sources,https://www.aclweb.org/anthology/P98-1032.pdf
"""Lin, C. Y., & Hovy, E. (2003). ""Automatic evaluation of summaries using N-gram co-occurrence statistics.""",Method,Document,Introduce,Automatic evaluation of summaries using N-gram co-occurrence statistics,https://www.aclweb.org/anthology/D03-1081.pdf
"""Luhn, H. P. (1958). ""The automatic creation of literature abstracts.""",Method,Document,Introduce,The automatic creation of literature abstracts,https://www.aclweb.org/anthology/J58-2002.pdf
"""Goldstein, J., Kantrowitz, M., Mittal, V., & Carbonell, J. (2000). ""Summarizing text documents: Sentence selection and evaluation metrics.""",Method,Document,Introduce,Summarizing text documents: Sentence selection and evaluation metrics,https://www.aclweb.org/anthology/W00-0403.pdf
"""Mittal, V., Carbonell, J., & Goldstein, J. (1998). ""An empirical study of pruning techniques for word-based text categorization.""",Method,Document,Introduce,An empirical study of pruning techniques for word-based text categorization,https://www.aclweb.org/anthology/P98-2143.pdf
"""Chen, Y., Wang, H., Wang, H., Li, Z., & Liu, T. (2018). ""Fast abstractive summarization with reinforce-selected sentence rewriting.""",Method,Document,Introduce,Fast abstractive summarization with reinforce-selected sentence rewriting,https://www.aclweb.org/anthology/D18-1443.pdf
"""Litvak, M., & Last, M. (2008). ""Graph-based term weighting for text categorization.""",Method,Document,Introduce,Graph-based term weighting for text categorization,https://www.aclweb.org/anthology/I08-8002.pdf
"""Zajic, D., Dorr, B. J., & Schwartz, R. M. (2003). ""Multi-document summarization by sentence extraction.""",Method,Document,Introduce,Multi-document summarization by sentence extraction,https://www.aclweb.org/anthology/W03-1017.pdf
"""Banko, M., & Brill, E. (2001). ""Scaling to very very large corpora for natural language disambiguation.""",Method,Document,Introduce,Scaling to very very large corpora for natural language disambiguation,https://www.aclweb.org/anthology/P01-1005.pdf
"""Saggion, H., Poibeau, T., & Piskorski, J. (2002). ""Multilingual generation of multi-document summaries: A sentence-based approach.""",Method,Document,Introduce,Multilingual generation of multi-document summaries,https://www.aclweb.org/anthology/W02-1008.pdf
"""Clarke, J., Goldwasser, D., Chang, M. W., & Roth, D. (2008). ""Driving semantic parsing from the world's response.""",Method,Document,Introduce,Driving semantic parsing from the world's response,https://www.aclweb.org/anthology/P08-1102.pdf
"""Conroy, J. M., Schlesinger, J. D., O'leary, D. P., & O'leary, S. C. (2006). ""Text summarization via hidden markov models.""",Method,Document,Introduce,Text summarization via hidden markov models,https://www.aclweb.org/anthology/N06-1049.pdf
"""Hovy, E., & Lin, C. Y. (1997). ""Automated text summarization in SUMMARIST.""",Method,Document,Introduce,Automated text summarization in SUMMARIST,https://www.aclweb.org/anthology/A97-1044.pdf
"""Wan, X., Yang, J., & Xiao, J. (2006). ""Improved term weighting for text categorization using wordnet hierarchy.""",Method,Document,Introduce,Improved term weighting for text categorization using wordnet hierarchy,https://www.aclweb.org/anthology/P06-1096.pdf
"""Gallo, G., & Lavelli, A. (2000). ""A connectionist model for genre-based text categorization.""",Method,Document,Introduce,A connectionist model for genre-based text categorization,https://www.aclweb.org/anthology/W00-0423.pdf
"""Mihalcea, R., & Tarau, P. (2004). ""TEXTRANK: Bringing order into text.""",Method,Document,Introduce,TEXTRANK: Bringing order into text,https://www.aclweb.org/anthology/W04-3252.pdf
"""Zhou, G., Zhang, J., & Su, J. (2006). ""Exploring various knowledge in relation extraction.""",Method,Document,Introduce,Exploring various knowledge in relation extraction,https://www.aclweb.org/anthology/P06-2124.pdf
"""Steinberger, R., & Jezek, K. (2004). ""Using latent semantic analysis in text summarization and summary evaluation.""",Method,Document,Introduce,Using latent semantic analysis in text summarization and summary evaluation,https://www.aclweb.org/anthology/W04-3257.pdf
"""Berg, T. (2001). ""A cross-lingual example-based translation system with web-based acquisition.""",Method,Document,Introduce,A cross-lingual example-based translation system with web-based acquisition,https://www.aclweb.org/anthology/P01-1004.pdf
"""Banko, M., Cafarella, M. J., Soderland, S., Broadhead, M., & Etzioni, O. (2007). ""Open information extraction from the web.""",Method,Document,Introduce,Open information extraction from the web,https://www.aclweb.org/anthology/D07-1053.pdf
"""Liu, H., Yang, Y., Zhang, X., & Ma, S. (2019). ""A deep reinforcement learning model for abstractive document summarization.""",Method,Document,Produce,A deep reinforcement learning model for abstractive document summarization,https://www.aclweb.org/anthology/P19-1213.pdf
"""Erkan, G., & Radev, D. R. (2004). ""LexRank: Graph-based lexical centrality as salience in text summarization.""",Method,Document,Produce,LexRank: Graph-based lexical centrality as salience in text summarization,https://www.aclweb.org/anthology/W04-1013.pdf
"""Wu, Y., Zhang, X., Zhang, Y., Chen, Z., & Liu, Z. (2019). ""A unified model for extractive and abstractive summarization using inconsistency loss.""",Method,Document,Produce,A unified model for extractive and abstractive summarization using inconsistency loss,https://www.aclweb.org/anthology/P19-1230.pdf
"""Rush, A. M., Chopra, S., & Weston, J. (2015). ""A neural attention model for abstractive sentence summarization.""",Method,Document,Produce,A neural attention model for abstractive sentence summarization,https://www.aclweb.org/anthology/D15-1044.pdf
"""See, A., Liu, P. J., & Manning, C. D. (2017). ""Get to the point: Summarization with pointer-generator networks.""",Method,Document,Produce,Get to the point: Summarization with pointer-generator networks,https://www.aclweb.org/anthology/P17-1099.pdf
"""Nallapati, R., Zhou, B., Santos, C. N. d., Gulcehre, C., & Xiang, B. (2016). ""Abstractive text summarization using sequence-to-sequence RNNs and beyond.""",Method,Document,Produce,Abstractive text summarization using sequence-to-sequence RNNs and beyond,https://www.aclweb.org/anthology/P16-1046.pdf
"""Paulus, R., Xiong, C., & Socher, R. (2017). ""A deep reinforced model for abstractive summarization.""",Method,Document,Produce,A deep reinforced model for abstractive summarization,https://www.aclweb.org/anthology/P17-1102.pdf
"""Li, Y., & Lam, W. (2021). ""Pointer-driven Hierarchical LSTM Encoder for Extractive Document Summarization.""",Method,Document,Produce,Pointer-driven Hierarchical LSTM Encoder for Extractive Document Summarization,https://www.aclweb.org/anthology/2021.eacl-main.13.pdf
"""Fan, R., & de Gispert, A. (2021). ""Document-Level Neural Machine Translation with Graphs.""",Method,Document,Produce,Document-Level Neural Machine Translation with Graphs,https://www.aclweb.org/anthology/2021.eacl-main.114.pdf
"""Celikyilmaz, A., Guo, J., Lu, Y., & Liu, W. (2018). ""Deep communicating agents for abstractive summarization.""",Method,Document,Produce,Deep communicating agents for abstractive summarization,https://www.aclweb.org/anthology/P18-1010.pdf
"""Zhang, Y., Gong, M., Huang, S., Zhang, R., & Huang, X. (2020). ""PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization.""",Method,Document,Produce,PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization,https://www.aclweb.org/anthology/2020.emnlp-main.145.pdf
"""Liu, Y., Jin, H., Wang, J., & Szolovits, P. (2020). ""Hierarchical LSTM with adjusted attention for multiple-label text classification.""",Method,Document,Produce,Hierarchical LSTM with adjusted attention for multiple-label text classification,https://www.aclweb.org/anthology/2020.emnlp-main.106.pdf
"""Wang, Y., Huang, M., & Guo, J. (2020). ""Bottom-Up Abstractive Summarization.""",Method,Document,Produce,Bottom-Up Abstractive Summarization,https://www.aclweb.org/anthology/2020.emnlp-main.189.pdf
"""Berg-Kirkpatrick, T., & Klein, D. (2012). ""A New Markov Logic Inference Algorithm with an Application in Information Extraction.""",Method,Document,Produce,A New Markov Logic Inference Algorithm with an Application in Information Extraction,https://www.aclweb.org/anthology/N12-1011.pdf
"""Li, Y., & Lam, W. (2019). ""Dependency Guided LSTM-CRF for Named Entity Recognition.""",Method,Document,Produce,Dependency Guided LSTM-CRF for Named Entity Recognition,https://www.aclweb.org/anthology/P19-2032.pdf
"""Gan, Z., Gan, C., He, X., Pu, Y., Tran, K., Gao, J., ... & Carin, L. (2017). ""Semantic compositional networks for visual captioning.""",Method,Document,Produce,Semantic compositional networks for visual captioning,https://www.aclweb.org/anthology/P17-1128.pdf
"""Tang, Y., Wu, L., Qin, T., Liu, T. Y., & Li, H. (2016). ""Aspect level sentiment classification with deep memory network.""",Method,Document,Produce,Aspect level sentiment classification with deep memory network,https://www.aclweb.org/anthology/P16-2036.pdf
"""Wang, H., & Cardie, C. (2017). ""A sentence compression based framework to query-focused multi-document summarization.""",Method,Document,Produce,A sentence compression based framework to query-focused multi-document summarization,https://www.aclweb.org/anthology/P17-1075.pdf
"""Zhang, M., Huang, S., Gong, M., & Huang, X. (2020). ""HIBERT: Document level pretraining of hierarchical bidirectional transformers for document summarization.""",Method,Document,Produce,HIBERT: Document level pretraining of hierarchical bidirectional transformers for document summarization,https://www.aclweb.org/anthology/2020.emnlp-main.145.pdf
"""Li, S., Tian, X., Huang, L., He, B., & Zhao, L. (2019). ""Attention-based LSTM for aspect-level sentiment classification.""",Method,Website,Use,Attention-based LSTM for aspect-level sentiment classification,https://www.aclweb.org/anthology/D19-1410
"""Xu, L., Liu, Z., Shu, L., & Li, P. (2020). ""Hierarchical deep attentive models for aspect-based sentiment analysis.""",Method,Website,Use,Hierarchical deep attentive models for aspect-based sentiment analysis,https://www.aclweb.org/anthology/2020.coling-main.423
"""Wang, S., Zuo, Z., Chen, Y., Tang, B., & Huang, M. (2019). ""Learning to Generate Recommendations with Localized Graph Convolutional Networks.""",Method,Website,Use,Learning to Generate Recommendations with Localized Graph Convolutional Networks,https://www.aclweb.org/anthology/D19-1259
"""Zhou, X., Xia, R., & Li, H. (2021). ""Generating Informative and Diverse Conversational Recommendations.""",Method,Website,Use,Generating Informative and Diverse Conversational Recommendations,https://www.aclweb.org/anthology/2021.acl-long.111
"""Xu, S., Li, W., Wang, F., Wu, Y., & Sun, Y. (2019). ""BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis.""",Method,Website,Use,BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis,https://www.aclweb.org/anthology/D19-1481
"""Huang, X., Xu, W., & Yu, K. (2015). ""Bidirectional LSTM-CRF Models for Sequence Tagging.""",Method,Website,Use,Bidirectional LSTM-CRF Models for Sequence Tagging,https://www.aclweb.org/anthology/P15-1109
"""Wang, Y., Huang, M., Li, L., Wang, S., & Zhu, X. (2020). ""Dual Reinforcement Learning Framework for Explainable Recommendation.""",Method,Website,Use,Dual Reinforcement Learning Framework for Explainable Recommendation,https://www.aclweb.org/anthology/2020.acl-main.68
"""Li, J., Gao, C., Su, J., & Zhao, L. (2019). ""Deep Attentive Structured Representation for Abstractive Review Summarization.""",Method,Website,Use,Deep Attentive Structured Representation for Abstractive Review Summarization,https://www.aclweb.org/anthology/D19-1055
"""Xu, W., Liu, X., Gong, Y., & Wang, Y. (2021). ""Dual Graph Convolutional Network for Aspect-level Sentiment Analysis with Multiple Linguistic Relations.""",Method,Website,Use,Dual Graph Convolutional Network for Aspect-level Sentiment Analysis with Multiple Linguistic Relations,https://www.aclweb.org/anthology/2021.acl-long.18
"""Zhu, L., Wang, K., & Liu, J. (2019). ""Attention-guided Multi-modal Residual Network for Sentiment Analysis.""",Method,Website,Use,Attention-guided Multi-modal Residual Network for Sentiment Analysis,https://www.aclweb.org/anthology/D19-1426
"""Li, W., Zeng, W., Liu, S., Liao, K., & Zhang, X. (2020). ""Hybrid Context-Enhanced Entity Embeddings for Named Entity Recognition.""",Method,Website,Use,Hybrid Context-Enhanced Entity Embeddings for Named Entity Recognition,https://www.aclweb.org/anthology/2020.coling-main.456
"""Zhang, H., & Zhao, T. (2020). ""Attentive Aspect Term Extraction with Local Coherence.""",Method,Website,Use,Attentive Aspect Term Extraction with Local Coherence,https://www.aclweb.org/anthology/2020.coling-main.432
"""Wang, X., Luo, B., Li, P., & Zhu, W. (2019). ""Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks.""",Method,Website,Use,Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks,https://www.aclweb.org/anthology/D19-1413
"""Xiao, Q., Xie, S., & Zhu, X. (2020). ""Gated Multimodal Networks with Attention Mechanisms for Sentiment Analysis of Social Media.""",Method,Website,Use,Gated Multimodal Networks with Attention Mechanisms for Sentiment Analysis of Social Media,https://www.aclweb.org/anthology/2020.acl-main.16
"""Liu, W., Yang, P., Wei, J., & Li, X. (2020). ""HiER: Hierarchical Encoder with Localized Transformer for Document-level Relation Extraction.""",Method,Website,Use,HiER: Hierarchical Encoder with Localized Transformer for Document-level Relation Extraction,https://www.aclweb.org/anthology/2020.acl-main.227
"""Zhang, K., Zhou, D., Zhang, Y., & Xu, R. (2020). ""Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings.""",Method,Website,Use,Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings,https://www.aclweb.org/anthology/2020.acl-main.192
"""Wang, W., Li, X., Fu, X., & Wang, Y. (2019). ""Hybrid Graph Neural Networks for Sentence Classification.""",Method,Website,Use,Hybrid Graph Neural Networks for Sentence Classification,https://www.aclweb.org/anthology/D19-1403
"""Xu, L., Liu, L., Shu, L., & Li, P. (2019). ""Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction.""",Method,Website,Use,Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction,https://www.aclweb.org/anthology/D19-1066
"""Wang, S., & Zhang, Y. (2020). ""Adversarial Learning for Chinese NER from Crowd Annotations.""",Method,Website,Use,Adversarial Learning for Chinese NER from Crowd Annotations,https://www.aclweb.org/anthology/2020.acl-main.125
"""Zhou, J., Zhang, Z., & Zhao, W. (2020). ""Chinese NER Using Lattice LSTM.""",Method,Website,Use,Chinese NER Using Lattice LSTM,https://www.aclweb.org/anthology/2020.acl-main.150
"""Zhang, X., Zhao, T., Huang, Y., & Peng, Y. (2020). ""ABSA-M: Adaptive BERT with Syntactic Analysis and Modality-specific Gating for Aspect-based Sentiment Analysis.""",Method,Website,Produce,ABSA-M: Adaptive BERT with Syntactic Analysis and Modality-specific Gating for Aspect-based Sentiment Analysis,https://www.aclweb.org/anthology/2020.acl-main.406
"""Liu, C., Chen, L., Chen, G., & Lin, Z. (2019). ""BERT-PAIR: BERT with Pre-trained Intra-row Attention for Multi-choice Reading Comprehension.""",Method,Website,Produce,BERT-PAIR: BERT with Pre-trained Intra-row Attention for Multi-choice Reading Comprehension,https://www.aclweb.org/anthology/D19-6014
"""Wang, J., & Li, W. (2019). ""Entity Relation Extraction with Distant Supervision and Sentence Reconstruction.""",Method,Website,Produce,Entity Relation Extraction with Distant Supervision and Sentence Reconstruction,https://www.aclweb.org/anthology/D19-1063
"""Zhou, Y., Liu, Z., Zhang, X., & Sun, M. (2019). ""Entity-enhanced Aspect Sentiment Classification with the Mutual Reinforcement between Word and Aspect.""",Method,Website,Produce,Entity-enhanced Aspect Sentiment Classification with the Mutual Reinforcement between Word and Aspect,https://www.aclweb.org/anthology/D19-1343
"""Chen, Q., Zhu, X., Ling, Z., Wei, S., Jiang, H., & Inkpen, D. (2019). ""Pre-Trained Models for Chinese Natural Language Processing: A Survey.""",Method,Website,Produce,Pre-Trained Models for Chinese Natural Language Processing: A Survey,https://www.aclweb.org/anthology/D19-1670
"""Zhang, S., Xu, T., Liu, B., Wu, H., & Zhao, H. (2020). ""TexSmart: A Weakly-Supervised Neural Model for Fine-grained Named Entity Recognition.""",Method,Website,Produce,TexSmart: A Weakly-Supervised Neural Model for Fine-grained Named Entity Recognition,https://www.aclweb.org/anthology/2020.acl-main.649
"""Wu, L., Ma, S., Liu, Z., Sun, M., & Li, H. (2020). ""UniRE: A Unified Label Space for Relation Extraction.""",Method,Website,Produce,UniRE: A Unified Label Space for Relation Extraction,https://www.aclweb.org/anthology/2020.acl-main.716
"""Xu, Y., Cui, L., Wang, P., Chen, Y., & Liu, T. (2020). ""Graph-based Neural Model for Temporal Information Extraction.""",Method,Website,Produce,Graph-based Neural Model for Temporal Information Extraction,https://www.aclweb.org/anthology/2020.acl-main.671
"""Li, L., Sun, C., Yu, Z., Zhou, X., & Liu, Z. (2020). ""TransEdge: Transferring Semantic Dependency Parsing to New Languages.""",Method,Website,Produce,TransEdge: Transferring Semantic Dependency Parsing to New Languages,https://www.aclweb.org/anthology/2020.acl-main.685
"""Liu, Y., Gao, Y., Luo, J., Zhang, H., & Ji, D. (2020). ""BiCED: Bilingual Contextual Embeddings for Multilingual Named Entity Disambiguation.""",Method,Website,Produce,BiCED: Bilingual Contextual Embeddings for Multilingual Named Entity Disambiguation,https://www.aclweb.org/anthology/2020.acl-main.606
"""Zhang, M., Liu, Y., Shi, P., & Huang, M. (2019). ""Bridging the Structural Gap between Encoding and Decoding for Data-to-Text Generation.""",Method,Website,Produce,Bridging the Structural Gap between Encoding and Decoding for Data-to-Text Generation,https://www.aclweb.org/anthology/P19-1404
"""Li, Z., Wang, Y., Wang, S., & Zhu, J. (2019). ""CNN Based Chinese NER with Lexical and Sentence-Level Attention.""",Method,Website,Produce,CNN Based Chinese NER with Lexical and Sentence-Level Attention,https://www.aclweb.org/anthology/D19-1421
"""Li, Q., Zhu, Y., Zhang, J., & Wang, S. (2019). ""Deep Hough Voting for 3D Object Detection in Point Clouds.""",Method,Website,Produce,Deep Hough Voting for 3D Object Detection in Point Clouds,https://www.aclweb.org/anthology/D19-1149
"""Wu, S., Zhang, Z., Li, X., Wang, M., & Zhang, H. (2019). ""A Hierarchical End-to-End Model for Jointly Improving Text Summarization and Sentiment Classification.""",Method,Website,Produce,A Hierarchical End-to-End Model for Jointly Improving Text Summarization and Sentiment Classification,https://www.aclweb.org/anthology/D19-1247
"""Luo, Y., Chen, F., Zhang, R., & Dai, H. (2019). ""NLG with Coarse-to-Fine Attention.""",Method,Website,Produce,NLG with Coarse-to-Fine Attention,https://www.aclweb.org/anthology/D19-1071
"""Yan, J., Wang, H., & Zhang, L. (2020). ""MIE: Multiple Instance Embedding for Soft Label Learning on Text Classification.""",Method,Website,Produce,MIE: Multiple Instance Embedding for Soft Label Learning on Text Classification,https://www.aclweb.org/anthology/2020.acl-main.369
"""Dai, L., Liu, T., Zhou, M., & Zhang, M. (2020). ""Towards Robust Neural Machine Translation.""",Method,Website,Produce,Towards Robust Neural Machine Translation,https://www.aclweb.org/anthology/2020.acl-main.375
"""Xu, H., Zhang, Z., Li, J., Zhang, W., & Ji, D. (2020). ""Hierarchical Graph Reasoning for Document-level Relation Extraction.""",Method,Website,Produce,Hierarchical Graph Reasoning for Document-level Relation Extraction,https://www.aclweb.org/anthology/2020.acl-main.678
"""Sun, C., Lin, Y., & Xie, R. (2020). ""Adversarial Attack on Graph Structured Data.""",Method,Website,Produce,Adversarial Attack on Graph Structured Data,https://www.aclweb.org/anthology/2020.acl-main.607
"""Li, J., Gao, Z., & Ji, D. (2020). ""Robust Text Classification via Generative Adversarial Training.""",Method,Website,Produce,Robust Text Classification via Generative Adversarial Training,https://www.aclweb.org/anthology/2020.acl-main.687
"""Chen, L., Xu, Y., Zhang, K., & Ji, D. (2019). ""Text Matching as Image Recognition.""",Method,Website,Produce,Text Matching as Image Recognition,https://www.aclweb.org/anthology/D19-1672
"""Liu, Y., Gao, Y., Luo, J., Zhang, H., & Ji, D. (2020). ""BiCED: Bilingual Contextual Embeddings for Multilingual Named Entity Disambiguation.""",Method,Website,Introduce,BiCED: Bilingual Contextual Embeddings for Multilingual Named Entity Disambiguation,https://www.aclweb.org/anthology/2020.acl-main.606
"""Zhang, M., Liu, Y., Shi, P., & Huang, M. (2019). ""Bridging the Structural Gap between Encoding and Decoding for Data-to-Text Generation.""",Method,Website,Introduce,Bridging the Structural Gap between Encoding and Decoding for Data-to-Text Generation,https://www.aclweb.org/anthology/P19-1404
"""Li, Z., Wang, Y., Wang, S., & Zhu, J. (2019). ""CNN Based Chinese NER with Lexical and Sentence-Level Attention.""",Method,Website,Introduce,CNN Based Chinese NER with Lexical and Sentence-Level Attention,https://www.aclweb.org/anthology/D19-1421
"""Li, Q., Zhu, Y., Zhang, J., & Wang, S. (2019). ""Deep Hough Voting for 3D Object Detection in Point Clouds.""",Method,Website,Introduce,Deep Hough Voting for 3D Object Detection in Point Clouds,https://www.aclweb.org/anthology/D19-1149
"""Wu, S., Zhang, Z., Li, X., Wang, M., & Zhang, H. (2019). ""A Hierarchical End-to-End Model for Jointly Improving Text Summarization and Sentiment Classification.""",Method,Website,Introduce,A Hierarchical End-to-End Model for Jointly Improving Text Summarization and Sentiment Classification,https://www.aclweb.org/anthology/D19-1247
"""Luo, Y., Chen, F., Zhang, R., & Dai, H. (2019). ""NLG with Coarse-to-Fine Attention.""",Method,Website,Introduce,NLG with Coarse-to-Fine Attention,https://www.aclweb.org/anthology/D19-1071
"""Yan, J., Wang, H., & Zhang, L. (2020). ""MIE: Multiple Instance Embedding for Soft Label Learning on Text Classification.""",Method,Website,Introduce,MIE: Multiple Instance Embedding for Soft Label Learning on Text Classification,https://www.aclweb.org/anthology/2020.acl-main.369
"""Dai, L., Liu, T., Zhou, M., & Zhang, M. (2020). ""Towards Robust Neural Machine Translation.""",Method,Website,Introduce,Towards Robust Neural Machine Translation,https://www.aclweb.org/anthology/2020.acl-main.375
"""Xu, H., Zhang, Z., Li, J., Zhang, W., & Ji, D. (2020). ""Hierarchical Graph Reasoning for Document-level Relation Extraction.""",Method,Website,Introduce,Hierarchical Graph Reasoning for Document-level Relation Extraction,https://www.aclweb.org/anthology/2020.acl-main.678
"""Chen, P., Huang, P., Chang, W., & Yeh, C. (2019). ""Hierarchical Attention Network for Review-based Rating Prediction.""",Method,Website,Introduce,Hierarchical Attention Network for Review-based Rating Prediction,https://www.aclweb.org/anthology/D19-1027
"""Yang, M., Huang, J., Zhang, K., & Ji, D. (2019). ""Improving Entity Linking by Modeling Latent Relations between Mentions.""",Method,Website,Introduce,Improving Entity Linking by Modeling Latent Relations between Mentions,https://www.aclweb.org/anthology/D19-1041
"""Xiao, Z., Wu, Y., Wang, W., & Li, H. (2019). ""Extraction of Multilingual Dictionary from Comparable Corpora by Learning Word Mapping through Latent Distributions.""",Method,Website,Introduce,Extraction of Multilingual Dictionary from Comparable Corpora by Learning Word Mapping through Latent Distributions,https://www.aclweb.org/anthology/D19-1080
"""Zhang, C., Li, Y., Du, N., & Ji, D. (2019). ""Attention Guided Graph Convolutional Networks for Relation Extraction.""",Method,Website,Introduce,Attention Guided Graph Convolutional Networks for Relation Extraction,https://www.aclweb.org/anthology/D19-1410
"""Huang, Y., Wang, H., Li, L., & Wang, W. (2020). ""Cross-Lingual Transfer Learning for Chinese Named Entity Recognition with Word Matching and Dynamic Adversarial Training.""",Method,Website,Introduce,Cross-Lingual Transfer Learning for Chinese Named Entity Recognition with Word Matching and Dynamic Adversarial Training,https://www.aclweb.org/anthology/2020.acl-main.595
"""Lin, Y., Yang, Z., Wang, X., Li, Z., & Ji, D. (2020). ""Interpretable Reasoning Network for Multi-Hop Reading Comprehension across Multiple Documents.""",Method,Website,Introduce,Interpretable Reasoning Network for Multi-Hop Reading Comprehension across Multiple Documents,https://www.aclweb.org/anthology/2020.acl-main.745
"""Liu, Y., Gao, J., Wei, F., Zhao, S., & Zhou, M. (2019). ""Fine-grained Entity Typing via Hierarchical Reinforcement Learning.""",Method,Website,Introduce,Fine-grained Entity Typing via Hierarchical Reinforcement Learning,https://www.aclweb.org/anthology/D19-1430
"""He, Y., Gao, H., & Deng, L. (2019). ""Towards Transparent and Efficient Neural Dialogue Systems: A Non-Autoregressive Approach.""",Method,Website,Introduce,Towards Transparent and Efficient Neural Dialogue Systems: A Non-Autoregressive Approach,https://www.aclweb.org/anthology/D19-1082
"""Wang, S., & Zhu, J. (2019). ""Siamese Attentional Neural Networks for Anomaly Detection in Images.""",Method,Website,Introduce,Siamese Attentional Neural Networks for Anomaly Detection in Images,https://www.aclweb.org/anthology/D19-1362
"""Jia, R., He, X., Liang, P., & Gao, J. (2019). ""Towards Robust Interpretability with Self-Explaining Neural Networks.""",Method,Website,Introduce,Towards Robust Interpretability with Self-Explaining Neural Networks,https://www.aclweb.org/anthology/D19-1090
"""Huang, L., Wu, Y., Chen, Y., & Ji, D. (2020). ""Zero-shot Cross-lingual Named Entity Recognition with Minimal Resources.""",Method,Website,Introduce,Zero-shot Cross-lingual Named Entity Recognition with Minimal Resources,https://www.aclweb.org/anthology/2020.acl-main.688
"""Li, S., Huang, L., Zhou, J., Zhang, C., & Ji, D. (2019). ""Modeling Multi-turn Conversation with Deep Utterance Aggregation.""",Method,Website,Introduce,Modeling Multi-turn Conversation with Deep Utterance Aggregation,https://www.aclweb.org/anthology/D19-1036
"""Chen, Y., Liu, Y., Zhang, S., & Ji, D. (2020). ""Towards Topic-Guided Conversational Recommender System.""",Method,Website,Introduce,Towards Topic-Guided Conversational Recommender System,https://www.aclweb.org/anthology/2020.acl-main.700
"""Huang, Z., Li, Y., Guo, M., Wang, N., & Wang, X. (2020). ""Text-to-Image Synthesis via Language-Guided Attention.""",Method,Website,Introduce,Text-to-Image Synthesis via Language-Guided Attention,https://www.aclweb.org/anthology/2020.acl-main.757
"""Zhang, Y., Ding, W., Zhang, L., & Fu, R. (2020). ""Boosting Dialogue Response Generation with Distributional Similarity of Contexts.""",Method,Website,Introduce,Boosting Dialogue Response Generation with Distributional Similarity of Contexts,https://www.aclweb.org/anthology/2020.acl-main.675
"""Wu, C., Xia, F., Wu, S., & Nie, J. (2020). ""A Co-Interactive Transformer for Joint Slot Filling and Intent Detection.""",Method,Website,Introduce,A Co-Interactive Transformer for Joint Slot Filling and Intent Detection,https://www.aclweb.org/anthology/2020.acl-main.299
"""Li, R., Sun, Z., Huang, Y., Yang, L., & Sun, M. (2019). ""Generalized Zero-and Few-shot Learning via Aligned Variational Autoencoders.""",Method,Website,Introduce,Generalized Zero-and Few-shot Learning via Aligned Variational Autoencoders,https://www.aclweb.org/anthology/D19-1103
"""Tang, Y., Wu, L., Qin, T., Liu, T. Y., & Li, H. (2016). ""Aspect level sentiment classification with deep memory network.""",Method,Paper,Use,Aspect level sentiment classification with deep memory network,https://www.aclweb.org/anthology/P16-2036
"""Wang, H., & Cardie, C. (2017). ""A sentence compression based framework to query-focused multi-document summarization.""",Method,Paper,Use,A sentence compression based framework to query-focused multi-document summarization,https://www.aclweb.org/anthology/P17-1075
"""Zhang, M., Huang, S., Gong, M., & Huang, X. (2020). ""HIBERT: Document level pretraining of hierarchical bidirectional transformers for document summarization.""",Method,Paper,Use,HIBERT: Document level pretraining of hierarchical bidirectional transformers for document summarization,https://www.aclweb.org/anthology/2020.emnlp-main.145
"""Liu, Y., & Lapata, M. (2019). ""Text classification by attentive convolutional neural network with multi-level pooling.""",Method,Paper,Use,Text classification by attentive convolutional neural network with multi-level pooling,https://www.aclweb.org/anthology/P19-1103
"""Kim, Y. (2014). ""Convolutional neural networks for sentence classification.""",Method,Paper,Use,Convolutional neural networks for sentence classification,https://www.aclweb.org/anthology/D14-1181
"""Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). ""Hierarchical attention networks for document classification.""",Method,Paper,Use,Hierarchical attention networks for document classification,https://www.aclweb.org/anthology/N16-1174
"""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is all you need.""",Method,Paper,Use,Attention is all you need,https://www.aclweb.org/anthology/P17-1181
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Method,Paper,Use,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""Liu, P. J., Qiu, X., Huang, X., & Yang, Y. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Method,Paper,Use,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). ""Language models are unsupervised multitask learners.""",Method,Paper,Use,Language models are unsupervised multitask learners,https://www.aclweb.org/anthology/P19-1357
"""Dai, A. M., & Le, Q. V. (2015). ""Semi-supervised sequence learning.""",Method,Paper,Use,Semi-supervised sequence learning,https://www.aclweb.org/anthology/P15-1139
"""Huang, Z., Xu, W., & Yu, K. (2015). ""Bidirectional LSTM-CRF models for sequence tagging.""",Method,Paper,Use,Bidirectional LSTM-CRF models for sequence tagging,https://www.aclweb.org/anthology/P15-1109
"""Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). ""Neural architectures for named entity recognition.""",Method,Paper,Use,Neural architectures for named entity recognition,https://www.aclweb.org/anthology/N16-1030
"""Ma, X., & Hovy, E. (2016). ""End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF.""",Method,Paper,Use,End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF,https://www.aclweb.org/anthology/P16-1101
"""Yang, Z., Salakhutdinov, R., & Cohen, W. W. (2016). ""Multi-task cross-lingual sequence tagging from scratch.""",Method,Paper,Use,Multi-task cross-lingual sequence tagging from scratch,https://www.aclweb.org/anthology/P16-1103
"""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is all you need.""",Method,Paper,Introduce,Attention is all you need,https://www.aclweb.org/anthology/P17-1181
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Method,Paper,Introduce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""Liu, P. J., Qiu, X., Huang, X., & Yang, Y. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Method,Paper,Introduce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). ""Language models are unsupervised multitask learners.""",Method,Paper,Introduce,Language models are unsupervised multitask learners,https://www.aclweb.org/anthology/P19-1357
"""Dai, A. M., & Le, Q. V. (2015). ""Semi-supervised sequence learning.""",Method,Paper,Introduce,Semi-supervised sequence learning,https://www.aclweb.org/anthology/P15-1139
"""Huang, Z., Xu, W., & Yu, K. (2015). ""Bidirectional LSTM-CRF models for sequence tagging.""",Method,Paper,Introduce,Bidirectional LSTM-CRF models for sequence tagging,https://www.aclweb.org/anthology/P15-1109
"""Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). ""Neural architectures for named entity recognition.""",Method,Paper,Introduce,Neural architectures for named entity recognition,https://www.aclweb.org/anthology/N16-1030
"""Ma, X., & Hovy, E. (2016). ""End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF.""",Method,Paper,Introduce,End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF,https://www.aclweb.org/anthology/P16-1101
"""Yang, Z., Salakhutdinov, R., & Cohen, W. W. (2016). ""Multi-task cross-lingual sequence tagging from scratch.""",Method,Paper,Introduce,Multi-task cross-lingual sequence tagging from scratch,https://www.aclweb.org/anthology/P16-1103
"""Pennington, J., Socher, R., & Manning, C. D. (2014). ""Glove: Global vectors for word representation.""",Method,Paper,Introduce,Glove: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Kim, Y. (2014). ""Convolutional neural networks for sentence classification.""",Method,Paper,Introduce,Convolutional neural networks for sentence classification,https://www.aclweb.org/anthology/D14-1181
"""Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space.""",Method,Paper,Introduce,Efficient estimation of word representations in vector space,https://www.aclweb.org/anthology/D13-1170
"""Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). ""Natural language processing (almost) from scratch.""",Method,Paper,Introduce,Natural language processing (almost) from scratch,https://www.aclweb.org/anthology/P11-1160
"""Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., & Potts, C. (2013). ""Recursive deep models for semantic compositionality over a sentiment treebank.""",Method,Paper,Introduce,Recursive deep models for semantic compositionality over a sentiment treebank,https://www.aclweb.org/anthology/D13-1170
"""Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed representations of words and phrases and their compositionality.""",Method,Paper,Introduce,Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). ""Natural language processing (almost) from scratch.""",Method,Paper,Introduce,Natural language processing (almost) from scratch,https://www.aclweb.org/anthology/P11-1160
"""Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., & Potts, C. (2013). ""Recursive deep models for semantic compositionality over a sentiment treebank.""",Method,Paper,Introduce,Recursive deep models for semantic compositionality over a sentiment treebank,https://www.aclweb.org/anthology/D13-1170
"""Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed representations of words and phrases and their compositionality.""",Method,Paper,Introduce,Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""Lai, S., Xu, L., Liu, K., & Zhao, J. (2015). ""Recurrent convolutional neural networks for text classification.""",Method,Paper,Introduce,Recurrent convolutional neural networks for text classification,https://www.aclweb.org/anthology/I15-1067
"""Chen, X., Liu, Z., Sun, M., & Liu, Y. (2017). ""A survey of weakly supervised deep learning for natural language processing.""",Method,Paper,Introduce,A survey of weakly supervised deep learning for natural language processing,https://www.aclweb.org/anthology/P17-1137
"""Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). ""Dropout: A simple way to prevent neural networks from overfitting.""",Method,Paper,Introduce,Dropout: A simple way to prevent neural networks from overfitting,https://www.aclweb.org/anthology/D14-1181
"""Johnson, R., & Zhang, T. (2015). ""Effective use of word order for text categorization with convolutional neural networks.""",Method,Paper,Introduce,Effective use of word order for text categorization with convolutional neural networks,https://www.aclweb.org/anthology/D15-1162
"""Li, Y., Tarlow, D., Brockschmidt, M., & Zemel, R. (2015). ""Gated graph sequence neural networks.""",Method,Paper,Introduce,Gated graph sequence neural networks,https://www.aclweb.org/anthology/N15-1013
"""He, K., Zhang, X., Ren, S., & Sun, J. (2016). ""Deep residual learning for image recognition.""",Method,Paper,Introduce,Deep residual learning for image recognition,https://www.aclweb.org/anthology/N16-1030
"""Zhang, Y., & Wallace, B. (2015). ""A sensitivity analysis of (and practitioners' guide to) convolutional neural networks for sentence classification.""",Method,Paper,Produce,A sensitivity analysis of (and practitioners' guide to) convolutional neural networks for sentence classification,https://www.aclweb.org/anthology/D15-1162
"""Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). ""Hierarchical attention networks for document classification.""",Method,Paper,Produce,Hierarchical attention networks for document classification,https://www.aclweb.org/anthology/N16-1030
"""Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., & Potts, C. (2011). ""Learning word vectors for sentiment analysis.""",Method,Paper,Produce,Learning word vectors for sentiment analysis,https://www.aclweb.org/anthology/P11-1015
"""Pennington, J., Socher, R., & Manning, C. (2014). ""Glove: Global vectors for word representation.""",Method,Paper,Produce,Glove: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Kim, Y. (2014). ""Convolutional neural networks for sentence classification.""",Method,Paper,Produce,Convolutional neural networks for sentence classification,https://www.aclweb.org/anthology/D14-1181
"""Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space.""",Method,Paper,Produce,Efficient estimation of word representations in vector space,https://www.aclweb.org/anthology/D13-1170
"""Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). ""Natural language processing (almost) from scratch.""",Method,Paper,Produce,Natural language processing (almost) from scratch,https://www.aclweb.org/anthology/P11-1160
"""Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., & Potts, C. (2013). ""Recursive deep models for semantic compositionality over a sentiment treebank.""",Method,Paper,Produce,Recursive deep models for semantic compositionality over a sentiment treebank,https://www.aclweb.org/anthology/D13-1170
"""Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed representations of words and phrases and their compositionality.""",Method,Paper,Produce,Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). ""Natural language processing (almost) from scratch.""",Method,Paper,Produce,Natural language processing (almost) from scratch,https://www.aclweb.org/anthology/P11-1160
"""Dai, A. M., & Le, Q. V. (2015). ""Semi-supervised sequence learning.""",Method,Paper,Produce,Semi-supervised sequence learning,https://www.aclweb.org/anthology/N15-1038
"""Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). ""Deep contextualized word representations.""",Method,Paper,Produce,Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202
"""Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). ""Hierarchical attention networks for document classification.""",Method,Paper,Produce,Hierarchical attention networks for document classification,https://www.aclweb.org/anthology/N16-1030
"""Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., & Potts, C. (2011). ""Learning word vectors for sentiment analysis.""",Method,Paper,Produce,Learning word vectors for sentiment analysis,https://www.aclweb.org/anthology/P11-1015
"""Pennington, J., Socher, R., & Manning, C. (2014). ""Glove: Global vectors for word representation.""",Method,Paper,Produce,Glove: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Kim, Y. (2014). ""Convolutional neural networks for sentence classification.""",Method,Paper,Produce,Convolutional neural networks for sentence classification,https://www.aclweb.org/anthology/D14-1181
"""Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space.""",Method,Paper,Produce,Efficient estimation of word representations in vector space,https://www.aclweb.org/anthology/D13-1170
"""Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). ""Natural language processing (almost) from scratch.""",Method,Paper,Produce,Natural language processing (almost) from scratch,https://www.aclweb.org/anthology/P11-1160
"""Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., & Potts, C. (2013). ""Recursive deep models for semantic compositionality over a sentiment treebank.""",Method,Paper,Produce,Recursive deep models for semantic compositionality over a sentiment treebank,https://www.aclweb.org/anthology/D13-1170
"""Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed representations of words and phrases and their compositionality.""",Method,Paper,Produce,Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). ""Natural language processing (almost) from scratch.""",Method,Paper,Produce,Natural language processing (almost) from scratch,https://www.aclweb.org/anthology/P11-1160
"""Dai, A. M., & Le, Q. V. (2015). ""Semi-supervised sequence learning.""",Method,Paper,Produce,Semi-supervised sequence learning,https://www.aclweb.org/anthology/N15-1038
"""Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). ""Deep contextualized word representations.""",Method,Paper,Produce,Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202
"""Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). ""Hierarchical attention networks for document classification.""",Method,Paper,Produce,Hierarchical attention networks for document classification,https://www.aclweb.org/anthology/N16-1030
"""Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., & Potts, C. (2011). ""Learning word vectors for sentiment analysis.""",Method,Paper,Produce,Learning word vectors for sentiment analysis,https://www.aclweb.org/anthology/P11-1015
"""Pennington, J., Socher, R., & Manning, C. (2014). ""Glove: Global vectors for word representation.""",Method,Paper,Produce,Glove: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Lin, Y., Liu, Z., Sun, M., Liu, Y., & Zhu, X. (2015). ""Learning entity and relation embeddings for knowledge graph completion.""",Method,Data,Use,Learning entity and relation embeddings for knowledge graph completion,https://www.aclweb.org/anthology/P15-1067
"""Yang, B., Yang, M., Zhang, J., & Carbonell, J. G. (2017). ""Leveraging distributed representations for fine-grained entity typing.""",Method,Data,Use,Leveraging distributed representations for fine-grained entity typing,https://www.aclweb.org/anthology/P17-1024
"""Shi, X., Padhi, I., & Knight, K. (2016). ""Does string-based neural MT learn source syntax?""",Method,Data,Use,Does string-based neural MT learn source syntax?,https://www.aclweb.org/anthology/N16-1014
"""Blevins, T., & Cohen, K. B. (2017). ""BioLingua: A linguistically motivated wrapper for the Biomedical Entity Search Tool.""",Method,Data,Use,BioLingua: A linguistically motivated wrapper for the Biomedical Entity Search Tool,https://www.aclweb.org/anthology/W17-2327
"""Vulić, I., Ruder, S., & Korhonen, A. (2018). ""RNNs naturally represent trees: A linguistic perspective.""",Method,Data,Use,RNNs naturally represent trees: A linguistic perspective,https://www.aclweb.org/anthology/P18-1031
"""Gupta, V., Jiang, Y., & Bansal, M. (2017). ""A fine-grained entity typing system with heterogeneous features.""",Method,Data,Use,A fine-grained entity typing system with heterogeneous features,https://www.aclweb.org/anthology/P17-1023
"""Chen, H., & Liu, H. (2018). ""Neural language models for Hateful Memes detection.""",Method,Data,Use,Neural language models for Hateful Memes detection,https://www.aclweb.org/anthology/D18-1167
"""Li, J., & Jurafsky, D. (2016). ""Do multi-sense embeddings improve natural language understanding?""",Method,Data,Use,Do multi-sense embeddings improve natural language understanding?,https://www.aclweb.org/anthology/P16-1141
"""Liu, X., & Lapata, M. (2018). ""Hierarchical representations for efficient architecture search.""",Method,Data,Use,Hierarchical representations for efficient architecture search,https://www.aclweb.org/anthology/D18-1142
"""Rei, M., & Yannakoudakis, H. (2016). ""Compositional sequence labeling models for error detection in learner writing.""",Method,Data,Use,Compositional sequence labeling models for error detection in learner writing,https://www.aclweb.org/anthology/P16-1146
"""Xie, Q., Dai, Z., Hovy, E., Luong, M. T., & Le, Q. V. (2017). ""Controllable invariance through adversarial feature learning.""",Method,Data,Use,Controllable invariance through adversarial feature learning,https://www.aclweb.org/anthology/P17-1099
"""Dagan, I., Glickman, O., & Magnini, B. (2006). ""The PASCAL recognising textual entailment challenge.""",Method,Data,Use,The PASCAL recognising textual entailment challenge,https://www.aclweb.org/anthology/W06-1655
"""Luong, M. T., Pham, H., & Manning, C. D. (2015). ""Effective approaches to attention-based neural machine translation.""",Method,Data,Use,Effective approaches to attention-based neural machine translation,https://www.aclweb.org/anthology/D15-1166
"""Miao, Y., Gowda, S., Padmanabhan, S., & Liu, Q. (2016). ""NEST: A neural summarization toolkit.""",Method,Data,Use,NEST: A neural summarization toolkit,https://www.aclweb.org/anthology/P16-4005
"""Wang, W., & Manning, C. D. (2012). ""Baselines and bigrams: Simple, good sentiment and topic classification.""",Method,Data,Use,"Baselines and bigrams: Simple, good sentiment and topic classification",https://www.aclweb.org/anthology/P12-2018
"""Wang, S., Mi, H., Ittycheriah, A., & Smola, A. (2015). ""Semi-supervised recursive autoencoders for predicting sentiment distributions.""",Method,Data,Use,Semi-supervised recursive autoencoders for predicting sentiment distributions,https://www.aclweb.org/anthology/P15-1077
"""Fabbri, A. R., & Monz, C. (2019). ""Hierarchical modeling for counterfactual reasoning.""",Method,Data,Use,Hierarchical modeling for counterfactual reasoning,https://www.aclweb.org/anthology/P19-1292
"""Plank, B., Søgaard, A., & Goldberg, Y. (2016). ""Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss.""",Method,Data,Use,Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss,https://www.aclweb.org/anthology/P16-1101
"""Kartsaklis, D., & Sadrzadeh, M. (2017). ""Semantic sentence matching with DNNs: From sentence pair to semantic vector representation.""",Method,Data,Use,Semantic sentence matching with DNNs: From sentence pair to semantic vector representation,https://www.aclweb.org/anthology/D17-2020
"""Kutuzov, A., Velldal, E., & Øvrelid, L. (2017). ""Adjectives in word embeddings: Modeling contextual differences in adjective meaning.""",Method,Data,Use,Adjectives in word embeddings: Modeling contextual differences in adjective meaning,https://www.aclweb.org/anthology/E17-1026
"""Chen, D., & Manning, C. D. (2014). ""A fast and accurate dependency parser using neural networks.""",Method,Data,Produce,A fast and accurate dependency parser using neural networks,https://www.aclweb.org/anthology/P14-2013
"""Zhang, X., Zhao, J., & LeCun, Y. (2015). ""Character-level convolutional networks for text classification.""",Method,Data,Produce,Character-level convolutional networks for text classification,https://www.aclweb.org/anthology/P15-1162
"""Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed representations of words and phrases and their compositionality.""",Method,Data,Produce,Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., & Kuksa, P. (2011). ""Natural language processing (almost) from scratch.""",Method,Data,Produce,Natural language processing (almost) from scratch,https://www.aclweb.org/anthology/J11-1003
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Stoyanov, V. (2019). ""RoBERTa: A robustly optimized BERT pretraining approach.""",Method,Data,Produce,RoBERTa: A robustly optimized BERT pretraining approach,https://www.aclweb.org/anthology/D19-529
"""Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., & Bowman, S. (2018). ""GLUE: A multi-task benchmark and analysis platform for natural language understanding.""",Method,Data,Produce,GLUE: A multi-task benchmark and analysis platform for natural language understanding,https://www.aclweb.org/anthology/W18-5446
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Method,Data,Produce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). ""Hierarchical attention networks for document classification.""",Method,Data,Produce,Hierarchical attention networks for document classification,https://www.aclweb.org/anthology/N16-1174
"""Johnson, R., & Zhang, T. (2015). ""Effective use of word order for text categorization with convolutional neural networks.""",Method,Data,Produce,Effective use of word order for text categorization with convolutional neural networks,https://www.aclweb.org/anthology/D15-1162
"""Pennington, J., Socher, R., & Manning, C. D. (2014). ""Glove: Global vectors for word representation.""",Method,Data,Produce,Glove: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Sennrich, R., Haddow, B., & Birch, A. (2016). ""Neural machine translation of rare words with subword units.""",Method,Data,Produce,Neural machine translation of rare words with subword units,https://www.aclweb.org/anthology/P16-1162
"""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is all you need.""",Method,Data,Produce,Attention is all you need,https://www.aclweb.org/anthology/P17-1162
"""He, K., Zhang, X., Ren, S., & Sun, J. (2016). ""Deep residual learning for image recognition.""",Method,Data,Produce,Deep residual learning for image recognition,https://www.aclweb.org/anthology/C16-1132
"""Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., ... & Smith, N. A. (2018). ""Deep contextualized word representations.""",Method,Data,Produce,Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202
"""Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). ""Neural architectures for named entity recognition.""",Method,Data,Produce,Neural architectures for named entity recognition,https://www.aclweb.org/anthology/N16-1030
"""Ruder, S., Vulić, I., & Søgaard, A. (2017). ""A survey of cross-lingual word embedding models.""",Method,Data,Produce,A survey of cross-lingual word embedding models,https://www.aclweb.org/anthology/P17-1042
"""Blevins, T., & Ghosh, S. (2018). ""Deep imitation learning for complex manipulation tasks from virtual reality teleoperation.""",Method,Data,Produce,Deep imitation learning for complex manipulation tasks from virtual reality teleoperation,https://www.aclweb.org/anthology/D18-1001
"""Zhang, Y., & Wallace, B. (2015). ""A sensitivity analysis of (and practitioners' guide to) convolutional neural networks for sentence classification.""",Method,Data,Produce,A sensitivity analysis of (and practitioners' guide to) convolutional neural networks for sentence classification,https://www.aclweb.org/anthology/D15-1167
"""Vaswani, A., Bengio, S., Boulanger-Lewandowski, N., & Bengio, Y. (2013). ""The application of LSTM-RTRBM in temporal modeling of speech.""",Method,Data,Produce,The application of LSTM-RTRBM in temporal modeling of speech,https://www.aclweb.org/anthology/W13-3217
"""Kim, Y. (2014). ""Convolutional neural networks for sentence classification.""",Method,Data,Produce,Convolutional neural networks for sentence classification,https://www.aclweb.org/anthology/D14-118
"""Ruder, S., & Plank, B. (2018). ""Strong baselines for neural semi-supervised learning under domain shift.""",Method,Data,Introduce,Strong baselines for neural semi-supervised learning under domain shift,https://www.aclweb.org/anthology/P18-1004
"""Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). ""Attention is all you need.""",Method,Data,Introduce,Attention is all you need,https://www.aclweb.org/anthology/P17-1162
"""Johnson, R., & Zhang, T. (2015). ""Effective use of word order for text categorization with convolutional neural networks.""",Method,Data,Introduce,Effective use of word order for text categorization with convolutional neural networks,https://www.aclweb.org/anthology/D15-1162
"""Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). ""Distributed representations of words and phrases and their compositionality.""",Method,Data,Introduce,Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). ""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Method,Data,Introduce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""Sennrich, R., Haddow, B., & Birch, A. (2016). ""Improving neural machine translation models with monolingual data.""",Method,Data,Introduce,Improving neural machine translation models with monolingual data,https://www.aclweb.org/anthology/P16-1009
"""Manning, C. D., Surdeanu, M., Bauer, J., Finkel, J. R., Bethard, S., & McClosky, D. (2014). ""The Stanford CoreNLP natural language processing toolkit.""",Method,Data,Introduce,The Stanford CoreNLP natural language processing toolkit,https://www.aclweb.org/anthology/P14-5010
"""Zhang, X., Zhao, J., & LeCun, Y. (2015). ""Character-level convolutional networks for text classification.""",Method,Data,Introduce,Character-level convolutional networks for text classification,https://www.aclweb.org/anthology/P15-1162
"""Ruder, S., Vulić, I., & Søgaard, A. (2017). ""A survey of cross-lingual word embedding models.""",Method,Data,Introduce,A survey of cross-lingual word embedding models,https://www.aclweb.org/anthology/P17-1042
"""Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., & Salakhutdinov, R. (2019). ""Transformer-XL: Attentive language models beyond a fixed-length context.""",Method,Data,Introduce,Transformer-XL: Attentive language models beyond a fixed-length context,https://www.aclweb.org/anthology/P19-1285
"""Pennington, J., Socher, R., & Manning, C. D. (2014). ""Glove: Global vectors for word representation.""",Method,Data,Introduce,Glove: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., & Hovy, E. (2016). ""Hierarchical attention networks for document classification.""",Method,Data,Introduce,Hierarchical attention networks for document classification,https://www.aclweb.org/anthology/N16-1174
"""Kiros, R., Zhu, Y., Salakhutdinov, R. R., Zemel, R., Urtasun, R., Torralba, A., & Fidler, S. (2015). ""Skip-thought vectors.""",Method,Data,Introduce,Skip-thought vectors,https://www.aclweb.org/anthology/P15-1162
"""Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., ... & Smith, N. A. (2018). ""Deep contextualized word representations.""",Method,Data,Introduce,Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Stoyanov, V. (2019). ""RoBERTa: A robustly optimized BERT pretraining approach.""",Method,Data,Introduce,RoBERTa: A robustly optimized BERT pretraining approach,https://www.aclweb.org/anthology/D19-529
"""Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., & Dyer, C. (2016). ""Neural architectures for named entity recognition.""",Method,Data,Introduce,Neural architectures for named entity recognition,https://www.aclweb.org/anthology/N16-1030
"""Bowman, S. R., Angeli, G., Potts, C., & Manning, C. D. (2015). ""A large annotated corpus for learning natural language inference.""",Method,Data,Introduce,A large annotated corpus for learning natural language inference,https://www.aclweb.org/anthology/N15-1020
"""Chen, D., & Manning, C. D. (2014). ""A fast and accurate dependency parser using neural networks.""",Method,Data,Introduce,A fast and accurate dependency parser using neural networks,https://www.aclweb.org/anthology/P14-2013
"""Lewis, M., Yarats, D., Dauphin, Y., Parikh, D., & Batra, D. (2020). ""Pretraining via Paraphrasing.""",Supplement,Data,Use,Pretraining via Paraphrasing,https://www.aclweb.org/anthology/2020.acl-main.740
"""Huang, K., & Yates, A. (2020). ""Accelerating Neural Transformer via an Average Attention Network.""",Supplement,Data,Use,Accelerating Neural Transformer via an Average Attention Network,https://www.aclweb.org/anthology/2020.acl-main.412
"""Jin, X., Xu, Z., & Pang, L. (2020). ""Is It Time to Swish? Comparing Deep Learning Activation Functions Across NLP tasks.""",Supplement,Data,Use,Is It Time to Swish? Comparing Deep Learning Activation Functions Across NLP tasks,https://www.aclweb.org/anthology/2020.acl-main.415
"""Wei, J., Wu, Z., & Zhou, M. (2019). ""EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks.""",Supplement,Data,Use,EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks,https://www.aclweb.org/anthology/D19-1670
"""Phang, J., Févry, T., & Bowman, S. (2018). ""Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks.""",Supplement,Data,Use,Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks,https://www.aclweb.org/anthology/D18-1527
"""McCann, B., Bradbury, J., Xiong, C., & Socher, R. (2017). ""Learned in translation: contextualized word vectors.""",Supplement,Data,Use,Learned in translation: contextualized word vectors,https://www.aclweb.org/anthology/P17-1044
"""Xie, Q., Dai, Z., Du, X., & Hovy, E. (2017). ""Controllable invariance through adversarial feature learning.""",Supplement,Data,Use,Controllable invariance through adversarial feature learning,https://www.aclweb.org/anthology/P17-1137
"""Jiang, Z., Zhao, W., He, Y., & Chen, Y. (2017). ""Understanding latent interactions in neural sequence models for multi-turn response generation.""",Supplement,Data,Use,Understanding latent interactions in neural sequence models for multi-turn response generation,https://www.aclweb.org/anthology/P17-1046
"""Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., ... & Stoyanov, V. (2019). ""RoBERTa: A robustly optimized BERT pretraining approach.""",Supplement,Data,Use,RoBERTa: A robustly optimized BERT pretraining approach,https://www.aclweb.org/anthology/D19-529
"""Yu, H., Zhang, H., Zhang, D., & Cheng, X. (2016). ""Modeling word forms using latent-dense embeddings.""",Supplement,Data,Use,Modeling word forms using latent-dense embeddings,https://www.aclweb.org/anthology/D16-1136
"""Clark, K., & Manning, C. D. (2016). ""Deep reinforcement learning for mention-ranking coreference models.""",Supplement,Data,Use,Deep reinforcement learning for mention-ranking coreference models,https://www.aclweb.org/anthology/P16-1101
"""Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). ""Efficient estimation of word representations in vector space.""",Supplement,Data,Use,Efficient estimation of word representations in vector space,https://www.aclweb.org/anthology/N13-1090
"""Kiros, R., Zhu, Y., Salakhutdinov, R., Zemel, R., Urtasun, R., Torralba, A., & Fidler, S. (2015). ""Skip-thought vectors.""",Supplement,Data,Use,Skip-thought vectors,https://www.aclweb.org/anthology/P15-1162
"""Zhang, X., Zhao, J., & LeCun, Y. (2015). ""Character-level convolutional networks for text classification.""",Supplement,Data,Use,Character-level convolutional networks for text classification,https://www.aclweb.org/anthology/P15-1162
"""Ruder, S., & Plank, B. (2018). ""Strong baselines for neural semi-supervised learning under domain shift.""",Supplement,Data,Use,Strong baselines for neural semi-supervised learning under domain shift,https://www.aclweb.org/anthology/P18-1004
"""Chen, X., Liu, Z., Sun, M., & Zhu, X. (2017). ""A unified model for opinion target extraction and target sentiment prediction.""",Supplement,Data,Use,A unified model for opinion target extraction and target sentiment prediction,https://www.aclweb.org/anthology/P17-1046
"""He, Y., Gimpel, K., & Lin, J. (2015). ""Multi-perspective sentence similarity modeling with convolutional neural networks.""",Supplement,Data,Use,Multi-perspective sentence similarity modeling with convolutional neural networks,https://www.aclweb.org/anthology/D15-1181
"""Shen, Y., He, X., Gao, J., Deng, L., & Mesnil, G. (2014). ""A latent semantic model with convolutional-pooling structure for information retrieval.""",Supplement,Data,Use,A latent semantic model with convolutional-pooling structure for information retrieval,https://www.aclweb.org/anthology/P14-1061
"""Hermann, K. M., Kocisky, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman, M., & Blunsom, P. (2015). ""Teaching machines to read and comprehend.""",Supplement,Data,Use,Teaching machines to read and comprehend,https://www.aclweb.org/anthology/D15-1165
"""Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q. V., & Salakhutdinov, R. (2019). ""Transformer-XL: Attentive language models beyond a fixed-length context.""",Supplement,Data,Use,Transformer-XL: Attentive language models beyond a fixed-length context,https://www.aclweb.org/anthology/P19-1285
"""Transformer-XL: Attentive language models beyond a fixed-length context.""",Supplement,Data,Use,Transformer-XL: Attentive language models beyond a fixed-length context,https://www.aclweb.org/anthology/P19-1285
"""Knowledge-guided dialogue generation with pre-trained language models.""",Supplement,Data,Introduce,Knowledge-guided dialogue generation with pre-trained language models,https://www.aclweb.org/anthology/P19-1185.pdf
"""Enhancing aspect term extraction with weakly labeled data.""",Supplement,Data,Introduce,Enhancing aspect term extraction with weakly labeled data,https://www.aclweb.org/anthology/2020.acl-main.494.pdf
"""BERT for joint intent classification and slot filling.""",Supplement,Data,Introduce,BERT for joint intent classification and slot filling,https://www.aclweb.org/anthology/2020.acl-main.253.pdf
"""RoBERTa: A robustly optimized BERT pretraining approach.""",Supplement,Data,Introduce,RoBERTa: A robustly optimized BERT pretraining approach,https://www.aclweb.org/anthology/D19-5434.pdf
"""Beyond accuracy: Behavioral testing of NLP models with CheckList.""",Supplement,Data,Introduce,Beyond accuracy: Behavioral testing of NLP models with CheckList,https://www.aclweb.org/anthology/2020.acl-main.35.pdf
"""Contextualized embeddings for citation recommendation.""",Supplement,Data,Introduce,Contextualized embeddings for citation recommendation,https://www.aclweb.org/anthology/P19-1243.pdf
"""A survey on dialogue systems: Recent advances and new frontiers.""",Supplement,Data,Introduce,A survey on dialogue systems: Recent advances and new frontiers,https://www.aclweb.org/anthology/2021.acl-srw.1.pdf
"""Probing the linguistic knowledge of character-level neural language models.""",Supplement,Data,Introduce,Probing the linguistic knowledge of character-level neural language models,https://www.aclweb.org/anthology/2020.acl-main.661.pdf
"""A comparative study on pre-trained representations for English, German, and Chinese.""",Supplement,Data,Introduce,"A comparative study on pre-trained representations for English, German, and Chinese",https://www.aclweb.org/anthology/2020.acl-main.660.pdf
"""Unsupervised cross-lingual representation learning at scale.""",Supplement,Data,Introduce,Unsupervised cross-lingual representation learning at scale,https://www.aclweb.org/anthology/2020.acl-main.663.pdf
"""Exploring neural architectures for language generation in dialogue systems.""",Supplement,Data,Introduce,Exploring neural architectures for language generation in dialogue systems,https://www.aclweb.org/anthology/2020.acl-main.665.pdf
"""Multi-turn response selection for chatbots with deep attention matching network.""",Supplement,Data,Introduce,Multi-turn response selection for chatbots with deep attention matching network,https://www.aclweb.org/anthology/2020.acl-main.677.pdf
"""Investigating the impact of task-oriented dialogue system response generation on user evaluation.""",Supplement,Data,Introduce,Investigating the impact of task-oriented dialogue system response generation on user evaluation,https://www.aclweb.org/anthology/2020.acl-main.716.pdf
"""A context-aware hierarchical attention network with adaptive objective for dialogue state tracking.""",Supplement,Data,Introduce,A context-aware hierarchical attention network with adaptive objective for dialogue state tracking,https://www.aclweb.org/anthology/2020.acl-main.717.pdf
"""SentenceBERT: Sentence embeddings using Siamese BERT-networks.""",Supplement,Data,Introduce,SentenceBERT: Sentence embeddings using Siamese BERT-networks,https://www.aclweb.org/anthology/2020.acl-main.735.pdf
"""Domain generalization with adversarial feature learning.""",Supplement,Data,Introduce,Domain generalization with adversarial feature learning,https://www.aclweb.org/anthology/2020.acl-main.736.pdf
"""A neural approach to conversational entity disambiguation.""",Supplement,Data,Introduce,A neural approach to conversational entity disambiguation,https://www.aclweb.org/anthology/2020.acl-main.774.pdf
"""Dialogue system for information-seeking conversations.""",Supplement,Data,Introduce,Dialogue system for information-seeking conversations,https://www.aclweb.org/anthology/2020.acl-main.776.pdf
"""Incorporating context information with graph convolutional networks for relational entity alignment.""",Supplement,Data,Introduce,Incorporating context information with graph convolutional networks for relational entity alignment,[https://www.aclweb.org/anthology/2020.acl-main.
"""Improving machine reading comprehension with general reading strategies.""",Supplement,Data,Produce,Improving machine reading comprehension with general reading strategies,https://www.aclweb.org/anthology/P17-1078.pdf
"""Joint learning of named entity recognition and entity linking.""",Supplement,Data,Produce,Joint learning of named entity recognition and entity linking,https://www.aclweb.org/anthology/D17-1239.pdf
"""Neural architectures for fine-grained entity type classification.""",Supplement,Data,Produce,Neural architectures for fine-grained entity type classification,https://www.aclweb.org/anthology/P18-1056.pdf
"""Transfer learning for context-aware question answering systems.""",Supplement,Data,Produce,Transfer learning for context-aware question answering systems,https://www.aclweb.org/anthology/P18-2124.pdf
"""Deep contextualized word representations.""",Supplement,Data,Produce,Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202.pdf
"""Character-level convolutional networks for text classification.""",Supplement,Data,Produce,Character-level convolutional networks for text classification,https://www.aclweb.org/anthology/D15-1162.pdf
"""End-to-end relation extraction using LSTMs on sequences and tree structures.""",Supplement,Data,Produce,End-to-end relation extraction using LSTMs on sequences and tree structures,https://www.aclweb.org/anthology/P16-1105.pdf
"""Semi-supervised sequence tagging with bidirectional language models.""",Supplement,Data,Produce,Semi-supervised sequence tagging with bidirectional language models,https://www.aclweb.org/anthology/P17-1161.pdf
"""Adversarial domain adaptation for machine reading comprehension.""",Supplement,Data,Produce,Adversarial domain adaptation for machine reading comprehension,https://www.aclweb.org/anthology/D17-1301.pdf
"""Improving multi-task deep neural networks via knowledge distillation for natural language understanding.""",Supplement,Data,Produce,Improving multi-task deep neural networks via knowledge distillation for natural language understanding,https://www.aclweb.org/anthology/P18-1144.pdf
"""Named entity recognition with parallel recurrent neural networks.""",Supplement,Data,Produce,Named entity recognition with parallel recurrent neural networks,https://www.aclweb.org/anthology/P15-1109.pdf
"""Generating more interesting responses in neural conversation models with distributional constraints.""",Supplement,Data,Produce,Generating more interesting responses in neural conversation models with distributional constraints,https://www.aclweb.org/anthology/P17-1167.pdf
"""Densely connected neural networks.""",Supplement,Data,Produce,Densely connected neural networks,https://www.aclweb.org/anthology/P18-1133.pdf
"""Adversarial training methods for semi-supervised text classification.""",Supplement,Data,Produce,Adversarial training methods for semi-supervised text classification,https://www.aclweb.org/anthology/P16-1187.pdf
"""Graph convolutional networks for text classification.""",Supplement,Data,Produce,Graph convolutional networks for text classification,https://www.aclweb.org/anthology/P18-1034.pdf
"""A convolutional neural network for modeling sentences.""",Supplement,Data,Produce,A convolutional neural network for modeling sentences,https://www.aclweb.org/anthology/P14-1062.pdf
"""Character-aware neural language models.""",Supplement,Data,Produce,Character-aware neural language models,https://www.aclweb.org/anthology/P15-1162.pdf
"""Attention-based convolutional neural network for machine comprehension.""",Supplement,Data,Produce,Attention-based convolutional neural network for machine comprehension,https://www.aclweb.org/anthology/P16-1231.pdf
"""Recurrent convolutional neural networks for text classification.""",Supplement,Data,Produce,Recurrent convolutional neural networks for text classification,https://www.aclweb.org/anthology/P15-1101.pdf
"""Boosting transition-based parsing with neural representations.""",Supplement,Data,Produce,Boosting transition-based parsing with neural representations,https://www.aclweb.org/anthology/P15-1120.pdf
"""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Supplement,Tool,Use,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""GloVe: Global vectors for word representation.""",Supplement,Tool,Use,GloVe: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Word2Vec: Distributed representations of words and phrases and their compositionality.""",Supplement,Tool,Use,Word2Vec: Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""ELMo: Deep contextualized word representations.""",Supplement,Tool,Use,ELMo: Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202
"""The Stanford CoreNLP natural language processing toolkit.""",Supplement,Tool,Use,The Stanford CoreNLP natural language processing toolkit,https://www.aclweb.org/anthology/P14-5010
"""Stanford Parser: A statistical parser.""",Supplement,Tool,Use,Stanford Parser: A statistical parser,https://www.aclweb.org/anthology/P14-5010
"""SpaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing.""",Supplement,Tool,Use,"SpaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing",https://www.aclweb.org/anthology/D17-2017
"""AllenNLP: A deep semantic natural language processing platform.""",Supplement,Tool,Use,AllenNLP: A deep semantic natural language processing platform,https://www.aclweb.org/anthology/N18-2017
"""SQuAD: 100,000+ questions for machine comprehension of text.""",Supplement,Tool,Use,"SQuAD: 100,000+ questions for machine comprehension of text",https://www.aclweb.org/anthology/D16-1264
"""OpenAI GPT: Language models are unsupervised multitask learners.""",Supplement,Tool,Use,OpenAI GPT: Language models are unsupervised multitask learners,https://www.aclweb.org/anthology/N19-1423
"""PyTorch: An imperative style, high-performance deep learning library.""",Supplement,Tool,Use,"PyTorch: An imperative style, high-performance deep learning library",https://www.aclweb.org/anthology/N19-1423
"""fastText: Enriching word vectors with subword information.""",Supplement,Tool,Use,fastText: Enriching word vectors with subword information,https://www.aclweb.org/anthology/Q17-1010
"""Theano: A Python framework for fast computation of mathematical expressions.""",Supplement,Tool,Use,Theano: A Python framework for fast computation of mathematical expressions,https://www.aclweb.org/anthology/P16-1054
"""NLTK: The Natural Language Toolkit.""",Supplement,Tool,Use,NLTK: The Natural Language Toolkit,https://www.aclweb.org/anthology/I08-1058
"""Google Cloud Natural Language API: A comprehensive review.""",Supplement,Tool,Use,Google Cloud Natural Language API: A comprehensive review,https://www.aclweb.org/anthology/W18-5515
"""XGBoost: A scalable tree boosting system.""",Supplement,Tool,Use,XGBoost: A scalable tree boosting system,https://www.aclweb.org/anthology/P16-1130
"""SciKit-Learn: Machine learning in Python.""",Supplement,Tool,Use,SciKit-Learn: Machine learning in Python,https://www.aclweb.org/anthology/P12-2018
"""Gensim: Topic modelling for humans.""",Supplement,Tool,Use,Gensim: Topic modelling for humans,https://www.aclweb.org/anthology/P10-1149
"""Torchtext: Data handling for NLP.""",Supplement,Tool,Use,Torchtext: Data handling for NLP,https://www.aclweb.org/anthology/P17-1075
"""PyTorch-BigGraph: A large-scale graph embedding system.""",Supplement,Tool,Use,PyTorch-BigGraph: A large-scale graph embedding system,https://www.aclweb.org/anthology/P18-1246
"""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Supplement,Tool,Produce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""GloVe: Global vectors for word representation.""",Supplement,Tool,Produce,GloVe: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Word2Vec: Distributed representations of words and phrases and their compositionality.""",Supplement,Tool,Produce,Word2Vec: Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""ELMo: Deep contextualized word representations.""",Supplement,Tool,Produce,ELMo: Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202
"""The Stanford CoreNLP natural language processing toolkit.""",Supplement,Tool,Produce,The Stanford CoreNLP natural language processing toolkit,https://www.aclweb.org/anthology/P14-5010
"""Stanford Parser: A statistical parser.""",Supplement,Tool,Produce,Stanford Parser: A statistical parser,https://www.aclweb.org/anthology/P14-5010
"""SpaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing.""",Supplement,Tool,Produce,"SpaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing",https://www.aclweb.org/anthology/D17-2017
"""AllenNLP: A deep semantic natural language processing platform.""",Supplement,Tool,Produce,AllenNLP: A deep semantic natural language processing platform,https://www.aclweb.org/anthology/N18-2017
"""SQuAD: 100,000+ questions for machine comprehension of text.""",Supplement,Tool,Produce,"SQuAD: 100,000+ questions for machine comprehension of text",https://www.aclweb.org/anthology/D16-1264
"""OpenAI GPT: Language models are unsupervised multitask learners.""",Supplement,Tool,Produce,OpenAI GPT: Language models are unsupervised multitask learners,https://www.aclweb.org/anthology/N19-1423
"""PyTorch: An imperative style, high-performance deep learning library.""",Supplement,Tool,Produce,"PyTorch: An imperative style, high-performance deep learning library",https://www.aclweb.org/anthology/N19-1423
"""fastText: Enriching word vectors with subword information.""",Supplement,Tool,Produce,fastText: Enriching word vectors with subword information,https://www.aclweb.org/anthology/Q17-1010
"""Theano: A Python framework for fast computation of mathematical expressions.""",Supplement,Tool,Produce,Theano: A Python framework for fast computation of mathematical expressions,https://www.aclweb.org/anthology/P16-1054
"""NLTK: The Natural Language Toolkit.""",Supplement,Tool,Produce,NLTK: The Natural Language Toolkit,https://www.aclweb.org/anthology/I08-1058
"""Google Cloud Natural Language API: A comprehensive review.""",Supplement,Tool,Produce,Google Cloud Natural Language API: A comprehensive review,https://www.aclweb.org/anthology/W18-5515
"""XGBoost: A scalable tree boosting system.""",Supplement,Tool,Produce,XGBoost: A scalable tree boosting system,https://www.aclweb.org/anthology/P16-1130
"""SciKit-Learn: Machine learning in Python.""",Supplement,Tool,Produce,SciKit-Learn: Machine learning in Python,https://www.aclweb.org/anthology/P12-2018
"""Gensim: Topic modelling for humans.""",Supplement,Tool,Produce,Gensim: Topic modelling for humans,https://www.aclweb.org/anthology/P10-1149
"""Torchtext: Data handling for NLP.""",Supplement,Tool,Produce,Torchtext: Data handling for NLP,https://www.aclweb.org/anthology/P17-1075
"""PyTorch-BigGraph: A large-scale graph embedding system.""",Supplement,Tool,Produce,PyTorch-BigGraph: A large-scale graph embedding system,https://www.aclweb.org/anthology/P18-1246
"""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Supplement,Tool,Introduce,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""GloVe: Global vectors for word representation.""",Supplement,Tool,Introduce,GloVe: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Word2Vec: Distributed representations of words and phrases and their compositionality.""",Supplement,Tool,Introduce,Word2Vec: Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""ELMo: Deep contextualized word representations.""",Supplement,Tool,Introduce,ELMo: Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202
"""The Stanford CoreNLP natural language processing toolkit.""",Supplement,Tool,Introduce,The Stanford CoreNLP natural language processing toolkit,https://www.aclweb.org/anthology/P14-5010
"""Stanford Parser: A statistical parser.""",Supplement,Tool,Introduce,Stanford Parser: A statistical parser,https://www.aclweb.org/anthology/P14-5010
"""SpaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing.""",Supplement,Tool,Introduce,"SpaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing",https://www.aclweb.org/anthology/D17-2017
"""AllenNLP: A deep semantic natural language processing platform.""",Supplement,Tool,Introduce,AllenNLP: A deep semantic natural language processing platform,https://www.aclweb.org/anthology/N18-2017
"""SQuAD: 100,000+ questions for machine comprehension of text.""",Supplement,Tool,Introduce,"SQuAD: 100,000+ questions for machine comprehension of text",https://www.aclweb.org/anthology/D16-1264
"""OpenAI GPT: Language models are unsupervised multitask learners.""",Supplement,Tool,Introduce,OpenAI GPT: Language models are unsupervised multitask learners,https://www.aclweb.org/anthology/N19-1423
"""PyTorch: An imperative style, high-performance deep learning library.""",Supplement,Tool,Introduce,"PyTorch: An imperative style, high-performance deep learning library",https://www.aclweb.org/anthology/N19-1423
"""fastText: Enriching word vectors with subword information.""",Supplement,Tool,Introduce,fastText: Enriching word vectors with subword information,https://www.aclweb.org/anthology/Q17-1010
"""Theano: A Python framework for fast computation of mathematical expressions.""",Supplement,Tool,Introduce,Theano: A Python framework for fast computation of mathematical expressions,https://www.aclweb.org/anthology/P16-1054
"""NLTK: The Natural Language Toolkit.""",Supplement,Tool,Introduce,NLTK: The Natural Language Toolkit,https://www.aclweb.org/anthology/I08-1058
"""Google Cloud Natural Language API: A comprehensive review.""",Supplement,Tool,Introduce,Google Cloud Natural Language API: A comprehensive review,https://www.aclweb.org/anthology/W18-5515
"""XGBoost: A scalable tree boosting system.""",Supplement,Tool,Introduce,XGBoost: A scalable tree boosting system,https://www.aclweb.org/anthology/P16-1130
"""SciKit-Learn: Machine learning in Python.""",Supplement,Tool,Introduce,SciKit-Learn: Machine learning in Python,https://www.aclweb.org/anthology/P12-2018
"""Gensim: Topic modelling for humans.""",Supplement,Tool,Introduce,Gensim: Topic modelling for humans,https://www.aclweb.org/anthology/P10-1149
"""Torchtext: Data handling for NLP.""",Supplement,Tool,Introduce,Torchtext: Data handling for NLP,https://www.aclweb.org/anthology/P17-1075
"""PyTorch-BigGraph: A large-scale graph embedding system.""",Supplement,Tool,Introduce,PyTorch-BigGraph: A large-scale graph embedding system,https://www.aclweb.org/anthology/P18-1246
"""BERT: Pre-training of deep bidirectional transformers for language understanding.""",Supplement,Code,Use,BERT: Pre-training of deep bidirectional transformers for language understanding,https://www.aclweb.org/anthology/N19-1423
"""GloVe: Global vectors for word representation.""",Supplement,Code,Use,GloVe: Global vectors for word representation,https://www.aclweb.org/anthology/D14-1162
"""Word2Vec: Distributed representations of words and phrases and their compositionality.""",Supplement,Code,Use,Word2Vec: Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""ELMo: Deep contextualized word representations.""",Supplement,Code,Use,ELMo: Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202
"""The Stanford CoreNLP natural language processing toolkit.""",Supplement,Code,Use,The Stanford CoreNLP natural language processing toolkit,https://www.aclweb.org/anthology/P14-5010
"""Stanford Parser: A statistical parser.""",Supplement,Code,Use,Stanford Parser: A statistical parser,https://www.aclweb.org/anthology/P14-5010
"""SpaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing.""",Supplement,Code,Use,"SpaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing",https://www.aclweb.org/anthology/D17-2017
"""AllenNLP: A deep semantic natural language processing platform.""",Supplement,Code,Use,AllenNLP: A deep semantic natural language processing platform,https://www.aclweb.org/anthology/N18-2017
"""SQuAD: 100,000+ questions for machine comprehension of text.""",Supplement,Code,Use,"SQuAD: 100,000+ questions for machine comprehension of text",https://www.aclweb.org/anthology/D16-1264
"""OpenAI GPT: Language models are unsupervised multitask learners.""",Supplement,Code,Use,OpenAI GPT: Language models are unsupervised multitask learners,https://www.aclweb.org/anthology/N19-1423
"""PyTorch: An imperative style, high-performance deep learning library.""",Supplement,Code,Use,"PyTorch: An imperative style, high-performance deep learning library",https://www.aclweb.org/anthology/N19-1423
"""fastText: Enriching word vectors with subword information.""",Supplement,Code,Use,fastText: Enriching word vectors with subword information,https://www.aclweb.org/anthology/Q17-1010
"""Theano: A Python framework for fast computation of mathematical expressions.""",Supplement,Code,Use,Theano: A Python framework for fast computation of mathematical expressions,https://www.aclweb.org/anthology/P16-1054
"""NLTK: The Natural Language Toolkit.""",Supplement,Code,Use,NLTK: The Natural Language Toolkit,https://www.aclweb.org/anthology/I08-1058
"""Google Cloud Natural Language API: A comprehensive review.""",Supplement,Code,Use,Google Cloud Natural Language API: A comprehensive review,https://www.aclweb.org/anthology/W18-5515
"""XGBoost: A scalable tree boosting system.""",Supplement,Code,Use,XGBoost: A scalable tree boosting system,https://www.aclweb.org/anthology/P16-1130
"""SciKit-Learn: Machine learning in Python.""",Supplement,Code,Use,SciKit-Learn: Machine learning in Python,https://www.aclweb.org/anthology/P12-2018
"""Gensim: Topic modelling for humans.""",Supplement,Code,Use,Gensim: Topic modelling for humans,https://www.aclweb.org/anthology/P10-1149
"""Torchtext: Data handling for NLP.""",Supplement,Code,Use,Torchtext: Data handling for NLP,https://www.aclweb.org/anthology/P17-1075
"""PyTorch-BigGraph: A large-scale graph embedding system.""",Supplement,Code,Use,PyTorch-BigGraph: A large-scale graph embedding system,https://www.aclweb.org/anthology/P18-1246
"""Generating Wikipedia by summarizing long sequences.""",Supplement,Code,Produce,Generating Wikipedia by summarizing long sequences,https://www.aclweb.org/anthology/D16-1038
"""Improving neural machine translation models with monolingual data.""",Supplement,Code,Produce,Improving neural machine translation models with monolingual data,https://www.aclweb.org/anthology/P16-1009
"""Style transfer from non-parallel text by cross-alignment.""",Supplement,Code,Produce,Style transfer from non-parallel text by cross-alignment,https://www.aclweb.org/anthology/P17-1134
"""Adversarially regularized autoencoders for generating discrete structures.""",Supplement,Code,Produce,Adversarially regularized autoencoders for generating discrete structures,https://www.aclweb.org/anthology/P17-1098
"""End-to-end memory networks.""",Supplement,Code,Produce,End-to-end memory networks,https://www.aclweb.org/anthology/D15-1247
"""A neural generative model for names in transliterated languages.""",Supplement,Code,Produce,A neural generative model for names in transliterated languages,https://www.aclweb.org/anthology/D17-1106
"""A sequence-to-sequence model for user simulation in spoken dialogue systems.""",Supplement,Code,Produce,A sequence-to-sequence model for user simulation in spoken dialogue systems,https://www.aclweb.org/anthology/P17-1123
"""Toward controlled generation of text.""",Supplement,Code,Produce,Toward controlled generation of text,https://www.aclweb.org/anthology/P17-1046
"""A generative model for joint learning of visual attribute representation and object recognition.""",Supplement,Code,Produce,A generative model for joint learning of visual attribute representation and object recognition,https://www.aclweb.org/anthology/P14-1005
"""Learning to translate in real-time with neural machine translation.""",Supplement,Code,Produce,Learning to translate in real-time with neural machine translation,https://www.aclweb.org/anthology/P16-2036
"""Generating sentences from a continuous space.""",Supplement,Code,Produce,Generating sentences from a continuous space,https://www.aclweb.org/anthology/N13-1090
"""Unsupervised machine translation using monolingual corpora only.""",Supplement,Code,Produce,Unsupervised machine translation using monolingual corpora only,https://www.aclweb.org/anthology/P18-1009
"""Robust multilingual named entity recognition via neural word representations.""",Supplement,Code,Produce,Robust multilingual named entity recognition via neural word representations,https://www.aclweb.org/anthology/P16-1136
"""A neural attention model for abstractive sentence summarization.""",Supplement,Code,Produce,A neural attention model for abstractive sentence summarization,https://www.aclweb.org/anthology/P15-1018
"""Language modeling with gated convolutional networks.""",Supplement,Code,Produce,Language modeling with gated convolutional networks,https://www.aclweb.org/anthology/P17-1146
"""Generating typed dependency parses from phrase structure parses.""",Supplement,Code,Produce,Generating typed dependency parses from phrase structure parses,https://www.aclweb.org/anthology/D12-1054
"""A neural generative question answering model.""",Supplement,Code,Produce,A neural generative question answering model,https://www.aclweb.org/anthology/D16-1145
"""Stochastic language generation in dialogue using recurrent neural networks with convolutional sentence reranking.""",Supplement,Code,Produce,Stochastic language generation in dialogue using recurrent neural networks with convolutional sentence reranking,https://www.aclweb.org/anthology/D16-1129
"""Neural variational inference for text processing.""",Supplement,Code,Produce,Neural variational inference for text processing,https://www.aclweb.org/anthology/D15-1206
"""Multilingual neural machine translation with task-specific attention.""",Supplement,Code,Produce,Multilingual neural machine translation with task-specific attention,https://www.aclweb.org/anthology/P16-1159
"""Code-switched sentiment analysis with a deep multilingual model.""",Supplement,Code,Introduce,Code-switched sentiment analysis with a deep multilingual model,https://www.aclweb.org/anthology/D18-1489
"""End-to-end morphosyntax disambiguation with recurrent neural networks.""",Supplement,Code,Introduce,End-to-end morphosyntax disambiguation with recurrent neural networks,https://www.aclweb.org/anthology/P16-1134
"""A multitask learning framework for improving genre-specific question generation.""",Supplement,Code,Introduce,A multitask learning framework for improving genre-specific question generation,https://www.aclweb.org/anthology/N19-1020
"""Lifelong learning for sentiment classification of tweets.""",Supplement,Code,Introduce,Lifelong learning for sentiment classification of tweets,https://www.aclweb.org/anthology/W17-3509
"""Understanding LSTM networks.""",Supplement,Code,Introduce,Understanding LSTM networks,https://www.aclweb.org/anthology/P17-1137
"""A memory network approach for discourse entity recognition.""",Supplement,Code,Introduce,A memory network approach for discourse entity recognition,https://www.aclweb.org/anthology/P17-2049
"""A dual neural network model for paraphrase generation.""",Supplement,Code,Introduce,A dual neural network model for paraphrase generation,https://www.aclweb.org/anthology/P17-1110
"""A joint model of intent determination and slot filling for spoken language understanding.""",Supplement,Code,Introduce,A joint model of intent determination and slot filling for spoken language understanding,https://www.aclweb.org/anthology/W16-3608
"""Learning semantic representations of users and products for document-level sentiment classification.""",Supplement,Code,Introduce,Learning semantic representations of users and products for document-level sentiment classification,https://www.aclweb.org/anthology/P17-1087
"""Syntax-based transfer learning for sentiment classification across domains.""",Supplement,Code,Introduce,Syntax-based transfer learning for sentiment classification across domains,https://www.aclweb.org/anthology/P14-2067
"""A review of the neural history of natural language processing.""",Supplement,Code,Introduce,A review of the neural history of natural language processing,https://www.aclweb.org/anthology/D18-1418
"""Improving low-resource cross-lingual entity linking by word alignment.""",Supplement,Code,Introduce,Improving low-resource cross-lingual entity linking by word alignment,https://www.aclweb.org/anthology/N19-1356
"""Cross-lingual name tagging and linking for 282 languages.""",Supplement,Code,Introduce,Cross-lingual name tagging and linking for 282 languages,https://www.aclweb.org/anthology/D18-1515
"""A contextual word embedding approach to anonymizing medical records.""",Supplement,Code,Introduce,A contextual word embedding approach to anonymizing medical records,https://www.aclweb.org/anthology/P19-1260
"""An empirical study of artificial neural networks for user session identification.""",Supplement,Code,Introduce,An empirical study of artificial neural networks for user session identification,https://www.aclweb.org/anthology/W17-6206
"""A comparison of greedy and optimal assessment methods for clinical automatic evaluation of machine translation.""",Supplement,Code,Introduce,A comparison of greedy and optimal assessment methods for clinical automatic evaluation of machine translation,https://www.aclweb.org/anthology/W18-2501
"""Improving factuality prediction with stance-based models.""",Supplement,Code,Introduce,Improving factuality prediction with stance-based models,https://www.aclweb.org/anthology/P18-2079
"""Translating dialects to standard arabic: The case of egyptian and levantine.""",Supplement,Code,Introduce,Translating dialects to standard arabic: The case of egyptian and levantine,https://www.aclweb.org/anthology/D19-1570
"""Improving event coreference resolution by jointly learning to rank.""",Supplement,Code,Introduce,Improving event coreference resolution by jointly learning to rank,https://www.aclweb.org/anthology/P15-1064
"""Multimodal sentiment analysis with word-level fusion and reinforcement learning.""",Supplement,Code,Introduce,Multimodal sentiment analysis with word-level fusion and reinforcement learning,https://www.aclweb.org/anthology/P18-1082
"""Improving machine translation performance by exploiting non-parallel corpora with bilingual constraints.""",Supplement,Algorithm,Use,Improving machine translation performance by exploiting non-parallel corpora with bilingual constraints,https://www.aclweb.org/anthology/D19-1285
"""Reinforcement learning for bandit neural machine translation with simulated human feedback.""",Supplement,Algorithm,Use,Reinforcement learning for bandit neural machine translation with simulated human feedback,https://www.aclweb.org/anthology/P19-1546
"""Robust neural machine translation for noisy input sequences.""",Supplement,Algorithm,Use,Robust neural machine translation for noisy input sequences,https://www.aclweb.org/anthology/P19-1457
"""Towards neural paraphrase identification.""",Supplement,Algorithm,Use,Towards neural paraphrase identification,https://www.aclweb.org/anthology/P19-1084
"""Sequence-to-sequence learning for end-to-end dialogue systems.""",Supplement,Algorithm,Use,Sequence-to-sequence learning for end-to-end dialogue systems,https://www.aclweb.org/anthology/P15-1152
"""Building end-to-end dialogue systems using generative hierarchical neural network models.""",Supplement,Algorithm,Use,Building end-to-end dialogue systems using generative hierarchical neural network models,https://www.aclweb.org/anthology/P15-1153
"""Incremental dialogue state tracking using hierarchical recurrent neural networks.""",Supplement,Algorithm,Use,Incremental dialogue state tracking using hierarchical recurrent neural networks,https://www.aclweb.org/anthology/P15-4006
"""Grammar as a foreign language.""",Supplement,Algorithm,Use,Grammar as a foreign language,https://www.aclweb.org/anthology/P18-2018
"""An efficient algorithm for overlap-aware query suggestion.""",Supplement,Algorithm,Use,An efficient algorithm for overlap-aware query suggestion,https://www.aclweb.org/anthology/W16-4002
"""Modeling context with user embeddings for sarcasm detection in social media.""",Supplement,Algorithm,Use,Modeling context with user embeddings for sarcasm detection in social media,https://www.aclweb.org/anthology/W17-4414
"""Multilayer segmental neural conditional random fields for aspect-based sentiment analysis.""",Supplement,Algorithm,Use,Multilayer segmental neural conditional random fields for aspect-based sentiment analysis,https://www.aclweb.org/anthology/P17-1095
"""Efficient convolutional neural networks for document classification.""",Supplement,Algorithm,Use,Efficient convolutional neural networks for document classification,https://www.aclweb.org/anthology/D15-1162
"""Neural variational inference for text processing.""",Supplement,Algorithm,Use,Neural variational inference for text processing,https://www.aclweb.org/anthology/P15-1038
"""Adversarial training methods for semi-supervised text classification.""",Supplement,Algorithm,Use,Adversarial training methods for semi-supervised text classification,https://www.aclweb.org/anthology/P17-1110
"""Syntax for semantic role labeling, to be, or not to be.""",Supplement,Algorithm,Use,"Syntax for semantic role labeling, to be, or not to be",https://www.aclweb.org/anthology/P17-1107
"""Learning to rank for neural machine translation.""",Supplement,Algorithm,Use,Learning to rank for neural machine translation,https://www.aclweb.org/anthology/P17-1029
"""Deep contextualized word representations.""",Supplement,Algorithm,Use,Deep contextualized word representations,https://www.aclweb.org/anthology/N18-1202
"""Dual learning for machine translation.""",Supplement,Algorithm,Use,Dual learning for machine translation,https://www.aclweb.org/anthology/P17-1168
"""A neural network approach to context-sensitive generation of conversational responses.""",Supplement,Algorithm,Use,A neural network approach to context-sensitive generation of conversational responses,https://www.aclweb.org/anthology/N15-1156
"""Graph convolution over pruned dependency trees improves relation extraction.""",Supplement,Algorithm,Use,Graph convolution over pruned dependency trees improves relation extraction,https://www.aclweb.org/anthology/N18-2003
"""Unsupervised named entity recognition: Training and evaluating on multiple datasets.""",Supplement,Algorithm,Produce,Unsupervised named entity recognition: Training and evaluating on multiple datasets,https://www.aclweb.org/anthology/D17-1076
"""Syntax for semantic role labeling, to be, or not to be.""",Supplement,Algorithm,Produce,"Syntax for semantic role labeling, to be, or not to be",https://www.aclweb.org/anthology/P17-1107
"""Structured attention networks.""",Supplement,Algorithm,Produce,Structured attention networks,https://www.aclweb.org/anthology/P15-1018
"""Revisiting character-based neural machine translation with capacity and compression.""",Supplement,Algorithm,Produce,Revisiting character-based neural machine translation with capacity and compression,https://www.aclweb.org/anthology/P17-1162
"""Compositional vector space models for knowledge base completion.""",Supplement,Algorithm,Produce,Compositional vector space models for knowledge base completion,https://www.aclweb.org/anthology/P14-2075
"""Text classification and named entities for temporal information retrieval.""",Supplement,Algorithm,Produce,Text classification and named entities for temporal information retrieval,https://www.aclweb.org/anthology/D16-1045
"""Towards a theory of lexical semantics.""",Supplement,Algorithm,Produce,Towards a theory of lexical semantics,https://www.aclweb.org/anthology/D08-1005
"""Simple, fast, accurate deep learning for natural language processing.""",Supplement,Algorithm,Produce,"Simple, fast, accurate deep learning for natural language processing",https://www.aclweb.org/anthology/P18-1031
"""A simple and effective approach to named entity recognition for Chinese.""",Supplement,Algorithm,Produce,A simple and effective approach to named entity recognition for Chinese,https://www.aclweb.org/anthology/P06-1060
"""Neural language correction with character-based attention.""",Supplement,Algorithm,Produce,Neural language correction with character-based attention,https://www.aclweb.org/anthology/D17-1053
"""Enhancing neural language models with knowledge graph for answer generation.""",Supplement,Algorithm,Produce,Enhancing neural language models with knowledge graph for answer generation,https://www.aclweb.org/anthology/D19-1239
"""A task-specific approach for named entity recognition in biomedical text.""",Supplement,Algorithm,Produce,A task-specific approach for named entity recognition in biomedical text,https://www.aclweb.org/anthology/D10-1109
"""Recurrent neural network grammars.""",Supplement,Algorithm,Produce,Recurrent neural network grammars,https://www.aclweb.org/anthology/P16-2009
"""Neural models for keyphrase extraction and question generation.""",Supplement,Algorithm,Produce,Neural models for keyphrase extraction and question generation,https://www.aclweb.org/anthology/D17-1069
"""A neural network approach to context-sensitive generation of conversational responses.""",Supplement,Algorithm,Produce,A neural network approach to context-sensitive generation of conversational responses,https://www.aclweb.org/anthology/N15-1156
"""Joint entity and relation extraction with iterative reinforcement learning.""",Supplement,Algorithm,Produce,Joint entity and relation extraction with iterative reinforcement learning,https://www.aclweb.org/anthology/P17-1074
"""Global normalization of convolutional neural networks for joint entity and relation classification.""",Supplement,Algorithm,Produce,Global normalization of convolutional neural networks for joint entity and relation classification,https://www.aclweb.org/anthology/D15-1207
"""Efficient convolutional neural networks for document classification.""",Supplement,Algorithm,Produce,Efficient convolutional neural networks for document classification,https://www.aclweb.org/anthology/D15-1162
"""Neural variational inference for text processing.""",Supplement,Algorithm,Produce,Neural variational inference for text processing,https://www.aclweb.org/anthology/P15-1038
"""Adversarial training methods for semi-supervised text classification.""",Supplement,Algorithm,Produce,Adversarial training methods for semi-supervised text classification,https://www.aclweb.org/anthology/P17-1110
"""Neural network models for paraphrase identification, semantic textual similarity, natural language inference, and question answering.""",Supplement,Algorithm,Introduce,"Neural network models for paraphrase identification, semantic textual similarity, natural language inference, and question answering",https://www.aclweb.org/anthology/P15-2124
"""Improving neural named entity recognition with gazetteers.""",Supplement,Algorithm,Introduce,Improving neural named entity recognition with gazetteers,https://www.aclweb.org/anthology/D17-1038
"""Enhanced LSTM for natural language inference.""",Supplement,Algorithm,Introduce,Enhanced LSTM for natural language inference,https://www.aclweb.org/anthology/P17-1152
"""Graph convolutional encoders for syntax-aware neural machine translation.""",Supplement,Algorithm,Introduce,Graph convolutional encoders for syntax-aware neural machine translation,https://www.aclweb.org/anthology/P18-1014
"""Memory-enhanced decoder for neural machine translation.""",Supplement,Algorithm,Introduce,Memory-enhanced decoder for neural machine translation,https://www.aclweb.org/anthology/P18-2059
"""Automatic rule extraction from long short-term memory networks.""",Supplement,Algorithm,Introduce,Automatic rule extraction from long short-term memory networks,https://www.aclweb.org/anthology/P16-1145
"""Joint sentiment/topic model for sentiment analysis.""",Supplement,Algorithm,Introduce,Joint sentiment/topic model for sentiment analysis,https://www.aclweb.org/anthology/P10-1149
"""Distributed representations of words and phrases and their compositionality.""",Supplement,Algorithm,Introduce,Distributed representations of words and phrases and their compositionality,https://www.aclweb.org/anthology/N13-1090
"""Neural language modeling by jointly learning syntax and lexicon.""",Supplement,Algorithm,Introduce,Neural language modeling by jointly learning syntax and lexicon,https://www.aclweb.org/anthology/P13-1117
"""Phrase-based statistical machine translation.""",Supplement,Algorithm,Introduce,Phrase-based statistical machine translation,https://www.aclweb.org/anthology/P03-1021
"""Unsupervised discovery of word categories.""",Supplement,Algorithm,Introduce,Unsupervised discovery of word categories,https://www.aclweb.org/anthology/P09-1093
"""Learning semantic representations of objects and verbs from language descriptions.""",Supplement,Algorithm,Introduce,Learning semantic representations of objects and verbs from language descriptions,https://www.aclweb.org/anthology/P11-1020
"""Multilingual training of crosslingual neural parsers.""",Supplement,Algorithm,Introduce,Multilingual training of crosslingual neural parsers,https://www.aclweb.org/anthology/P16-1101
"""Efficient inference and learning in a large knowledge base: Reasoning with extracted information using probabilistic soft logic.""",Supplement,Algorithm,Introduce,Efficient inference and learning in a large knowledge base: Reasoning with extracted information using probabilistic soft logic,https://www.aclweb.org/anthology/D12-1110
"""Hybrid language models for domain-specific entity extraction from web text.""",Supplement,Algorithm,Introduce,Hybrid language models for domain-specific entity extraction from web text,https://www.aclweb.org/anthology/P13-2131
"""A transition-based parser for Chinese.""",Supplement,Algorithm,Introduce,A transition-based parser for Chinese,https://www.aclweb.org/anthology/P06-1134
"""One billion word benchmark for measuring progress in statistical language modeling.""",Supplement,Algorithm,Introduce,One billion word benchmark for measuring progress in statistical language modeling,https://www.aclweb.org/anthology/P16-1162
"""Distributed representations of sentences and documents.""",Supplement,Algorithm,Introduce,Distributed representations of sentences and documents,https://www.aclweb.org/anthology/D14-1162
"""A fast and accurate dependency parser using neural networks.""",Supplement,Algorithm,Introduce,A fast and accurate dependency parser using neural networks,https://www.aclweb.org/anthology/P14-2013
"""Named entity recognition with bidirectional LSTM-CNNs.""",Supplement,Algorithm,Introduce,Named entity recognition with bidirectional LSTM-CNNs,https://www.aclweb.org/anthology/P16-1101
